performance	638
results	138
quality	126
accuracy	124
training data	123
state-of-the-art performance	113
features	105
state-of-the-art results	105
data	99
number	76
better performance	72
information	69
robustness	69
experimental results	68
superior performance	63
promising results	60
parameters	57
output	56
complexity	51
superiority	51
competitive results	50
effectiveness	48
high accuracy	47
competitive performance	47
training time	45
efficiency	45
input	44
structure	43
good performance	42
knowledge	41
gap	39
answer	39
large number	38
best results	38
context	37
translation quality	37
classification accuracy	37
distribution	36
significant improvements	36
question	34
model performance	33
representation	33
size	32
large margin	32
better results	32
prior knowledge	31
labeled data	30
comparable performance	29
difference	29
predictions	29
contextual information	28
unlabeled data	28
similarity	28
distance	28
level	27
image	27
search space	27
comparable results	27
higher accuracy	27
large amounts	27
word embeddings	26
weights	26
representations	26
characteristics	26
correlation	26
uncertainty	25
semantic information	25
best performance	25
test time	25
high performance	25
time	24
input data	24
outputs	24
small number	24
loss function	24
relation	24
relationships	24
new state-of-the-art results	24
differences	23
meaning	23
properties	23
constraints	23
relations	23
limitations	23
real-time	23
promising performance	22
word	22
performances	22
state of the art results	22
computational cost	22
labels	22
improved performance	21
strong baselines	21
state - of - the - art performance	21
noise	21
generalization ability	21
recognition accuracy	21
diversity	20
visual features	20
cost	20
difficulty	20
baselines	20
classification performance	20
F1 score	20
content	20
model parameters	20
robust	20
inference time	19
metrics	19
bias	19
advantages	19
prediction	19
good results	19
computational complexity	19
entity types	19
ground truth	18
training examples	18
loss	18
synthetic data	18
computational efficiency	17
global information	17
extracted features	17
impressive performance	17
baseline	17
excellent performance	17
errors	17
mutual information	17
annotated data	17
target domain	17
domain knowledge	17
different scales	17
model size	16
significant margin	16
objective function	16
probability	16
syntactic information	16
semantics	16
loss functions	16
trade-off	15
embedding space	15
state - of - the - art results	15
words	15
task	15
test data	15
feature	15
structural information	15
prediction accuracy	15
relevant information	15
contribution	15
relationship	15
large amount	15
latent space	14
overall performance	14
challenges	14
state-of-the-art	14
label	14
new state-of-the-art performance	14
NER performance	14
importance	14
real data	14
image features	14
time series	14
data distribution	13
adversarial examples	13
semantic relations	13
relevance	13
graph structure	13
capacity	13
policy	13
model accuracy	13
factors	13
ability	13
speed	13
visual information	13
domain gap	13
examples	13
state	13
state-of-the-art performances	13
dependencies	13
model robustness	13
answers	13
POS tags	12
biases	12
number of parameters	12
different levels	12
consistency	12
theoretical results	12
given question	12
candidate answers	12
empirical results	12
state of the art	12
improvements	12
error	12
measure	12
score	12
power	12
image quality	12
inputs	12
aspect	12
degree	12
annotations	12
behavior	12
target data	12
embeddings	12
excellent results	12
observations	12
precision	12
correct answer	11
result	11
high quality	11
better accuracy	11
convergence speed	11
topology	11
potential	11
poor performance	11
code	11
sentence embeddings	11
validity	11
sentence	11
system performance	11
point	11
different modalities	11
raw data	11
condition	11
benefits	11
time-consuming	11
information loss	11
complementary information	11
similarities	11
open-sourced	11
data privacy	11
class	11
vector representations	11
instability	11
aspects	11
model's performance	11
state-of-the-art accuracy	11
pseudo labels	10
word representations	10
spatial information	10
gains	10
handcrafted features	10
strong performance	10
node embeddings	10
temporal information	10
detection accuracy	10
real time	10
requirements	10
improved results	10
additional information	10
heterogeneity	10
ambiguity	10
performance improvements	10
input image	10
order	10
outcome	10
significant improvement	10
private data	10
relevant features	10
similar performance	10
time series data	10
performance degradation	10
parallel data	10
accurate	10
human performance	10
high cost	10
property	10
variance	10
frame	10
sentiment	10
generalization capability	10
pattern	10
monotonicity constraint	9
reward function	9
correlations	9
translation performance	9
large number of parameters	9
long-range dependencies	9
network parameters	9
risk	9
good accuracy	9
large datasets	9
input images	9
improvement	9
amount of data	9
cosine similarity	9
impressive results	9
premise	9
fewer parameters	9
sentiment polarity	9
sparsity	9
local features	9
coverage	9
sample efficiency	9
contributions	9
strength	9
tasks	9
end-to-end	9
predictive performance	9
memory footprint	9
context information	9
baseline results	9
function	9
images	9
significant gains	9
Knowledge Graphs (KG)	9
topological features	9
additional features	9
hyper-parameters	9
missing values	9
weak supervision	9
class labels	9
query	9
discriminative features	9
significant performance gains	9
input text	9
computationally expensive	9
useful information	9
source code	9
location	9
augmented data	9
large poses	8
current state	8
attributes	8
new data	8
limited data	8
new tasks	8
noisy labels	8
remarkable results	8
node features	8
remarkable performance	8
weaknesses	8
EEG data	8
hand-crafted features	8
action space	8
length	8
discrepancy	8
linguistic features	8
evaluation metrics	8
scores	8
observation	8
training objective	8
capabilities	8
state of the art performance	8
probabilities	8
name	8
model capacity	8
much faster	8
redundant information	8
position	8
error rate	8
discourse structure	8
search efficiency	8
feature space	8
Cartesian product	8
50%	8
metric	8
input features	8
soft labels	8
constraint	8
high-quality	8
sub-optimal	8
highest performance	8
additional data	8
loss of accuracy	8
time step	8
stability	8
findings	8
global model	8
textual descriptions	8
evaluation results	8
rate	8
mapping	8
feature representations	8
high efficiency	8
model complexity	8
imbalanced data	8
relative pose	8
performance improvement	8
ground-truth	8
highest accuracy	8
visual content	8
effectiveness and efficiency	8
reliability	8
limited training data	8
latent variables	7
balance	7
gender bias	7
future frames	7
high variance	7
batch size	7
samples	7
flexibility	7
side information	7
dimensionality	7
convergence rate	7
effects	7
limited resources	7
performance gap	7
Euclidean distance	7
semantic space	7
latent representation	7
correct answers	7
EEG features	7
energy consumption	7
code and data	7
word level	7
multiple times	7
commonsense knowledge	7
ones	7
sentence boundaries	7
unseen data	7
semantic similarity	7
space	7
variations	7
NP-hard	7
preliminary results	7
patterns	7
hierarchical structure	7
word boundaries	7
type	7
significant performance improvements	7
training samples	7
large scale	7
semantic roles	7
sense	7
shape	7
Knowledge Graphs (KGs)	7
data point	7
binary features	7
amount	7
bottleneck	7
user experience	7
comparable accuracy	7
BLEU scores	7
parameter space	7
different views	7
various aspects	7
class label	7
modalities	7
translation accuracy	7
memory consumption	7
domain shift	7
external knowledge	7
training efficiency	7
computation	7
solution	7
factual information	7
layers	7
KG	7
contextual embeddings	7
empirical evidence	7
inductive bias	7
learned knowledge	7
strengths	7
linguistic information	7
theoretical analysis	7
label information	6
low cost	6
encouraging results	6
mismatch	6
objective	6
response	6
significant results	6
optimal policy	6
word features	6
significant margins	6
classification results	6
increased performance	6
higher efficiency	6
gradient	6
latent representations	6
short time	6
word sense	6
limited number	6
computation time	6
rich information	6
generalization performance	6
dynamics	6
high dimensionality	6
facial expressions	6
final performance	6
recognition performance	6
missing data	6
safety	6
shared parameters	6
attention weights	6
open-source	6
1st place	6
historical data	6
feature representation	6
early stage	6
gradients	6
large circular kernels	6
lack of data	6
redundancy	6
high number	6
Bidirectional Encoder Representations	6
relative importance	6
3D pose	6
one image	6
ranking	6
correctness	6
selected features	6
modality	6
different aspects	6
learned features	6
directions	6
label noise	6
multiple facts	6
reward	6
top-1 accuracy	6
two sentences	6
data imbalance	6
category	6
success rate	6
problems	6
instance	6
individual features	6
human ranking	6
relative compositionality	6
contexts	6
training and test data	6
regular expressions	6
concept	6
terms	6
higher performance	6
unseen classes	6
local structure	6
original data	6
sensitivity	6
significantly better	6
types	6
pixel	6
class imbalance	6
identity	6
global context	6
step	6
accuracy and efficiency	6
optimal policies	6
iteration	6
accurate results	6
scalability	6
Answering (VQA)	6
outstanding results	6
little data	6
success	6
reconstruction accuracy	6
contrastive loss	6
performance gain	6
high computational cost	6
segmentation accuracy	6
likelihood	6
data scarcity	6
detection performance	6
search cost	6
labeled training data	6
local data	6
one language	6
data sparsity	6
optimal architecture	6
global features	6
user intents	5
depth	5
topic	5
local information	5
details	5
synthetic and real data	5
valuable information	5
task performance	5
two modalities	5
measures	5
dataset bias	5
communication cost	5
architecture	5
mitotic count	5
human knowledge	5
spatial resolution	5
labelled data	5
future	5
image data	5
length constraints	5
hidden states	5
second-order information	5
strengths and weaknesses	5
target distribution	5
dialogue context	5
spatial context	5
word error rate	5
Wasserstein distance	5
efficacy	5
variability	5
high-dimensional data	5
low-level features	5
prediction performance	5
translation directions	5
Word Embeddings	5
obtained results	5
spatial features	5
small amounts	5
confidence scores	5
low computational cost	5
communication efficiency	5
EEG signals	5
priori knowledge	5
sequential data	5
questions	5
segmentation results	5
feature maps	5
one of them	5
available data	5
structured data	5
low resolution	5
probability distributions	5
adversarial robustness	5
local context	5
generalizability	5
confidence score	5
additional training data	5
satisfactory performance	5
multi-scale information	5
perceptual loss	5
GCN	5
instance level	5
''}	5
vulnerability	5
sample-efficient	5
average score	5
computational resources	5
perceptual quality	5
states	5
image-level labels	5
syntactic structure	5
source sentence	5
low-resource settings	5
wide range	5
textual data	5
several metrics	5
substantial improvements	5
final prediction	5
2nd place	5
publicly available	5
bottlenecks	5
limited size	5
suboptimal performance	5
new state - of - the - art results	5
consistent improvements	5
strong results	5
temporal relations	5
description	5
noisy conditions	5
textual information	5
low-resolution images	5
significant performance	5
orders of magnitude faster	5
problem	5
best accuracy	5
extent	5
shortcomings	5
word senses	5
similarities and differences	5
four languages	5
strong correlation	5
matrices	5
number of classes	5
feature distributions	5
global optimum	5
values	5
rules	5
solution space	5
capability	5
bounding box	5
video	5
domain discrepancy	5
prediction results	5
deep features	5
less training data	5
distinction	5
them	5
strong baseline	5
posterior distribution	5
facial features	5
assumption	5
translation results	5
semantic relationships	5
vector space	5
conditions	5
overall accuracy	5
fine-grained	5
significantly faster	5
visual quality	5
cues	5
node	5
semantic attributes	5
accurate predictions	5
general knowledge	5
given image	5
relatedness	5
temporal context	5
weak labels	5
possible spans	5
structured information	5
inference speed	5
statistical properties	5
labeled examples	5
few	5
robust performance	5
noisy data	5
dialogue history	5
generated questions	5
data representation	5
inference latency	5
BLEU score	5
components	5
sentence level	5
order of magnitude	5
high recall	5
meaningful representations	5
discriminative ability	5
new state of the art	5
gate parameters	4
attentional state	4
query terms	4
source domain	4
given task	4
unknown emotion	4
hand-engineered features	4
single-cell data	4
barriers	4
pose	4
multiple scales	4
sampling distribution	4
MSE	4
queries	4
training cost	4
lower bound	4
popularity bias	4
node representations	4
unsatisfactory results	4
edge weights	4
levels	4
uncertain knowledge	4
novel relations	4
persistence diagrams	4
terminal rewards	4
shapes	4
abstract concepts	4
low recall	4
structure information	4
gloss	4
FI names	4
GPR data	4
inter-annotator agreement	4
nested structure	4
reasonable accuracy	4
geometry	4
similarity scores	4
huge number	4
human judgements	4
outstanding performance	4
training loss	4
relation types	4
best baseline	4
triplet loss	4
two images	4
estimates	4
temporal consistency	4
seizure type	4
geodesic distance	4
proximity pattern	4
SOTA results	4
poor generalization	4
large amounts of data	4
global view	4
evidence	4
false positives	4
real-world problems	4
high computation cost	4
class information	4
model uncertainty	4
region proposals	4
classification performances	4
optimal performance	4
model behavior	4
overestimation bias	4
competitive baselines	4
smoothness	4
confidence	4
simplicity	4
different classes	4
dynamic range	4
closed form	4
attack types	4
two or more	4
graph topology	4
80%	4
key features	4
decision	4
evaluation metric	4
final result	4
resource constraints	4
theoretical guarantees	4
text data	4
inherent structure	4
learning performance	4
network structure	4
given text	4
20%	4
representation space	4
super-resolution	4
quantization error	4
final accuracy	4
Zen-Score	4
word representation	4
acoustic features	4
travel time	4
theoretical findings	4
trajectory	4
original image	4
limited labeled data	4
data efficiency	4
similarity measure	4
model structure	4
sparse data	4
reconstruction quality	4
mild conditions	4
ASR errors	4
adjacency matrix	4
relative position information	4
sequential information	4
value function	4
suboptimal policies	4
top performance	4
higher scores	4
target one	4
solutions	4
decision boundary	4
correspondence	4
private information	4
time-series data	4
availability	4
BERT embeddings	4
computational time	4
terms of accuracy	4
inherent uncertainty	4
two aspects	4
network evaluation cost	4
high dimensions	4
several factors	4
consistent gains	4
edge features	4
sample size	4
classification accuracies	4
goal	4
user privacy	4
FCN s	4
several aspects	4
target sequence	4
labelled training data	4
parameter	4
LLM	4
inconsistency	4
quadratic time	4
motion information	4
conversational history	4
three classes	4
texture details	4
network architecture	4
additional supervision	4
single image	4
factor	4
rewards	4
large numbers	4
behaviors	4
inference efficiency	4
factual knowledge	4
overhead	4
technical details	4
losses	4
superior results	4
Semantic Similarity	4
structures	4
whole slide images	4
comparable result	4
static attention	4
audio features	4
covariance	4
Gaussian distributions	4
architecture parameters	4
meta-features	4
small amount	4
supervision signal	4
several strong baselines	4
long range dependencies	4
issues	4
tagging accuracy	4
human behavior	4
low latency	4
spans	4
input sequences	4
accurate performance	4
variety of tasks	4
vector representation	4
logical relationship	4
adversarial inputs	4
inductive biases	4
limited capacity	4
semantic relationship	4
domain information	4
many	4
human effort	4
dimensions	4
large proportion	4
limited time	4
WSD accuracy	4
previous state-of-the-art results	4
increasing number	4
long-distance dependencies	4
recall	4
part	4
high precision	4
word order	4
proper names	4
topic information	4
criteria	4
previously reported results	4
empirical data	4
fine details	4
run-time	4
lexical information	4
subtask	4
human judgments	4
downstream performance	4
two metrics	4
statistics	4
syntactic patterns	4
density	4
future directions	4
index size	4
meanings	4
priori	4
syntactic features	4
trainable parameters	4
ranks	4
low accuracy	4
NP-complete	4
high reliability	4
F-score	4
text	4
limits	4
referring expressions	4
lexical features	4
power consumption	4
input sentence	4
better robustness	4
evaluation measures	4
weight	4
significance	4
input sequence	4
external data	4
intensity	4
large amounts of training data	4
appearance	4
points	4
two	4
generalization	4
functions	4
reconstruction error	4
better representations	4
significant performance drop	4
downstream task	4
merits	4
optimal solutions	4
bounds	4
three factors	4
high detection rate	4
previous tasks	4
collaborative fairness	4
dependency	4
different distributions	4
data distributions	4
computationally efficient	4
measurements	4
text description	4
three aspects	4
fraction	4
multimodal features	4
model quality	4
original training data	4
probability distribution	4
great progress	4
high resolution	4
format	4
wide margin	4
various levels	4
memory usage	4
Stiefel manifold	4
chance level	4
target sentence	4
user interaction data	4
reasonable performance	4
sample complexity	4
real-world data	4
latent factors	4
95% accuracy	4
similar representations	4
semantically similar	4
auxiliary information	4
manual annotations	4
classes	4
significant accuracy loss	4
scarcity	4
data heterogeneity	4
nodes	4
efficiency and effectiveness	4
order of magnitude faster	4
time complexity	4
weakness	4
times	4
relation type	4
character	4
user behavior	4
submission	4
object boundaries	4
video frames	4
discourse relations	4
divergence	4
texture	4
privacy concerns	4
different frames	4
every frame	4
summary	4
generalization capabilities	4
zero-shot	4
sub-optimal solutions	4
privacy	4
better representation	4
semantic labels	4
bounding box annotations	4
source data	4
domain mismatch	4
high performances	4
multiple granularities	4
hyperparameters	4
knowledge graphs	4
promising performances	4
positive and negative examples	4
product descriptions	4
Experimental results	4
voltage	3
breast cancer phenotypes	3
regularized loss function	3
Margin	3
spatiotemporal space	3
initial proposal	3
subcategorization cues	3
target vocabulary	3
sufficient conditions	3
object pose	3
object proposals	3
request	3
global optimality	3
semi-Riemannian space	3
quantitative satisfaction	3
contextual knowledge	3
localization accuracy	3
ranking information	3
illumination	3
pairwise data	3
temporal relationships	3
complementary strengths	3
classifier discrepancy	3
temporal smoothness	3
latency	3
reference video	3
noisy images	3
KG subgraph	3
PASCAL VOC	3
end - to - end	3
new class	3
class embeddings	3
visual data	3
exposure bias	3
transfer performance	3
amount of training data	3
standard benchmarks	3
new predicates	3
target task	3
bilevel optimization problems	3
causal relations	3
long-distance node relations	3
word vectors	3
global knowledge	3
correct meaning	3
illumination changes	3
dependency context	3
behavioural patterns	3
pseudo points	3
game context	3
temporal structure	3
different dynamics	3
statistical heterogeneity	3
1%	3
uniqueness	3
conversation context	3
global variables	3
correlated equilibrium	3
creative ability	3
low level style features	3
main characteristics	3
uncertainty estimates	3
accuracies	3
highly correlated	3
keywords	3
user preferences	3
underlying structure	3
easy to difficult instances	3
knowledge estimates	3
model{'}s prediction confidence	3
pose information	3
every time step	3
different nature	3
dense labels	3
relative depth	3
frequent words	3
entropy	3
spectral density	3
background noise	3
generalization guarantees	3
important features	3
first-order proximity	3
interpretability	3
best solution	3
argument	3
orthographic features	3
number of features	3
supervised training data	3
visual appearance	3
individual knowledge	3
2EXPTIME-complete	3
cross-validated errors	3
different levels of abstraction	3
$\epsilon$-stationary solution	3
large volumes	3
distributed representations	3
fast	3
visual context	3
story	3
arbitrary number	3
comparable quality	3
analytical expression	3
real world data	3
relation facts	3
sound quality	3
different perspectives	3
spatial relations	3
single sample	3
joint error	3
better result	3
Riemannian manifolds	3
convolutional features	3
throughput	3
compression objective	3
gold standard	3
entity	3
comparison	3
unsatisfactory performance	3
pixel values	3
person	3
sizes	3
current frame	3
control	3
corpus data	3
tensor	3
learned policy	3
estimate	3
naturalness	3
spurious correlations	3
final output	3
different objective functions	3
prediction consistency	3
variables	3
region size	3
relative performance	3
world knowledge	3
centrality measures	3
three	3
wealth of information	3
novel intents	3
boundary information	3
training schedule	3
form	3
semantic structures	3
false negatives	3
unique properties	3
latent relations	3
Visual Question Answering (VQA)	3
temporal correlation	3
similarity score	3
three tasks	3
inner interactions	3
anomalies	3
semantic context	3
large domain gap	3
intents	3
entity embeddings	3
actual human rating standards	3
trend	3
fully differentiable	3
different degrees	3
significantly improved performance	3
state-of-the-artresults	3
event mentions	3
test-time	3
robust features	3
Gaussian distribution	3
prediction quality	3
complex	3
gender	3
joint probability	3
similarity measures	3
Semantic Textual Similarity	3
background clutter	3
content information	3
attention	3
expert evaluations	3
approx.	3
unique characteristics	3
semantic constraints	3
missing information	3
variable structure	3
color	3
answerable ones	3
high-resolution representations	3
word information	3
shared task	3
labeled source data	3
local minima	3
raw images	3
text input	3
domain labels	3
less data	3
initial weights	3
good features	3
upper bound	3
target	3
complex logic	3
limited context	3
vocabulary size	3
different conditions	3
NER labels	3
model performances	3
Wikipedia link structure	3
different tasks	3
Named Entity Recognition (NER )	3
rich morphology	3
morphological information	3
intermediate features	3
input tokens	3
new metric	3
OSR annotations	3
estimation	3
low memory footprint	3
considerable improvement	3
deficiency	3
model's accuracy	3
graph data	3
paired data	3
fused features	3
efficiency and accuracy	3
internal states	3
prediction errors	3
feature map	3
Olarge-scale	3
Ofirst-order	3
high-order	3
inter-object relations	3
teacher knowledge	3
retrieval accuracy	3
margin	3
instance-level correspondences	3
observation function	3
prominent features	3
word-level	3
three levels	3
two levels	3
maximum	3
full-precision counterparts	3
routing congestion	3
on-par	3
associated sentiment	3
quantization depth	3
real-time data	3
intent	3
personal information	3
sample efficient	3
point of view	3
state estimation	3
aspect terms	3
privileged information	3
given context	3
every time	3
3D poses	3
translated images	3
spatial contents	3
expressivity	3
current state-of-the-art	3
different properties	3
current question	3
accurately	3
global contextual information	3
F1 points	3
slot values	3
data points	3
small scale	3
visual concepts	3
various scales	3
attention map	3
much lower	3
weights and activations	3
90%	3
personal identity information	3
security issues	3
vector	3
low computation cost	3
high-dimensional observations	3
precision and recall	3
predictive power	3
heart rate	3
search bias	3
new lower bounds	3
3rd place	3
spatio-temporal information	3
significant performance gain	3
inter-expert variability	3
training speed	3
stable	3
ordinal nature	3
sequences	3
true positives	3
threshold	3
pixel level	3
``}	3
several features	3
continuous space	3
abundance	3
half	3
matrix	3
prior information	3
speech quality	3
near-optimal performance	3
high frequency information	3
real-world settings	3
-of-the-art results	3
extra supervision	3
3%	3
wind speed	3
image resolution	3
curse of dimensionality	3
low performance	3
target model	3
generalization error	3
effective information	3
perspective	3
opinions	3
valid answer	3
computational burden	3
local gradients	3
communication overhead	3
translation errors	3
signals	3
training images	3
large size	3
offensive language	3
spectral features	3
third	3
word embedding	3
feature vector	3
Top-1 accuracy	3
given topic	3
input information	3
auxiliary loss	3
popularity	3
summaries	3
high-level semantics	3
given pair	3
semantic descriptions	3
extra information	3
data sparsity problem	3
state-of-the-art result	3
dimension	3
cognitive features	3
high classification performance	3
non-linearity	3
higher quality	3
benefits and drawbacks	3
edge information	3
external information	3
false alarms	3
lexical overlap	3
theoretical understanding	3
trajectories	3
missing details	3
$T$	3
one	3
individual predictions	3
scarce training data	3
online data	3
spatial distribution	3
number of tasks	3
large extent	3
natural images	3
compressed representation	3
ground-truth labels	3
LB Keogh	3
different structures	3
intra-class variations	3
indicator	3
benchmark	3
model structures	3
domain-specific features	3
short texts	3
good performances	3
fairness	3
similar distribution	3
great performance	3
sentence representations	3
stable performance	3
lack	3
computational costs	3
reward functions	3
consistency loss	3
trace	3
large amount of information	3
new task	3
model architecture	3
motion features	3
SSIM	3
given time	3
sensor data	3
behaviour	3
cost function	3
$\epsilon$-stationary point	3
message	3
state-of-art performance	3
SOTA performance	3
contextual features	3
easy examples	3
missing views	3
large amount of labeled data	3
prompt	3
BN statistics	3
additional input	3
video data	3
compression ratio	3
token level	3
clean data	3
multi-scale features	3
increased complexity	3
dialog history	3
image content	3
validation data	3
candidate relations	3
emotional state	3
nearly optimal number	3
low-rank matrix	3
accuracy and robustness	3
skeleton data	3
different characteristics	3
volume	3
consecutive hidden states	3
recommendation performance	3
multiple layers	3
KL divergence	3
correct sense	3
new classes	3
Q-values	3
learned weights	3
inference-time	3
degradation	3
multimodal data	3
minority class	3
given search space	3
{``}	3
different question types	3
abstraction	3
recognition errors	3
large variation	3
prior distribution	3
multiple objectives	3
$N$	3
MFCC features	3
appropriate features	3
two parts	3
timeline	3
desirable properties	3
sample	3
lower quality	3
semantic relation	3
loss in performance	3
long-distance relationships	3
frequencies	3
global structure	3
execution time	3
Classification performance	3
attention scores	3
improved accuracy	3
important aspects	3
hand - crafted features	3
polarity	3
large quantity	3
detailed information	3
dot product	3
crucial information	3
sentiment polarities	3
two stages	3
baseline methods	3
surface forms	3
small portion	3
rapid progress	3
similar number of parameters	3
final answer	3
exact match	3
best result	3
sequence	3
candidate answer	3
sparse	3
instances	3
best published results	3
human parity	3
graph representation	3
semantic representations	3
many features	3
arbitrary length	3
1000	3
long term dependencies	3
informative features	3
encoder	3
one sentence	3
user requirements	3
information need	3
style	3
statistical information	3
different features	3
source language	3
language similarity	3
large quantities	3
complex tasks	3
limited capabilities	3
proxy	3
data quality	3
three dimensions	3
dependency relations	3
final segmentation	3
dependency information	3
feature structures	3
different viewpoints	3
novel features	3
language	3
language independent	3
noise levels	3
temporal dependencies	3
graph structures	3
opinion	3
input embeddings	3
better predictions	3
tendency	3
global constraints	3
original query	3
word error rates	3
discriminative information	3
node attributes	3
substantial gains	3
dependency structure	3
linear speedup	3
lexical semantics	3
occurrences	3
true performance	3
retrieval performance	3
amount of information	3
discrepancies	3
systematic differences	3
frequency	3
single word	3
user satisfaction	3
facial expression representation	3
translation rules	3
useful features	3
word matches	3
semantic equivalence	3
number of factors	3
linguistic knowledge	3
polynomial time	3
types of features	3
semantic features	3
n-best hypotheses	3
syntactic structures	3
10 %	3
structured representations	3
information needs	3
segment length	3
entity information	3
word form	3
implicit relations	3
hierarchical structures	3
M-BERT	3
lexical ambiguity	3
paragraph	3
prohibitively expensive	3
output quality	3
significantly better results	3
models	3
memory constraints	3
local smoothness	3
convergence guarantees	3
positions	3
high robustness	3
tokens	3
nested labels	3
character level	3
equivalence	3
semantic distance	3
human pose	3
relative positions	3
spatial relationships	3
correspondences	3
accuracy rate	3
pairwise constraints	3
partition	3
high computation complexity	3
network traffic	3
class representatives	3
sensitive attribute	3
high-quality pseudo labels	3
negative transfer	3
$n$	3
best one	3
several dimensions	3
query image	3
distributions	3
completeness	3
relational knowledge	3
LM	3
limited amount	3
complexities	3
higher performances	3
visual cues	3
computational budget	3
partially observable	3
quantized models	3
multiple views	3
decisions	3
responses	3
user attributes	3
discretization	3
Gaussian Processes (GPs)	3
distances	3
entity mentions	3
better scores	3
state-of-the-artperformance	3
domain-specific information	3
human judgment	3
potential biases	3
contextualized embeddings	3
test image	3
textual description	3
new knowledge	3
visual image quality	3
angle	3
grammatical errors	3
discriminator	3
generated images	3
in-degree	3
feature vectors	3
reward signal	3
validation accuracies	3
specific problem	3
latent features	3
corresponding entity	3
runtime	3
collision-free paths	3
human-aware constraints	3
contextualized word embeddings	3
large improvements	3
goodness	3
training epochs	3
Traveling Salesman Problem (TSP)	3
mentions	3
quantization errors	3
model assumptions	3
strong assumptions	3
face images	3
human responses	3
metric space	3
non-Euclidean data	3
3D shapes	3
low resource settings	3
resource intensive	3
40%	3
human annotation	3
source	3
traditional features	3
specific properties	3
specific challenges	3
good generalizability	3
computation cost	3
domains	3
disparity	3
quantitatively and qualitatively	3
poses	3
bilingual word embeddings	3
several baselines	3
consistent improvement	3
FLOPs	3
performance gains	3
significant performance improvement	3
existing data	3
text genre	3
intra-domain gap	3
large amount of data	3
scale	3
previous frames	3
NER results	3
limited coverage	3
10% improvement	3
noisy pseudo-labels	3
word frequency	3
n-grams	3
structural differences	3
user queries	3
ST task	3
Knowledge Graphs (KGQA)	3
60%	3
amount of effort	3
computationally inefficient	3
higher classification accuracy	3
great results	3
learning rate	3
different sizes	3
ReLU activations	3
explicit knowledge	3
popular benchmarks	3
structural properties	3
KG embeddings	3
false information	3
interpretable results	3
mild assumptions	3
better generalization performance	3
user information	3
model weights	3
experiment results	3
resource consumption	3
limitation	3
token	3
learned metric	3
input space	3
empirical observations	3
similar accuracy	3
visual similarity	3
gold data	3
best reported results	3
deep representations	3
automatic features	2
stationary points	2
optimality gap	2
additional knowledge	2
abstract meanings	2
label hierarchy	2
raw EEG features	2
high-quality images	2
forecasting performance	2
reference point	2
shorter bit-width	2
architecture hyper-parameters	2
optimized feature space	2
clinical texts	2
CP Pair	2
object information	2
$\mu$	2
sum	2
positive LIGAS	2
piecewise strongly convex	2
future learning tasks	2
rich global context information	2
normalized Laplacian	2
spatio-temporal trade-off	2
posterior over hyperparameters	2
local and global features	2
predicted poses	2
stochasticity	2
source modal sequence	2
embedding size	2
target semantics	2
time frames	2
PPG objective	2
anchor knowledge	2
fundamental limitations	2
TEG characteristics	2
computationally cheaper	2
total energy of each gap	2
submissions	2
spatial coherence	2
wall-clock training time	2
good prediction accuracy	2
test runtime	2
local and long-range contextual information	2
clustering performance	2
feature embeddings	2
full SLAM	2
number of target variables	2
$ii$)	2
local maxima	2
good data representations	2
symmetry	2
inadequate training problem	2
spatial dimension	2
human-level performance	2
time steps	2
over-parameterization	2
label and direction	2
inference information	2
entity level, sentence level and document level	2
AE space	2
bandwidth consumption	2
instance-level	2
quantitative and qualitative evaluations	2
negatively correlated	2
search experience	2
global coherence	2
initial proposals	2
entity type	2
soft-DTW	2
BERT vectors	2
classic features	2
posterior estimates	2
training nor labels	2
downstream tasks	2
abstract state	2
theclassification performance	2
covariance information	2
syntactic roles	2
language definition	2
different types of knowledge	2
associative similarity	2
taxonomic similarity	2
correlation measure	2
pos tag ambiguity	2
manually sense-tagged data	2
minimal overhead	2
neighborhood contribution representation	2
unobserved, normally distributed hidden variables	2
observed variables	2
temporal expressions	2
summarization quality	2
shortest path	2
one or more	2
discourse connectives	2
characterization	2
utterances	2
specific knowledge	2
text descriptions	2
conjugate priors	2
index	2
object shape	2
frequency components	2
free word order	2
generalized translation knowledge	2
practical considerations	2
correct parse	2
system output	2
input question	2
local range	2
anaphoric relations	2
relevant times	2
lexical-cohesion and conversational features	2
subtopic boundaries	2
information about meeting context	2
word co-occurrences	2
geometric context	2
cellular and cell-layer level patterns	2
motion estimation	2
one category	2
object class	2
class structures	2
real image data	2
experience	2
BN model parameters	2
separating hyperplane	2
higher recognition rate	2
global properties	2
intrinsic representation	2
rotation-invariant features	2
tensors	2
line	2
syntactic cues	2
word-sense distinctions	2
high-quality data	2
factual correctness	2
improved language modeling accuracy	2
transformer parameters	2
significantly more knowledge	2
entity signals	2
wSTL formulas	2
one dimension	2
number of layers	2
hard examples	2
previous knowledge	2
low BLEU score	2
better structure	2
translations	2
quality of the features	2
residuals	2
two factors	2
50 million	2
local spatiotemporal contextual feature	2
perplexity	2
high-dimensional outputs	2
best overall performance	2
acoustic similarity	2
boundary knowledge	2
relatively large	2
economic properties	2
key feature	2
similar distributions	2
NP-hard problem	2
sentence meaning	2
sentences	2
best submission	2
adaptability	2
peaky distributions	2
specific task	2
language modeling performance	2
simulation results	2
convergence performance	2
missing entries	2
hidden variables	2
musical style	2
robustness ofVQA models	2
mDWT coefficients	2
selected source data	2
skill context vectors	2
primary actions	2
supporting text	2
ideal multilingual performance	2
dropped pronouns	2
lighting variations	2
labeling rules	2
hyponym word	2
skill vectors	2
expression-shared features	2
expression-specific features	2
salient and discriminative features	2
user interest	2
smart contracts	2
different values	2
current information	2
worst-case risk	2
material names and properties	2
short	2
real time performance	2
conditional probability	2
artifacts	2
NPD features	2
new feature	2
indices	2
canonical positions	2
strong dependencies	2
human biases	2
frequency density	2
aggregate channel features	2
heavy occlusion	2
detection range	2
gap between theory	2
bad saddle points	2
period of time	2
improve performance	2
fully unsupervised	2
anatomical variations	2
exceptionally pose variations	2
facial landmarking and pose estimation	2
limited performance	2
potential dependencies	2
spatially and temporally	2
lifelong tickets	2
image context	2
left to right	2
map	2
real - time speed	2
resemblance	2
video representations	2
span answers	2
freeform answers	2
\textit{ActorQ}	2
accuracy costs	2
passenger intents	2
detection results	2
depth information	2
detection header	2
conjecture	2
contradicting contexts	2
semantic equality	2
2D images	2
various types of noise	2
log-ratio	2
record	2
diagnosis performance	2
specific dimension	2
different dimensions	2
resting state	2
English test data	2
desired properties	2
disease state	2
unit spheres	2
Product Quantization	2
model knowledge	2
high computational costs	2
single vector	2
direct supervision	2
ground motion intensitymeasures	2
novel loss functions	2
reconstructed image	2
facial shape	2
core challenges	2
real documents	2
previous frame	2
link structure	2
quantitative measures	2
number of copies	2
sample of possible fault explanations	2
high costs	2
spatial and temporal information	2
labeled images	2
surprising results	2
grammar	2
Jensen divergence	2
coverage and the performance	2
hidden representation	2
respective context	2
substantial improvement	2
granularity	2
expert labels	2
user-item relationships	2
quantization levels	2
fluent but inadequate translations	2
skeletal information	2
facial expression	2
real-time constraints	2
enough training data	2
target-side sequential dependency	2
little	2
Bregman distance	2
nonsmooth regularization	2
gloss information	2
original gloss	2
lexical knowledge	2
context and glosses	2
glosses ( sense definitions	2
lexical resources	2
massive labeled data ( context )	2
IoU variance	2
intra-class variance	2
interaction labels	2
6D pose	2
synthetically generated data	2
number of different sense tags	2
purely observational data	2
relative camera pose	2
concepts	2
detailed analysis	2
global perspective	2
anatomical information	2
autoregressive counterparts	2
remarkable margin	2
iterations	2
significantly less supervision	2
complex concepts	2
variable ( and possibly large ) sizes	2
' text region embedding + pooling '	2
minimal degradation	2
classification head	2
fairness sensitive information	2
training signal	2
significant performance degradation	2
effectiveness and superiority	2
accurate information	2
successful results	2
OCR results	2
positional context	2
low-level texture features	2
inverse depth	2
various styles	2
20 times	2
best architecture	2
latent frequencies	2
large inter-slice spacing	2
overall scores	2
significant performance boost	2
sensor noise	2
two major features	2
binary codes	2
sequential binary codes	2
A-phases	2
information gain	2
loss perturbation	2
strict computational constraints	2
predicted sequence	2
community correlation	2
top-K retrievals	2
composed feature vectors	2
dissimilar component	2
similar component	2
word vector	2
clues and semantic meanings	2
Lagrange multiplier	2
MT output	2
different states	2
enough information	2
noisy measurements	2
successor feature functions	2
heterogeneous situation	2
new scene configurations	2
domain-specific bias	2
''''''``unspecified''''''''	2
low-dimensional representations	2
answer distribution	2
guarantees	2
number density	2
label complexity	2
individual needs	2
translation words	2
compromise	2
current user{'}s preferences	2
Bayesian nature	2
ASR accuracy	2
unsupervised setting	2
anomalous training images	2
quality of the results	2
physician impression	2
duration	2
time-to-accuracy performance	2
expensive annotation costs	2
speed and accuracy	2
finest level	2
output logits	2
accuracy higher	2
new state of the art results	2
matter of seconds	2
top-k retrieval results	2
past data	2
past knowledge	2
Gaussian Processes	2
appearance information	2
correct translations	2
unlabeled target data	2
inducing points locations	2
inducing points	2
original distribution	2
causes	2
tolerance	2
specific patterns	2
given test data	2
0.69 (best run)	2
posttest	2
ranking performance	2
incomplete KGs	2
spatial locations	2
geometry attributes	2
high prediction accuracy	2
latent information	2
priority	2
neighboring information	2
given video	2
answer sequence	2
query images	2
oscillation problem	2
varying locality	2
original embedding	2
estimated parameters	2
future poses	2
total number of parameters	2
latent variable	2
moderate size	2
variety of matching tasks	2
rich matching patterns	2
internal structures	2
warm start	2
learning problem	2
state and action spaces	2
signal-to-noise ratio	2
different configurations	2
subsequent frames	2
latent states	2
state space	2
energy efficiency	2
logits	2
highly sensitive	2
decreased values	2
cooperation level	2
7	2
real-valued user factors	2
Code and data	2
tradeoff	2
multiple temporal dependencies	2
total computational cost	2
goals	2
combinations of 4 doses	2
semantic knowledge	2
compression artifacts	2
various artifacts	2
low computational complexity	2
4%	2
dense structure	2
pros and cons	2
ROUGE scores	2
proportion	2
given input image	2
long time	2
rate of convergence	2
high-order proximities	2
first-order and high-order proximities	2
pay-off matrix	2
search time	2
architecture parameter	2
qualitatively and quantitatively	2
labeling noise	2
multiple factors	2
probabilistic perspective	2
sample bias	2
substring	2
partial parsing rules	2
lightweight	2
static word embeddings	2
biased representations	2
shared weights	2
event	2
clean images	2
compression performance	2
development data	2
small changes	2
uncertainty estimation	2
camera poses	2
similar scores	2
automatic metrics	2
$s$	2
''class''	2
labeled and unlabeled data	2
corresponding positions	2
training data locally	2
dependency types	2
best baseline accuracy	2
sentiment scores	2
effective performance	2
dataset biases	2
hypothetical behaviors	2
small amount of direct data	2
Fuzzy Soft Relation	2
\texttt{PETGEN}	2
item-item relations	2
limited amount of training data	2
sequential order	2
lot	2
graph labels	2
collection	2
non-convex objective	2
local models	2
anchor point	2
negative samples	2
new coming data	2
functional topological relationship	2
topological relationship	2
brain activity	2
quality and flexibility	2
stylistic quality	2
target token	2
radiomics shape features	2
term weight	2
given query	2
likelihood function	2
inner products	2
input noise	2
Human motion prediction	2
50 labeled examples	2
desired solutions	2
simple prior knowledge	2
learned structure	2
useful structure	2
small amounts of prior knowledge	2
highly competitive results	2
holistic knowledge	2
inherent correlation	2
inherent correlations	2
5G	2
transmission latency	2
daily life	2
control condition	2
reasonable time	2
visual results	2
crisp boundaries	2
user's preference	2
tree structure	2
candidate corrections	2
spelling errors	2
data characteristics	2
learned attention weights	2
small amount of training data	2
significantly slower	2
two data points	2
spectral embedding	2
class membership information	2
certain attributes	2
user modeling	2
embedding dimensions	2
offline data	2
safety constraints	2
high-resolution	2
predictor	2
helpful knowledge	2
personalized labels	2
disentangled representations	2
Universal Dependencies	2
new camera configuration	2
fundamental aspects	2
translation robustness	2
reported results	2
settings	2
opcode level	2
outcomes	2
user intent	2
functional connectivity	2
raw EEG data	2
hyperedge	2
normalizing constant	2
optimal perturbation positions	2
minimal loss	2
energy-efficiency	2
substantial margin	2
average precision	2
regular shape	2
complete content	2
strong robustness	2
changing network bandwidth	2
computational heterogeneity	2
perceptual metrics	2
statistical significance	2
approximate solutions	2
which	2
structured ontology	2
project page	2
generalization behavior	2
text features	2
terms of both precision and recall	2
better performances	2
robustness issue	2
name variations	2
sub-optimal performance	2
symbolic representation	2
well-defined	2
LGFO	2
expected damages	2
social cost	2
shift or scale	2
previous results	2
seven	2
symmetric positive definite matrices	2
biased data	2
resource restrictions	2
conjunctive structures	2
cycle loss	2
23 percent	2
uncertainty information	2
parameter knowledge	2
semantic role labeling	2
past	2
every order	2
non-entities	2
k-space	2
kernel decay	2
sample-efficiency	2
latent hierarchical structure	2
tighter bound	2
specific constraints	2
high-dimensional time-series patterns	2
adjustable parameters	2
restrictions	2
contents	2
shared needs	2
4-bit weights	2
scale factors	2
experimental data	2
structured attributes	2
online setting	2
EEG patterns	2
maximum benefit	2
small deviations	2
trained policies	2
different embedding dimensions	2
vertices	2
multiple aspects	2
path	2
real-time speed	2
running speed	2
Abstract Meaning	2
word recognition accuracy	2
performance drops	2
measurement noise	2
entity names	2
competitive or better results	2
unstructured text data	2
KG sparsity	2
relative position	2
actions	2
arguments	2
theoretical properties	2
morphology	2
hair attributes	2
RC training data	2
state-of-art results	2
overall improvement	2
predicate-argument mapping information	2
incomplete syntax	2
relevant statistics	2
recent advances	2
edge	2
scoring functions	2
redundant parameters	2
new intents	2
severity	2
informative statistics	2
facial landmarks	2
event types	2
two perspectives	2
growing rapidly	2
sacrificing accuracy	2
best translations	2
additional structural information	2
graph similarity	2
false ones	2
paraphrase relationship	2
transfer learning	2
non-linearities	2
coarse-grained	2
good balance	2
human factors	2
token-level labels	2
noisy pseudo labels	2
better language representations	2
highly accurate results	2
accuracy and visual quality	2
different resolutions	2
inverse covariance matrix	2
posterior	2
Gaussian	2
mode collapse	2
reliable pseudo-labels	2
reliable pseudo labels	2
local coherence	2
underlying biology	2
well calibrated uncertainty estimates	2
Empirical results	2
lower computational complexity	2
advances	2
camera viewpoint	2
data loss	2
relational direction	2
achievestate-of-the-art results	2
different word embeddings	2
unseen features	2
higher incidence	2
increasing difficulty	2
final results	2
lingual embedding	2
annotation bottleneck	2
better feature representations	2
corresponding depth maps	2
texture information	2
session information	2
real images	2
loss of information	2
textual and visual features	2
boundaries	2
200	2
Computational results	2
annotation quality	2
hundreds to thousands	2
spatial correlations	2
several stages	2
closed-world assumption	2
Knowledge Graph Completion (KGC)	2
background knowledge	2
task-specific knowledge	2
item attributes	2
structure space	2
covariance matrix	2
class similarities	2
10x speedup	2
large beams	2
beam size	2
relational triples	2
context words	2
retrieval effectiveness	2
discriminative	2
local structures	2
sentence semantics	2
proper responses	2
small perturbations	2
insufficient data	2
p2p similarity	2
understanding results	2
target image	2
segmentation quality	2
valuable experiences	2
significant improvements in performance	2
low error	2
high detection rates	2
competitive scores	2
higher order proximities	2
steep learning curve	2
existing results	2
inferential relations	2
people's trajectories	2
specificities	2
winnability percentage	2
bandwidth	2
good representation	2
meta level	2
enough labeled data	2
small fraction	2
perfect match	2
validation loss	2
configuration	2
feature importance	2
Learning discriminative features	2
new record	2
transcription errors	2
round	2
various types	2
differential entropy features	2
synthetic samples	2
image contents	2
raw pixels	2
large availability	2
two baselines	2
amount of time	2
time limit	2
Ontological KGs	2
subset of features	2
generalisation capabilities	2
reasoning paths	2
large amount of training data	2
language independent features	2
traffic signs	2
fixed dimensionality	2
challenging conditions	2
unique patterns	2
privacy security	2
domain distance	2
assignments	2
correct assignments	2
document-level sentiment preference information	2
subgoals	2
continuous state space	2
tedious and time-consuming	2
spans (pairs)	2
HPO problem	2
language barrier	2
timbre	2
network types	2
sizing information	2
intermediate representations	2
frames	2
data and algorithmic levels	2
daily lives	2
surface level	2
numerical attributes	2
architectural bias	2
comparable or superior performance	2
valid corrections	2
long-tailed distribution	2
feasible range	2
color variants	2
high-level semantic information	2
information gap	2
final translation quality	2
non-identical and independent distribution (non-IID)	2
regulatory restrictions	2
privacy, communication costs	2
unreliable predictions	2
abundance of data	2
local optimal	2
modeling capacity	2
proximity	2
explicit relation	2
convergence speed and overall model performance	2
20% WERR	2
regularizer of the gradient quality	2
3D space	2
promising progress	2
event triggers	2
four tasks	2
various factors	2
versatility	2
{`}	2
readable text	2
phonetic similarity	2
close embedding space representation	2
characters with similar structures	2
structure features	2
semantic, glyph, and phonetic features	2
language pattern	2
unrecognizable or recognition errors	2
new collocations	2
Internet age	2
new collocation	2
synthetic and real-world data	2
LR images	2
extracted information	2
textual features	2
strong performance guarantees	2
low-data regime	2
transferable features	2
Classification accuracies	2
winner	2
communication costs	2
high computational resources	2
question difficulty	2
non-differentiable	2
slot-value pairs	2
kinds	2
impact factors	2
better extrapolation ability	2
extrapolation ability	2
high-quality labels	2
specific role	2
original meta-features	2
meta-level	2
potential mentions	2
data size	2
large errors	2
VarDial workshop proceedings	2
complex relationships	2
optimal results	2
annotation budget	2
independent and identically distributed	2
abilities	2
qualitative results	2
large training data scenarios	2
contextual representations	2
surrounding context	2
domain-invariant features	2
fidelity	2
prior tasks	2
EEG s.	2
user request	2
transcript text	2
audio spans	2
de-ID	2
SED performance	2
network performance	2
incomplete data	2
SSIM scores	2
data samples	2
novel classes	2
branch	2
sub-optimal results	2
largely increased search dimension	2
optimal estimation	2
relation mention	2
tremendous strides	2
different feature spaces	2
labeled aspects	2
QA data	2
extra input features	2
much better results	2
low-quality embedding	2
embedding	2
amount of context	2
high variability	2
similar performances	2
synaptic weights	2
official results	2
negative impact	2
extra-data	2
node embedding	2
previous metrics	2
cell outputs	2
memory efficient	2
voxel features	2
lower accuracy	2
3D data	2
effective features	2
data dependencies	2
machine translation output	2
much larger	2
policy distribution	2
execution latency	2
better capacity	2
internal features	2
boundary	2
learning efficiency	2
absolute position encodings	2
distortion	2
computationally prohibitive	2
bidirectional GRU	2
expressive	2
long-term dependencies	2
20 FPS	2
image plane	2
additional parameters	2
teacher features	2
distant labels	2
increasing popularity	2
structural characteristics	2
relative locations	2
intended message	2
similarity metric	2
source and target data	2
sample space	2
ill-posed	2
near-optimal policies	2
appearance and motion cues	2
visual clues	2
valence and arousal dimensions	2
valence-arousal ratings	2
good classification performance	2
theoretical and empirical issues	2
clipping bias	2
key observation	2
substantial data heterogeneity	2
client-level differential privacy	2
differential privacy	2
huge search space	2
volumetric 3D CT baggage security screening imagery	2
break-even point	2
given problem	2
Reproducing Kernel Hilbert Space (RKHS)	2
attitude	2
observed results	2
different thresholds	2
weighted sum	2
target word	2
prevalence	2
value generation objective	2
operation prediction objective	2
expected loss	2
hard samples	2
person names	2
programming knowledge	2
location information	2
definitions	2
social biases	2
rationale	2
suitable positions	2
multiple loss functions	2
kernel size	2
user and item embeddings	2
considerable speedup	2
previous baselines	2
current challenges	2
representational capacity	2
low-quality facial images	2
uncertainties	2
stochastic gradients	2
global representation	2
low signal-to-noise ratio	2
subtle differences	2
Long-Short Term Memory	2
report	2
K identities	2
10%	2
source and the prefix	2
functionality	2
selected opinions	2
space and time	2
comprehensive attention	2
image-level category labels	2
improving performance	2
finer features	2
detailed textures	2
sharper edges	2
baselines by significant margins	2
system description papers	2
GCN s	2
noisy words	2
representative features	2
stronger performance	2
different quantization parameters	2
prior distributions	2
approximation	2
covariance function	2
prediction uncertainty	2
substantial performance gain	2
zero-shot AutoML	2
data meta-features	2
mean and variance	2
synthetic QA pairs	2
student model's performance	2
delay	2
specific features	2
clinical records	2
distinctive features	2
entity representations	2
key differences	2
activity	2
content and style	2
contextualized representations	2
official rankings	2
Intersection over Union (IoU)	2
action proposals	2
precise start and end times	2
sufficient data	2
expressive power	2
local level	2
graph information	2
super-human performance	2
small/extreme large batch sizes	2
Multiply-Accumulates	2
lower error	2
representation power	2
efficiency and quality	2
less hidden	2
varying dimension	2
non-stationary behavior	2
fully observed variables	2
underlying cause-effect relationships	2
architectural distribution	2
shape features	2
shared representations	2
choices	2
research gap	2
64.7% of cases	2
larger the better	2
score (i.e. 0, 1, 2	2
English translations	2
150,000 images	2
calculation quantity	2
dependence	2
large data	2
conflict	2
\emph{i.e.}	2
different semantic scales	2
trials	2
best scores	2
optimal number of extracted dimensions	2
public trust	2
object category	2
semantic annotations	2
set of labels	2
domain shifts	2
weakly labeled data	2
partial labels	2
EEG recordings	2
alternating periods	2
informative	2
informative samples	2
labeling costs	2
learning capacity	2
amount of computation	2
fewer training samples	2
heterogeneous features	2
dummy identities	2
POS tag	2
featurespace	2
rewards and associated overfitting risks	2
pseudo-bisimulation metric	2
behavioral similarity	2
reward-based signal	2
behaviorally similar observations	2
solely an auxiliary SSL objective	2
latent representation space	2
two functions	2
ad-hoc	2
map information	2
original sentence	2
baseline performance	2
unexpected volatility	2
different quantization bits	2
local geometry	2
particular domain	2
graph structured data	2
segmentation errors	2
noisy output	2
10 seconds	2
differentiated emotional behaviors	2
similar semantics	2
inter-image separability	2
asymptotic normality	2
DFV	2
sensitive information	2
heavy resource consumption	2
changes	2
alpha rhythm	2
single EEG measurement	2
better classification results	2
long distance dependencies	2
broad coverage	2
grammatical knowledge	2
labelled samples	2
uncertainty measure	2
pixel-level	2
selected data	2
high capacity	2
various sizes	2
high rewards	2
multiple modalities	2
highly efficient	2
re-id features	2
frequency domain	2
richer information	2
Edit Distance	2
poor accuracy	2
English descriptions	2
faster runtime	2
fake news	2
6.5%	2
classification task	2
state transitions	2
learning speed	2
intrinsic relationships	2
two different representations	2
missing elements	2
perturbation	2
overall segmentation performance	2
additional constraints	2
uploading data	2
secondary information	2
increased robustness	2
standard performance metrics	2
two properties	2
transparent inner structure	2
descriptions	2
minimal changes	2
large capacity	2
targets	2
side-information	2
reconstructed images	2
low frequency information	2
state-of-the art results	2
complex operations	2
size and complexity	2
superficial correlations	2
genuine understanding	2
toxic spans	2
pre-trained word embeddings	2
learning parameters	2
expert policy	2
variants	2
HR images	2
long periods of time	2
GAN s	2
quantization parameters	2
multiple distributions	2
minimal number	2
large performance improvement	2
common subspace	2
therotation angle	2
new annotations	2
video descriptions	2
batch-size	2
entity knowledge	2
ternary values	2
potential performance	2
$\mathcal{Y}$-discrepancy	2
diverse feature spaces	2
new SOTA results	2
whose performance	2
good trade-off	2
cross-sentence information	2
several sentences	2
generalization bounds	2
underlying distributions	2
substantial progress	2
intrinsic information	2
multi-modal data	2
class distribution	2
correct predictions	2
graphical representation	2
regularizer	2
added value	2
high coefficients	2
{'}	2
Transformer baseline	2
noisy observations	2
smooth trajectories	2
policies	2
convergence time	2
inference cost	2
previously visited states	2
dialogue states	2
competitive baseline	2
MuSe-Physio	2
small margin	2
quality loss	2
one token	2
online inference efficiency	2
good scalability	2
resource scarcity	2
sign	2
hypothesis	2
quality of life	2
consequences	2
facial details	2
extra computational cost	2
latent state	2
deviation	2
connection	2
hinge loss	2
speaker similarity	2
optimization objective	2
competitive	2
emotional states	2
two terms	2
DILATE (DIstortion Loss including shApe and TimE)	2
minimal data	2
new state-of-the-art	2
satisfactory results	2
quantization accuracy	2
topics	2
shared features	2
interesting results	2
prediction error	2
future motion	2
complex traffic scenarios	2
valence	2
weighted average	2
participation	2
potentiality	2
absolute performance	2
paucity	2
motion patterns	2
sufficient training data	2
informative content	2
vectors	2
MR images	2
hidden state	2
evaluation data	2
training stages	2
vector size	2
DTW	2
streaming data	2
sentence-level	2
14 categories	2
standard deviations	2
seizure variabilities	2
labor-intensive and error-prone	2
quantized model	2
accuracy gap	2
accuracy degradation	2
top results	2
CPU time	2
training and validation datasets	2
video super-resolution	2
extra word-level information	2
word-level information	2
auxiliary task	2
main task	2
Mahalanobis distance	2
performance and efficiency	2
sparse code functions	2
Riemannian geometry	2
additional constraint	2
center	2
hard tasks	2
predictive variance	2
manifold	2
two variations	2
convergence analysis	2
adversarial loss	2
lower layers	2
residual connection	2
global perception	2
question representation	2
common patterns	2
abnormalities	2
embedding layer weights	2
asymptotically optimal	2
complex network structures	2
generalisation ability	2
long sequence	2
heavy computational cost	2
one of the classes	2
tighter lower bound	2
acceleration	2
better architectures	2
unseen combinations	2
label dependencies	2
remarkable improvement	2
graph context	2
positional embeddings	2
varying degrees of success	2
image representation	2
final layer representations	2
LSTM s	2
video frame	2
10	2
different loss functions	2
guidance	2
new ones	2
human-annotated labels	2
image frames	2
aligned features	2
spatial and temporal features	2
high correlation	2
facts	2
question types	2
noisy modalities	2
performance drop	2
causal dynamics	2
failure	2
expert knowledge	2
limited availability	2
easy samples	2
high diversity	2
100x faster	2
combinations	2
cluster assignments	2
network size	2
wide range of tasks	2
substantial amount	2
10M	2
IACS	2
joint representation	2
sleep stages	2
micro-sleep data	2
better feature representation	2
self-consistency	2
perceptual image quality	2
data dimension	2
existing personalized FL objective	2
$\rho=65$	2
larger imbalance	2
similar imbalance ratio ($\rho<20$)	2
task-level	2
meta-dataset imbalance	2
different frequencies	2
certain dependencies	2
global dependencies	2
thermal properties	2
image size	2
accuracy and latency	2
temporal alignments	2
global transformation	2
temporal shifts	2
temporal variability	2
shared limitations	2
weak and strong points	2
types of errors	2
noise distribution	2
minimal accuracy loss	2
theoretical guarantee	2
significantly less time	2
similar	2
weighted F1-score	2
objectives	2
hierarchical relations	2
unified formulation	2
sub-optimal and time-consuming	2
large design space	2
input difference	2
output difference	2
adversarial example	2
quantization	2
Quantization Mimic	2
true posterior	2
known analytical form	2
chance	2
error term	2
three kinds of NER subtasks	2
specificity	2
bilevel optimization	2
generated samples	2
two measurements	2
speaker identity	2
profile	2
extreme cases	2
3x and 2.8x more sample efficient	2
accuracy and sampling efficiency	2
75.5\% top-1 accuracy	2
97.84\% top-1 accuracy	2
1000 samples	2
number of epochs	2
distributed design	2
network accuracies	2
state level	2
shorter time	2
prohibitive amount of computations	2
inferior performance	2
predicted class	2
given sample	2
residual connections	2
beginning time	2
remarkable progress	2
large number of training samples	2
large volumes of data	2
Classification results	2
intra-class variability	2
99%	2
document level	2
document-level metrics	2
relevant documents	2
competitive result	2
spatial structure	2
seen and unseen classes	2
coverage criteria	2
safety assurance	2
organizational counts	2
various settings	2
spatial redundancy	2
communication rounds	2
Dynamic Time Warping distance	2
clear superiority	2
soft pseudo-labels	2
available information	2
element	2
return distribution	2
much fewer parameters	2
simpler consistency loss	2
reconstruction model loss	2
superhuman performance	2
generated image	2
better initialization	2
similar structure	2
two views	2
desired entity types	2
temporal correlations	2
user's information need	2
reference summaries	2
architectural hyperparameters	2
meaningful information	2
daily basis	2
morphological features	2
time that is linear in the length	2
two core properties	2
temporal resolution	2
source sequence	2
large portion	2
past events	2
input and output	2
objective functions	2
link prediction	2
little computational overhead	2
feature statistics	2
4-bit quantization	2
less than 1% loss of accuracy	2
kernel weights	2
far less expensive integer counterparts	2
single-precision operations	2
8-bit quantizations	2
network weights	2
POS information	2
various features	2
weight tensor	2
kernels	2
significant progress	2
False Discovery Rates	2
divergence parameter $\beta$	2
$\beta	2
linear time	2
doubly robust	2
$\beta$-divergences	2
feature extraction capability	2
large and complex	2
complex data	2
model-agnostic	2
improved robustness	2
high sensitivity	2
ease of access	2
freezing parameters	2
LLM's embeddings	2
12-26% absolute improvement in precision and 36-50% absolute improvement in consistency	2
continuous ones	2
natural language prompts	2
experts)	2
set of continuous prompts	2
continuous prompts	2
LLM embeddings	2
same, accurate responses	2
different wording	2
3D images	2
expensive computations	2
architecture space	2
epochs	2
nearly linear time (in matrix dimensions) algorithm	2
frequency positional information	2
strong characteristics	2
short duration test recordings	2
coarse class	2
PanPhon features	2
kernel function	2
many samples	2
block-cyclic structure	2
pre-trained weights	2
class hierarchy	2
higher sensitivity	2
remarkable improvements	2
transition depth	2
reported performance	2
different methods	2
higher compression ratio	2
domain-shift	2
deficiencies	2
driving safety	2
final output image	2
inherent problems	2
computation complexity	2
embedding vectors	2
less than 0.01% accuracy loss	2
accuracy pretty close	2
large intra-class variations	2
performance boost	2
fixed weights	2
optimal sampling distribution	2
delivery operator	2
powerful representation ability	2
MAML objective	2
benign landscape	2
AU-level features	2
multivariate time series data	2
dataset sizes	2
better discriminative ability	2
generalisation performance	2
$K$	2
true loss	2
client data	2
5.36M parameters	2
limited computational resources	2
slight modifications	2
computational consumption	2
graph structure noise	2
memory intensive	2
large volume	2
visual input	2
meta information	2
average subject independent accuracies	2
emotion	2
substantial performance gains	2
medical conditions	2
transfer capabilities	2
similar results	2
high dimensional space	2
multilingual BERT	2
links	2
insights	2
rotation invariance	2
rotated or sheared images	2
large circular kernel	2
operation space	2
corresponding square kernels	2
similar or even competitive performance	2
proposed integrated kernels	2
corresponding circular kernels	2
strong detection capabilities	2
complex features	2
stage	2
network accuracy	2
related context	2
overparameterization	2
English)	2
compression rate	2
overall quality	2
metadata	2
unsupervised data	2
massive amounts	2
latent code	2
underlying patterns	2
human evaluation	2
temporal characteristics	2
low-dimensional states	2
high-level	2
word similarity	2
stability measurement	2
54 languages	2
control policy	2
new state-of-the-art result	2
temporal long-term dependencies	2
learning capabilities	2
significant features	2
inner workings	2
label similarity	2
direction	2
final classification	2
Low-Resolution (LR) images	2
single feature	2
semantic content	2
adaptive weights	2
different importance	2
different training stages	2
later stage	2
hard ones	2
domain-specific knowledge	2
camera parameters	2
quantitative and qualitative results	2
2D pose	2
binary precision	2
noticeable quality degradation	2
4-bit precision	2
stale gradient	2
limited hardware capability	2
adversarial perturbations	2
question and answer	2
accuracy and speed	2
big data	2
average accuracy	2
high temporal resolution	2
high slip angles	2
reliable information	2
rich knowledge	2
highest	2
short queries	2
significantly better performance	2
confounding factors	2
lines of code	2
search spaces	2
high-resolution images	2
fluorescence excitation exposure	2
therapeutic outcomes	2
memory size	2
brain states	2
original problem	2
recognition rate	2
posterior probabilities	2
parametric costs	2
simple graph problems	2
strictly more expressive dynamic attention	2
restricted kind	2
limited kind of attention	2
100% success rate	2
gray scale images	2
unseen test data	2
document embeddings	2
8 languages	2
source context	2
statistically significant improvements	2
reader comments	2
main aspect	2
conditioning information	2
data efficient	2
compute time	2
aspect information	2
sentiment features	2
position information	2
fixed length vector	2
contextual representation	2
wide variety of tasks	2
limited training examples	2
given aspect	2
conversation history	2
current sentence	2
parsing speed	2
sketch	2
user embeddings	2
instance labels	2
multiple relations	2
larger datasets	2
new state - of - the - art accuracy performance	2
one - pass encoding	2
input paragraph	2
soft constraints	2
readily available side information	2
new state - of - the - art performance	2
span - level features	2
multimodal representations	2
connections	2
semantic parse	2
prosodic prominence	2
regularization term	2
training data size	2
word incrementally refined label distributions	2
label embeddings	2
much information gain	2
scope resolution of 92.36	2
decision choices	2
important characteristic	2
74.9 % accuracy )	2
word - embedding representations	2
variety of trainable perspectives	2
passage , question , and answer	2
parallel hierarchy	2
better features	2
understanding	2
order of magnitude in time complexity	2
RNN 's time axis	2
trigger ( context sentence	2
informed query	2
state - changing triggers	2
context sentences	2
short - term ( local ) and long - term ( global ) sequential dependencies	2
semantic aspects	2
original form	2
optimization problem	2
relevant answer	2
final predictions	2
parameter size	2
upper layers	2
reward signals	2
skills	2
irrelevant information	2
Subtask A	2
primary submission	2
evidence document	2
allowed answers	2
> 50 %	2
5 %	2
words or start and end markers	2
separate predictions	2
fixed length representations	2
supplied text	2
arbitrary strings	2
logistic regression and manually crafted features	2
output tokens	2
variable lengths	2
30	2
variational lower bound	2
hierarchy	2
document	2
Cloze - style queries	2
similar capabilities	2
rich contextual representations	2
different training objectives	2
interactions	2
long - term dependencies	2
much more data	2
new state - of - the - art result	2
local dependency	2
state - of - theart performance	2
multiple perspectives	2
layer	2
original features	2
elements	2
word overlap	2
data preparation	2
existing benchmarks	2
large - scale conditions	2
correct evidence	2
quite easy	2
small portion of the range of possible questions	2
set of features	2
significance of the results	2
raw frequency	2
role	2
NER problem	2
four types of internal and external evidences	2
names , times and numerical quantities	2
best	2
transliteration accuracy	2
extensive system development effort	2
word bits	2
lexical similarity	2
linguistic complexity	2
standard metrics	2
positive results	2
learning rates	2
highly ambiguous	2
promising result	2
equivalent or better performances	2
multiple criteria	2
detection rate	2
two features	2
semantic ambiguities	2
unary rules	2
discourse markers	2
annotation errors	2
useful clues	2
argument structure	2
linguistic structure	2
different granularity	2
number of recognized word forms	2
standard 360K	2
middle of the scale	2
word forms	2
terms of performance	2
linguistic rules	2
informativeness	2
knowledge acquisition bottleneck	2
tag	2
average F1 score	2
linguistic style	2
perspectives	2
conditional probabilities	2
existing grammar	2
high level	2
semantic relatedness	2
many instances	2
ITG constraints	2
random baseline	2
best set of parameters	2
higher level	2
wide variety	2
domain-independent	2
summary responses	2
decision rules	2
rich texts	2
achieved accuracy	2
simple patterns	2
globally optimal solutions	2
algorithmic level	2
knowledge level	2
sentence structure	2
promising accuracy	2
different kernel sizes	2
past frames	2
dependency structures	2
temporal ordering	2
sequence information	2
vector spaces	2
unwanted meanings	2
1 million	2
pore features	2
speaker style	2
structural complexity	2
100 million	2
hundreds of millions	2
semantic verb classes	2
argument effectiveness	2
argument conciseness	2
evaluative arguments	2
cluster number	2
lexical , prosodic , and syntactic realization	2
significant gap	2
network topology	2
Tested accuracy	2
retrieval time by orders of magnitude	2
phrase translations	2
computational complexity and average retrieval times	2
less memory	2
temporal coherence	2
existing annotations	2
many aspects	2
higher correlations	2
different modes	2
code, data and the full result tables	2
XLM-RoBERTa	2
Word-level usage	2
similar characteristics	2
identity information	2
on-line	2
paraphrase classification accuracy	2
lesser extent	2
non-matches	2
part of speech information	2
classification problem	2
subjectivity clues	2
likely topics	2
common sense	2
common sense knowledge	2
semantic patterns	2
data domain and size	2
large performance gains	2
rest	2
characteristic	2
low probability	2
individual analysis results	2
significantly lower computational cost	2
functional structure	2
parts	2
human rater scores	2
lower computational cost	2
certain threshold	2
coarse-to-fine	2
suitability	2
composition	2
feature similarity	2
highly precise	2
semantic dimensions	2
string similarity	2
comprehensive evaluation	2
context features	2
definition	2
name identification capability	2
compression	2
continuity	2
utility	2
limited set of features	2
number of possible choices	2
morphological or syntactic features	2
additional conditioning variables	2
given anaphor	2
specification	2
best combination of features	2
domain , topic and time	2
domain and time	2
good match	2
reasonable success	2
positive or negative	2
linguistic properties	2
semantic properties	2
body of knowledge	2
significant speedups	2
best features	2
-LRB- 2 -RRB-	2
expected cumulative reward	2
given sentence	2
high precision and recall	2
various metrics	2
textual entailment	2
23%	2
specific instances	2
input texts	2
user utterances	2
generated sentences	2
deadline	2
control structure	2
absolute improvements	2
noise level	2
M'	2
linear convergence	2
two observations	2
Identity uncertainty	2
alignment quality	2
utterance	2
speaker's intention	2
initial ranking	2
specific words	2
extensive experimental results	2
accuracy and scalability	2
word error rate (WER)	2
connectivity	2
output sequence	2
word segmentation problem	2
raw text	2
alternative senses	2
model predictions	2
target features	2
little overhead	2
advantage of parallelism	2
superior empirical performance	2
low-dimensional representation	2
larger number	2
pixel accuracy	2
relative positioning	2
partial occlusions	2
low-level information	2
topological structure	2
graph	2
number of points	2
basics	2
translation relation	2
vocabulary	2
optimal structural descriptions	2
influence	2
large degradation	2
large quantization error	2
wide dynamic range	2
task definitions	2
entire house data	2
redundant computations	2
statistical measure	2
number of measurements	2
energy usage	2
true reward function	2
new states	2
relative improvement	2
extracted feature	2
competitive ratio	2
question type	2
numerical experiments	2
speed and quality	2
internal representation	2
privacy issues	2
sensitive attributes	2
less number	2
optimal solution	2
heavy computation	2
many factors	2
ground truth labels	2
domain gaps	2
filtered soft labels	2
category-relevant losses	2
overall tagging accuracy	2
saliency patterns	2
cosine similarity scores	2
ill-posed problem	2
transfer learning capabilities	2
competitive translation quality	2
target language	2
large	2
new image	2
novel compositions	2
personal fixations	2
High similarities	2
complex relations	2
complex properties	2
relation patterns	2
various relations	2
locations	2
linguistic performance	2
optimality	2
pseudo-labels	2
given labels	2
old data	2
signed power mean Laplacian	2
global and local information	2
shallow features	2
image space	2
lower complexity	2
high fairness	2
much information	2
rewardless states	2
activation function	2
strengths and limitations	2
ML models	2
gradient mismatch problem	2
recommendations	2
competitive accuracy	2
large dataset	2
intermediate information	2
class imbalance problem	2
segmentation performance	2
problem settings	2
compatibility	2
75% accuracy	2
identities	2
lesser amount	2
coefficient matrices	2
trade-offs	2
Area under the ROC curve (AUC)	2
optimal decisions	2
target accuracy	2
much data	2
state-of-the-arts	2
alpha matte	2
simulated and real data	2
prior	2
expressiveness	2
97 million	2
future trajectories	2
large number of classes	2
higher score	2
high correlations	2
noisy input	2
various stages	2
KD loss	2
previous classes	2
initial results	2
caption	2
advantage function	2
data space	2
better solutions	2
common structure	2
Modified Focal Loss	2
mask vector	2
differentiable NAS	2
heuristic rules	2
base classifiers	2
non-convex	2
statistical differences	2
imbalance	2
Recognition performance	2
out-of-distribution situations	2
common representation	2
multi-modality	2
quality range	2
exponentially many	2
QA pairs	2
text size	2
human labor	2
Knowledge Graph (KG)	2
different task	2
realism	2
individual differences	2
necessary features	2
convergence	2
local minimum	2
two objectives	2
new insights	2
difficulty labels	2
EL performance	2
target words	2
log-likelihood	2
gradient bias	2
discrete random variables	2
SSIM and PSNR	2
acceptable results	2
perceived audio quality	2
observed data	2
discrete time	2
learned representations	2
cross-entropy loss	2
additional attributes	2
speaker embeddings	2
tfMRI data	2
superior quality	2
error rates	2
two problems	2
severe degradation	2
10 times faster	2
training iterations	2
geometric structures	2
gradient maps	2
maximum number of features	2
mention detection part	2
quantized parameters	2
quantize parameters	2
parameters of each layer	2
high computational complexity	2
cost functions	2
closed-form solutions	2
attack samples	2
different types	2
good generalization	2
question correctly	2
unseen domains	2
label space	2
label structure	2
ranking function	2
spatial-temporal correlation	2
missing connections	2
tasks, data, and measures	2
Video to Text Description (VTT)	2
significant time	2
supervised data	2
significant speedup	2
texts	2
five tasks	2
cross-task constraints	2
skip connections	2
high heterogeneity	2
statistically significant differences	2
computational overhead	2
30%	2
current capabilities	2
Chinese characters	2
time consuming	2
reconstruction performance	2
terms of PSNR and SSIM	2
domain	2
joint distribution	2
real business scenarios	2
scene structure	2
F1-score	2
different Knowledge Graphs (KGs)	2
reliability and efficiency	2
network's performance	2
fourth place	2
dimension of data	2
statistical features	2
primary colors	2
better generalization	2
state-of-the-art or competitive performance	2
answer choices	2
subitizing information	2
supervised baselines	2
training dataset	2
additional computation resources	2
English data	2
synthetic images	2
effective results	2
\textit{viz.}	2
error type	2
co-occurrence relations	2
previous dialogue state	2
open vocabulary	2
highly accurate	2
high confidence predictions	2
superior accuracy	2
user's privacy	2
inter-domain gap	2
systole and diastole phases	2
higher level of abstraction	2
sentiment information	2
data hungry	2
expensive manual annotations	2
token-level	2
privacy and data access constraints	2
Lexical Complexity Prediction (LCP)	2
significantly different	2
resulting predictive distributions	2
compositional structure	2
clinical entities	2
lower latency	2
latency requirements	2
teacher performance	2
State-of-the-art results	2
potential pitfalls	2
semantic connection	2
5%	2
fully supervised performance	2
semantic structure	2
Pareto frontier	2
fairness measures	2
inherent trade-off	2
training data and the testing data	2
insufficient training data	2
variation	2
protected variables	2
certain class	2
performance of 28.64 BLEU score	2
learning patterns	2
particular task	2
official submissions	2
hardware constraints	2
hidden layers	2
spatial correlation	2
missing relations	2
missing facts	2
negative correlation	2
group sparsity	2
ranked 5th	2
embedding spaces	2
misalignment	2
corpus statistics	2
even better results	2
BSNLP 2019	2
aggregated knowledge	2
different model architectures	2
generated adversarial examples	2
attribute	2
product categories	2
adversarial texts	2
good margin	2
state-of-the-art (SOTA) results	2
anchors	2
emotional characteristics	2
under-resourced	2
gold standards	2
target labels	2
robust performances	2
unprecedented performances	2
intermediate layers	2
overfitting problem	2
discrimination power	2
distance function	2
stationary point	2
teacher predictions	2
real user questions	2
in-passage span annotations	2
low overall accuracy	2
top few predictions	2
heuristically retrieved negative examples	2
distantly supervised positive examples	2
speech data	2
customer histories	2
rich semantics	2
OCR accuracy	2
orientation	2
document's content	2
text structure	2
documents	2
previous best results	2
class imbalance issues	2
state-of-art performances	2
better reasoning abilities	2
question-answer pairs	2
query representations	2
domain specific	2
performance loss	2
susceptibility	2
large margins	2
empirical findings	2
different baselines	2
Local Key Terms	2
practical situations	2
1.64x faster	1
strong performance of 84.7% top-1 accuracy	1
previous best published single model and single scale results	1
49.7% Box AP	1
44.4% Mask AP	1
baselines significantly	1
thereal ones	1
8-connected gradient difference loss	1
totalvariation loss	1
color-depth image	1
depth image	1
information of color image	1
problems of depth super-resolution and colorsuper-resolution	1
image-to-image translation and imagesuper-resolution	1
accuracy by an average of 3.54% across all scenarios	1
5 channels	1
accuracy of 80.70% on Valence and 81.41% on Arousal	1
accuracy of 95.32% on Valence and 95.68% on Arousal	1
reduced 5-channel extract	1
individual's emotional state	1
Valence and Arousal dimensions	1
proposed DWT Entropy and Energy features	1
full session data	1
time-windows of a few seconds	1
time-frequency domain features	1
32 or more	1
four or five	1
reduced number	1
0.728 F1-score	1
0.707 F1-score	1
discriminant features	1
optimal warping path	1
new training sample	1
similar temporal properties	1
new training samples	1
model's generalization	1
wide margins	1
latent true labels	1
token-wise transition and emission probabilities	1
contextual representation power	1
multi-source noisy labels	1
true labels	1
63.31% on AffectNet 7-way classification	1
59.58% on AffectNet 8-way classification	1
87.76% on the FER+	1
top accuracy of 75.42% on FER 2013	1
selected training samples	1
input test image	1
nearest training samples	1
Dense-Sparse-Dense	1
increasing accuracy more amount of time	1
100 samples	1
greater execution time	1
comparative analysis of performance	1
demographic parity andequality of opportunity	1
demographic parity orequality of opportunity	1
protected attributes	1
nonconvex meta-objectives	1
function approximators	1
inner-level objectives	1
functional geometry	1
inner-level and outer-level problems	1
outer-level objective	1
meta-objective	1
nonconvexity	1
aggregated performance	1
optimal shared prior	1
outer level	1
inner level	1
many wavelengths	1
aggregate statistics (means, variances)	1
spectrum of wavelengths	1
single wavelength	1
spectroscopy time-series data	1
driving scenarios	1
sensor specifications	1
LiDAR information	1
abstract answers	1
realistic controlimplementation	1
around 31 hour forweekend and 116 hour for working days)	1
around8 minute training time	1
occupancy profile	1
energyconsumption effects	1
thermal inertia	1
energymanagement	1
RL-SHAP values	1
learned actions and SHAP values	1
single lane route	1
speed limits	1
dataset a graph-aware annotation proximity measure	1
frequent, few, and zero-shot learning	1
vanilla LWANs	1
graph-aware annotation proximity	1
human labelling guidelines	1
label hierarchies	1
skewed label distributions	1
well represented	1
accuracy results	1
reward/punishment functions	1
per-layer compression ratios	1
best possible accuracy	1
{\it iPods}	1
mean Average Precision (mAP) of 65.3\% over five	1
one type	1
small-world topology	1
possible gains	1
96% less	1
98% less edges	1
1000-node topology	1
similar convergence speed	1
effective momentum	1
unbiased gradients	1
global class distribution	1
local joint distribution	1
novel topology	1
underlying communication topology	1
data non-IIDness	1
local class bias	1
increased parameter size	1
positive findings	1
Negative medical findings	1
ImageNet and on NATS-Bench size search space	1
0.78 and 0.76 Spearman correlation	1
superior architecture rating accuracy	1
2.4% with comparable compute time	1
82.5% accuracy	1
searchable down-sampling positions	1
population center	1
biased supervision	1
large weight-sharing space	1
inaccurate architecture rating	1
disparate candidates	1
human efforts	1
batch sizes	1
NER tags	1
2 unique sentences	1
meaningful electroencephalography (EEG ) features	1
batch diversity	1
batch setting	1
multiple possible values	1
multiple categorical variables	1
values for both categorical and continuous inputs	1
fundamental seq2seqarchitecture	1
three fundamentalarchitectures	1
much larger margin	1
model's quality	1
vocabulary and output	1
explicit domain knowledge	1
average F1 score of 0.735	1
smaller standard deviation	1
model's quality and output	1
locations, time periods	1
$\sim 658$ Million words	1
1.8% AP and 1.3% AP improvement	1
single FOC	1
reference feature	1
query feature	1
fixed IoU threshold	1
serious false positive problem	1
poor classification ability	1
lot of false positives	1
query image and the reference image	1
given textual query	1
certain object	1
model{'}s performance	1
current model competence	1
competence of current model	1
training instance	1
data bias	1
limited medical data	1
serious data bias	1
long and coherent descriptions	1
240 times faster	1
4-bit ResNet	1
inter-layer and intra-layer sensitivity	1
power of quantization	1
cross-layer dependency	1
second-order error	1
one-by-one	1
limits of bitwidth	1
Quantization -Aware Training (QAT)	1
less powerful quantized models	1
small subset of training data	1
Post-training Quantization (PTQ)	1
convincing advantages	1
nonsmooth responses	1
high-dimensional input spaces	1
expensive or time-consuming	1
energy burden	1
different levels and iterations	1
ineffective multi-scale features	1
network computational cost	1
pre-set iteration time	1
adversarial data	1
representations' similarity	1
BERT 's Next Sentence Prediction head	1
similar ones	1
BERT 's parameters	1
macro-F1 score of 62.55{\%}	1
intersection kernel	1
presence bits kernel	1
two blended kernel functions	1
String Kernels	1
returned sequences	1
kernels of different sizes	1
Closed Shared Task	1
facial components	1
existing resources	1
91.5% on SNLI	1
accuracy of 95.9% on	1
retrieved external knowledge	1
relevant external knowledge	1
BERT 's language understanding and reasoning capabilities	1
explicit grounding	1
independent object pose	1
deviations	1
pose features	1
geometric poses	1
Holistic Pose Graph (HPG)	1
modeling geometric structure	1
inherent geometric relationships	1
local relationships	1
single RGB image	1
missing depth cues	1
explainability	1
2.7% and 0.7%	1
70.3% accuracy	1
average accuracy of 87.8%	1
large (96.4% vs. 91.2%) and small (91.8% vs. 71.2%)	1
lane changes	1
subjective risk	1
ADS' safety	1
subjective risk level	1
considerable evidence	1
complex road conditions	1
reliable predictions and confidence values	1
scene information	1
generalization of standard NeRF	1
Stochastic Neural Radiance Fields (S-NeRF )	1
model estimations	1
implicit 3D representations	1
AUC score ranging from 0.78 to 0.97	1
additional evidence	1
graph-structured data	1
exclusive proxies of essentiality	1
experimental constraints	1
assigned prototypes	1
distribution of prototypes	1
learned embedding space	1
additional (commonsense) knowledge	1
non-monotonic	1
sharp token contributions	1
source information	1
source and target relative contributions	1
proportion of each token's influence	1
token importance	1
abstract quantity	1
relative contribution	1
relative source and target contributions	1
two types of context	1
F1 scores by $6\%$ to $16\%$ absolute points	1
clue prediction	1
syntactic dependencytree representation	1
target question	1
diverse range ofother features	1
accurate boundaries	1
times, stability	1
different quantization rates	1
forward stability	1
symmetric and stable variants	1
distribution of values	1
type of computations	1
face up	1
vertical axis	1
far left to the left and those looking far right to the right	1
new emerging structure	1
classification precision	1
high-dimensional neighbor information	1
subset ofdata	1
differentiable objective	1
2D or 3D	1
much smaller model size	1
low, middle and high levels	1
improved ranking lossto	1
visualsimilarities at different levels	1
proposed Convolution SimilarityNetworks	1
spatial attention	1
thesimilarity score maps	1
two inputimages	1
low-complexity network structures	1
multi-level similarity	1
multiple levels	1
one single convolutionallayer	1
labels ten times faster	1
computed label estimates	1
crowdsourced IC labels	1
6,000	1
near-real-timeapplications	1
broad source categories	1
particular order	1
highly-correlated	1
mesoscale brain dynamics	1
low cost measure	1
accuracy of 83.3%	1
results and main findings	1
diverse modalities	1
client's capabilities	1
model width	1
client system heterogeneity	1
Ordered Dropout	1
linear maps	1
model's capacity	1
uniform limit	1
system heterogeneity	1
network bandwidth	1
processing capabilities	1
statistical data heterogeneity	1
fairness, training performance	1
client heterogeneity	1
vision to keyboard predictions	1
usernames ayushk and harsh_6	1
F1 scores of 0.707 (ranked 5th) and 0.725 (ranked 13th)	1
correct sentiment	1
positive and negative tweets	1
social or political sentiments	1
https://github.com/alexander-malafeev/microsleep-detection ) and data ( https://zenodo.org/record/3251716 )	1
low inter-expert reliability	1
good	1
recently developed scoring criteria MSEs, microsleep episode candidates (MSEc), and episodes of drowsiness (ED)	1
MWT data	1
laborious work	1
established scoring criteria	1
30-s epochs	1
classical definition	1
standard criteria	1
main characteristic	1
microsleep episodes (MSEs)	1
shorter than 15 s	1
chromatic information	1
Color Constancy	1
factor of four	1
efficient matrix multipliers	1
low-latency vector-vector operations	1
latency at inference time	1
NLP applications	1
significant increase (from 82% to 98%)	1
augmented training data	1
frequency domain with time domain features	1
novel loss function	1
realistic GPR data	1
satisfying results	1
RGB plus Depth)	1
group of ADHD behavioural patterns	1
intra-class gesture variability	1
classical warping path	1
theoretical contribution	1
approximation of Convex Hulls	1
certain gesture category	1
gesture class	1
gesture sample	1
gesture category	1
various downsampling factors	1
reference image	1
sample images	1
given reference image	1
desired semantics	1
NER in Bengali and Hindifinds accuracy (F measure) of 87% and 79%	1
highest F measure of 88% for Englishand the lowest F measure of 69%	1
set of language independent features	1
super human performance	1
challenges TVQA	1
knowledge of visual (V) modality	1
variable weights	1
similar architectures	1
different BERT instances	1
BERT encodings	1
multiple input modalities	1
labeled source and target data	1
MAPPO 's practical performance	1
implementation and algorithmic factors	1
comparable sample efficiency	1
surprisingly strong performance	1
multi-agent settings	1
variant of PPO	1
significantly less sample efficient	1
officially ranked 2nd and 3rd	1
2nd out of 8	1
overlap micro-F1 score of 86.88{\%}	1
strict micro-F1 score of 80.92{\%}	1
given sense	1
best accuracy and precision	1
specific mention	1
human keypoints	1
human detection and visual features representation	1
RGB and Depth videos	1
two input modalities	1
17.53 on BLEU metrics	1
large margin of 13.26 on readability-aware WER (RA-WER)	1
30%sensitivity at 6 false alarms per 24 hours	1
significantly betterperformance	1
dance recognition performance	1
movement and genre labels	1
30 hours	1
154 movement types	1
dance genre	1
photometric continuity	1
spatial and temporal motion smoothness	1
noise and interframe correspondence ambiguities	1
body part movements	1
3D-to-2D imaging parameters	1
corresponding 3D poses	1
high-level (dance genre	1
mid-levels (human poses and bodypart movements)	1
low-level (raw images, image sequences	1
hierarchy of information	1
comparable or higher results	1
detailed segmentation map	1
local 3D context information	1
topology-preserving graph-to-grid mapping	1
2D image space	1
local patterns	1
effective recognition rate	1
eigenfaces of the provided images	1
face landmark points	1
computational geometry	1
Linear Algebra	1
stated flaw	1
published research	1
significant investment of time and efforts	1
longer life	1
reference signal	1
extremely small	1
instance quantity	1
variety of event types	1
sample scarcity	1
event prototypes	1
robust sentence encodings	1
better prototypes	1
diverse appearance and shapes	1
global intensity	1
chest CT images	1
imaging characteristics	1
improvement of 6% mAP	1
different amounts	1
realistic sensor model mapping	1
real LiDAR dataset	1
existence of paired data	1
monolingual BERT -based on Russian data	1
novel tracker performance	1
high real-time (33FPS) performance	1
template accuracy	1
interval updates	1
long-term memory ability	1
tracking efficiency	1
track 2	1
micro-average F1-score of 0.8391	1
track 1	1
micro-average F1-score of 0.9105	1
shared task data	1
track 1)	1
high-dimensional space	1
time period 03/09/2001-29/10/2020	1
different model orders	1
Geometric Harmonics	1
original high-dimensional space	1
embedded time series	1
embedded dynamics	1
F-score of 79.97{\%} (strict)	1
Sub-task 1 (NER )	1
F-score of 86.76{\%}	1
best run	1
highest score	1
mention	1
potential entity mentions	1
target span	1
forward- and backward-context of bidirectional LSTM (Bi-LSTM ) output	1
surrounding semantic information	1
concept unique identifiers (CUIs)	1
multi-domain distributions	1
synthesized target domains	1
data availability	1
mid-ranked	1
third and fourth positions	1
Graded Word Similarity in Context (GWSC)	1
compression rates equal to 2-bit and 1-bit	1
$1\times1$ convolution	1
relatively minimal loss of accuracy	1
low bit quantization rates	1
computational savings	1
compression ratios	1
modern CNNs	1
workhorse	1
$1\times1$	1
extensive computational resources	1
1-shot and 5-shot settings	1
utterance distribution	1
intent label	1
existing intents	1
physiological features	1
players' burnout or fatigue detector	1
73.5% accuracy	1
88.3%	1
ROC AUC score 0.706	1
fixed time	1
22 matches	1
future encounter	1
in-game logs	1
lifespan	1
in-game mechanics	1
in-game data	1
precision and recall of 95.29% and 89.01%	1
precision and recall of 94.60% and 80.21%	1
detected signs	1
intersection over union loss	1
L1 term	1
Tversky loss function	1
stable reference voltage	1
mathematical calculations	1
value between the two	1
value at its output	1
0.1	1
earlobes voltage	1
0 V.	1
two points	1
reference potential	1
accuracy of 0.1	1
electric potential	1
electrical noise	1
network noise	1
significant distortion	1
50% energy reduction	1
1% accuracy loss	1
65% multiplication operations	1
various bit-widths	1
precision/accuracy and power consumption	1
better tradeoff	1
practical power reduction	1
floating-point numbers	1
input data and weights	1
dropout ratio	1
correct relative importance	1
relative importance of hyper-parameters	1
similar relative importance	1
different hyper-parameters covariate levels	1
hyper-parameters relative importance	1
LSTM hyper-parameters	1
distinct conditions	1
default settings	1
three important new observations	1
time-varying fairness	1
when	1
transparent explanations	1
70.30% and 64.38%	1
subtask 1 and 2	1
23.01% and 22.95%	1
task data	1
fine representation and performance	1
lengthy	1
technical report	1
fragment text level	1
appropriate hyper-parameters	1
F1 score of 0.24	1
variant of 1 Dimensional Convolutional Neural Network (Conv1D) hyper-parameters value	1
single PLM	1
various latency constraints	1
tiny PLMs	1
tiny sizes	1
quarter of the intermediate dimension	1
hidden dimension	1
default setting of architecture hyper-parameters	1
first out of 10	1
-0.38 TER and +0.8 BLEU)	1
lower but statistically significant gains	1
baseline up to -5.3 TER and +8.23 BLEU points ranking second out of 11	1
neural outputs	1
MT outputs	1
PBSMT subtask	1
automatic evaluation metrics	1
raw MT output	1
better balance of Specificity and Recall	1
better AUC scores	1
pathology whole slide images (WSIs)	1
random patches and labels	1
mean average precision	1
measurement	1
desired bit length	1
correlation coefficients	1
label vectors	1
projections	1
single-labeled images	1
global statistics	1
high-dimensionality	1
maximum inter-class variance	1
minimum intra-class variance	1
low dimensional optimized feature space	1
9,000 SGD updates	1
many as 600 classes	1
state-of-the-art continual learning performance	1
PLN	1
backward pass	1
default tendency	1
18.7% in the CQA datasets	1
maximum improvement of 13.1%	1
impacting factors	1
data quantity	1
Many impacting factors	1
pretrained weights	1
macro F1 score of 68.82% gaining 7.47% over the score	1
macro F1 score of 74.85%	1
expression level	1
absence	1
1.4 million	1
labelled one	1
raw one	1
ranking 16th of 85	1
language habits	1
75.25% for meters	1
recognition rates reached 93.6% for dials	1
100.0% F1-score	1
shared upon request	1
850,000 readings	1
type of meter readings	1
less rich	1
model's robustness	1
larger margin	1
relatively balanced distribution	1
scarcity of labels	1
phonetic similarity characteristic	1
search keys	1
2nd and 3rd	1
terms information	1
biomedical words	1
accuracy percentage of 99.25\%	1
different activation functions	1
z-score or norm L2	1
25-seconds time frames	1
thoughts, actions, and emotions	1
statistics of extracted features	1
threat detection false alarm rates	1
Faster R-CNN losses	1
hand-collected data	1
supervised loss function	1
superficial characteristics	1
minimal cost	1
state-of-the-art result (95.95\% f-measure)	1
character, subword, and word levels	1
different input features	1
long-range context	1
WeightedF1-Score	1
minority performance	1
greater uniformity	1
security risks	1
non-stationarity	1
skewed response distribution	1
off-the-shelf	1
unseen concepts	1
concept coverage	1
two separate outputs	1
following link https://iplab.dmi.unict.it/EGO-CH-OBJ-UDA/	1
considered settings	1
real and synthetic images	1
significant drop in performance	1
costs	1
lot of times and high costs	1
large quantities of labeled data	1
difference character embeddings	1
original feature	1
refined feature	1
feature aggregation and weight allocation	1
class mask	1
coarse segmentation result	1
coarse-to-fine paradigm	1
distinctive class representation	1
trade-off between performance	1
one example	1
pairs similarities	1
new attack-class (out of many)	1
limited number of examples	1
high false-positive rates	1
significantly less accurate	1
sufficient volume of data	1
time-window	1
significant volumes	1
context and temporal features	1
fine temporal information	1
high frame rates	1
fast pathway	1
low frame rates	1
slow pathway	1
single frame rate	1
frame rates	1
different settings	1
background, camera motion	1
human activities	1
:https://github.com/open-mmlab/mmdetection	1
ranking 1st	1
test-challenge split	1
mask AP	1
38.4 and 1.5 improvement	1
complementary features	1
limited gain	1
absolute gain of 4.2% accuracy	1
universal representations	1
token-level cross entropy	1
SOTA \(F_{1}\)-score from 97.81 to 98.17	1
78.50 to 80.42	1
NDA \(F_{1}\)	1
flat layout	1
baseline RoBERTa	1
coordinates	1
language semantics	1
layout features	1
local semantics	1
non-trivial layout	1
linear connections	1
NDCG of 0.0315	1
LightGCN vs. 0.0442	1
recall of 0.0411	1
smooth ODE solutions	1
NODE regime	1
linear GCNs	1
linear GCN concept	1
lenient match	1
0.904 (95% CI, 0.896-0.902)	1
macro F1 scores equal to 0.876 (95% CI, 0.896-0.902)	1
221,356 tokens	1
9,685 sentences	1
clinical notes and pathology reports	1
3 million	1
patients' clinical notes and pathology reports	1
2010 to 2020	1
texts data	1
pre-training Bidirectional Encoder Representations	1
relative improvement of 33% to 50%	1
effectiveness of our CP Representation	1
CAM s.	1
object-region relations	1
CAM s	1
three regularization functions	1
original CAM	1
baseline CAM	1
greater than or equal to the information	1
CAM	1
information of the sum	1
outputs of Class Activation Map (CAM )	1
precise clinical labels	1
less dependency	1
available training data	1
architectural parameters	1
terms of performance and run-time	1
AUC of 98.5%	1
56% relative improvement	1
834h in duration	1
large amount of weakly labelled data	1
2.6% F1	1
90.4(F1)	1
95.924% F1-Score	1
official best result	1
range from (88% to 96%)	1
questions similarity	1
Semantic Question Similarity	1
satisfactory run-time speed, accuracy and energy-efficiency	1
signal interpretation	1
multiple features	1
time-dependency	1
coarse EEG signals	1
coarse results	1
aspects of similarity	1
$786$\% speed-up	1
negligible cost	1
auto-generated soft pseudo-labels	1
less accurate	1
shared label	1
multilingual knowledge	1
discriminative brain representations	1
classification accuracies in the range of 12.62% - 53.99%	1
exemplars (72 classes)	1
cross-subject of 66.81% and 27.08% for categories (6 classes)	1
total of 72	1
50,000 EEG trials	1
feature representation space	1
response image stimuli-related information	1
Event-Related Potential (ERP)-Long short-term memory	1
erroneous predictions	1
similar spatio-temporal trajectories	1
gold entity spans	1
drop of overall accuracy	1
two competition metrics	1
long-tailed relationship distribution	1
object-specific edge information	1
objects and object-object relationships	1
improvement of 3 points	1
existing baseline semantic segmentation results	1
dramatic improvement of 20.4% absolutely	1
3 points	1
many overlapping instances	1
large deformations	1
complex layering	1
trainable end-to-end	1
specific trajectory	1
fixed position	1
minimum update rate of 500 Hz	1
arbitrarily apart	1
clipped surrogate objective	1
$A$ is the advantage	1
condition$A(\frac{\pi}{\mu}-1)\leq0$	1
policy $\pi$	1
policy gradientobjective	1
fundamental property	1
LB Enhanced	1
modest additional computational overhead	1
LB Improved	1
four new DTW lower bounds	1
constant with respect to window size	1
series length	1
linear with respect	1
worst case computational complexity	1
LB Improved and LB Enhanced	1
Two recent lower bounds	1
useful trade-off	1
range of different trade-offs between tightness and computational efficiency	1
Many alternative lower bounds	1
poor matches	1
lower bounds	1
high computation time	1
vanishing gradient problem	1
low expressive power	1
shallow structure	1
reality	1
future trend	1
well selected medians	1
large scope	1
general trends	1
basic statistics	1
superior interpretability	1
prediction effectiveness	1
large-scale real-world data	1
mastery	1
knowledge state matrix	1
student's integrated state vector	1
Markov property	1
encoding of each exercise's content	1
integrated vector	1
student's state	1
exercise contents	1
student's records	1
primary goal	1
student performance prediction	1
student performance	1
precise predictions	1
exercise content	1
knowledge concepts	1
exercising records	1
e.g., scores	1
14.28%	1
5.93% and	1
5, 20 and 50 shot	1
significant improvements in accuracy	1
highly varying dissimilarity	1
score-based metric space	1
pre-softmax classification scores	1
classification scores	1
good initializations	1
+2.5% additional points	1
TI and SRL of ~1%and~3.5% points	1
target predicate	1
production grammar rule	1
Target Identification (TI), FrameIdentification (FI), and Semantic Role Labeling (SRL)	1
LIGAS	1
Around 57%	1
prediction confidence	1
strong positive relationship	1
Correctly classified sentences	1
around 88% to 100%	1
Constituency Parse Tree (CPT)	1
Linguistically Unacceptable (LUA) sentences	1
significantly smaller	1
Linguistic Acceptability criteria	1
Layer Integrated Gradients Attribution Scores (LIGAS)	1
Inception Score (IS)	1
27.9\% and 41.6\%	1
Top-5 accuracy	1
traditional metrics	1
Classification Accuracy Score (CAS)	1
labels on real data	1
class labels of real data	1
variational autoencoders	1
number of model classes	1
heuristics such as Frechet Inception Distance (FID)	1
nearly photorealistic samples	1
{\it similar}	1
privacy noise}.	1
clients' transmitted model updates	1
state of the art result	1
47 epochs	1
96.12% accuracy	1
50 Basic, 10 Numerals	1
84 classes	1
trainingoccurs fast	1
input image sizes	1
OneCycle Policy	1
lesser iterations	1
BLEU score of 12%, 11%, and 6%	1
LSTM based OpenNMT	1
parallel data scarcity	1
4.9 BLEU points)	1
virtual sentences	1
two vicinity distributions	1
vicinal risk	1
61.08{\%}	1
81.95{\%} of subtask A	1
input formats	1
subtask A	1
majority of test cases	1
terms of precision, F1 score and Area Under Curve (AUC)	1
original dimension	1
two randomly chosen vectors	1
corresponding randomly interpolated data points	1
double size vector	1
inputs and outputs of traditional SMOTE	1
n different classification results	1
n different synthesized in-stances	1
different times	1
even imbalanced classification results unstable	1
synthesized data	1
almost all out-of-sample periods	1
CVaR, VaR, Sortino ratio, Rachev ratio, and STARR ratios	1
downside deviation	1
varying out-of-sample time line of 3, 6, 9, 12 and 24 months	1
period of 6 years from April 2014 to March 2020	1
Empirical performance	1
financial ratios	1
PCA -SPO(A)	1
former extracted ratios	1
SSD criteria	1
communalities	1
dominant ratios	1
sector wise over a period of 10 years	1
liquidity, solvency, profitability, and valuation	1
four categories of ratios	1
well known financial ratios	1
total of 11	1
final optimal investment	1
dominant financial ratios	1
value investment	1
three standard image classification problems	1
stochastic gradient descent trajectories	1
theoretical work	1
training error below a given threshold	1
norm ball	1
non-zero critical points	1
every differentiable critical point	1
global minimizers	1
weight decay	1
ReLU non-linearities	1
loss surface	1
10{\%}.	1
1st among 22	1
correct warrant	1
contradicting claims	1
two lexically close warrants	1
two challenging factors	1
representative samples	1
imbalanced subset	1
relevant data	1
abundance of available data	1
data privacy issues	1
numerous modalities	1
inter-sentence overlapping ratio	1
diverse abundance of context	1
inter-sentence context	1
rich training signals	1
fine-grained annotations	1
various forms	1
consistent and complete syntax	1
OpenVINO Training Extensions	1
minimal adaptations	1
existing training code	1
original accuracy	1
sparsity, quantization,	1
13.1% error reduction	1
1.3% absolute improvement)	1
highest error reduction of 5.8% on F1	1
one final passage	1
Face Detection Dataset andBenchmark (FDDB)	1
high degree of variability	1
strong illumination	1
extremely lowresolutions	1
facedetection problem	1
3D facial model construction	1
facialexpression recognition	1
task-oriented syntactic information	1
previous SOTA performances	1
sentiment-word-oriented	1
induced tree	1
induced trees	1
sufficient syntactic information	1
ABSA performance	1
polarities	1
data-efficiency on average	1
curiosity-based intrinsic rewards	1
standard Hindsight Experience Replay	1
imaginary data	1
shaped reward signals	1
model-free counterparts	1
improved data-efficiency	1
one user	1
ground-truth data	1
one XAI method	1
consistent progress	1
gold set of features	1
images and textual interpretations	1
attentions	1
commonality	1
multiple frames of features	1
all/any possible attention(s)	1
content or usability	1
thestate-of-the-art result	1
one prediction	1
number of tags	1
previousseveral tags	1
current tag	1
current token	1
longer distance dependencies	1
thetag dependencies	1
neighboring tags	1
current tokenindependent	1
competitive performance of about 10% improvement	1
person-specific calibration	1
eye anatomical information	1
Gaze Estimation (FLAME)	1
strict constraints	1
anatomical differences	1
lack precision	1
line of sight	1
corresponding frozen head vectors	1
feature vectors (representations)	1
meta-initialization parameters	1
meta-initialization point	1
Akan Knowledge	1
CARLA Autonomous Driving Challenge	1
three out of the four tracks	1
least number	1
challenging traffic situations	1
document-level RE performance	1
progressively more global context	1
partially connected graphs	1
compositional and lexical information	1
42.1 points	1
boost between 2.2 and 2.7 points in F1 score	1
lexical semantics (surprisal and antonymy)	1
compositional semantics (negation and Semantic Role Labeling)	1
basic arithmetic (counting phrases)	1
picture of what type of knowledge	1
synchronization overhead	1
memory footprint low	1
single-machine accuracy	1
small amount of edge and vertex information	1
multiple partitions	1
lost information	1
graph partitioning boundaries	1
accuracy problems	1
training inputs	1
i.i.d)	1
independently identical distributed	1
memory problems	1
intractable	1
F1 score of $94.53\%$.	1
superior configuration	1
$4,305$ patches	1
$79	1
approximately $12\%$	1
tissue glass slide images	1
different types of design problems	1
MLA architecture	1
additional computational costs	1
intermediate complexity	1
high-dimensional	1
MLAs accuracy	1
model accuracy and robustness	1
benchmark examples	1
model parameters and hyperparameters	1
big datasets	1
design variables	1
complex interrelations	1
7.7% increase in BLEU score	1
71.3% reduction in inference time	1
73.1% reduction	1
theoretical analysis of FARL	1
astonishing results	1
independently or sequentially actions	1
smaller components	1
evaluation metrics LPIPS, SSIM and PSNR	1
visual superiority	1
MIG scores	1
disentangled video representations	1
latent generative factors	1
predicted pose representations	1
low dimensional pose representations	1
content and low dimensional pose	1
high dimensional video frames	1
high dimensional nature	1
bidirectional encoding	1
test targets	1
positive, negative"	1
aclassification accuracy of 93.9%	1
~11%	1
aclassification accuracy of 97.95%	1
normalized feature vectors	1
SAT-4 and SAT-6	1
multiple class labels	1
thehigh variability	1
33%, 31%, and 47%	1
ID switches	1
short-term motion prediction	1
short-term motion estimates	1
predicted trajectory forecasts	1
non-linear trajectories	1
objects' locations	1
short-term estimations	1
objects' current and future trajectories	1
word-level features	1
syntactic, semantic and word sense knowledge	1
significantly improved results	1
94%	1
substantial loss of performance	1
growing computational cost	1
$+1.6$ BLEU improvements	1
robust neighborhood-enhanced sign representation	1
two distinctive characteristics	1
direction and distance unaware	1
absolute position encoding	1
sign gestures	1
temporal semantic structure	1
sign video representation	1
long-term dependency	1
performance and cost	1
low GPU memory	1
smaller amount of training data	1
less computing resources	1
language specificity	1
independent Bernoulli entries	1
best spectral concentration bound	1
bounded degree	1
sparse case	1
regular the DSBM	1
much	1
sufficiently smooth	1
DSBM	1
improved error bounds	1
dynamic case	1
static case	1
expected degree	1
0.2477 F1_all_per_sent	1
72.57 localization accuracy	1
Activitynet 2021	1
grounding results	1
event descriptions	1
whole system performance	1
complexity of each module	1
grounded or faithful a description	1
lengths and directions of bones)	1
layers and input samples	1
number of relevant incomplete kernel matrices	1
missingkernel matrix entries	1
algorithm efficient interms of time and memory	1
E-step andthe M-step	1
theobtained estimates	1
model matrix	1
missing entriesof the kernel matrices	1
kernel matrixcompletion	1
notions	1
multiplekernel matrices	1
several incomplete kernelmatrices	1
heterogeneous form	1
precision and execution time	1
target's heading	1
cyclist's orientation	1
11,103 images	1
20,229 cyclist instances	1
performance comparison	1
future trajectory	1
good notion	1
cyclists' orientation	1
largest number	1
event modelingover concept space	1
textual event query	1
event categorieswhile	1
tags	1
world'slargest manual	1
4,876 concepts	1
realistic occlusion	1
upper half	1
enriched media experiences	1
Facial expressions	1
test stage	1
F-1 score	1
properties and potential impacts	1
claims	1
automatically extract features	1
Natural Language Processing (NLP) and the Time Series Classification (TSC) domains	1
automatically extracting key features	1
user habits	1
ISWC and WWW conference publications	1
human-annotated ground-truth OCR annotations	1
object-object, object-text and text-text relationships	1
text-visual reasoning capacity	1
poor text reading ability	1
Optical Character Recognition (OCR) tokens	1
high acceleration factors	1
prior-information	1
less than half a second	1
acceleration factor of 16	1
0.939 $\pm$ 0.008 and 0.957 $\pm$ 0.006	1
6.25~\% of the k-space	1
average SSIM	1
higher similarity	1
reconstructed dynamic SR results	1
different parameters	1
3D dynamic data	1
high resolution dynamic images	1
required scan-time	1
considerable ratio	1
distribution of source data	1
higher possibility	1
new state	1
averaged 1.68~3.36 times parameters	1
shared point-knowledge	1
rank of 33rd, 54th and 52nd out of 103, 75 and 65	1
Macro F1 score of 0.7594, 0.5378 and 0.4588 in Task(A,B,C)	1
offensive and not offensive	1
3.1%)	1
4.5%)	1
2.4%error rate	1
image-relatedquestions	1
1st, 2nd, and 3rd	1
weighted-average F1 scores of 0.97, 0.77, and 0.72	1
MSE and MAE	1
optimization details	1
transposed convolutions	1
upsampling block	1
dilated convolutions	1
perspective view	1
severe occlusion	1
97% of their performance	1
training convergence	1
parameter and structure knowledge	1
token information	1
discriminative token relations	1
token hard dropping	1
token similarity	1
token number	1
two orthogonal directions	1
exhausting token-to-token comparison	1
huge computation burden	1
accuracy of 84.00% ,80.66%, and 94.00% on these labels	1
6.66%,3.00% , and 1.33%	1
one, two, or all three labels	1
Matthews Correlation Coefficient	1
important metrics	1
accuracy, precision, and f0.5	1
either normal or abnormal	1
several downsides	1
approximately half	1
abnormality of morphological characteristics	1
GPU memory budget	1
maximum number	1
fast as with four	1
GPU energy consumption	1
larger batch size	1
footprint reduction ratios of 1.89X on average and 3.13X maximum	1
GPU memory footprint	1
layer specifics	1
recomputation overhead	1
memory benefits	1
total execution time	1
total memory footprint	1
memory bottleneck	1
profiling results	1
GPU memory capacity	1
Hamiltonian Monte Carlo (HMC)	1
intractable hyperparameter posterior	1
\textit{Fully Bayesian Gaussian Process Regression} (GPR )	1
marginal likelihood yielding fixed point estimates	1
mean and the covariance function	1
generatedclasses	1
average MS-SSIM of 0.14	1
mean MS-SSIM scores	1
relative increase of 7.8%	1
inception score	1
Inception-Score	1
thediscriminability of the generated images	1
structural coherence	1
visually pleasing results	1
content loss	1
Adaptive Instance Normalization (AdaIN) and Whitening and Coloring Transform (WCT)	1
relations of our formulation	1
encoders	1
state-of-the-art Frechet Inception Distance (FID) scores	1
consistent and considerable improvements	1
unconditional GAN	1
original distribution and model distribution	1
Jensen-Shannon (JS) divergence	1
original GAN	1
distribution of the augmented data	1
specific image features	1
image representation and class attributes	1
compatibility function	1
word error rate (WER) relative reduction of 7%	1
user provided structure	1
lexical contextual cues	1
sentence-wise	1
advanced retrieval performance	1
physicians' tasks	1
BERT or PubMedBERT embeddings	1
medical decisions	1
scientific proof	1
Intermediate supervisions	1
input and target poses	1
coarse to fine scale	1
fine to coarse scale	1
pose prediction	1
abstraction level	1
set of poses	1
dynamic relations	1
unique referent	1
optimal anaphoric referent	1
Cognitive plausibility	1
syntactic , semantic , and pragmatic knowledge	1
RGB and depth based modalities	1
skeleton-based predictions	1
skeleton features	1
subject-invariant and background-invariant nature	1
limited and noisy data	1
new state-of-the-art of 73.9% unweighted accuracy (UA)	1
acoustic and linguistic knowledge	1
8 times more data	1
low as 125	1
67.15{\%}	1
65.06{\%} F-score	1
query and a sentence	1
various medical symptoms	1
similarity or relatedness	1
clinical jargon	1
domain-specific challenges	1
specific clinical queries	1
increasing amount	1
classical counterparts	1
probabilistic ranking functions	1
particular query	1
variety (wide range)	1
temporal-differencing (TD) error and an episodic memory	1
/out environment reward)	1
DRL in RL setting	1
stored data)	1
latent factors ofusers and items	1
intractable distributions	1
users and items	1
better latent representations	1
matrix sparsity	1
prior of latent factors	1
poor latent representations	1
users' latent factors	1
margin of 10-22 {\%} weighted F1 absolute	1
many invalid outputs	1
paraphrasing results	1
non-pretraining and pre-training settings	1
new state-of-the-art BLEU scores	1
hypothesis space	1
locality assumption	1
whole document	1
single sentence	1
relative improvement up to 14.1%	1
high discriminative features	1
rich image information	1
high discriminability	1
Top DropBlock	1
various extreme changes of view	1
external dictionary information	1
sequence context features	1
important sequence information	1
traditional character representation ability	1
machine translation performances	1
+0.97 to +1.94	1
+0.8 to +1.5 of BLEU	1
small quantity	1
configuration 2	1
configuration 3)	1
unconstrained)	1
large quantity of external monolingual data	1
constrained)	1
performance under three configurations	1
multi-view and comprehensive retrieval results	1
feature-level and semantic-level	1
negative sample interactions	1
different feature characteristics	1
resembling goal	1
eBERT model's performance	1
input in at most 0.2ms	1
enormous size	1
low-latency	1
new state-of-the-art benchmark results	1
much as 2.5 BLEU	1
baseline 6-layer counterparts	1
12 decoder layers	1
encoder layers	1
60	1
terms of floating-point operations (FLOPs)	1
77.3%	1
competing performance	1
2.82% trainable parameters	1
3 dB in PSNR and 0.036 in SSIM	1
high resolution HSI	1
performance, efficiency (training and inference time)	1
2D measurement	1
relative WER between 1.6% and 9.1% and a slot labeling F1 score improvement of 4% over non-contextual baselines	1
user provided on-the-fly speech patterns	1
sharp nearby, fuzzy far away problem	1
forms of contextual information	1
turn based context history	1
powerful predictor	1
high configurability	1
data I/O, preprocessing, data augmentation	1
significant gain	1
every $k$ layers	1
PKD-Skip	1
multiple intermediate layers	1
last layer	1
resource hunger	1
slower per epoch	1
1.2% of its size	1
86% of the performance	1
diminishing returns in performance	1
within and across families	1
embeddings' performance	1
trade-off between performance (predictive & run-time)	1
non-Gaussian assumptions	1
degenerate likelihood	1
less pairwise mutual information	1
dipole amplitude	1
dipole locations	1
empirical spectral covariance matrices	1
sum of divergences	1
negative log-likelihood	1
Gaussian assumption	1
stationary Gaussian time series	1
non-Gaussian	1
signal matrix	1
explicit morphologicalinformation	1
itsmorphologically rich POS tag	1
large vocabulary sizes	1
L2R and R2L translations	1
\textbf{agreement regularization} term	1
interactive history	1
helpful target information	1
L2R translation quality	1
novel \textbf{D}ynamic \textbf{I}nteraction \textbf{M}odule (\textbf{DIM}	1
future (right) semantics information	1
Top-1 localization error	1
$37.69\%$ and $48.81\%$	1
distinguish ability	1
batch sample level	1
feature-level representation	1
additional hyper-parameters	1
background contents	1
image category labels	1
classification and localization results	1
high-performing demonstrations automatically	1
expert human performance	1
mean score of almost 60k points	1
zero	1
strictest definition of superhuman performance	1
human world record	1
max performance of nearly 18 million	1
mean of over 650k points	1
almost 4 times the previous state	1
mean of over 43k points	1
available means	1
promising state	1
intrinsic motivation	1
totally convolution-free	1
natural language description	1
training and test times	1
1.2--67.8x speedup	1
3.1 percent points better ROC	1
low bias	1
unit sphere	1
uniformly and independently	1
set of random unit vectors	1
latency as low as 45ms	1
minor accuracy loss	1
7.8x speedup	1
resource and real-time specifications	1
gradient formula	1
advantage-policy plane	1
gradient of the VPG objective	1
VPG objective	1
F0.5 of 48.2	1
GLEU of 62.4	1
F0.5 of 58.3	1
LR input	1
node feature representations	1
brain ROI (node)	1
identity feature vectors	1
original node features	1
brain connectivity strength	1
nodes have no features	1
low-dimensional space (encoding and decoding node attributes or sample features	1
samples and node features	1
low-resolution graphs	1
i.e. parcellation	1
higher resolution (HR)	1
benchmark results	1
boost	1
even more pretraining	1
clear benefit	1
provided embeddings	1
small amount of additional pretraining	1
motion	1
noise level up to 0.8	1
average accuracy close to 90%	1
46.5 s into future	1
useful early-warning information	1
Real-time motion prediction	1
13.4% and 19.4% over the baseline in day and night images	1
paired thermal and color images	1
night orin bad lighting conditions	1
fine-tuning BERT	1
perceived translation quality	1
pronoun choice	1
critical errors	1
text's meaning	1
important determinants	1
noises	1
individual event types	1
several general findings	1
strong correlations	1
{\em passage understanding} attentions	1
\em passage-to-question}	1
potential explainability	1
loss geometries	1
parameter selections	1
matching upper bounds under certain conditions	1
first lower bounds	1
relaxed assumptions	1
higher efficiency and scalability	1
approximate implicit differentiation (AID) and iterative differentiation (ITD)	1
inner-level solution	1
minimizer of a given loss function	1
inner-level problem	1
two classes of bilevel optimization formulations	1
local models (e.g., BiLSTM) and global models (e.g., CRF )	1
https://github.com/tensorflow/models/tree/master/official/.	1
72.9%	1
18.8%	1
15.7%	1
70.4% top-1 accuracy	1
spatial and temporal cues	1
unlabeled videos	1
spatiotemporal visual representations	1
i.e. 80.9% vs 78.3% in averaged Dice score, 4.35mm vs 11.59mm inaveraged robust Hausdorff distance	1
9th out of 22teams	1
rich context information	1
EEG classification accuracy and EEG loss function fitness	1
GD initializers	1
GD optimization performance	1
different randomized initial states	1
multiple scales of convexities	1
0% top-1 (0.5% top-5	1
speaker identity accuracy	1
dropout rate of 0.2	1
34% top-1 accuracy (51% top-5 accuracy)	1
speaker's identity	1
second derivatives	1
mAP of 98.6%, 81.3%, 77.9% and 22.3% with gains of 2.9%, 4.3%, 0.7% and 3.9% over the best competitors	1
tubelet proposal	1
tubelet proposals	1
next frame	1
start frame	1
localized action proposals	1
temporal contextual relations	1
complex variations	1
fewwords	1
'asked'	1
three evaluation metrics RMSE, MAPE and MAE	1
dynamic time-specific spatial relationships	1
dynamic graph structure	1
different pair-wise correlations	1
irregular non-Euclidean spatial correlations	1
static spatial relationships	1
fixed graph structure	1
complicated irregular non-Euclidean spatial correlations	1
user experiences	1
vehicle utilization	1
pre-allocate	1
Accurate Ride-hailing demand prediction	1
best prediction capability	1
enhanced performance	1
easily measured meteorological parameters	1
PE values	1
high rate	1
precise estimation	1
accurate performances	1
input parameters of T, RH, W	1
T, W and S	1
input parameters	1
Root Mean Squared Error, correlation coefficient and Mean Absolute Error	1
statistical indices	1
2011 through 2017	1
sunny hours	1
PE, temperature, relative humidity	1
meteorological data	1
precise estimations	1
multiple climatic factors	1
complex landscape geometry	1
simple topology	1
good local minimum	1
three landscapes of TEG characteristics	1
search trajectories	1
search time cost	1
2.3x reduction	1
improved search accuracy	1
effective and efficient guidance	1
TEG indicators	1
Trainability, Expressivity, Generalization	1
training-free indicators	1
limited properties	1
truncated training	1
in-depth interpretation	1
four different entity types	1
inter-sentence coherence	1
sub-domain specific	1
heavy reliance	1
multiple types and concepts	1
biomedical named entity recognition (BioNER )	1
growing amount	1
translation adequacy	1
1.36, 1.50, and 0.63 BLEU improvements	1
overconfidence degree	1
predicted probability	1
hallucination problem	1
next token	1
stronger representation ability	1
observed task specification	1
F1 score of 85.6$\%$ and 76.8$\%$	1
BERT base and BERT large models	1
entityness and entity type	1
performance advantages	1
uplink/downlink communication noises	1
O(t^2)	1
uplink and downlink signal-to-noise ratio (SNR)	1
O(1/T) convergence rate	1
convergence behavior	1
non-independent and identically distributed (IID) local datasets	1
communication noise	1
uplink and downlink communications	1
Danish NER	1
much more parameter and data-efficient	1
raw audio waveforms	1
loss-floor	1
audio waveforms	1
extremely large sequence length	1
-2gram TF-IDF features	1
four parts:patient/problem (P), intervention (I), comparison (C) and outcome (O)	1
clinical problem	1
specific clinical problem	1
interpretable PCA factors	1
sparsity and smoothness	1
discrete region of activation (spatial sparsity)	1
forms of structure	1
sparse and functional (smooth) aspects	1
moderate run-time	1
matching patterns	1
1 and 30%	1
artificially inserted missing values	1
six shares	1
similar properties	1
energy time series	1
jumps or constant shifts	1
total energy of gaps	1
10.88%, 15.34%, and 11.73% F1 score	1
92.55% F1 score	1
corresponding template scores	1
candidate span	1
source sequence and the target sequence	1
NER model parameters	1
provided parallel data	1
{``}constrained{''} conditions	1
models' generalization ability	1
soft pseudo labels	1
300K+ weak annotated images	1
20 datasets	1
enough data	1
extensive unlabeled data	1
new unseen scenario	1
restoration solutions	1
load-side loss	1
varying load marginal value	1
omniscience assumption	1
two layers	1
followers' responses	1
followers' response behaviors	1
minimum cost	1
center node	1
local topology	1
non-grid structure data	1
existing loss functions	1
different losses	1
Hard-Mining loss	1
existing loss function	1
harder examples	1
number of easy examples	1
high priority	1
Various loss functions	1
best performers	1
general superior performance	1
spatially heterogeneous pathological images	1
global long-distance dependencies	1
programmer's capabilities	1
average lemmatization accuracy	1
places second	1
highest average accuracy and f1 score	1
lemmatization and morphology tagging accuracy	1
cross-lingual information	1
fine-tuning multilingual BERT	1
exceptional evaluation performance	1
Crosslinguality and Context	1
LSTM and character embeddings	1
BLEU reward	1
dynamic unsupervised reward function	1
non-differentiable evaluation metrics	1
final evaluation metrics	1
settings of MML	1
limitation of information diversity	1
cross years	1
99.85% and 99.74% overall accuracies	1
Harmonized Landsat Sentinel data	1
years 2013 to 2016	1
high classification accuracies	1
measurement errors	1
temporal and spectral variations	1
angular distances	1
previously labeled data	1
year's crop map	1
present year's labeled data	1
unprecedented improvement	1
best f1-score of 0.95	1
word, character and lexical features	1
insufficient information	1
motion context	1
one future motion	1
useful observed motion information	1
crucial characteristics	1
future human motions	1
observed motion sequence	1
observed human motions	1
future motions	1
content-based information	1
local and global	1
additional contextual information	1
subtle extra computational overhead	1
feature level	1
feature grid and all featurelevels	1
topmost feature	1
information path	1
accuratelocalization signals	1
0.7%	1
0, 0.5, 1 three values	1
weight parameters	1
lossy quantization	1
almost no recognition performance	1
number of training datapoints	1
large-molecule energies	1
35000-fold and 4500-fold reductions	1
300	1
chemical accuracy (1 kcal/mol error)	1
thermalized geometries	1
greatly reduced wall-clock training times	1
combined RC/LR/RFC and RC/GPR /RFC	1
chemically intuitive groupings	1
MOB feature values	1
post-Hartree-Fock correlation energies	1
previous mask predictions	1
common performance degradation	1
neuron level	1
individual learning rates	1
optimal learning behavior	1
model initialization and learning rates	1
one-shot test runtime and performance	1
local segmentation masks	1
object detection task	1
test time optimization	1
minDCF of 0.1291 and 0.1313	1
third place	1
binary cross-linguality trial feature	1
speaker verification scores	1
differences in language and background conditions	1
intra-speaker variability	1
level of intra-speaker variability	1
absolute frequency positional information	1
subword representations	1
fasttext embeddings	1
F-measure of 58.89\%	1
inference time being 4.2s per processed scan	1
best single-model FROC performance	1
classifier branch	1
candidate generation and the False Positive Reduction (FPR) purposes	1
confusing	1
7th out of 48	1
30.25{\%} macro-averaged F-score	1
50% parameters and 53% FLOPs	1
structure information of input images	1
body structural information	1
four directions	1
spatial and temporal relationships	1
shortest path calculation	1
prediction reliability	1
significantly reduced travel distances	1
latest prediction states	1
unique strengths	1
blended plans	1
incurred travel distance	1
next sampling locations	1
overall prediction precision	1
relatively short travel distance	1
accuracy improvement	1
scientific knowledge	1
large amounts of labeled data	1
wide range of benefits	1
set of predefined classes	1
trends and challenges	1
realistic images	1
inverted code	1
structure of learned representations	1
one of the two inputs	1
two latent representations	1
linear interpolations	1
semantically mixed outputs	1
one key characteristic	1
good data representation	1
37.7% inference speedup	1
41.9% training speedup	1
7.8X parameter reduction	1
training iteration	1
number of Conformer layers	1
Layer Consistency	1
similar representing power	1
similarity of feature distributions	1
Layer Consistency (LC)	1
large parameter budget	1
prohibitively high computational cost	1
1.454 (1.918 for human	1
generated answers	1
phrase or a single word	1
https://github.com/kujason/avod	1
extents, orientation	1
reliable 3D object proposalsfor	1
multimodal featurefusion	1
crucial context	1
wrong spatial context	1
combinatorialrelations between objects	1
image level	1
S3E2's superiority and flexibility	1
semantic and syntactic relationships	1
syntactic and semantic relationships	1
opinion span	1
classifier's performance	1
AUC of 0.84	1
enough time	1
patient's health	1
SemEval 2012, Task 6 and SemEval 2014, Task 1)	1
classification performance of 76.7% mAP onHollywood2, 69.4% on HMDB51, and 93.6% on UCF101	1
entirevideo clip	1
dynamic behaviour	1
rich frame level features	1
arbitrary long video clipsbased	1
temporal semantics	1
end-to-endtrainable	1
CNN filters andfully-connected weights	1
network activations	1
video representation	1
Riemannian subgradient information	1
number of summands in the objective	1
finite-sum case	1
$\mathcal{O}(n+\sqrt{n}\epsilon^{-3})$ IFOs	1
online case	1
$\mathcal{O}(\epsilon^{-3})$ IFOs	1
incremental first-order oracle (IFO) complexity	1
Riemannian setting	1
Euclidean setting	1
proximal SpiderBoost	1
proximal SGD	1
R-ProxSGD and R-ProxSPB	1
nonsmooth function	1
significant improvement in accuracy	1
8% increase in accuracies	1
state-of-the-artaccuracy	1
compression and computational speed	1
3-4% improvements	1
inputbinarization-error	1
binarization tradeoff	1
significant improvementsin accuracy	1
layer-level granularity	1
energy and memory savings	1
largecomputational speedups	1
lower computational load	1
better localization accuracy	1
localization mode	1
average longitudinal speed of 36 m/s	1
1\%	1
relative translation error	1
localization on data	1
map saving feature	1
continuous localization accuracy	1
low driving speeds	1
map of visual features	1
reference	1
fusion systems results	1
high levelfeatures	1
acoustic conditions	1
stable efficiency	1
next-token	1
next-POS	1
two posterior probabilities	1
syntactic structure clues	1
one word	1
photorealistic details	1
simpler Mean Squared Error (MSE)	1
better loss	1
Structural Similarity (SSIM )	1
originalimage	1
decreased performance	1
images lesspleasant	1
Compression artifacts	1
certain demographics	1
least bias	1
unpublished and noisy field data	1
5{\%}	1
1.2{\%} in accuracy for published data	1
greatest average difference	1
.09 improvement	1
largest average difference	1
unpublished linguistic field data	1
published data	1
identical data	1
unseen observations	1
bound	1
reasonable representations	1
relatively complete and equally spaced	1
low dimensional representations	1
Longman Dictionary	1
undirected graphs	1
hops	1
noisy representation	1
two limitations	1
sequential context	1
Euclidean data	1
duplicate entities	1
several large KGs	1
different auto-regressive factorization order	1
plain vanilla policy gradient	1
algorithm's performance	1
limited exploration budgets	1
hyper-parameter dependencies	1
missing instance	1
previous and current frames	1
new mask probability	1
region ofinterest of the instance	1
original mask probability	1
thefull image	1
theprobability map predictor	1
mask probability map	1
appearance of current frame	1
maskprobability map	1
feasible initialization	1
regular MAML	1
high number of classes	1
number of output neurons	1
specific weight initialization	1
weight initialization	1
task-specific parameters faster	1
weight initializations	1
keyword annotations	1
65.6% mIoU	1
certain wrong assignments	1
attention information	1
single keyword (tag)	1
similarity features	1
salient instances (candidate objects)	1
image level keyword annotations	1
L2 norm	1
high responsiveness	1
index of visual features	1
perceived structure	1
aesthetic quality	1
improved prediction performance	1
structural features	1
count-down to song conclusion and meter markers	1
33% absolute improvement) languages	1
27% absolute improvement in Weighted Macro F1 score)	1
IOU 0.5	1
higher values of IOUs i.e. an accuracy of 100\%	1
Accuracy, Precision, Recall, and F1-Score	1
IOU (Intersection Over Union)	1
basis of object detection performance measure parameters	1
great extent	1
pose, scale	1
great level of difficulties	1
enough discriminating characteristics	1
biometric trait	1
strong demand	1
accuracy of 0.876, recall of 0.856 and F1 score of 0.855	1
judgment documents	1
accuracy promotion	1
high accuracy requirements	1
learnedrepresentation of 72.54%	1
lower accuracy (67.09%)	1
lower energy	1
89.9$\times$ faster training time	1
average 74.29%:	1
Similar trend	1
accuracy to 84.22% (1.55% higher than SVM	1
training benefitswhile	1
22.3$\times$ lower energy	1
26.8$\times$ faster	1
average accuracy (79.56% vs. 82.67%)	1
accuracy and/or computationalcomplexity requirements	1
chosen (or configured	1
10,000 bits	1
binary HD space	1
HD representationsusing	1
quantization based thermometer and Gray coding	1
$f$-MICL	1
effective $f$-divergences	1
data representations	1
uniformity	1
positive pairs	1
InfoNCE loss	1
58.71%	1
65.2% on Affect-Net	1
90.42% on RAF-DB	1
weight of eroded features	1
two different directions	1
output feature map named albino feature	1
certain affinity features	1
face variants	1
local contrast and color variations	1
human symmetry uncertainty	1
longer choice RT	1
hue, saturation	1
non-homogenous appearance	1
perfect geometric mirror symmetry	1
symmetry uncertainty states	1
problem of uncertainty	1
regular patterns	1
informative contents	1
$i$)	1
domain a given passage-question pair	1
$ii$	1
($i$)	1
computational loss	1
long-distance labeldependency	1
precedent entity information	1
outside label	1
transition information	1
outside tokens	1
entity tagging F-score	1
average 4.45% improvement	1
overall performance higher	1
corresponding semantic roles	1
Frame Semantics	1
Dialogue Acts	1
Dialogue Acts and Frame-like structures	1
GP	1
acceptance ratio	1
sampling)	1
difference w.r.t	1
input videos	1
appropriate hierarchical representations	1
temporal connections	1
discontinuity points	1
thehierarchical structure	1
corresponding description	1
input video	1
W6A6 quantization	1
low as W3A3 quantization	1
full-precision accuracy	1
W4A4, 2.6% on	1
1.3% improvement	1
quantizaion-friendly	1
good initialization	1
care-fully coordinated	1
Quantization -aware Knowledge Distillation (QKD)	1
short-coming	1
already reduced representation power	1
memory and power consumption	1
vascular segmentation	1
visual perceptive image quality	1
Reconstruction metrics	1
improved reconstruction metrics	1
mean square error, mean-SSIM	1
subset	1
vessel segmentations	1
voxelwise mean-error	1
normal cerebrovascular structure	1
vessel abnormalities	1
slot labeling F1 improvement of 6.4%	1
content WER reduction of 19.2% on	1
cross utterance context carry over	1
content word robustness	1
cross utterance contextual cues	1
monetary transactions	1
Automatic Speech Recognition (ASR)	1
five tasks out of six	1
better user visual experience	1
thousands of pictures	1
results (image contents	1
SVM and SIFT descriptors	1
perceptual perspective	1
perceptual viewpoint	1
certain number of images	1
visual experience	1
https URL	1
safe operating voltage	1
safe and correct	1
timing	1
difficult aspects	1
internal representations	1
highly structured	1
competitive in terms of accuracy	1
Deep Gaussian Layer-wise loss functions (DGLs)	1
transferable properties	1
panoptic annotations	1
final panoptic segmentation output	1
fine and contextual features	1
semantically rich multi-scale features	1
general scene semantics	1
best existing models	1
test error of 2.41% with only 1.52M parameters	1
4.0 GPU hours	1
stochastic encoding architecture parameters	1
HyperNetwork	1
performance of 62.87 {\%} and 62.12 {\%}	1
character and word features	1
predictions of values	1
inter-slot dependencies	1
turn level	1
session-level annotations	1
improvements in state tracking performance	1
causal, sequential prediction	1
excellent balance of model accuracy	1
inherent privacy risks	1
gain-loss ratios	1
probability of out-performance	1
measures of (i) mean and median out-performance	1
arbitrary action	1
future rewards	1
Q-value function	1
available execution actions	1
trading signals	1
limit order book	1
optimal actions	1
stringent model assumptions	1
energy efficiencycompared	1
40x and 11.5x higher	1
43x and 3x faster	1
powerdissipation of 41 Watts	1
2.52 TOPS	1
performance of 282 GOPS	1
theprediction accuracy	1
negligible loss	1
2x from quantization	1
20x(10x from pruning	1
LSTM model size	1
high total cost of ownership (TCO)	1
high power consumptionand	1
computation intensive andmemory intensive	1
higher prediction accuracy	1
drop-in replacement	1
original one	1
sentence pairs	1
97 sentences	1
8400 sentences	1
85.3% 10-fold cross-validation accuracy	1
mild AD conditions	1
definitive diagnosis	1
neurocognitive impairments	1
AreaUnder Curve (AUC)	1
baseline comparison	1
MTWLB, xDAWN, Common Spatial Pattern(CSP)	1
thediscriminative information	1
Event-related Potentials (ERPs)	1
detected class labels	1
real-time frames	1
low inference time	1
perfect balance	1
layer arrangements	1
re-adjusting filter sizes	1
lesser computational requirements	1
smaller weight size	1
camera view	1
reduced trainable parameters	1
higher segmentation Intersection over Unions (IoUs)	1
minimum number	1
abstract semantic information	1
comparable or better results	1
weighted multi-step transition probabilities	1
different edge type information	1
neighbour features	1
$51$ out of $57$ games	1
improved generalization guarantees	1
explicit invariance constraints	1
pretraining representations	1
costly supervised signal	1
best across all datasets	1
F1-score as our metric	1
bidirectionality	1
comprehensively	1
varying levels of difficulty	1
human and existing model performance	1
surge	1
considerable growth	1
enumerated instances	1
ruggednessand the expected runtime	1
standard BOA	1
PGM structure	1
iterationof BOA	1
solutionsample	1
optimal Bayesian network structure	1
results outperformstate-of-the-art significantly	1
temporal representation	1
three salient aspects	1
different questionsrequire different number	1
useful attention cues	1
2)motion and appearance information	1
imagescontaining richer information	1
three unique attributes	1
videotemporal structure	1
overall classification performance	1
systems more stability	1
machine translated data	1
small training data	1
sub-task A	1
conversion similarity	1
speech waveform	1
synthetic parallel data	1
fraction of the computational expense	1
state-of-the-art solutions	1
data-efficiency, performance, and speed	1
3D tasks	1
Relative 3D patch location	1
required cost	1
reference pattern	1
sample pattern	1
sample patterns	1
shape descriptors	1
Dynamic Time Warping (DTW )	1
element alignment properties	1
17/20 and 16/20	1
aggregation of predictions	1
13/20 and 14/20	1
syntactic properties of languages (L2V)	1
manually created language vectors	1
source and target languages (KL)	1
POS n-gram distributions	1
parser accuracies	1
empirical observation	1
every step	1
query relations	1
Mean Selection Rate (MSR) and Mean Replacement Rate (MRR)	1
lacking memory components	1
problem of incompleteness	1
demonstrably superior results	1
training performance differences	1
image model predictions	1
solely image input	1
word-lattice information	1
low data regime	1
performance equivalent	1
special delimiter [SEP].	1
simpler utterance representation	1
downstream SLU performance	1
multiple text alternatives (hypotheses)	1
dialog acts	1
Word embeddings	1
word meanings	1
less dependence	1
state of the art (orclose to) accuracy	1
sentence level tag informationthanks	1
past and future input features	1
first generalisation bound	1
generalisation and tasks similarity	1
closed form expression	1
Neural Tangent Kernel regime	1
three different granularities	1
document-level inference information	1
sentence-level inference information	1
entity-level information and sentence representation	1
entity-level inference information	1
abundant information	1
multi-granularity inference information	1
de-identification performance	1
distantly related auxiliary data	1
personal data	1
computational and optimization point of view	1
one for left-to-right decoding and one for right-to-left	1
bidirectional STR	1
robust output sequences	1
METEOR of 0.091	1
CIDEr of 92.4	1
gain in performance	1
significant representations	1
high-level semantic context	1
98.0% and 99.8%	1
advantages of them	1
description of it	1
trends of behaviors	1
normal behavior	1
continuous observation	1
i.e.~73%average overlap with ground-truth	1
high localization accuracy	1
30% of all images	1
bounding-boxannotations	1
0.5 million images	1
theamount of returned annotations	1
quality estimate	1
Theprobabilistic nature	1
annotation smoothly	1
close up	1
side view	1
window appearance	1
even pixel-levelsegmentations	1
many more bounding-boxes	1
-box annotations	1
semantically relatedclasses	1
spatial ( n - gram ) information	1
comparable or even superior performance	1
rigorous evaluation	1
substantial number of parameters	1
area under theoperating characteristic curve (AUC) of 77.68% and 75.47%	1
trained Discriminator	1
seizure predictionaccuracy	1
labeledEEG signals	1
accuracy loss	1
least 100% lower	1
accuracy loss no more than 1.06%	1
14.9 times less bandwidth	1
different network conditions	1
tradeoff between bandwidth consumption	1
lightweight autoencoder	1
data privacy preservation	1
response latency	1
cloud bandwidth consumption	1
lower memory cost	1
Czech to English (0.6 BLEU)	1
0.5 BLEU)	1
extra positional embeddings	1
25 languages	1
hyper parameters empirically	1
probability of every similarity score	1
two semantic vectors	1
proper form	1
GloVe word vectors	1
two trick points	1
every dimension	1
every sentence	1
semantic vector	1
semantic vectors	1
semantic similarity score	1
various levels of label ambiguities	1
F1-score and 24.8% accuracy	1
absolute 0.159	1
refined results	1
linking ambiguities	1
cross-group correlations	1
label ambiguity challenge	1
within-group instance-label link annotations	1
group-level	1
instance --	1
supervision assumption	1
last year solution	1
encouraging progresses	1
1x to 4x magnification	1
accurate texture features	1
deep feature correspondences	1
queries and keys	1
LR and Ref images	1
Image Super-Resolution (TTSR)	1
Ref images	1
high-resolution (HR) textures	1
references (Ref)	1
image super-resolution (SR)	1
85,900 cities	1
search step	1
micro-average F1 score	1
69.93{\%}	1
hidden units	1
ELMo word embeddings	1
ULM successes	1
meaning our dream)	1
similar success	1
minimal amounts	1
surprisingly good performance	1
availability of transfer task training data	1
accuracy and compute resources	1
trade - offs	1
qualitative enhancements	1
feature distances	1
misclassifications	1
best reported numbers	1
12k and 1.5k labeled sentences	1
F1 scores of 64{\%} and 60{\%}	1
language boundaries	1
model expectations	1
features or gold labels	1
noisy videos	1
outlier elements	1
common signal	1
sensitive attribute information	1
opposite trend	1
knowledge-graph embeddings (KGE)	1
link prediction accuracy	1
node popularity	1
Knowledge Graph (KG) embeddings	1
applications of KG	1
model prediction errors	1
real-world robustness	1
gain of up to 3.14 BLEU score	1
additional feature	1
low false positive rate	1
normal working conditions	1
actual samples	1
generator-reconstructed data	1
potential latentinteractions	1
sensor's and actuator's timeseries independently	1
normal workingconditions	1
themultivariate time series	1
system behaviour	1
five scores	1
customized fuzzy-match score	1
RoBERTa [17]	1
sentence embeddings [7]	1
average word2vec embeddings [15]	1
three other similarity scores	1
question pairs	1
unnormalized and normalized similarity scores	1
direct answers	1
important relationship structure	1
learned embeddings	1
intrinsic difference	1
proximal information	1
item pairs	1
user-item interaction data	1
item	1
comparative evaluations	1
NLP designs	1
taxonomy	1
optimal performance and efficiency	1
efficient attention	1
greater efficiency and accuracy	1
data size challenge	1
nearly similar performances	1
moderate model sizes	1
contextsensitive convolutional filters	1
input sentences	1
closer mentions	1
trade-off between expressiveness and data requirements	1
natural language	1
additional objective function	1
modified input embeddings	1
model and system performance	1
experimental findings	1
labeling requirements	1
privacy risks	1
less than $10$ MB data	1
training time of 2 minutes	1
test-accuracy of up to 85%	1
weight updates	1
model convergence	1
users care	1
50% improvement	1
variety of realistic bipartite graph distributions	1
order ofmagnitude	1
number of	1
thecommunication cost	1
vertex programming abstractions	1
unsupervised DTW -preserving shapelets	1
user?s interpretation	1
link constraints	1
must link	1
limited amount of user knowledge	1
DTW properties	1
representation learning models	1
DTW -preserving shapelets	1
axioms of a metric	1
several similarity measures	1
sample duration	1
potential phase shift	1
SR results	1
real image super-resolution	1
recent success	1
domain consistency	1
bicubic down-sampling assumption	1
domain)	1
noise-free settings	1
low-resolution (LR) and the high-resolution (HR) images	1
competition ranking	1
first positions	1
task 12	1
potential generalization and cost benefits	1
training time, and total computational operations	1
code and task-specific metrics	1
total compute cost and prediction performance	1
different trade-off	1
small project-specific prefix vector	1
language model parameters	1
token representations	1
state-of-the-art status	1
current limitations	1
priming few-shot ability	1
set of parameters	1
few-shots	1
least amount of samples	1
significant degrees of variability	1
temporal coding	1
scores of good ones	1
bad proposals	1
basic WSOD	1
integrity	1
feature semantics	1
extended proposal	1
well-designed sequential order	1
different positions	1
boundary of initial proposals	1
extension ones	1
habit	1
insufficient integrity	1
instance classification problem	1
huge annotation costs	1
36.75% and 25.94% respectively)	1
42.05% and 32.24%	1
1-character and 2-character	1
1.1%-1.5% absolute difference	1
66% fewer	1
2.1% in Sentiment Analysis F1 score, 4.4% in NER F1 score	1
22% of FAQ Retrieval MRR metric	1
Hugging Face	1
virtual assistant data	1
amazing digital customer experience	1
increased interest	1
lowervalidation loss	1
course of one week	1
therelative complexity	1
highly parallel	1
amodel's ability	1
user-configured values	1
resulting distinct feature distributions	1
entity type level	1
separate cell state	1
highly different	1
handcrafted engineering features	1
Person, Location or Organisation	1
series of subjective tests	1
precisely determine free parameters	1
sensing capability	1
weather data	1
complex input-output relationships	1
Real weather data	1
multivariate multidimensional historical weather data	1
spatial and temporal characteristics	1
attention scores per weather variable	1
wind speed prediction	1
Reliable and accurate wind speed prediction	1
26% and 19%	1
underlying generalization problem	1
volatile behavior	1
\textit{unexpected changes	1
semantically and syntactically correct	1
BERT 's performance	1
BERT model's performance	1
different pretraining objectives	1
less than a minute	1
312K classes	1
half a million	1
one billion words in less than ten minutes	1
many orders of magnitude faster	1
average accuracy 96.33%)	1
Decision Tree (DT)	1
complex and high dimensions	1
combinatorial constraints	1
communication loads	1
hierarchical learning structure	1
better generalization capability	1
different aggregation levels	1
incoherent model performances	1
new/unseen data	1
limited scope	1
summary of model performances	1
analytical insights	1
complex node attributes	1
highest PMA	1
short inter-bust periods	1
long EEG bursts	1
36 weeks PMA	1
three EEG features	1
best computational efficiency	1
highest scores (Cohen's kappa =0.71)	1
-automatic agreements	1
95\% accuracy (kNN, SVM and LR)	1
36 - 41 weeks PMA	1
born after 28 weeks ofgestation)	1
visuallylabeled EEG recordings	1
36 weeks)	1
PMA $\geq$	1
preterminfants reaching term ages	1
35 weeks of post menstrual age (PMA)	1
EEG bursts	1
thesame domain data	1
90% of the accuracy	1
remaining 25%	1
secondbest performance	1
66% of experiments	1
models' performance loss	1
source domain (subject)	1
limitations and challenges	1
enough data foreach	1
dramatic performance drop	1
fair amount of labeled data	1
fourth best cased BLEU scores	1
second best BLEU scores	1
stable performance improvement	1
different segmentation models	1
WMT 2018	1
VGA-resolution images	1
3$\times$ faster	1
$4.78\%$ (AP at hard set)	1
wide range of compute regimes	1
state-of-the-art accuracy-efficiency trade-off	1
SHREC 2017	1
SPD matrix	1
3D coordinates	1
SPD matrices	1
coreference error	1
document-level translation performance	1
NMT abilities	1
translation draft	1
extra inputs	1
less-forgetting constraint	1
instance-level and distribution-level	1
auxiliary samples	1
insufficient target domain training samples	1
speech features	1
heavy class imbalance	1
e-WER	1
continuous variable	1
transcription and the speech signal features	1
WER	1
transcription	1
number of errors	1
Word Error Rate (WER)	1
BLEU and SimHash score	1
objective evaluationsuch	1
Named Entity Recognition (NER) information	1
thewriting style	1
BLEU scores of 24.58, 27.51, and 27.61	1
ROUGE-L F1 scores	1
improvement of about 40%	1
exact answer span	1
normalized probabilities	1
unbalanced OT	1
time shifts	1
new property	1
smooth variant of DTW	1
time samples	1
spatial differences	1
chronological order	1
chronological structure of data	1
spatial and temporal variability	1
un-supervised and language independent	1
morphological richness	1
technical terms	1
shortcut layers	1
different number	1
power spectral density and differential entropy	1
conditional Wasserstein GAN (cWGAN ), selective VAE (sVAE ), and selective WGAN (sWGAN )	1
generated data	1
EEG training data	1
second-order-masking level	1
visibility	1
Bernoulli distribution	1
semantic preservation aspect	1
irrelevant words	1
F1 = 0.83	1
1st in Tamil (F1 = 0.61)	1
1st in English (F1 = 0.93)	1
promising accuracy and efficiency	1
136 fps)	1
high speed	1
newly proposed shape jittering and shape scaling	1
finer and bigger training data	1
high resolutions	1
pose and illumination changes	1
intrinsic invariance	1
https://github.com/allenai/scibert/.	1
new state - of - theart results	1
suite of tasks	1
large - scale labeled scientific data	1
high - quality	1
thefinal recognition output	1
similarity metricbetween	1
RF signals	1
information over many time-steps	1
corresponding RF data	1
RF data	1
mankind's long-standing dreams	1
visual barrier	1
1'st place	1
three different continual learning scenarios	1
learning stability	1
baselines by a margin	1
UAV images	1
almost 80%	1
less than half a percent of oracle-provided labels	1
extremely rare	1
likelihood of being animals	1
CNN scores	1
CNN activations	1
manually labeled gound truth	1
52.32 and 45.25	1
previous level	1
longer word span	1
labeled bracketed F-scores of 75.46, 52.84 and 49.66	1
less than 1{\%}	1
pseudo-data and real world data	1
POS tag n-grams	1
windowed word n-grams	1
required amounts of training data	1
considerably more data	1
limited real training data	1
complex structure	1
multiple intents	1
individual customer utterances	1
low resource situations	1
bones information	1
results on-par	1
joints' coordinates	1
backbone results	1
inter-frame correlations	1
joint motion patterns	1
spatial and temporal dependencies	1
dynamic camera views	1
body scales	1
e.g. orthographic features	1
additional hand-crafted features	1
effective performances	1
generalized view	1
several open research issues and challenges	1
cutting edge solutions	1
VL multimodal problems	1
Visual-Linguistic (VL) multimodal problems	1
29th out of 38	1
45th out of 55	1
task at hand	1
number of senses	1
word length	1
n-gram frequency	1
social-interaction level	1
accuracy of 99.59%	1
output label predictions	1
98.96% classification accuracy	1
average increase of classification accuracy by 4.01%	1
two epochs	1
total of 483 responses	1
large set of training data	1
various performancebenchmarks	1
Cycleconsistency loss	1
outputis a denoised image or ground truth original image	1
noiseperturbations smoothly	1
artificially added sharp gradients	1
sparse, multi-scale measurements	1
sharp gradients	1
sparse observations	1
logistical restrictions	1
budget constraints	1
subsurface features	1
topography	1
perspective of pruning	1
\textbf{3.6s} and \textbf{79s}	1
initialization problem	1
poor indicator	1
supernet weights	1
fundamental properties	1
GRLagents	1
certain priors	1
obstacles	1
almost the same number of parameters	1
small performance drop	1
tasks and unseen data	1
near-state-of-the-art performance	1
2-D matrices	1
twelve points	1
F1 Score	1
improved performanceon	1
informative multimodalrepresentations	1
different variations	1
policy performance	1
current abstract state	1
reward shaping	1
supervisory signals	1
task relevant features	1
task completion	1
good-quality policies	1
limitations of DQN	1
transaction descriptions cost	1
manually labelled data	1
transaction	1
market needs	1
certain destination	1
highest Spearman's Rho and Mean Reciprocal Rank of 0.338 and 0.9622	1
input size limitations	1
F1 score of 0.893	1
F1 scores above 0.860	1
DS adverse events	1
related	1
positive (i.e., indication), negative (i.e., adverse events)	1
safety signals	1
significantly less training time and parameters	1
positive, negative and neutral polarities	1
discrete dataanalogue of DTW	1
semantically significantclusters	1
anytimeframework	1
unavoidable calculations	1
level of speedup	1
least an order of magnitude faster	1
provably identical results	1
expensive distance calculations	1
large fraction	1
upper and lower boundsto	1
Clustering time series	1
ever larger datasets	1
considerable degree of accuracy	1
RUL	1
Anomaly Detection (AD) and the Remaining Useful Life (RUL)	1
expert knowledge and data	1
spatial patterns	1
generic or ambiguous	1
values of the attributes	1
accuracy and good speed	1
hard negativeexamples	1
insufficient resolution	1
unsatisfactoryaccuracy	1
downstream classifierdegrades	1
-crafted and deep convolutional features	1
special topic	1
standard task metrics	1
user's query	1
different BERT variations	1
Persian text contextual information	1
\emph{linear speedup}	1
$\mathcal{O}(\epsilon^{-2.5})$ for two-timescale AC	1
best-known sample complexity	1
$\epsilon$ accuracy	1
sample complexity of $\mathcal{O}(\epsilon^{-2.5}/N)$ per worker	1
i.i.d	1
provable convergence guarantees	1
A3C -TD(0)	1
a.k.a. speedup	1
performance gain of parallelism	1
Frame Error Rate	1
improvement ofapproximately 40%	1
margin of separation	1
thetraditional Softmax	1
mentioned task	1
89.4% mAP	1
fractional anchors	1
beneficial features	1
hundreds of thousands	1
computational capacity	1
accuracy requirements	1
compression ratios ranging from 500x to 1720x and beyond	1
data features	1
significant network bandwidth costs	1
set of challenges	1
data privacy and computation challenges	1
spatial context information	1
several unique properties	1
fast and wide-spread popularity	1
high - level features	1
results of LET	1
crucial features	1
high - level lexical and syntatic features	1
gloss knowledge	1
much improvement	1
gloss (sense definition)	1
exact sense	1
relative improvement of 25%	1
average F-score of 61%	1
F-score of 48.44%	1
Global Vectors	1
time and human effort	1
large investments	1
professional medical terms	1
laymen medical terms	1
poor understanding	1
layman knowledgeable	1
specialized terms	1
82.75% in termof GAP@20	1
depth of 7 layers	1
frame-level features	1
various temporal modelingapproaches	1
pre-extracted visual and audio featuresinstead	1
difference of 0.0002 AP	1
MDSRx4 enhanced images	1
nearly identical results	1
little difference in accuracy	1
NN counterparts	1
Average Precision (AP)	1
effective GSD of 7.5cm	1
30cm Ground Sample Distance (GSD)	1
upscaling images	1
upscaling factor of 4	1
satellite data	1
improvements in accuracy	1
outermost entity predictions	1
outside-to-inside)	1
inner dependencies	1
previous practical findings	1
task optima	1
smaller average distance	1
optimal adaptation learning rate	1
underlying dependence	1
population risk of MAML	1
optimal adaptation learning rates	1
adaptation learning rate	1
adaptation error	1
value in practice	1
adaptation (inner loop) learning rate	1
toxic speech	1
high accuracy classifiers	1
Data Scarcity	1
informationextracted	1
Theoretical properties	1
non-convex loss function	1
seemingly useless unlabeleddata	1
dimension is greater than the size of thelabeled data	1
labeleddata alone	1
large number of observations	1
small portion of labeled data	1
manually place labels	1
potential of LDA	1
sample covariance	1
new state - of - the - art performances	1
second - order interactions	1
improvement of 6.29%	1
temporal features	1
time-locked EEG sequences	1
reading activities	1
crowd-sourced annotated data	1
reading intent	1
reading process~(the cognitive load	1
physiological aspects	1
Electroencephalogram~(EEG ) and Eye movement~(EM) data	1
human reader intent	1
segmented strings	1
set of rules	1
Japanese information extraction ([3]	1
high level of granularity and specificity	1
user proficiency	1
preliminary empirical evidence	1
language proficiency	1
Proposition Bank data	1
non-local depenencies	1
various types of linguistic structures	1
best distributional concept-distance measures	1
order of semantic distance	1
traditional distributional word-distance measures	1
existing measures	1
% the size	1
possible distance values	1
distributional measures	1
labor intensive pattern engineering requirement	1
linguistically significant combinations	1
matching contents	1
types of inter-annotator variation	1
level of agreement	1
useful syntactic and semantic features	1
level of discourse structure	1
capacity and limitations	1
word's category	1
better clues	1
morphological and syntactic information	1
best public score	1
noun WSD problems	1
optimum iteration number	1
previous winner's results	1
explicit supervision	1
meaningful sound patterns	1
fixed dimensional representation	1
various patterns	1
high-level feature representation	1
silverware clinking sound	1
overlapping sounds patterns	1
complex sound patterns	1
crossing liaisons	1
selected trajectory	1
best correspondence	1
language (L0)	1
interlingual form	1
patchy syntactic coverage	1
ungrammatical input	1
strongly adequate grammar	1
schematic variables	1
category labels	1
finite sequences	1
particular construction	1
type of ambiguity	1
specialized ambiguity representations	1
type of construction	1
ambiguous situations	1
range of ambiguous possibilities	1
case-frame instantiation dominating	1
much higher degree of flexibility	1
measure of success	1
certain aspects	1
additional transfer mappings	1
basic mapping	1
sentiment keywords	1
songs appropriate sentiment labels	1
abstract moves	1
various rhetorical functions	1
specific move	1
patch)	1
PSVM classifier	1
SVM classifier (without patch)	1
S2, S1 (VH)	1
VH polarization	1
VV polarization	1
Fusion results	1
improved classification results	1
terms of spatial and spectral features	1
better-quality image	1
complimentary information	1
particular scenario	1
questions (and answers )	1
distinctive indicators	1
certain relations	1
fewer in number	1
marks	1
rhetorical patterns	1
Chinese punctuation marks	1
rhetorical structure	1
LSA-based and the cooccurrence-based word vectors	1
dictionary-based word vectors	1
two kinds of similarity	1
kind of word vectors	1
kind of similarity	1
linguistic pattern	1
certain layout structures	1
eigenvectors	1
submanifold of data	1
adjacency graph 's Laplacian	1
various lexical and syntactic features	1
precision of 70% and a recall of 49%	1
precision of 96% and a recall of 98%	1
path weights	1
mapping score	1
corresponding relations	1
mapped question phrases	1
accurate ccg supertagging	1
pos tagging accuracy	1
automatically assigned pos tags	1
pos level	1
suitable level of lexical category ambiguity	1
performance above 97% accuracy	1
negligible runtime	1
degree of ambiguity	1
USRs	1
fewer mutually equivalent readings	1
USR	1
underspecified semantic representation (USR)	1
top accuracy of 99.8\%	1
small set of labelled training data	1
CNN's limitations	1
high yield	1
variety of knowledge	1
reading texts	1
system's output	1
order of magnitude smaller	1
CCG principles	1
author's general feeling	1
70% precision and 66% recall rate	1
scf types	1
English corpus data	1
associated frequency information	1
adjectival subcategorization frames ( scfs )	1
manual word alignments	1
translation probabilities	1
paraphrase probability	1
pivot	1
32%	1
error reduction of 22%	1
argument frames	1
joint structure	1
core argument frame	1
18.6% improvement	1
millions of features	1
block bigram features	1
block identities	1
real-valued features (e.g. a language model score )	1
translation speed and quality	1
dependency trees	1
terms of accuracy and MCC score	1
another two iterations	1
data ordering	1
randomness	1
relative error rate reduction of 6.56%	1
in-domain word alignment results	1
different strengths and weaknesses	1
lower error rate	1
human transcriptions and speech recognition output	1
variety of communicative signals	1
performance of 86.6% (F1, sentences < 40 words )	1
empirically compared	1
several approximations	1
Finegrained CFG rules	1
PCFG-LA	1
highly accurate one	1
moderately accurate hypotheses	1
topic signatures	1
topic signature	1
particular concept	1
English topic signatures	1
structural and lexical dependencies	1
acoustic, n-gram, and parser probabilities	1
domain dependence	1
sense coverage	1
14.0%	1
accuracy difference	1
lower chances	1
size of splitting window	1
densely distributed	1
accuracy of results	1
different window sizes	1
different rebar arrangements	1
comparative option	1
96% of the performance	1
improvement of 22-38% in average precision	1
87.5% agreement	1
desired domain or genre	1
dialogue duration	1
cooperative responses	1
reasonable classification accuracy	1
real dialogue data	1
degree of hastiness	1
skill level	1
promising features	1
kernel functions	1
HDAG Kernel	1
common attribute sequences	1
weighed sum	1
several levels	1
high quality IE results	1
extended set of features	1
IE paradigm	1
F-measures of 96.6% and 94.1%	1
external macro context feature	1
internal gazetteer feature	1
internal semantic feature	1
simple deterministic internal feature	1
either ofthe two	1
significant boost in performance	1
different flavors	1
larger improvements	1
operational semantics	1
search engine 's operational semantics	1
practical evaluation	1
suitable superset of L	1
non-deterministic parsing choices	1
practical efficiency	1
O(n6) time	1
equivalent RCG	1
worst-case parsing time complexity	1
equivalent RCGs	1
many classical grammatical formalisms	1
range concatenation languages [RCL]	1
many attractive properties	1
96.90 %	1
final accuracy of 79.49 %	1
35.9 % and 53.85 % accuracy	1
little memory requirements	1
everyday situations	1
safety and security	1
drivers physical and behavioral needs	1
retrieval accuracy superior	1
segment contiguity	1
segment order	1
2 2	1
1 distance	1
2 distance	1
posterior inference	1
stochastic gradient estimates	1
jointly Gaussian likelihoods	1
multinomial distribution	1
year to year	1
children's names	1
one position	1
form of dependency	1
multinomial distributions	1
given state and year	1
multinomial or categorical distributions	1
least (1-1/e)-approximation to the optimum	1
Three attribute selection criteria	1
subset of discriminative attributes	1
action attributes	1
two types of action attributes	1
high-level concepts	1
rich spatial-temporal structures	1
several challenging open problems	1
nearly optimal	1
competence levels	1
sharp error estimates	1
known expert competence levels	1
consistency (both asymptotic and finitary)	1
cycle structure	1
polytope of concavity	1
explicit characterization	1
global optima	1
Kikuchi expansion	1
weight assignments	1
reweighted objective function	1
product distribution	1
log partition function	1
reweighted version	1
missing data points	1
time frame	1
3D shape and motion	1
time instant	1
arbitrary deformations	1
rigid component (rotation and translation)	1
uncalibrated 2D tracking data	1
time-varying shape	1
away	1
hyperplane	1
true gender	1
texture and flowfield representation	1
Principal Components	1
gender judgment, reaction time and confidence rating	1
trade-offs and some experimental results	1
Computing power per area and power consumption	1
complex programmable spatio-temporal dynamics	1
AUC, AUPR and HR indicators	1
predicted value	1
drug latent factor and disease latent factor	1
ancillary information	1
overall information	1
latent factor	1
inference ability	1
cold start problem	1
advantages of both of them	1
interesting (and unavoidable) trade-offs	1
Relaxations of these properties	1
clustering function	1
set of three simple properties	1
technical level	1
separation quality	1
noise-free and noisy data	1
intrinsic property	1
various degrees of sparsity	1
signals into sets of local features	1
appropriate representation	1
mixing matrix	1
higher data likelihood	1
normally distributed hidden variables	1
lower-dimensional hidden space	1
linear relationships	1
near-Bernoulli statistics	1
binary products	1
random statistics	1
Full digital resolution	1
language and behavioral patterns	1
relative performances	1
5 ACE relation major types	1
convolution kernel	1
syntactic structure features	1
syntactic structure information	1
highly varied argument structures	1
much wider range of verb entailment types	1
asymmetric, or directional, relations	1
entailment relations	1
87% for multi-field records	1
average precision of 98%	1
entire multi-field records	1
arbitrary, overlapping features	1
sample dynamic	1
condition probability	1
high-quality semantic space	1
inspiring performance	1
specific loss functions	1
statistical MT performance	1
word-to-word alignments	1
different levels of linguistic information	1
hierarchy of loss functions	1
Minimum Bayes-Risk	1
translingual reach	1
time finding more data	1
little robustness	1
phrase length	1
unigram counts	1
block selection criteria	1
source interval projections	1
much simpler set of model parameters	1
NE types	1
supervised NE performance	1
minimal DFA	1
word-trie	1
in-degree greater than one and out-degree greater than one	1
bigger performance gains	1
style and/or topic	1
guaranteed grammaticality	1
Overall summarization quality	1
close correlation	1
character and word error rate	1
true text	1
average precision metric	1
32.8% improvement	1
number of questions correctly answered	1
35.0% relative improvement	1
question, passage, and/or answer levels	1
1.4 higher score	1
much larger model size	1
architecture's transfer and generalization abilities	1
various downstream tasks	1
different model capacities	1
inter-layer level	1
attention structure	1
novel attention structures	1
intra-layer level	1
arbitrary dependency structures	1
aggressively	1
long - range relations	1
utterance classification performance	1
rating on average is only 5% worse	1
sentence plan	1
ranking rules	1
top-ranked plan	1
potentially large list of possible sentence plans	1
basis of feedback	1
high rate of success	1
words, conceptual mappings , and discourse patterns	1
sublanguage and domain-specific grammar	1
whole MWEs	1
salience	1
statistical parameters	1
100 mil. tokens	1
basic types of MWEs	1
160 000	1
efficiency and domain independent nature	1
prior domain knowledge	1
kinds of terms	1
strict limit or hard rules	1
term frequency	1
much more stable and domain independent	1
terms from non-terms	1
fewer features	1
domain specific terms	1
internal and contextual information	1
training material	1
three results	1
best M translation paths	1
off-line	1
feature functions	1
vector components	1
statistical feature functions	1
vectors representing morpho-syntactic properties	1
shallow mapping and permutation rules	1
translation hypotheses	1
similar semantic properties	1
similar SCFs distributions	1
previous lexico-syntactic knowledge	1
limited number of search heuristics	1
new, discourse level	1
theoretical background	1
Oseven-year	1
philosophy andfunctionality	1
set of coherence rules	1
future research topics	1
interaction requirements	1
benefits and costs	1
incomplete knowledge	1
incomplete lexicon	1
two robustness problems	1
reasonable incomplete analyses	1
specific ones	1
less specific patterns	1
hierarchy of patterns	1
specific phrasal analysis rules	1
qualitative performance results	1
new word senses	1
word sense definitions	1
hierarchy of phrasal patterns	1
participants ' knowledge	1
processing description	1
intentions	1
Various properties	1
cue phrases	1
objects, properties, and relations	1
focus of attention	1
intentional structure	1
state of focus of attention	1
structure of purposes (called the intentional structure )	1
linguistic structure )	1
clear evidence	1
expected meanings	1
new inputs	1
dialogue patterns	1
final text	1
best among competing combinations	1
potential sentences	1
excess redundancy	1
appropriate combinations	1
scarce resources	1
100,000 words )	1
gain	1
0.0076-0.1059 absolute points	1
3.8% absolute and Maximum Term-Weighted Value	1
Term Error Rate Performance	1
web data	1
large reductions	1
corresponding word error rate	1
measure, called mean absolute error	1
receiving operating curve	1
automatic transcriptions	1
i.e. words erroneously recognized	1
small word error rate	1
context-dependent one	1
sequence of the Fujisaki-model parameters	1
raw F0 contours	1
Fujisaki-model parameters	1
discrete-time version	1
fundamental frequency (F0) contour	1
56 FPS	1
speed/accuracy trade-off	1
latest advances	1
little degradation	1
experimental evaluations	1
conversion accuracy	1
highly portable	1
sufficient computational resources	1
French broadcast news transcriptions	1
sparse se-lectional preferences	1
discriminative model's posterior	1
basic syntactic knowledge	1
MSG (Modulation-filtered Spec-troGram) auditory features[2].	1
ANF-based and ON-based auditory features	1
dead time period	1
discrete nerve-action potentials	1
articulatory trajectories	1
precise deformations	1
extreme values	1
discrete (categorical) and continuous (attribute) emotional assessments	1
intended emotions	1
emotions	1
better decoders	1
assessments	1
mismatches	1
intended emotion	1
good approximation	1
various recall rates	1
annotation elements	1
distillation queries	1
relevant pieces of information	1
Extra Large (more than 1M words	1
broad range of noise conditions	1
reasonable durations	1
explicit duration constraints	1
word duration probabilities	1
word duration constraints	1
unrealistic durations	1
weak duration constraints	1
average number of turns	1
question-answering capability	1
Bayes risk	1
several choices	1
realistic, emergent behavior	1
human demonstrations	1
highway driving behavior	1
latent variability	1
human-like driving behavior	1
underlying cost function	1
Human driving behavior	1
large or continuous state and action spaces	1
fewer classification features	1
better classification accuracy	1
unknown transcriptions	1
alignments	1
particular situational setting	1
transcription types	1
manually verified phonetic transcriptions (MPTs)	1
automatic phonetic transcriptions (APTs)	1
various artificial re-verberant conditions	1
reverberation time	1
room full-band reverberation time	1
Maximum Likelihood estimate	1
reverberation times	1
distinguishing features	1
semantic and pragmatic level	1
performance even better	1
experiment result	1
8% in mean precision	1
annotation performance	1
5000 images	1
likely associated keywords	1
image semantics	1
traditional video representations	1
local temporal relationship	1
deep video representation	1
inherent structure?the correlations	1
Learning video representation	1
different domains	1
maximum margin criterion	1
intermediate one	1
various resolutions and changing illuminations	1
one dominant factors	1
lower rate	1
better incentives	1
IR in expectation	1
IR violations	1
realization	1
core-selecting payment rules	1
low efficiency	1
violations of individual rationality (IR)	1
times of emergency	1
auctioned off	1
final availability	1
around 9.4% in the F1-score	1
increasing requirements	1
expected contributions	1
future work	1
completed work	1
generality of FAD	1
0.6 GPU-days	1
28 GPU-days)	1
single-scale testing	1
46.4 AP	1
prominent improvements	1
best combinations	1
convolution types	1
optimal configuration	1
unknown sizes	1
scale variation	1
input QCN	1
-consistency	1
specific patchwork property	1
G-consistency	1
partial consistency	1
chordal QCNs	1
QCN	1
feasible base relations	1
minimal labeling problem (MLP)	1
Qualitative Constraint Network (QCN)	1
qualitative information	1
qualitative temporal and topological relations	1
many design considerations	1
two implementations	1
block of data	1
memory capacity	1
generative and discriminative components	1
hyperparameters and expression of the prior	1
effective sample points	1
hyperparameters of conjugate priors	1
inherent geometry	1
Bregman divergence	1
mathematical convenience	1
sources	1
effect	1
existing KB	1
planning knowledge	1
process models	1
results reported in the literature	1
average packing utilization of more than 87%	1
substantial navigational effort	1
savings	1
deep link structures	1
rhythm, chords	1
output information	1
perceptual sound organization	1
batch stochastic gradients	1
Hessian	1
randomly generated compressed form	1
sketch of the Hessian	1
enriched curvature information	1
object category representations	1
object pose information	1
effectiveness of features	1
re-coverable	1
certain conditions	1
low rank matrix	1
prior structure	1
row and/or column entities	1
low rank plus sparse structure	1
sparse residual	1
low rank part	1
data matrix	1
smooth interpolations	1
computed optimal mapping	1
optimal mappings	1
large family of transport costs	1
existence and uniqueness	1
given transportation cost	1
approximately minimal w.r.t	1
little theoretical understanding	1
majority of settings	1
meaningful correspondence	1
infeasibly large numbers	1
real-life	1
model (or simulator)	1
34% of test positions	1
excellent prediction performance	1
local pattern context	1
board position	1
distribution over the values	1
expert game records	1
given size and shape	1
given position	1
game records	1
action models	1
experience and observation	1
solutions of a quality	1
symmetric and asym-metric instances	1
varied multiple lighting conditions	1
real scene change mask	1
normal-aware lighting difference	1
three related factors	1
two times observations	1
last time lighting conditions	1
multiple illuminations	1
detection sensitivity	1
nearly the same pose and position of the last time observation	1
fine-grained subtle changes	1
extra personalized facial characteristics	1
linear combination	1
particular aging process pattern	1
high-quality candidate solutions	1
exact EIoU	1
(EIoEU)	1
Expected-Intersection-over-Expected-Union	1
first approximates the Expected-IoU (EIoU) score	1
Intersection-over-Union (IoU) measure	1
evaluation function	1
loss-aware predictions	1
0.5s per image	1
object rotation scenarios	1
rotation invariant property	1
number of proposals	1
fixed sizes	1
resulting proposals	1
different orientations	1
local maximum likelihoods	1
i.e., sizes and orientations)	1
different shapes	1
pixelwise object probability	1
various orientations	1
detection error	1
crowd patterns	1
underlying geometric structure	1
3D line constraints	1
analysis	1
Constrained Delaunay Triangulation (CDT)	1
line constraints	1
largely bi-linear	1
sampled points (rays)	1
light field triangulation and stereo matching	1
scene description	1
8 of 9	1
tag granularity	1
tag sequences	1
continuous vector	1
discrete tag	1
different building styles	1
overall structure	1
tiling	1
best speedups	1
kinds of image and video data	1
varying degrees of spatio-temporal continuity	1
energy function (e.g., unary, pairwise, and higher-order terms	1
finest graph	1
coarser graphs	1
series of simpler energies	1
energy	1
hierarchical abstraction	1
high subpixel precision	1
scene geometry	1
indirect lighting and scene discontinuities	1
gray-level band-pass white noise patterns	1
unstructured patterns	1
several zero-crossings	1
Subpixel accuracy	1
relative geometry	1
preliminary knowledge	1
photometric calibration	1
dense sub-pixel camera-projector correspondence	1
Pragmatic aspects	1
abnormal behaviours	1
rare behaviours	1
single modalities	1
heavy clutter	1
complementary object information	1
selection of geometric estimation problems	1
theoretical predictions	1
average, 3-10 times fewer samples	1
significant speed-up	1
'non-randomness'	1
high intra-class variability	1
raw output	1
varying degrees of supervision	1
standard tensorface and eigenface representations	1
improved recognition rates	1
testing inputs	1
different imaging modalities	1
high-resolution tensor space	1
maximum likelihood identity parameter vector	1
high-resolution reconstructions	1
training tensor	1
tensor space	1
face image super-resolution	1
variations in viewpoint and illumination)	1
low recognition rate	1
face recognition accuracy	1
poor illumination	1
practical feasibility	1
different refractive indices	1
known motion	1
illumination , shape, and albedo	1
affine camera parameters	1
surface orientation	1
former	1
spatial and temporal intensity variation	1
distant illumination	1
shape, motion	1
low-prevalence seizure type	1
6.3 points (9.2%)	1
Receiver Operating Characteristic curve (AUROC)	1
6.3 points (7.8%)	1
unlabeled EEG data	1
natural geometry	1
modeling choice	1
image-like structure	1
cyclopean views	1
spatial and temporal artefacts	1
three-dimensional matching cost space	1
temporal artefacts (flicker)	1
compact geometric derivation	1
correct occlusion labeling	1
arbitrary position	1
smaller search space	1
face geometry	1
meaningful deformations	1
face metrics	1
correct locations	1
fewer equations	1
fewer unknowns	1
elegant formulation	1
small set of parameters	1
isolated 3D features (usually points)	1
unknown motions	1
3D model	1
differential features	1
strong description and modeling properties	1
reconstruction results	1
Structural or numerical constraints	1
satisfactory reconstruction results	1
3?D shape	1
image information	1
priori geometric constraints	1
greater set of the difficult situations	1
better approximations	1
probabilistic predictions	1
individual action potentials or multi-unit activity	1
HFO features	1
occurring	1
Bayes classification error	1
time, space, and patients	1
time, space (i.e. recording electrode/channel)	1
linear manifold	1
features space	1
dimension less	1
promising biomarker	1
High frequency oscillations (HFOs)	1
SIR is smaller than 0dB.	1
various NSI conditions	1
large bispectrum amplitude	1
speech sparsity	1
speaker DOA cues	1
different distribution	1
zero value	1
favorable properties of bispectrum	1
larger-than-15dB SNR	1
compact physical size	1
interference robustness	1
speaker DOA estimation accuracy	1
separation accuracy	1
assumed model	1
separated signals	1
corresponding Cram?r-Rao lower bound)	1
nearly statistically efficient	1
different epochs	1
varying variances	1
piecewise stationary	1
accurate intelligibility predictions	1
less accurate predictions	1
subjective scores	1
correlations of around 0.83	1
best predictors	1
Dau and the glimpse measures	1
subjective intelligibility scores	1
Perceptual Evaluation of Speech Quality (PESQ)	1
quality measure	1
Speech Intelligibility Index (SII)	1
glimpse proportion	1
Dau measure	1
three intel-ligibility measures	1
diverse noisy situations	1
four objective measures	1
initial values	1
estimation problem	1
speed measurements	1
gear scale factors	1
relations (scale factors)	1
speed and related states	1
ambient sound	1
electrical system voltage level	1
rotational speed	1
low 1.5% rate of false acceptance	1
moderate 12% rejection rate	1
acoustic measures	1
Word Spotting and Noise Spotting capabilities	1
decoded string hypotheses	1
POS tag, lemma and morph features	1
additional linguistic knowledge	1
data sparsity issue	1
sufficient parallel training data	1
morphological complexity	1
12.5% compression ratio	1
translation knowledge	1
high precision , 94.3% and 84.6% respectively	1
dependency relation	1
bilingual context	1
bilingual dependency relations	1
source of data	1
kind of information	1
cost-efficiency , exhaustiveness , and reliability	1
BLEU, NIST, WER and PER	1
larger volume	1
18.3M	1
legal text hierarchy	1
subparagraph level	1
1.6 million words	1
330 hours	1
good baseline results	1
significantly less development time	1
hot spots	1
recent speculative claims	1
word sense disambiguation performance	1
n-gram statistics	1
vocabularies containing up to 20k words	1
closely matched conditions	1
immediately following frames	1
moredistant frames	1
tongue contours	1
8 preceding frames	1
the9\textsuperscript{th} frames	1
short period	1
New experimental results	1
Gaussian mixture observation densities	1
reestimation formulas	1
37% reduction	1
parsing accuracy rate from 60% to 75%	1
relevant aspects	1
lexical, syntactic, semantic, and structural information	1
detailed linguistic information	1
accomplishments of MADCOW	1
Evaluation test results	1
useful improvements	1
error rate by about 10%	1
SI result	1
4.1% --- a 45%	1
40 utterances	1
target speaker	1
training (reference) speaker	1
best condition	1
7.5% word error rate	1
semantic and syntactic information	1
unification-based linguistic descriptions	1
many of the properties	1
richer descriptions	1
existing metrics	1
information nugget	1
TRDR score	1
IDF-weighted word overlap	1
time-sensitive	1
potential interactive knowledge	1
glyph representation	1
BERT representation	1
interactive information	1
glyph information	1
extra interactive information	1
exponential time lower-bound	1
hardness results	1
parse trees	1
NLP structures	1
~0.25% improvement	1
F-measure improvement of ~1.25%	1
required summations	1
hidden-variable assignments	1
exponential number	1
discriminative training criterion	1
human annotation performance	1
link decisions	1
99% accuracy	1
error-correction rules	1
status	1
sample output	1
three minutes per extract	1
machine translation outputs	1
set of up to six	1
similar criteria	1
less than 100 words	1
intelligibility	1
translation output	1
relatively free word order	1
semantic frame	1
small size	1
Emotions and other indices	1
meeting situation	1
time and place	1
additional indices	1
document representation	1
histogram of keywords	1
action	1
typical sliding window design	1
start and end points	1
action type and temporal localiza-tion information	1
streaming skeleton data	1
action positions	1
action type	1
increasing attention	1
total of 21 submissions	1
F1 of 0.844	1
guidance and target images	1
guidance image	1
structural details	1
robust deep metrics	1
better generalization ability	1
metric weight constraint	1
graphical relationship	1
training and test	1
pedestrian data	1
large variations of pose, illumination, occlusion and camera view	1
much more accurate 3D reconstructions	1
non-rigid image registration and depth estimation	1
joint problem	1
15,000 questions and answers	1
5,000 diagrams	1
constituents and relationships	1
exhaustive annotations	1
structure of diagrams	1
Diagram Parse Graphs (DPG)	1
constituents	1
structure of a diagram	1
annotation outliers	1
annotation outliers/errors	1
reliable	1
interesting-ness value of training data	1
highly subjective visual attribute	1
image or video interestingness	1
step forward in performance	1
superior localization accuracy	1
2D features	1
natural boundaries	1
Gaussian scale space	1
different scale levels	1
nonlinear scale spaces	1
KAZE features	1
affine projection	1
intrinsically local nature	1
hard combinatorial problem	1
trajectory basis	1
temporal prior	1
2D point correspondences	1
created synthetic facial performance	1
better temporal consistency	1
lenght of branches	1
number and size	1
different error accumulation	1
reduced alignment path length	1
One or more	1
dissimilarity measure	1
temporally consistent representation	1
nearly perfect recognition rate (over 99.7% on all three databases	1
extreme illumination, pose and head motion variation	1
1300	1
face motion patterns	1
unseen head poses	1
robust same-identity likelihood	1
geodesically local appearance manifold structure	1
extreme illumination changes	1
generic face appearance variation	1
wide variability	1
lighting, pose and user motion pattern	1
training and recognition input	1
illumination and pose invariance	1
different search space definitions	1
search space definition	1
architecture search spaces	1
spatial nonuni-formity	1
real-world images	1
accuracy of up to a few hundredth pixels/frame	1
reliable and dense displacement vector fields (DVF)	1
first-order derivatives	1
interesting parameters	1
source of evidence	1
Term similarities	1
different co-occurrence similarities	1
extended domain of locality (EDOL)	1
best published chunking results	1
chunking performance	1
data representation choice	1
better training resources	1
additional temporal anaphora phenomena	1
different notions of reference time	1
careful distinction	1
temporal connective	1
wrong truth-conditions	1
vowel harmony	1
number of phonetic rules	1
surface realizations	1
vice-versa	1
verbal structure	1
nominal	1
finite-state	1
phonological and morphological rules	1
23,000	1
intuitive distinction	1
wide range of phenomena	1
Test performance data	1
scale of plausibility	1
likelihood of each successful parse	1
multiple analyses	1
training and the evaluation data	1
one feature structure	1
strict compositionality	1
anaphoric component	1
complex contextual reference	1
three important requirements	1
demands	1
resolution component	1
exact meaning	1
temporal coordinates	1
plausible choice of anchors	1
location time	1
speech time	1
one or more reference times and temporal perspective times	1
temporal adverbials	1
preceeding text	1
event structure	1
events	1
tenses	1
H. Kamp	1
aspectual information	1
completed, going on	1
present , past or future (= deictic information	1
two kinds of information	1
special relationship	1
unadulterated systemic grammar	1
ad hoc or inefficient	1
corresponding reduced IL formulae	1
derivational history	1
Montague analysis trees	1
compositional syntax rules	1
analytical inverses	1
conceptualizes scenes descriptions	1
conceptual level	1
epistemological level	1
different level	1
level of abstraction	1
set of effectiveSVM	1
general preference	1
better indicators	1
top-level boundaries	1
top-level and predicting subtopic boundaries	1
impact on performance	1
top-level topic shifts	1
segment boundaries	1
automatic evaluation measures	1
additional increase of correlation	1
word dependent substitution costs	1
word-dependent substitution costs	1
little gain	1
speaker's gaze information	1
conversational context and utterance features	1
classifiers ' performances	1
gaze , utterance and conversational context features	1
addressee	1
instantiation of the one sense per collocation observation	1
polynomial time approximations	1
P = NP and P#P = P	1
hard problems	1
polynomial time solution	1
conceptually and computationally simple	1
fundamental problems	1
variety of insights	1
32,000 fine-grained triplet ranking annotations	1
fine-grained matching harder	1
highly abstract	1
cross-domain	1
limited amount of laser ground truth data	1
vast amount of automatically generated training data	1
three learned confidence measures	1
huge amount of training data	1
different view points	1
set of stereo images	1
necessary training data	1
Learned confidence measures	1
human accuracy	1
'same' and 'different' pairs	1
urban aerial imagery	1
reach of SIFT	1
appearance variation	1
large camera rotations	1
wide array	1
natural language descriptions	1
120K natural language descriptions	1
100K	1
rich meta-data	1
within-view neighborhood structure preservation constraints	1
cross-view ranking constraints	1
large-margin objective	1
linear projections	1
specific strong parameters	1
VGG 16 and VGG 19)	1
nearly real-time	1
video segmentation	1
overall actionness score	1
set of action proposals	1
high actionness scores	1
meaningful motion	1
action proposal	1
heterogeneous data modalities	1
corresponding location grouping space	1
image appearance space	1
geometric prior	1
certain vantage points	1
pictured	1
minimal subsets	1
cones	1
loose within-class shape similarity assumptions	1
visual hull proposals	1
object shapes	1
ground truth figure-ground segmentations	1
many quantitative metrics	1
several synthetic and real data examples	1
transformations	1
rigid and non-rigid transformations	1
analytic expressions	1
natural metric	1
intrinsic geometry	1
point on a unit	1
square-root density	1
unit L2 norm	1
analytic expression	1
SDT representation	1
corresponding static Hamilton-Jacobi equation	1
Schr?dinger distance transform (SDT) representation	1
shape representation	1
main geometric classes	1
96% accuracy	1
20,000 frames	1
100	1
granularity a priori	1
multiple segmentation hierarchy levels	1
homogeneity	1
appearance and motion features	1
geometric classes	1
broad 3D geometric structure	1
several hundred	1
convex constraints	1
asymmetric map-uniqueness criterion	1
label costs	1
convex formulation	1
parametric representation	1
multi-label representation	1
discovered dis-criminative co-occurrence patterns	1
minimum empirical error	1
optimal co-occurrence pattern	1
discriminative co-occurrence patterns	1
conjunction (AND) and disjunction (OR)	1
two types of co-occurrence patterns	1
combination of binary or local features	1
co-occurrence pattern	1
parallel or orthogonal	1
two intersection points	1
relative translation	1
relative rotation	1
two of the lines	1
object color (surface reflectance)	1
scene illuminants	1
multi-view constraints	1
matching local region features	1
illuminants	1
surface properties	1
color constancy	1
important constraints	1
surface re-flectance estimates	1
uncontrolled images	1
highly discriminative	1
feature length movies	1
motion similarity	1
depth ordering constraints	1
past and future frames	1
long-range motion cues	1
many video frames	1
motion and appearance	1
rich visual cues	1
171 whole slide images	1
predicted grades	1
histopathological images	1
robust representations	1
papillary architecture	1
similar pattern	1
prognostic factor	1
type 1 vs. type 2	1
Histological subtype	1
reliable starting point	1
nonlinear monomials	1
easily estimable gravity vector	1
non-linear nature	1
basic paradigm	1
missing point correspondences	1
typical outdoor surveillance settings	1
covariance-based region features	1
wide-area settings	1
well-known limitations	1
pathological motion	1
motion trajectories	1
one layer	1
memory and computationally efficient	1
small number of constraints	1
equivalent convex problem	1
large margin estimation	1
various drawbacks	1
Rank-HLapSVM	1
one training instance	1
vertex	1
repeatability and distinctiveness	1
blur and illumination changes	1
illumination variation	1
strong invariance	1
distinctive textured patterns	1
large-scale structures	1
distinct distribution	1
image intensity	1
pixel-wise differences	1
histogram information	1
recognition scores	1
position and viewpoint	1
explicit correspondences	1
discretized viewpoints	1
collection of salient image features	1
appearance information and geometric constraints	1
semi-Riemannian geometry	1
nonsingular case)	1
face recognition (singular case )	1
metric tensors	1
quadratic quantities	1
geometrization of class structures	1
nullity	1
discrete functions	1
Semi-Riemannian metrics	1
local metrics	1
ambient semi-Riemannian space	1
submanifold	1
semi-Riemannian manifold	1
top-down knowledge	1
intuitive evaluation met-rics	1
multiple segmentations	1
simple and generic qualitative constraints	1
generic qualitative knowledge	1
quantitative prior	1
various physical or geometric constraints	1
available qualitative prior knowledge	1
various computer vision problems	1
stronger inductive biases	1
accuracy ranged from 0.00% to 66.2%	1
accuracy ranging between 83.6% and 84.8%	1
syntactic generalization	1
100 instances	1
similar linguistic generalizations	1
local tracker	1
local modes	1
inevitable tracking failures	1
good estimate of object parameters	1
translation, rotation and scale	1
local mode	1
frame to frame	1
normal tracking conditions	1
black-box measure	1
blur information	1
image color, gradient, and spectrum information	1
several blur features	1
blur types	1
photometric and geometric data	1
amount of recovered surface detail	1
geometric correspondence data	1
particular spatial relationships	1
scene representation	1
codebook of region types	1
relatively uniform color and texture properties	1
rich motion information	1
well known Motion History Image (MHI)	1
compacted motion features	1
flow segments	1
number of flow segments	1
Lagrangian Coherent Structures (LCS)	1
maximum eigenvalue	1
Cauchy Green Deformation tensor	1
spatial gradients	1
flow instabilities	1
wide variety of image completion examples	1
MRF energy function	1
existing labels	1
intolerable computational cost	1
two very important extensions	1
10 positive and 10 negative examples	1
corresponding positive half space	1
simple prior	1
certain amount	1
resulting model	1
linearity	1
pri-ori knowledge	1
convincing experimental results	1
much better-conditioned	1
subsequent 3-D reconstruction	1
relations of homo-graphies	1
different algebraic properties	1
real quadratic form	1
complex bilinear form	1
homography	1
different homographies	1
two (uncalibrated) perspective images	1
accuracy of 88.4\%	1
inference speed of 2.44 ms per word	1
inference time and memory footprint	1
on-device metrics	1
horizontal and vertical text	1
almost 2\%	1
word accuracy	1
minimal computational cost	1
channel and spatial attention information	1
0.88M parameters	1
local variables	1
translation, scale or viewpoint	1
learning and detection phases	1
i.e., positions, velocities and appearance	1
positions and velocities	1
utility and performance	1
dynamic characteristics	1
inter-expert variations	1
Reliable detection and robust tracking results	1
maximum likelihood	1
posterior shape model	1
subspace constraints	1
predicted shape prior	1
local detection uncertainties	1
tracking performance	1
shape priors	1
system dynamics	1
measurement information	1
ambiguous segmentations	1
robust-ness requirement	1
probabilistic shape knowledge	1
color and texture	1
mixtures of feature distributions	1
shape information	1
type of tracking problems	1
interesting properties	1
learned intrinsic object structure	1
2 dimensions	1
object state	1
obtained non-rigid part	1
object intrinsic representation	1
low dimensional manifold	1
parameterized object state	1
intrinsic object structure	1
rotation-invariant texture features	1
rotated image textures	1
image textures	1
tensorial support	1
data hierarchy	1
desired level of detail	1
different levels of detail	1
mesh connectivity requirement	1
scanning resolution	1
upper bounded	1
current level of detail	1
sub-voxel precision	1
per-vertex normals	1
local shapes	1
continuum of primitive connectivity, view dependence, and levels of detail (LOD)	1
good efficiency and robust-ness	1
reconstruction on demand	1
advantages of LNMF	1
localized features	1
standard NMF	1
non-negativity constraint	1
lo-calization constraint	1
visual patterns	1
spatially localized, parts-based subspace representation	1
Good layer descriptions	1
subspace constraint	1
Global optimality	1
low dimensional linear subspace	1
line correspondences	1
point correspondences	1
simple geometric interpretation	1
trifocal tensor	1
neccessary and sufficient constraints	1
points and lines across two or three views	1
known projective relations	1
registered tensors	1
affine case	1
projective unifocal, bifo-cal, and trifocal tensors	1
continuously changing human poses, illuminations and point of views	1
greater complexity	1
similar color	1
quantized levels	1
discrete motor control representation	1
cycloidal motion parameters	1
small number of values	1
general pen trajectory	1
phase lags	1
amplitudes	1
local CURVE-ELEMENT attributes	1
given scale	1
multiple tokens	1
given segment of image contour	1
rich and redundant	1
resulting image description	1
support	1
idiosyncracies	1
complementary semantic information	1
generalizable semantic principles	1
predicative information	1
morpho-syntactic and semantic characteristics	1
15-fold improvement	1
predictably related	1
syntactic behavior	1
verb semantics	1
97.9% accuracy	1
6.3% accuracy	1
word-sense ambiguity	1
frequency of occurrences	1
concept hierarchy constraints	1
meaning of representation	1
type of unit classifier	1
noun	1
corresponding classifier	1
word-based collocational properties	1
pre-processing distortion	1
whole sentence	1
parse record	1
only2.69M weights	1
much smaller basicstructures	1
dimension consistency	1
component of ISSwill	1
LSTM s.	1
Intrinsic Sparse Structures (ISS)	1
inconsistent dimensions	1
cell states	1
input updates	1
quick responses	1
reasonable margin	1
automatically extracted features	1
manually extracted features	1
appropriate pints	1
translation examples	1
individual lexical rules	1
log(d)	1
one speed-up element	1
6 million	1
arguments and defeat rules	1
computational issues	1
synchronous TAGs	1
translates	1
associated semantics	1
limited confines of syntax	1
Implementation and empirical results	1
complicated large knowledgebases	1
domain targeted preference knowledge	1
Sentence ambiguities	1
preference knowledge	1
robustly	1
rule packets	1
simplifications	1
high-fidelity spaceborne illumination conditions	1
accurate and maximally diverse pose labels	1
9,531 simulated images	1
60,000 synthetic images	1
target spaceborne images	1
illumination variability	1
Spacecraft PosE Estimation Dataset (SPEED)	1
shared lexical information	1
different amounts and types of information	1
lexical gap	1
new linguistic concepts	1
lexical hierarchy	1
presuppositional nature	1
insightful counterexamples	1
stereotyped text structure	1
formatted weather data	1
marine weather forecasts	1
estimation of the results	1
superordinate -hyponym relation	1
particular interpretation	1
inherent ambiguity	1
global meaning	1
Multiple Layer of Grammars	1
(1)	1
detailed construction	1
vagueness	1
less than 400GB	1
disk space	1
reasonable size memory (less than 4GB)	1
wildcards	1
fillers	1
fraction of a second	1
F1-score and mean between 10 runs	1
ASR error	1
noisy inputs	1
improved classification performance	1
source of additional information	1
remaining tokens	1
robust latent representations	1
Language resource quality	1
segmentation	1
monolingual and bilingual information	1
word segmentation	1
alignment errors	1
translation equivalents	1
co-occurrence patterns	1
lexical affinity	1
arbitrary windows	1
co-occurrence distribution	1
discourse segments	1
summary coherent	1
similar meanings	1
level of meaning	1
level of form	1
lower one and a higher one	1
two estimates	1
walk :: I laughed :	1
walked :	1
0.889 F-measure	1
contextual similarity	1
edit distance	1
lexical probabilities	1
published results	1
unsupervised and supervised case	1
useful aspects	1
relation features	1
current aspect	1
neighborhood information	1
latent semantic aspect	1
multi-channel entity representations	1
different labels	1
directed links	1
simple undirected and single relational graph data	1
surprising claims	1
extreme operating conditions	1
around the same point	1
high accuracies	1
Empirical experience	1
better word similarity performance	1
superior feature vectors	1
feature vector quality	1
objective measure	1
word similarity results	1
empirical quality	1
semantic criterion	1
human agreement	1
good level	1
application	1
meaning-entailing substitutability	1
word similarity measures	1
Horn clauses	1
significant predictive power	1
similar success rates of approx 90%	1
input dataset	1
set of domain independent features	1
clauses	1
predicates	1
probabilistic Horn clauses	1
set of heuristic principles	1
large treebank grammars	1
probabilistic finite automata	1
distributional approximation	1
cross-entropy	1
one part	1
probabilistic finite automaton	1
probabilistic context-free grammar	1
relative entropy	1
Kullback-Leibler distance	1
scenario consistency	1
associative relationship	1
associative relationships	1
joint interpretation	1
alternative multimodal interpretations	1
input modes	1
multiple input modes	1
utterances whose content	1
diversity) summaries	1
concise (i.e., short) and comprehensive (i.e., improved coverage	1
diversity, uniqueness, and popularity	1
human friendly	1
consistency results	1
architecture and performance	1
cognitive semantics	1
several levels of knowledge	1
narrative content	1
fact assertions	1
flowing text	1
fine-grained probabilistic estimation of outcomes	1
dormant independencies	1
interventional distribution	1
independence	1
interventional distributions	1
conditional independencies	1
special subset of Verma constraints	1
Verma constraints	1
algebraic constraints	1
conditional inde-pendencies	1
set of constraints	1
non-experimental data	1
full unification	1
combination of compile time and run time checks	1
universal quantification	1
limited expressive power	1
genre-specific regularities	1
likely positions	1
statistical profile	1
language independent developments	1
zero-shot videoclassification performance	1
synthetic features	1
video feature	1
semantic knowledge and visual distribution	1
informationdegradation issue	1
discriminative informationimplied	1
seen-to-unseen correlation	1
approximately 9000 verbs	1
LCS representations	1
valid semantic interpretation	1
amount of ambiguity	1
syntactic categories	1
phrase boundary heuristics	1
longest possible span	1
every final constituent	1
topmost of the edges	1
algorithmic efficiency	1
specific information	1
required world knowledge	1
inherently robust	1
complete and correct interpretations	1
particular characteristics	1
NL evaluations	1
competing claims	1
information of the wrong kind	1
users' expectations	1
graphical information	1
other's proposals	1
theories	1
efficient statistical ranking	1
unseen hashtags recommendations	1
effectiveness and scalability	1
hashtag labels	1
unseen hashtag labels	1
possible hashtag labels	1
zero shot training setting	1
unknown word	1
multiple types of evidence	1
minimum changes	1
new representations	1
new balanced representations	1
false positive	1
imbalanced nature	1
devastating outcomes	1
occupancy status	1
number of weights	1
formula	1
overall wSTL formula	1
higher weights	1
quantitative semantics	1
logical and temporal operators	1
Weighted Signal Temporal Logic (wSTL) formulas	1
temporal logics	1
billions of samples	1
straightforward estimation	1
unbounded growth	1
desired precision	1
Lebesgue-integrable continuous kernel	1
vector-valued observations	1
stationary GP	1
one-dimensional GP	1
linearly-scaling computational costs	1
arbitrarily-spaced intervals	1
scalar or vector time series	1
statistical robustness	1
30 runs	1
new evolved activation functions	1
completely new activation functions	1
set of predefined functions	1
new activation functions	1
better activation functions	1
crucial hyper-parameters	1
architectural configurations	1
good set of hyper-parameters	1
substantial expert knowledge	1
shape and time features	1
structured shape and time diversity	1
STRIPE++ (Shape and Time diverRsIty	1
positive semi-definite (PSD) kernels	1
differentiable loss functions	1
smooth relaxation of Dynamic Time Warping (DTW) and Temporal Distortion Index (TDI)	1
shape and temporal similarities and dissimilarities	1
shape and temporal criteria	1
deterministic and probabilistic contexts	1
sharp predictions	1
variants of the MSE	1
sudden changes	1
question tags	1
best answerers	1
CQA node embeddings	1
heterogeneous graph and textual information	1
graph structural information	1
suitable expertise	1
a.k.a cold questions	1
relativestrengths and weaknesses	1
dissimilar nodes	1
similar nodes	1
classification capability	1
obtained classification problem	1
samples of the majority class	1
state-based features	1
100K environment and interaction steps benchmarks	1
1.9x and 1.2x performance gains	1
high-level features	1
domain soft-assignment scores	1
different data distributions	1
privacy-constrained	1
original as well as reducedresolution and additional metadata	1
resulting keyframes	1
commons license	1
overall length of about 3'800 hours)	1
theInternet in terms of content, length, or resolution	1
properties of video	1
number and volume	1
massivegrowth	1
additional 17.5%	1
32.1% CA-WER relative improvement	1
ASR performance	1
Callsign Word Error Rate (CA-WER)	1
e.g. data	1
WFST the contextual knowledge (i.e. air-surveillance data	1
ASR system error rates	1
final denoising image	1
50% and 25% for	1
number of labeled samples	1
plasma dosage	1
rapid and simple measurements	1
food quality, safety, and nutritional properties	1
human-defined parameters	1
forced operations	1
final model architectures	1
human response patterns	1
test set accuracyis	1
gain in predictiveperformance	1
comprehensivemetafeatures is	1
bestmetafeatures	1
metafeaturesfrom multiple dimensions	1
Collaborative Filtering problem	1
interestingand effective findings	1
problem characteristics	1
thepotential impact	1
Chinese Machine Reading Comprehension (CMRC-2017)	1
https://github.com/qxcv/magical/.	1
substantially different behaviour	1
narrow perceptual invariances	1
different kinds of distribution shift	1
substantially different deployment settings	1
100 seconds	1
subset of TRECVidimages	1
feedback	1
different degrees offamiliarization	1
different rates (5Hz and 10Hz)	1
total length of 3 hours and 42 minutes of valid data	1
total number of 12	1
gait acceleration (ACC), electroencephalogram (EEG ), electromyogram (EMG), and skin conductance (SC)	1
multimodal physical and physiological information	1
data more comprehensively	1
view	1
neighboring characteristics	1
explanation beyond accuracy	1
faithful and human-readable	1
sufficient alignments	1
complex language features	1
EN -> ML	1
period of three years	1
average position errorof 3.7mm	1
around 90%	1
visualisation	1
highspatial-temporal resolution	1
13,509 utterances	1
associated causes	1
natural form	1
clinical factors	1
meaningful markers	1
single factors	1
single EEG representation	1
various clinical labels	1
novel, single EEG trajectories	1
depression diagnosis	1
participant age	1
clinical labels	1
interpretable features	1
$\beta$-VAE	1
lack of knowledge of which aspects	1
inherent noise	1
clinical utility	1
course	1
even predictors	1
reliable objective correlates	1
EEG -based neural measures	1
substantial subjective judgment	1
three-fold	1
simpler problems	1
straightforward question	1
language structure	1
minimal prior knowledge	1
large scale supervised reading comprehension data	1
service delay	1
average energy consumption	1
Q-Learning based optimized trajectory	1
movement decisions	1
service priorities	1
IoT nodes	1
nodes' service requirements	1
service priority	1
flying energy	1
Shorter trajectories	1
service continuity	1
12% and 6%	1
F-measure (ODS)	1
complementary merits of learned side edges	1
tracing boundaries	1
novel tracing loss	1
side predictions	1
localization ambiguity	1
formal definitions	1
distilled knowledge	1
higher-quality action representations	1
unsupervised settings	1
remarkable action recognition results	1
contrastive context	1
cross-view consistency	1
embedding similarity	1
high-confidence positive/negative samples	1
Answering Dataset (SQuAD) and Natural Questions (NQ) challenges	1
theactivation values of validation images	1
resulting weightscannot	1
training error	1
specific bilevel optimization problems	1
different modeling aspects	1
Videos of results	1
design principles	1
policy and structure	1
environment parameters	1
notion of cumulative reward	1
subjective and objective quality tests	1
completely training data-unaware	1
imperceptible attack images	1
imperceptibility factor	1
validation phase	1
perceptible noise	1
arithmetic, geometric and harmonic means	1
matrix means	1
labeled and unlabeled observations	1
comparative results	1
least number of parameters	1
12.1 % and 5.7 % relative error reductions in F1score on ACE2005 and ACE2004	1
word sequence and dependency tree substructure information	1
69.8 -RRB-	1
-LRB- f-score	1
63.6 % recall and 77.3 % precision	1
grammatical relationships	1
detailed keystroke statistics	1
post-editing time	1
sentence-level information	1
publishable quality	1
time and costs	1
much larger volumes	1
increasing demand	1
Machine Translation (MT) quality	1
IEMOCAP, DailyDialog)	1
pre-trained memory	1
previous utterances	1
machine generated sentences	1
task rewards	1
informative rewards	1
poor task performance	1
informative reward signal	1
spurious associations	1
critical vulnerability	1
pixel labeling	1
centroid voting	1
native operators	1
pixel-wise votes	1
instance centroids	1
discretized, probabilistic votes	1
3% higher accuracy	1
ZeroFL and 95% sparsity	1
unique aspects	1
client side	1
totality of the energy consumption	1
federated models	1
majority of the time	1
every round)	1
hundreds of times	1
convergence rates	1
sophistication	1
battery powered	1
orders of magnitude more constrained	1
training quality	1
memory and compute requirements	1
gains of up to about 21%	1
varying sizes	1
false matches	1
half the parameters	1
large viewpoint variations	1
good feature representations	1
transformation patterns	1
multiple camera views	1
matching images	1
large number of labels	1
specialized expertise	1
data deficiency	1
base models	1
ground-truth answers	1
subset of models	1
factor of 10	1
amount of required data	1
NLU problems	1
low data regimes	1
QuestionAnswering (QA) problems	1
Different flavors	1
sensorial noise	1
potential of deep learning-based feature descriptors	1
visual SLAM (VSLAM)	1
environment's features	1
consistent map	1
language similarities	1
reasoning types	1
interesting effects	1
zero-shot transfer efficiency	1
different kinds	1
impressive zero-shot accuracies	1
source and target perturbed features	1
category or object size	1
location evenly	1
individual position	1
discriminator and classifier	1
several attack objectives	1
head categories	1
alignment objective	1
marginal distribution	1
ranked 4th	1
non-augmented one of 67.3%	1
accuracy of 70.1% which is 2.8% better	1
classification result	1
highly realistic skin lesion samples	1
limited reasonably alternative data	1
class frequencies	1
high accuracy (97.5%)	1
repaired output	1
kinds of defects	1
significant flaws	1
small defect	1
AUC values up to 0.73	1
edges PAC values	1
electrodes	1
connectivity information	1
marker	1
phase and amplitude	1
highly accurate ground truth pose estimates	1
3D mesh	1
higher-level space	1
LIDAR scans and image data	1
common geometric features	1
fundamentally different characteristics	1
suitable visual features	1
accurate poses	1
least one name	1
84%	1
several evaluation measures	1
names	1
confidential data	1
VQA accuracy by 0.78% overall	1
Consensus Score by 1 .63% over an improved baseline	1
answer consistency	1
alternately or jointly --	1
discriminative power of representations	1
cross-entropy and contrastive losses	1
combined data	1
question paraphrases	1
small linguistic variations	1
synthetic noise	1
groundtruth labels	1
relatively consistent benefits	1
relatively low variance	1
prediction margin	1
input sensitivity	1
recent theoretic advances	1
different methods and tasks	1
long - range dependency	1
paragraphs	1
human - level performance	1
automatic as well as human metrics	1
multimodal output	1
better cognitive understanding	1
outlier pixels	1
image intensity scaling	1
Typical similarity measures	1
ground-truth results	1
reproducibility quantitatively	1
sufficient meta-data	1
Implicit assumptions	1
description level	1
image similarity metrics	1
good agreement	1
assumed field-of-view or resolution	1
image orientation	1
Pixel-wise differences	1
key figures	1
Ok-space	1
results of Advances	1
industrial data	1
continuous measure of the probability	1
various multivariate water quality signals	1
unexpected water quality conditions	1
network's trained performance	1
initial state	1
network's trained accuracy	1
vast numbers	1
right stimulus type	1
TTIs and Hamming-distances	1
particular spatial properties	1
stimulus types	1
new EEG data	1
possible psychophysiological consequences	1
significantly reduced average target-to-target interval (TTI)	1
target frequency	1
maximal minimum-Hamming-distance criterion	1
sample efficiency, generalization, and stability	1
strictly non-augmented data	1
augmented and non-augmented data	1
soft constraint	1
lower sample efficiency	1
relevant connections	1
user representation	1
connections uniformly	1
social connections	1
theglobal optimality of their solutions	1
large-scaleproblems	1
validdistance metric	1
stand-alone place recognition capabilities	1
improved computational efficiency	1
speed-optimised version	1
Facebook Mapillary Visual Place Recognition Challenge	1
state-of-the-art visual place recognition results	1
comparable compute	1
condition (season, structure, and illumination) and viewpoint (translation and rotation) changes	1
patch sizes	1
complementary scales	1
multi-scale fusion of patch features	1
deep-learned local features	1
existing local keypoint features	1
NetVLAD residuals	1
patch-level features	1
twin problems	1
quality of life (QOL)	1
Good-quality, open-access and free EEG data	1
13 times faster	1
Faster RCNN	1
overall computation time	1
old knowledge	1
existing knowledge	1
ground truth reasonsbeing	1
human-readable reasons	1
unpredictability	1
One of the most intriguing features	1
e.g., 85.14% Acc and 78.91% F1 score on Sleep-EDFx, and 87.59% Acc and 79.62% F1 score on Sleep-EDF	1
accuracy and F1 score	1
Markov chain	1
sleep stage transition rule	1
prior stage distribution	1
output jitters	1
representation of deep features	1
considerable detailed information	1
anomaly type and score	1
global spatiotemporal contextual feature	1
spatiotemporal contextual feature	1
frame-level labels (abnormal/normal video frame	1
video-level labels (abnormal/normal video, anomaly type)	1
annotation data	1
crash, fire, violence	1
14 anomaly categories	1
precise time durations	1
video-level labels	1
search attention	1
MAPF-DLto	1
given start vertices	1
given goal verticesfrom	1
entity type information	1
external knowledge base (KB)	1
type (e.g., \emph{person} or \emph{location}	1
insufficient context	1
desired expectations	1
memory usage, floating-point operations (FLOPs) and number of parameters	1
1st, 3rd, and 4th places	1
memory and computational cost	1
acquisition function	1
Weinstein-Aronszajn identity	1
output posterior	1
large output dimensions	1
computational challenges	1
best benefit-cost ratio	1
new training examples	1
cost/accuracy trade-off	1
label andthe location of future actions	1
result by 2.7 % F 1	1
1.6 % F 1	1
new state of the art result	1
earlier results published	1
97.50\% and 98.50\%	1
99.50\% and99\% for the eyes open and eyes closed conditions	1
epileptic data	1
corresponding accuracy	1
normal subject data	1
thehighest classification accuracy (100\%)	1
last decomposition level	1
theapproximation coefficients	1
detailed coefficients	1
Entropy, Min, Max,Mean, Median, Standard deviation, Variance, Skewness, Energy and Relative WaveEnergy (RWE)	1
Various features	1
decomposition tree	1
4th level	1
epilepsyleaves their signature	1
EEG dataanalysis	1
neurological condition	1
one global optimum solution	1
super-)pixels contribute less	1
similar colors	1
weight of each (super-)pixel	1
Probabilistic Color Constancy (PCC)	1
best competingtransform	1
area-timeand area-time-squared VLSI metrics	1
35% and 37% improvements	1
bestcost-benefit ratio	1
PSNR and SSIM measurements	1
exact DCT, and coding performance measures	1
introduced transform	1
lowest arithmetic cost	1
44 additions	1
Jaccard index of 0.937 and 0.929 vs. 0.870, p < 0.01	1
weak staining	1
thetissue type	1
motion history	1
false assumptions	1
pedestrian motion prediction	1
synthetic statement	1
Visual Entailment	1
authenticity of answers	1
one best output	1
language priors problem	1
computational cost by approximately 50 percent	1
accuracy by an average of 1.5 percent	1
structural extensibility	1
dimensionality of fused feature	1
input modalities	1
depth data	1
front view information	1
depth images called sequential front view images (SFI) and signal images (SI)	1
depth and inertial sensor data	1
theutilization of uncertainty	1
semantic,syntactic and acoustic relationships	1
intuitive exploration	1
extra task relevant ambiguity information	1
word vector space	1
semantic-syntactic word relations	1
semantic-syntactic and word similarity evaluations	1
Confusion2Vec	1
range of representational ambiguities	1
Therepresentational ambiguity	1
contextual cues	1
acoustic similarity cues	1
representational ambiguity	1
fundamental trade - off	1
0.009-0.1Hz	1
8- 13 Hz	1
mean concentrations	1
hemodynamic responses	1
alpha rhythmic of Electroencephalography (EEG ) signals	1
electrical response	1
prefrontal cortex (PFC) functional connectivity	1
interesting features	1
learned contextual information	1
indicated goals	1
human behaviors	1
future goal	1
desired outcomes	1
ambiguous latent space	1
environment structure	1
potential consequences	1
causal knowledge	1
real-life videos	1
benchmark data	1
slowlyover time	1
evolving data	1
joint data distribution	1
alignment	1
later layers	1
ground truth density	1
attack success rate	1
ground truth distribution	1
much stronger transferability	1
small Gaussian noise	1
security concerns	1
86.41, 85.46, and 94.2 F1 scores on ACE2004, ACE2005, and NNE	1
improved representation focus	1
longer spans	1
nesting levels	1
prior boundary knowledge (BoningKnife)	1
expensive and inefficient	1
medium and large query batch sizes	1
unlabeled pool	1
examples to label	1
large query batch sizes	1
pretraining data	1
30 data pairs	1
good predictors	1
different aspects of similarity	1
payment accuracy loss	1
three-way performance tradeoffs	1
budget balance	1
(probably approximate) optimality	1
economic properties, scalability, and privacy	1
relatively more samples	1
less typical data distributions	1
unbalanced and non-i.i.d	1
risk bounds	1
feedback capturing sessions	1
Psychophysiological measurements (e.g. gaze, electrodermal activity, heart rate, etc.) related data	1
User state (e.g. fatigue detection, stress detection, emotion recognition, etc.)	1
e.g. demographic, anthropomorphic, educational, etc.)	1
User attributes	1
fine-grained representation	1
novel user profile formulation	1
long-term autonomy	1
critical challenges	1
previouslygenerated lists	1
generated lists	1
efficiency oftext classification	1
8.5\% absolute F-score gain	1
relation extraction(16\% absolute F-score gain	1
slot type	1
global attention	1
query and candidate filler	1
COSMO transferable features	1
multiple new operating conditions	1
Remaining Useful Life (RUL)	1
one setting	1
post-deployment data	1
pre-deployment data	1
comprehensive data	1
dynamic environmental conditions	1
experiment data	1
future field data	1
machine health	1
experiments under controlled conditions	1
close to 4 BLEU points	1
best single one	1
one million	1
112 more then 10 million	1
30 million	1
661 million	1
4.5 billions	1
32.7 billion	1
ten snapshots	1
thousands of words	1
varying levels of granularity	1
independently extracting features	1
ideal representations of data	1
resiliency	1
physical node failure conditions	1
activations and gradients	1
robust evaluation	1
reliance	1
corresponding statistics	1
supernet's shared weights	1
final design	1
number of prior samples	1
estimator	1
observed information and prior samples	1
posterior ratio function	1
two posterior probability density functions	1
ratio	1
\emph{inferred}	1
enhanced output	1
portion of the Mean Squared Error (MSE) loss	1
portion of outputs	1
clean features	1
Gradual Reduction of Enhanced Loss (GREL)	1
Gradual Application of Enhanced Features (GAEF)	1
speech recognition accuracy	1
public datasets	1
joint space ofspatial graph partitioning and temporal graph matching	1
sequence of solution states	1
aperoid of observed frames	1
posteriori	1
composite features	1
graph vertices	1
e.g. $15$ frames	1
target trajectories	1
long range	1
Opinion Polarity	1
final answer predictions	1
document - level attention	1
differences betweenthe values of the arms	1
second order terms	1
first almost optimalregret bound	1
regret upper bounds inboth finite and infinite settings	1
$\Doubler$ and $\MultiSbm$	1
extensive body ofknown results	1
generic schema	1
$\Doubler$, $\MultiSbm$ and$\DoubleSbm$ --	1
stated preferences	1
implicit user feedback	1
cardinal feedback	1
ordinal feedback	1
less than 4\% of the parameters	1
tradeoff between time and performance	1
spectral property	1
2D spectral images	1
cognitive states from Electroencephalograph (EEG ) recordings	1
train and test time	1
millions of parameters	1
cognitive states	1
Hausdorff Distance of 5.32 mm, 22.32 mm and 20.44 mm	1
Dice score of 0.8858, 0.8297 and 0.7900	1
neuroimaging data	1
probabilities of the previous stage	1
better FID scores	1
shot generation ability	1
3/4th the amount of training time or less	1
relevant and generalizable features	1
varying sample size	1
different distribution of values w.r.t	1
aggregated Reconstruction Error	1
Reconstruction Error	1
FS advantages	1
minority class observations	1
Class imbalance	1
best F1 (66.3{\%})	1
syntax information	1
intra- and inter-sentence relations	1
relation extraction features	1
one or multiple	1
one dependency graph	1
new weights	1
current learned policy	1
thedifferent weights	1
safe and reasonable outputs	1
weightis	1
heavier weightinitially	1
anew learned control policy	1
previously available controlpolicy	1
SIFT andGIST descriptors	1
beingseveral orders of magnitude faster	1
par with or lower than AQ	1
extremes	1
compositional quantizers	1
small binary codes	1
Metric for Evaluation of Translation with Explicit ORdering (METEOR) score of 0.50	1
BiLingual Evaluation Understudy (BLEU) score of 71.2	1
Word Error Rate (WER) of 15.55	1
baseline normalization results	1
corresponding human annotated normalized form	1
lexical and compositional semantics	1
pair of sentences ( e.g. , premise and hypothesis	1
complex inferences	1
Multiple Object Tracking Accuracy (MOTA) and Multiple Object Tracking Precision (MOTP) metrics	1
specific object tracking capabilities	1
sparse implicit user feedback	1
user-side	1
student model predictions	1
insufficient view	1
user-side ranking information	1
small model (student)	1
one task	1
aspect categories	1
high data rates	1
improved versions	1
correlation of ~0.84	1
manually-crafted features	1
~13%	1
13 submissions	1
Person correlation coefficient of 0.8328	1
visualfeatures of unknown categories	1
Zero-Shot classification task (ZSC)	1
practical and efficient	1
-optimal solutions	1
competitivesolutions on benchmark instances	1
largenumber of constraints	1
exponential but sparsetabular form	1
exponentialnumber of constraint factors	1
integral solutions --	1
baselines at every time	1
old distributions	1
fixed rules	1
old ones	1
key of CCTS	1
multi-distribution form	1
changing features	1
timely life-saving	1
vital signs	1
precision, recall and running time	1
surprising differences	1
blocked pairs	1
user to label	1
pairs	1
shallow heuristics	1
remaining errors	1
ambiguous relations	1
resulting error hypotheses	1
62.1 to 70.1	1
8% absolute F1 test error	1
label errors	1
performance ceiling	1
high error rate	1
heuristic matching layers	1
sentencelevel semantics	1
thelikelihood of meaningfully combining information	1
0.04% and 3%	1
high and aggregationquality low	1
9,784 manually-annotated judgments	1
chance sentenceaggregation quality	1
average of 4 to 6 facts	1
two facts	1
graphof facts	1
strong coherence	1
misleading evaluation results	1
loss of important information	1
small samples	1
hundreds of documents	1
tens of thousands	1
far larger	1
\url{https://github.com/ZJULearning/PTL}	1
whole dataset's distribution	1
mini-batch	1
different camera viewpoint	1
significant variations	1
target scenario	1
information at different frequencies	1
input initialization	1
training settings	1
CTC baseline	1
unreasonable alignments	1
number of CTC feasible paths	1
maximum conditional entropy	1
highly peaky and overconfident distributions	1
given action labels	1
synthesized motions	1
coherent and realistic results	1
better realism and global consistency	1
decoder and encoder features	1
distant relations	1
motion style	1
input conditions	1
parametric distribution	1
arbitrary input	1
various fidelity and diversity requirements	1
different input constraints	1
tasks of motion prediction, completion, interpolation, and spatial-temporal recovery	1
robust solutions	1
dirty training data	1
dirty data	1
task and data	1
6% better accuracy	1
2% higher	1
actual data sharing	1
common discriminative information	1
single-trial covariance matrix	1
Privacy concerns	1
\textbf{4\%}	1
merits of collaborative representation	1
cross-domain knowledge	1
domain-specific statistics	1
estimated statistics	1
conditions of both benign and adverse visibility	1
thermal embedding vectors	1
loop closures	1
MDN parameters	1
hallucinated visual (RGB) features	1
normalized 14-bit radiometric data	1
sensor abstraction	1
adverse visibility	1
ambient illumination conditions	1
61 %	1
7.91 perplexity	1
cyclical batch size schedule	1
2.5$\%$ EM and 2.3$\%$ F1 scores	1
source representations of different levels	1
wrong judgments	1
likelihood of similarity	1
location increasingly	1
growing number	1
\textit{fine-grained}	1
\textit{coarse-grained}	1
source sequences	1
learning service information	1
overall learning time	1
MS-FEDL	1
hyper-learning rate parameter	1
different learning services	1
learning information	1
communication resources	1
data locally	1
Extensive numerical results	1
two precision matrices	1
probabilistic matrix decomposition models	1
dual spaces	1
true network connectivity	1
graph-regularization terms	1
data matrices	1
varying desired characteristics	1
representation'sshortcomings	1
perceptually significant characteristics	1
log-magnitude	1
3different representations	1
one piece	1
different lengths and musical keys	1
?style	1
distinct artistic styles	1
past classes	1
bounded memory	1
evaluated settings	1
experimental evidence	1
number of incremental states	1
size of bounded memory	1
size of datasets	1
number of datasets	1
six desirable properties	1
good compromise	1
deep model size	1
deep model capacity	1
plausible caricatureswith larger diversity	1
Diversity Loss	1
vivid details	1
large variance	1
richer contents and stylescan	1
richness and diversity	1
reasonable exaggerations givenface images	1
0.73, 0.79, and 0.68	1
higher F1 scores	1
four different classifiers	1
fractal dimension and chaos theory features	1
frequency energies	1
continuous signal	1
Additional results and videos	1
equivalent number of samples	1
6-DoF manipulation settings	1
field test data	1
various noise	1
GPR raw data incompleteness	1
sparse input	1
quantitative and qualitative experiment results	1
positioning information	1
GPR measurements	1
underground objects	1
sparse GPR measurements	1
slight WER absolute increase of 1.5\% and 5.5\%	1
speedup up to 10.97$\times$	1
extra CTC loss	1
inherent ambiguity problem	1
feature representation ability	1
poor approximation	1
conditionally independent behavior	1
length of the output sequence	1
sequence lengths	1
high inference latency	1
definite improvement of accuracy	1
low absolute performance	1
general linguistic knowledge	1
mammalian lung images	1
class-specificfeatures	1
discriminativeclass-specific features	1
rich geometrical structure	1
diversity of histology features	1
main question	1
themain given question	1
naturallanguage question	1
: (i)	1
set of independent scalar coefficients	1
non-linearly	1
neutral vector	1
mDWT vector coefficients	1
neutrality of the mDWT coefficients	1
nonnegative and sum-to-one properties	1
low bpp (0.05)	1
10.3%	1
MS-SSIM	1
specific compression ratio	1
low bpp (bits per pixel)	1
severe distortion	1
importance of image contents	1
high balance across metrics	1
rank 3 on NDCG	1
complementary abilities	1
multiple correct answers	1
substantially better	1
certain keywords or patterns	1
context history	1
image and conversational context information	1
--}	1
MWE score	1
5.09 BLEU points	1
expressions	1
1%-2% better accuracy	1
SFL	1
IID data distribution	1
client-side	1
communication and computation overhead	1
higher level of model privacy	1
best of FL	1
privacy of raw data	1
thegeneral one	1
equal representation power	1
simpler normal form	1
presented normal form	1
complex or real life situations	1
real raw images	1
Gaussian and Poisson noise	1
defective pixel noise	1
low noise	1
impulsive noise	1
Gaussian and Poisson distributions	1
brightness of captured data	1
ISO (electronic gain)	1
high noise level	1
relatively large annotated data	1
0.78 to 0.90 AUC ROC	1
0.92 to 0.95 F1-score	1
relevance of the misinformation class	1
0.85 to 0.90 F1-score	1
Misinformation , Debunking Misinformation	1
likes, dislikes	1
videos metadata	1
misinformation or not	1
semanticdistortion metrics	1
LFIC's superior performance gain	1
face verification accuracy distortion metric	1
71.41%, 48.28% and52.67% bitrate saving	1
integrated hybrid semantic fidelity metric	1
gradient feedback	1
face verificationaccuracy metric	1
Time Windows	1
temperature	1
short and long-term predictions	1
slight parameters increment	1
noisy samples	1
predicted motion	1
value and the uncertainty	1
predicted result	1
highest PSNR and SSIM	1
image noise visually	1
detailed structure information	1
high-resolution (HR) ASL image (44 min acquisition)	1
peak signal-to-noise ratio (PSNR) and structural similarity index (SSIM ) using normal-resolution (NR) ASL image (5.5 min acquisition)	1
generator	1
corresponding T1-weighted image	1
super-resolution (SR) image	1
LR ASL image	1
additional loss	1
anatomical prior	1
T1-weighted image	1
long acquisition time	1
poor spatial resolution	1
low signal-to-noise ratio (SNR)	1
cerebral blood flow (CBF) quantitatively	1
quantitative evaluation	1
two different tasks	1
useful source data	1
high-quality source data	1
useful source domain data	1
source data distribution	1
rich data	1
visual ornot	1
nonsensical answers	1
posed question	1
Free-form and open-ended	1
inference amortization	1
intersection	1
capability and scalability	1
parameters' full posterior	1
orders of magnitude its parameterization	1
normalizing flows	1
summary statistics	1
target HBM	1
parameter posterior distributions	1
around 1 million parameters	1
300 brain locations	1
reduced example	1
least tens	1
4 measurement sessions	1
64 thousand brain locations	1
<Cat	1
supporting fact	1
image-question-answerg triplets	1
commonsense, or basic factual knowledge	1
weighted Riemannian mean	1
Symmetric and Positive-Definite (SPD) matrices	1
volume preserving map	1
well-defined sense	1
multiple computational hops	1
less supervision	1
22 ]	1
output symbol	1
multiple computational steps ( hops )	1
drowsiness estimation	1
-channel correlation	1
thenon-sparseness	1
network incompleteness	1
known network interaction matrix	1
topological interaction information	1
biomedical network links	1
multi-scale biomedical big data	1
clinically relevant problems	1
substantial improvement in SSIM	1
9.9 and28.1 dB improvement	1
cone beam geometryreconstructions	1
similar PSNR and SSIM	1
superior peak signal tonoise ratio (PSNR) and structural similarity (SSIM )	1
patient anatomy	1
3D geometry	1
cone beam geometry	1
thereconstruction results over several iterations	1
raw measured data	1
performance decay	1
theoretical lower bound	1
learnt representations	1
set of normal data	1
2020 version	1
less noisy	1
label reliability	1
head diversity	1
perspective of data size	1
first experience	1
4,700 RGB images	1
privacy budget	1
Accuracy declines less than 0.01	1
output performance	1
pairwise data privacy	1
output distance metric	1
involved correlations	1
worst case	1
standard differential privacy	1
differential pairwise privacy (DPP)	1
pairwise information	1
patients similarity	1
correctly labeled pairwise data	1
Distance Metric Learning (DML)	1
log-ratio transformations	1
rounded zeros	1
log-ratios	1
detection limit	1
observed positive entries	1
additive, centered or isometric log-ratio representations	1
good interpretability	1
smaller variance	1
baselines by a large margin	1
lower variance	1
$M$ skills	1
$M$ action policies	1
skill context vectors (embedding vectors	1
skills (abstract actions	1
MDP equivalence	1
abstract actions implicitly	1
low sample efficiency	1
termination probability	1
action policy	1
grade	1
accuracy of 81.5% (\k{appa}=0.74)	1
accuracy of 79.1% (Cohen's \k{appa}=0.55	1
model hyper-parameters	1
temporal organisation	1
processed output	1
lower-voltage activity	1
high-voltage activity (bursts)	1
distinctive component	1
language identification mistakes	1
current open-source language identifiers	1
estimated concordance	1
50K tokens per second	1
$ F$_1$ score	1
$1.8$ and$1.0	1
F$_1=82.7$	1
structural informationand long range dependencies	1
varying sampling ratios	1
multiple CSI modalities	1
given imaging setting	1
inference stage	1
image prior	1
one single model	1
variety of measurement matrices	1
specific settings	1
training difficulties	1
sampling ratios	1
imaging parameter	1
ill-poseness	1
implicitly learned prior	1
under-sampled measurements	1
underlying image	1
NP-hard in the worst case	1
linear rate of convergence	1
globally optimal pair of actor (policy) and critic (action-value function	1
linear quadratic regulators	1
empirical success	1
open issues	1
, memory, bandwidth, and energy budget	1
perspective of resource limitations	1
implementation and scalability challenges	1
varying computational resource capabilities	1
privacy leakage	1
processing delay	1
future events	1
vast amounts of data	1
higher processing/computing capabilities	1
1 to 5	1
KDDCup-`99?	1
1000 number of epochs	1
0.1 rate	1
dialectal data	1
available parallel MSA data	1
one Arabic form	1
better translation accuracy	1
task of Argument Unit Recognition and Classification (AURC)	1
good deep learning performance	1
59.25{\%}	1
nine categories	1
5 point improvement	1
traditional answerability prediction	1
SQUAD 2.0	1
novel white-box feature	1
Area Under the Curve (AUC) scores	1
improvements of up to 4 points	1
incorrect predictions	1
Mr. Confident	1
confidence estimates	1
academic benchmarks	1
user-specified accuracy-cost trade-off	1
lower regret bound	1
oracle's ability	1
substantial difference	1
complicate relation	1
necessary information	1
question relevant information	1
bigger picture	1
sample efficiency and asymptotic performance	1
capacities	1
learning trajectories	1
generation speed	1
control precision	1
bit-rate control measured by rate-distortion curves	1
compression quality	1
target metrics	1
various neural compression models	1
desired substitute	1
particular loss	1
fully differentiable structures	1
flexible distortion metric	1
sentence-level and word-level information	1
referents	1
object recognition (CIFAR-10)	1
1M GIST, 1B SIFT features	1
billions or trillions of centers	1
super-linearly	1
compositional parameterization	1
quantization errors small and model fidelity high	1
storage and runtime cost	1
number ofoverlapping health-related terms	1
number of stop words	1
invalid answer	1
considerably noisy	1
reasonably high rateof accuracy	1
proximately 8 %	1
anaccuracy of 86.2%	1
best answer	1
valid answers	1
health-relatedquestions based on past questions and answers (QA)	1
posted questions	1
health information needs	1
localization output	1
transfer ofsegmentation cues	1
geometricrelation	1
histogramdifference	1
linear constraints	1
spatial relationship	1
tworepresentations at different levels	1
high level localizationcues	1
low level appearance cues	1
single optimization problem	1
larger numbers	1
263,482 comments	1
sustained press attention	1
600,000	1
echo, filtering, poor signal to noise ratio	1
adverse recording conditions	1
reliable pitch curves	1
recently implemented features	1
various points of view	1
existing achievements and problems	1
survey results	1
stylistic features	1
performance limits	1
linguistic styles	1
two options	1
' context ' )	1
last sentence	1
close to state - of - the - art performance	1
stylistic differences	1
one of two potential endings	1
4 - sentence prompt	1
overall recognition quality	1
20% relative reduction	1
scrambled word order	1
longer sequences	1
permutation equivariant	1
correct sequence order	1
less semantic information	1
stroke	1
complete response	1
irrelevant and uninformative responses	1
detection and speed	1
regions of interest)	1
Attentional Point-	1
tracking results	1
longer video lengths	1
various challenge factors	1
around 2,500 frames	1
average video length	1
1,550 totaling more than 3.87 million frames	1
accuracy of 90%	1
physics data	1
93.44% and 67.15% (i.e., 3.93% and 2.13% improvement) Top-5 localization accuracy	1
extra annotation	1
pseudo label	1
accurate object mask	1
sharper boundaries robustly	1
commonly used features	1
Class activation maps (CAMs)	1
sensing modalities	1
feature positions	1
nonlinear optimization	1
high F1 scores	1
insufficient amounts	1
ideal factor $k$speed-up in learning performance	1
factor $\sqrt{k}$ parallel speed-up	1
times faster	1
amountof communication	1
non-trivial tradeoffbetween	1
$\epsilon$-optimal arm	1
12.62 % ( ROUGE - L ) relative improvement	1
span	1
reasoning overlong documents	1
known biases	1
9 out of 12	1
dataset-specific artifacts	1
datasets containing no (or different) hypothesis-only biases	1
datasets containing biases	1
hypothesis and NLI label	1
probability of a premise	1
non-trivial performance	1
hypothesis-only biases	1
cloud detection accuracy	1
dedicated term	1
spatial and spectral information	1
different but compatible spatio-spectral characteristics	1
new ground truth data	1
significant drops in accuracy	1
potential synergies	1
20	1
scene illumination color	1
single frame - shot frame -	1
conventional single-frame color constancy	1
name cQARank [\url{https://github.com/TitasNandi/cQARank}].	1
third in subtask A and eighth in subtask	1
primary evaluation metrics	1
subtask C	1
textual, domain-specific, word-embedding and topic-modeling features	1
relevantinteractions between modalities	1
VisualQuestion Answering (VQA) and Visual Relationship Detection (VRD)	1
practicalinterest	1
powerful mono-modal representations	1
fine interactions	1
expressiveness and complexity	1
concepts of rank and mode ranks	1
input dimensions	1
number of parametersgrows	1
subtle combination	1
accepting {``}wildcard{''} solutions	1
uncertain coverage	1
abstract linguistic level	1
improvement of AUC by 2.1% on average	1
data of PTA	1
model-free constraints	1
feasibility information	1
damage function	1
additional signal	1
unsafe state-action pairs	1
{\pi}	1
feasible trajectories	1
certain state-action pairs	1
policy {\pi}	1
feasible policies	1
value and action-value functions	1
action triplets	1
almost sure constraints	1
discriminative and generalizable features	1
PFID loss	1
individual identity sub-manifolds	1
notion of similarity	1
nuisance factors	1
unrelated factors	1
tedious and time consuming	1
close proximity	1
300 - sparsans	1
human evaluations	1
TIP quality scores	1
real CT volumes	1
generated TIP volumes	1
3D CT volume segmentation	1
vigilance and performance	1
ongoing performance	1
plausible and realistic manner	1
threat object signature	1
direct causes of the target	1
complicated dependences	1
general exponential family distributions	1
nonlinear classifiers	1
nonlinear representations	1
nonlinear setting	1
linear model class	1
spurious features	1
invariant relationship	1
better translation quality	1
time expensive	1
3D model's performance	1
amount of contextual information	1
area-plots	1
dice scores of 79% and 73%	1
peculiar pattern	1
area-plot	1
seed rules	1
average improvement of +20\% F1 score	1
augmented rules	1
candidate rules	1
new labeling rules	1
domain expertise	1
considerable amount of manual effort	1
heuristic labeling rules	1
55.03% and 59.07% joint accuracy	1
current turn	1
passage information	1
dialogue slots	1
corresponding last dialogue states	1
turn utterance	1
information of each dialogue turn	1
Predicted Dialogue States and Conversations network (FPDSC)	1
incomplete or erroneous	1
dialogue information	1
lastly predicted dialogue states	1
complete dialogue information	1
current dialogue states	1
context and the last dialogue states	1
spatio-temporal and relational context	1
wake state	1
theta rhythm	1
stimulating input	1
high acetylcholine levels	1
highserotonin and low acetylcholine state	1
septum and MHb connectivity	1
known findings	1
functional role	1
comprehensive corpus statistics	1
inter-annotator agreement scores	1
least four different annotators	1
posts	1
big problem	1
best possible automobile	1
phrase-level polarities	1
features (e.g. address book	1
e.g. my car	1
different types of annotations	1
1000 posts each)	1
observed difference in performance	1
increases in performance of 5-9%	1
strongly competitive results	1
multi-task format	1
reasonable answers	1
many sub-problems	1
test word	1
nearest similarity distance	1
hypernym list	1
hypernym lists	1
contextual similarities	1
richness of information	1
much richer information	1
many of the same flaws	1
everyday activities	1
dead-end	1
kind of expressions	1
search engine quality	1
different signals	1
term importance	1
strikingly low correlation	1
automatically produced annotations	1
SYntactic parses	1
Term Importance	1
named Entities	1
Root Mean Squared Error (RMSE) of 25.68 words per minute	1
input length	1
cognitive load	1
effort-impacting factors	1
time spent	1
much effort	1
fair pricing	1
completion timelines	1
distance matrices	1
strong positive correlation	1
vector space dimensionality	1
probabilistic skill similarity	1
knowledge state	1
KQN interpretable	1
corresponding skills	1
odds ratios	1
pairwise cosine and Euclidean distances	1
\textit{probabilistic skill similarity	1
knowledge state and skill vectors	1
low prediction accuracy	1
states and skills	1
students' states of knowledge	1
related skills	1
abetter reconstruction accuracy	1
numberof Gaussian kernels	1
convex sparsity-inducing penalty	1
accuracy--efficiency trade-off	1
lowerthe number	1
boththe modelling accuracy	1
Gaussian kernels	1
analog PSFmodels	1
theoretical and empirical PSFs	1
rich tailstructures	1
computationally intensive	1
sub-pixel accuracy	1
higher resolution	1
spatialresolution	1
opticaldistortions	1
transition point	1
point of criticality	1
critical temperature	1
correlation structurerandomly	1
internal organizational structure	1
wide span of levels and contexts	1
pervasiveness	1
one or otherregime	1
better or competitive performance	1
salient and discriminative information	1
labels of categories	1
proposal loss	1
attention factors	1
specific expressions	1
novel Feature Refinement ({FR})	1
specific discriminative characteristics	1
subtle facial changes	1
contextualized word representations	1
different tests	1
word and sense embedding representations	1
embedding similarity function	1
payoff	1
strategies	1
extra hyper-parameters or learnable parameters	1
intrinsic limitation	1
good result	1
high-quality and diverse results	1
several online metrics	1
recommendation quality	1
diversity and dynamic property	1
effective and diverse recommendation results	1
dynamic property	1
handcrafted sparse fea -	1
competitive or even better results	1
pre-defined vocabulary	1
candidate hypernyms	1
security of FL	1
security means	1
FL models	1
global models	1
two critical security threats	1
privacy preservation	1
relatively simple interpretable policies	1
non-interpretable	1
thousands of parameters	1
par closed-loop performance	1
one to four non-linear terms	1
relatively simple and interpretable rules	1
multiple discrete actions	1
different control problems	1
closed-loop performance	1
function of state variables	1
hierarchical set of nonlinear control rules	1
open-loop performance	1
control rules	1
developed control rules	1
optimal closed-loop performance	1
underlying control task	1
given control task	1
multi-class classification performance	1
locally stored data	1
tasks and settings	1
fraction of the usual size	1
largest to date	1
's scanning center shift gap	1
improved FWHM	1
terms of the Full Width at Half Maximum(FWHM) and Modulation Transfer Function (MTF)	1
scanning orbit	1
cylindrical artefacts	1
ring-type	1
field of view (FOV)	1
scanning time	1
reduced information loss	1
improved performance interms	1
drawbacks	1
paraphrasing capability	1
varied rewriting styles	1
readability	1
effectiveness of our theoretical results	1
bounded-PoF guarantees	1
$k$-center objective	1
\emph{Price of Fairness (PoF)}	1
values of $\alpha$	1
$\mathcal{S}_j$.	1
given $\alpha \geq 1$	1
$\alpha$-close (in a multiplicative sense	1
quality of service	1
set of other points $\mathcal{S}_j$ that it	1
point $j$	1
individual fairness	1
societal implications	1
fair variants	1
qualitative examples	1
pointwise mutual information)	1
NIST OpenSAT' 17	1
temporally consistent	1
predicted signal	1
\url{https://github.com/ChrisAllenMing/LtC-MSDA	1
features' intra-class invariance and inter-class separability	1
compactness of features	1
categories' relational interdependency	1
correlated prototypes	1
query samples	1
semantically adjacent representations	1
EMD(earth mover's distance	1
images' signatures	1
interestregions	1
binary signature	1
interestregions of image	1
additionaltraining data	1
accurate disambiguation capabilities	1
deeper measures	1
explicit perceptual knowledge	1
physical, cognitive and language-dependent aspects	1
spoken commands	1
strong attcks	1
channel sparsity	1
natural accuracy	1
struture of sparsity	1
DNNs' accuracy	1
sparse DNNs	1
4-bit, quantization	1
ternary (tnn)	1
DNNs robust	1
SemEval 2015 and SemEval 2016)	1
method flexibility	1
word semantics	1
non-contextual word embeddings	1
associated aspects	1
information of Relevance Feedback	1
0-th iteration retrieval accuracy	1
EEG latent representation	1
50 categories	1
high confidence	1
sufficiently early	1
correct grasp	1
chance level of 7.7%)	1
overall fusion accuracy of 95.3% among 13 labels	1
EMG and visual evidence	1
13.66% and 14.8%	1
reaching phase	1
instantaneous upcoming grasp type classification accuracy	1
individual evidence modality	1
multimodal evidence	1
function of time	1
individual and fused performance	1
view-angle	1
variable shapes	1
object occlusion	1
skin electrode junction impedance	1
motion artifacts	1
poor inference outcomes	1
thetraining data	1
variety of open questionsabout	1
boththe development and evaluation data	1
similar level	1
overall picture of what	1
key tasks	1
product features	1
digital form	1
sheer volume	1
300 px tall face	1
scale - invariant	1
role of scale invariance	1
colorbar on the right	1
Detector confidence	1
novel characterizations of scale , resolution	1
reportedly 1000 present	1
around 800 faces	1
exhibit good performance	1
optimal action-state decision policy	1
TransmissionTime Interval (TTI)	1
QoS Class Identifier (QCI)	1
number of resources	1
QoS levels	1
spectral efficiency and otherrelated channel issues	1
traffic class	1
traffic demand	1
unstable channel condition	1
94.38 F1-score	1
obtainstate-of-the-art performance	1
different sizes, genres and annotation schemes	1
accurate and robust	1
lower-than-character levelfeatures	1
rich contextual information	1
Chinese charactersthat	1
novel vector representations	1
common spatial patterns (CSPs)	1
terms of the PQ score	1
6.41 pp	1
extracting features	1
scans	1
raw LiDAR scans	1
environmental conditions	1
intensity distribution	1
mounting position	1
number of scan lines	1
additional data labeling	1
time savings	1
low-label conditions	1
uncertain class assignment	1
pair-wise distances	1
data uncertainty	1
original data point	1
high uncertainty	1
measurement inaccuracies	1
meaningful low dimensional embedding	1
sensitivity of 82.07 % and a low false positive rate (FPR) of 0.0799 /h	1
seizure prediction horizon (SPH) of 5 minutes and a seizure occurrence period (SOP) of 30 minutes	1
pre-ictal	1
given epoch	1
easy/hard	1
Semantic content	1
Entropy	1
pattern of answers	1
hyperedges withdifferent degrees empirically	1
various kinds of dependenciesamong	1
trackletsand	1
trackletsin a unified objective	1
different degrees of dependencies	1
higher order dependencies	1
mean Dice values of 0.81, 0.89 and 0.84 on ET, WT and TC regions	1
ranking in 10th place	1
equal 5th highest value	1
evaluation score	1
Dice value of 0.89	1
enhancing tumour (ET) and tumour core (TC)	1
Dice similarity coefficient of 0.77	1
high inter-rater variability	1
highly challenging	1
appearance and location	1
wide variation	1
Human3.6M)	1
state of the art interms	1
large number of pose classes	1
new synthetic image	1
selected images	1
projected 3D pose	1
imagewhose 2D pose	1
candidate 3D pose	1
2D human pose annotations	1
3D pose annotations	1
3D human pose estimation	1
manually annotated data	1
kNN by hundreds of times	1
cost functionwith linear computational complexity	1
training/testdata	1
Collapsing Metric Learning (MCML) objective	1
constrained	1
computational cost and resources	1
training data points	1
fairly big datasets	1
quadratic computational complexity	1
desirable theoretical properties	1
slight variation of WQL	1
tabular case	1
state-action pairs	1
Wasserstein barycenters	1
approximate posterior distributions	1
less repetition	1
translated contents	1
much repetition	1
past information	1
better levels	1
train nor at test time	1
best possible level	1
suf?cient size	1
fair minimax classi?er	1
worst-case fairness	1
space of solutions	1
needs	1
test, time	1
protected features	1
fairness properties	1
62.68 % and 52.41 % for	1
mean accuracy	1
mean accuracy reaches 71.52 % and 70.27 % for	1
$C_{z}$, $C_{3}$ and $C_{4}$	1
performance task	1
high and low power EEG imagery	1
pure imagery and transitional EEG	1
\textit{transitional imagery}	1
non-imagery EEG (\textit{background EEG }), (\textit{pure imagery}	1
PSNR and MS-SSIM metrics vs. bit-rate	1
objective comparison results	1
traditional codecs	1
mean recall by up to 21.9% on a single-language	1
four	1
(more abundant) language data	1
fewer annotations	1
MULE to visual data	1
75{\%}	1
90{\%} in English nodes	1
human agreement rate	1
DST structure	1
(POS) n-gram patterns	1
bilingual shallow semantic relations	1
accumulated error	1
back locations	1
potential scales	1
half the size of input	1
smaller scale	1
particular scale	1
bottleneck of computational cost	1
large scale variations	1
training time),suggesting	1
75x reduction	1
featuredesign	1
new evidence	1
distant (weak) supervision labels	1
macro-F1 score of 0.83{\%}	1
contents, size, coverage, and overlap	1
larger body	1
search results	1
current limitations of ILP	1
processing time exceeding 5 h	1
number of reports	1
200 degree	1
processing temperature	1
number of papers	1
micro-F1 score of 78.1%	1
301 papers	1
material names	1
promising terms	1
physical properties	1
ad campaign performance	1
actionable business goals	1
overall campaign performance	1
poorer online performance	1
traffic	1
live traffic	1
real-world performance metrics	1
bidding strategies	1
real-world business metrics	1
machine learning metrics	1
poorer performance	1
negligible accuracy losses	1
significant acceleration gains	1
type of errors	1
significant acceleration	1
available variables	1
prediction horizons	1
naturalness and target speaker similarity	1
rich literature	1
perceived identity	1
non-linguistic information	1
Word Error Rate (WER) of 0.278 and a BLEU score of 0.586	1
corpus size and quality	1
293 hours of data	1
publicly available data	1
rough but unbiased estimate	1
huge branching factor	1
target number of relevant features	1
finite unknown horizon	1
coarse - to - fine manner	1
face and landmark location	1
various poses	1
best ones	1
50% accuracy	1
mental states	1
varying potentials	1
relaxed mode	1
confused learning mode	1
engaged learning mode	1
student needs assistance	1
different grades of injury	1
81.5%	1
testing accuracy of 79.6% with one-step voting	1
63 hours	1
4 grades	1
phase spectrum	1
commonly used front-end MFCC features	1
assignment	1
Dirichlet distribution	1
prior distribution of coefficients	1
strong parametric assumption	1
richer signal	1
thespecific choice of the evaluation setting	1
internet vision-style problems	1
English subtasks A and B	1
57.19 and 63.7	1
official score (macro-averaged F1)	1
24 primary and 37	1
total of 61	1
yes, no, or unsure	1
good, bad, or potentially	1
environmental sound	1
environmental sounds	1
highest reported performance	1
20% CPU	1
70.9% mean 10-fold accuracy	1
model variations	1
maximum 50% utilization	1
resource budget	1
low-cost	1
energy-intensive	1
sound level	1
noise problems	1
/loshchil/SGDR	1
adownsampled version	1
3.14% and 16.21%	1
anytime performance	1
ill-conditioned functions	1
learned entity/word representation	1
textual query	1
fine-grainedparsing configuration	1
aunified interface	1
three benchmarks	1
upper bound of error rate	1
linear separability	1
theoretical upper bound of error rate	1
upper limit of error rate	1
cause of error	1
restricting factors of performance	1
new categories	1
ERF and face scales	1
100 % coverage	1
large range of continuous face scales	1
RF strides	1
theses RFs	1
distributed regularly	1
importance of receptive field ( RF ) and effective receptive field ( ERF )	1
low computing power	1
limited memory storage	1
geodesic normal coordinates	1
fuzzy equivalence	1
mechanism of its validity	1
high-fidelity images	1
distorted geometry and texture attributes	1
17 pairs of geometry and texture quantization parameters	1
combination of 20 sequences	1
six degrees of freedom	1
geometry and texture attributes	1
subjective and objective Point Cloud Quality Assessment (PCQA)	1
significant modifications	1
sentence splits	1
higher quality training examples	1
1-2 sentence alignments	1
BiSECT training data	1
long, complex sentence	1
acomprehensive comparison	1
super-slices	1
dimension of CNN inputsbased	1
one-dimensional inputtime-series	1
median task success rate of 81%	1
median relative word error rate improvement of 71% with only 50	1
delayed model-update times	1
visual, physical, task, and social complexity	1
restricted agent perspective	1
low task complexity	1
inaccurate physics	1
unrealistic visuals	1
histological images	1
diagnostic power	1
AUC greater than 0.96	1
modified Marsh score	1
CD severity	1
mild histologic features	1
non-specific clinical symptoms	1
decreased bone density	1
compromised intestinal barrier function	1
inter-aspect dependencies	1
aspect and its contextual information	1
desired diverse outputs	1
diversity of outputs	1
single output	1
studied problems	1
resulting optimal designs	1
various OED criteria	1
bilevel nature	1
finite parametrization	1
linearized CRs	1
informative measurements	1
available (experimental) degrees of freedom	1
least-squares parameter estimates	1
detection template	1
learned rules	1
complex face manifolds	1
scale invariant	1
Weber Fraction	1
two pixel values	1
difference to sum ratio	1
NPD feature	1
Normalized Pixel Difference ( NPD )	1
arbitrary pose variations	1
hard work and computation cost	1
useful patterns and characteristics	1
breakthrough performance	1
low illumination	1
occlusion, viewpoints	1
incredible performance	1
limited supervision	1
compositional languages	1
right structure	1
gold standard layouts	1
age	1
textual medical reports	1
spectral power changesin the delta (0-4 Hz) and theta (4-8 Hz) frequency range	1
ConvNet decoding behavior	1
nonlinearity	1
six seconds of each recording	1
1 minute of each recording	1
published result	1
~85% vs. ~79%)	1
6%better,	1
substantially better accuracies	1
task-related information	1
normal EEG recordings	1
Empirical histograms	1
conditionsand sleep stages	1
correlationdimension and minimum embedding dimension	1
largest Lyapunov exponent	1
chaotic indices	1
chaotic and nonlinear nature	1
representation learning quality	1
Cross-Entropy based and ranking-based Triplet Matching Losses	1
bidirectionally constrained	1
local image region-word level	1
global image-sentence level	1
associated free-text reports	1
unlabeled chest X-rays	1
image noise	1
many as possible training pairs	1
similar signals	1
independent but also correlated noise	1
complex structural patterns	1
real noise distributions	1
independent noise assumption	1
neighboring pixels	1
paired noise-clean or noise-noise samples	1
superior denoising performance	1
coarse-grained representation	1
another dimension of abstraction	1
inclination of political opinions	1
prospects	1
opinions and emotions	1
original document scores	1
human judgment scores	1
initial CLIR AQWV score	1
likely benefits	1
possible gain	1
many conditions	1
loss in AQWV	1
acceptance threshold	1
AQWV performance measure	1
resulting documents	1
irrelevant documents (false alarms)	1
AQWV score	1
face / non - face patterns	1
best scale	1
valid faces	1
face patterns	1
associated facial landmarks	1
Large pose variations	1
27M parameters	1
41.4\% mAP	1
different operators	1
one certain component	1
minor runtime overhead	1
15% energy	1
direct feedback	1
expected rewards	1
possible actions	1
information about available states	1
different compute characteristics	1
idle nor synchronisation phases	1
load balanced	1
executed code	1
idle or synchronisation periods	1
processor frequency	1
accurate but slow live measurements	1
time budget	1
substantially improved results	1
asan expected reduction in accuracy and hypervolume	1
inaccurate predictions	1
training tasks	1
ten combinations of metrics	1
18 different performance predictors	1
little known information	1
desired metrics	1
estimates of how	1
live measurements	1
optimal tradeoff of accuracy and latency	1
hardware-aware settings	1
(and in some cases - better) test accuracy	1
much faster training performance	1
various heterogeneous conditions	1
observed training performance and accuracy overtime	1
heterogeneity in resource and data quantity	1
straggler problem	1
training performance	1
quantity and content	1
computation and communication capacity	1
resource and data	1
One of the key attributes	1
privacy requirements	1
five times that	1
SILO's rate	1
gcc version 10.3 compiler's aggressive optimization level -O3	1
expected 6.2%	1
25K	1
optimal program	1
network architectures	1
13.28%	1
FedSTAR on average	1
little as 3% labeled data	1
varying percentages	1
training rounds	1
abundance of audio data	1
prohibitively expensive and time-consuming	1
dedicated loss term	1
P-frame coding conditions	1
Learned Image Compression 2020 (CLIC20)	1
high fidelity	1
real-world setting	1
useful gradient information	1
corresponding LR images	1
frequency domain consistency	1
undesired gap	1
real source domain	1
known degradation	1
significant performances	1
distinct themes	1
two constrained documents	1
probability distribution of topics	1
document constraints	1
two instances of CRTM	1
available domain knowledge	1
class of Constrained Relational Topic Models (CRTM)	1
hidden topics	1
42 FPS	1
multiscale version of features	1
simple form	1
oriented gradient histograms	1
gradient magnitude	1
diverse types	1
concept of channel features	1
large appearance variance	1
distance up to 50 meters	1
ground markings	1
longitudinal velocity	1
thetheoretical foundations	1
nonexistence of poor local minima	1
non-convexity)	1
theindependence assumption	1
thesame four statements	1
bad saddle point	1
thanthree layers)	1
negative eigenvalue	1
globalminimum is a saddle point	1
every critical point	1
every localminimum is a global minimum	1
non-convex and non-concave	1
depth andany widths	1
squared loss function	1
partiallyaddress an open problem	1
competitive caption quality	1
gender prediction errors	1
correct gender visual evidence	1
unwanted bias	1
high gender prediction errors	1
huge gender prediction errors	1
different gender-context joint distribution	1
correct gender features	1
incorrect or even offensive errors	1
learned priors	1
71.1 to 87.5 F1	1
r-NEs	1
flow graphs	1
annotations automatically	1
82.3 to 90.5 F1	1
two kinds	1
{`}recipe named entities{'} (r-NEs)	1
domain-specific linguistic and semantic structure	1
8% AP50	1
best baseline performance	1
Cityscapes-C.	1
Pascal-C and 5-6% AP	1
relative robustness improvement of 15-25% AP50	1
prior baselines	1
accuracy, robustness andtime-efficiency	1
3D distance error of 2mm	1
skeleton length	1
two skeletons	1
longeroperation hours	1
gap between knowledge-based and supervised Word Sense Disambiguation (WSD) performance	1
quantitative and qualitative measurements	1
image global correlation	1
highly realistic	1
organ properties	1
gold-standard anatomies	1
SSIM and less than 30%	1
8%	1
given image pair	1
deformation parameters	1
less than 50% time cost	1
corrected text	1
annotated erroneous spans	1
two subtasks: Erroneous Span Detection (ESD) and Erroneous Span Correction (ESC)	1
extreme poses	1
locations and sizes	1
location accuracy	1
approximately 1.0 BLEU	1
encouraging result	1
read , compose and write operations	1
ImageNet toobtain features	1
awide range of transfer tasks	1
SkipThought vectors	1
satisfactory enough performance	1
unsupervised representations	1
base features	1
image classification results	1
single configuration	1
original input	1
known hippocampal functions	1
wider range	1
local credit assignment	1
external labels	1
long-term memory	1
similar experiences	1
provided labels	1
one experience	1
specific experience	1
longer time span	1
better retrieval performance	1
different time span	1
diachronic text data	1
topic and semantic context	1
AUC score by 3% (absolute improvement)	1
zero-shot codes	1
F1 score from nearly 0 to 20.91%	1
conditioned ICD codes	1
real features	1
generated features	1
semantic consistency	1
ICD code hierarchical structure	1
ICD code descriptions	1
pseudo features	1
frequent and zero-shot codes	1
94.198\% @ 1e-8 and 72.981\% @ 1e-4	1
24.12 Gflops	1
28.25 Gflops	1
anchor finetuning	1
regular face	1
useful tricks	1
`ArcNegFace'	1
Flops constraint	1
`Efficient PolyFace'	1
computational budget no higher than 30 GFlops	1
\textit{flops} upper bound	1
acyclic case	1
rivals FCI	1
cyclic case	1
conditionalindependence oracle	1
cycles, latent variables andselection bias (CLS)	1
selection bias	1
vehicle's speed	1
-modal distributions	1
complex behaviors	1
distribution offuture trajectories	1
useful environmental andkinematic features	1
off-road driving data	1
30 km	1
state-space complexity	1
kinematic andenvironmental context	1
specified objectives	1
accurate motion prediction	1
heuristics or meta-data	1
visual summary	1
62 FPS	1
F-measure of 82.8	1
ideal tradeoff	1
detection accuracy and speed	1
thresholds	1
various shapes	1
image or video compression artifacts	1
extremely low resolutions	1
heavy facial occlusions	1
facial expression recognition	1
facial periocular recognition	1
various facial related problems	1
61.40%	1
88.62%, FERPlus with 89.22%, and AffectNet-7 with 64.57%	1
incorrect labels	1
incorrect decisions	1
subjectiveness of annotators	1
much fewer training examples	1
performance predictors	1
good and bad candidates	1
numerous training examples	1
efficiency challenge	1
adaptive ability	1
evolutionary patterns	1
proposed additional smoothing factor	1
measure of temporal smoothness	1
fine-granularity temporal relationships	1
factual plausibility	1
structural relationships	1
entities and relationships	1
volume ofthe data	1
several days/weeks	1
anew domain within few hours	1
human subjective evaluation metric	1
bothautomatic metrics	1
order of magnitude lower	1
state-of-the-art joint accuracy	1
slot and domain level	1
high time cost	1
(domain, slot) pairs	1
dynamic slot values	1
good performance gain	1
slot value candidates	1
current achievements	1
potential of neuroimaging	1
domain-invariant and domain-specific features	1
certain marginal distribution	1
high precision and reliability	1
summarized state	1
user's own state	1
news	1
fine-grained topic-specific similarities	1
key ideas	1
single similarity metric	1
interests	1
users' own reading histories	1
societal impact	1
societal influences	1
future items	1
users' recent browsing history	1
great opportunity	1
gate values	1
modality (visual or semantic)	1
fine-grained level	1
question-relevant information hierarchically	1
high-level visual semantics	1
semantic view	1
appearance-level information	1
visual and semantic perspectives	1
objects, relationships or semantics	1
broad range of visual content	1
one question	1
word embeddings efficiently	1
lot of terms	1
wider vocabulary	1
small training datasets	1
diversity of training data	1
final accuracy of output	1
scales	1
Low - level facial feature	1
adequate high - level context semantic feature	1
lower performance	1
detailed data	1
different complexity	1
deep learning models' performance	1
set of problems	1
significant advances	1
final classification performance	1
regularizationto the covariance matrices	1
traditional CSPsolution	1
slightly differentobjective function	1
variancefor one class	1
variousartifacts and noise	1
even higher accuracy	1
3-8% of the dense model size	1
re-)expand model capacity	1
top-down and bottom-up	1
compact network capacity	1
intrinsic bias	1
appropriate weight initialization	1
across domains	1
same	1
different knowledge	1
image object	1
one knowledge	1
multiple knowledge triplets	1
answer ambiguity	1
one or two triplets	1
question-answer pair	1
research boundary	1
superficial over-fitted correlations	1
annotator bias	1
image and text contexts	1
input-output correlation	1
underlying knowledge	1
competitive model evaluation accuracy	1
better architecture search performance	1
architecture search results sub-optimal	1
space of architecture candidates	1
Differential Privacy	1
possible fundamental trade-off	1
stringent privacy requirements	1
bandwidth efficient	1
biased quantization	1
robustness, privacy, bandwidth efficiency, and model accuracy	1
different trade-offs	1
generated model	1
associated privacy risks	1
advanced knowledge	1
opposite direction	1
template functions	1
adaptively select parameters	1
localized information	1
featurizations	1
persistence diagram	1
stable vector representation	1
mathematical creativity	1
potentially big overhead	1
theDelaunay property	1
position estimate	1
3D reconstruction	1
3D Delaunay triangulation	1
availableframe-by-frame	1
125 FPS	1
recall rate	1
discretizing anchors	1
Multiple Scale Convolutional Layers ( MSCL )	1
F1 score of 0.67 on test1 and 0.66 on test2	1
2,631 and 2,664 images	1
two datasets test1 and test2	1
road damages	1
clear evaluation metrics	1
well-defined problem	1
Big Data Cup challenges	1
Global Road Damage Detection Challenge (GRDDC)	1
better location	1
generalizable knowledge	1
well-performingarchitectures	1
large space of possiblechoices	1
infrared sounding data	1
propagated error terms	1
analytical error propagation formulation	1
derivative	1
instrument error	1
training and testing points	1
confidence intervals	1
predictive variance function	1
useful property	1
accurate estimates	1
qualities of features	1
limit on either of these properties	1
bounded conditional geometric dependency measure	1
feature's importance	1
OSFS with Streaming Samples (OSFS-SS)	1
OSFS's main assumption	1
assessment score	1
ground truth scores	1
two action videos	1
final score	1
temporal variations w.r.t	1
given action video	1
awarded score	1
ground truth score	1
judgment bias	1
accuracy of 85%$	1
shape of the boundaries	1
statistics features	1
top scores of 93.76% and 88.82%	1
Dice and IoU metrics	1
typical adversarial loss	1
relative impact	1
different resolutions of BUS images	1
tumor features	1
treebank	1
largetreebank, a small treebank	1
strong baselines ina range of data scenarios	1
parser's performance	1
linguistic universals andtypological similarities	1
fine-grained POS tags	1
iii)language-specific features	1
token-level language information	1
multilingual wordclusters and embeddings	1
motivation, development and differences	1
role-based structural similarity	1
another type of structural similarity	1
corresponding representations	1
second stage	1
insufficient texture data	1
individual and pairwise label information	1
binary hash code	1
learnt texture specific information	1
newer texture content	1
enlarged view	1
input texture images	1
binary hash codes	1
anaverage 57.93% and 33.20% SSIM improvement	1
average 7.47dB and 5.98dB PSNR	1
wide range of compression ratios (CRs)	1
flexibleresolution	1
improved quality	1
incremental resolution	1
contextual latent vector	1
CS measurements	1
pyramid level	1
theconcept of Laplacian pyramid	1
state of the art average precision ( AP ) by 1.1 % ( achieving AP equal to 91.4 % )	1
pixel - wise 3D shape face information	1
extra supervision signal	1
F1=0.81)	1
F1=0.87)	1
distributions over 30 runs	1
less satisfactory results	1
known answer	1
paraphrased span	1
strict spans	1
long answers	1
ground-truth answer span	1
span answer	1
particular passage	1
single span of text	1
result of 87.28% and 86.60% accuracy	1
competitive search effectiveness	1
improved search efficiency	1
much faster and cheaper	1
even betteraccuracies	1
wide variety of historicalprintings	1
character accuracieswell above 90%	1
different printing dates	1
76% to 97% (word level	1
94% tomore than 99% (character level)	1
machine-readable texts	1
Character and word accuracies (percentage of correctly recognized items	1
necessary *ground truth*is	1
1487 and 1870	1
scanned images	1
unknown or non-ideal	1
different settings perimage	1
poor SR results	1
non-ideal PSF	1
distracting artifacts(e.g	1
high-resolution (HR) counterparts ispredetermined (e.g., bicubic downscaling)	1
specific training data	1
Super-Resolution (SR) performancein	1
dramatic leap	1
overall trends	1
approach and results	1
high margin	1
16 domains	1
16000 dialogues	1
system attributes	1
model load time	1
communication time	1
various runtime costs	1
end to end speedups of $>$ 1.5 $\times$ - 2.5 $\times$	1
corresponding quantization error	1
quantization's computational benefits	1
computational overheads	1
computational demands	1
significant milestones	1
resultswith	1
noisyAutomatic Speech Recognition (ASR) outputs	1
overall F1 scores	1
certain competitive baselines	1
relevant slots	1
driving behavior	1
destination	1
appropriate functionality	1
commandsproperly	1
accurate segmentation	1
much environment noise information	1
normal circumstances	1
good detection performance	1
image and BEV features	1
cropped image features	1
corresponding map crops	1
new state-of-the-art scores	1
automatic and human evaluation results	1
output question	1
explicit structure information	1
target answers	1
single KG triple	1
KGs and target answers	1
62x speedup	1
16 sampling steps	1
1000 steps	1
comparable or even higher quality samples	1
3 sampling steps	1
inference noise schedules	1
pre-trained DDPM	1
simple-to-train	1
surrogate objective	1
standard evidence lower bound	1
new lower bound tighter	1
bilateral modeling objective	1
high-quality samples	1
significantly fewer steps	1
word aligned	1
93.17$\%$ accuracy	1
discriminative and powerful features	1
class-specific information	1
F1 score of 37.31{\%}.	1
approximately 10K manually checked passage-question-answer instances	1
input entity mentions	1
dependency and semantics relations	1
important context information	1
clear margin	1
mining instance masks	1
Label-PEnet	1
inverse order	1
increasing accuracy	1
low-level pixels	1
high-level images	1
pixel-wise labels	1
imagelevel labels	1
macro F1 score of 0.91344	1
11th place out of 82	1
uncertain partitions	1
output predictions	1
samples of EEG data	1
electroencephalographic(EEG ) data	1
memory of variable length	1
substantial number	1
15 fps	1
State - of - the - art object detection performance	1
memory and computation costs	1
objects of different scales	1
domain and size	1
$6.29$ F1	1
gains of up to $17.69\%$ accuracy	1
small corpus size	1
1600	1
amounts of raw text	1
threat	1
10K	1
real and fake information	1
contradicting information	1
false, inaccurate, and misleading information	1
global solutions	1
gradient information of costs	1
far fewer	1
valid diffeomorphism	1
environment occupancy data	1
continuous occupancy representation	1
environment geometry	1
desirable behaviour	1
gradient information of desired costs	1
sampling distributions	1
desired level of sparsity	1
different attack types	1
even more computational resources	1
arbitrarily many	1
predefined maximum number	1
sampling	1
computational expenses	1
classification accuracy high	1
three fourths	1
number of consumed packets	1
question of computational efficiency	1
network data	1
61.4%, 63.3%, 64.5%, and 61.5%	1
67.5%	1
average emotion recognition accuracy	1
emotion recognition accuracy	1
median +62%, maximum +13,140%)	1
17 out of the 20	1
median +96%, maximum +3,756%)	1
median +31%, max +668%) and 19 out of 20 tested Atari games	1
performance in 8 out of 8	1
action grammars	1
2.4% on average	1
correspondence of modalities	1
multi-modal nature	1
unavoidable domain shift	1
drop in performance	1
environmental bias	1
subjective vision and objective quantization	1
original image color and texture	1
qualitative comparisons	1
PSNR	1
structural similarity (SSIM )	1
peak signal-to-noise ratio (PSNR)	1
various real images	1
qualitative and quantitative evaluations	1
sharper edge information	1
alpha shadow scale factor	1
technological issues	1
video scans	1
corrected stitch	1
stitch	1
pairwise translations	1
overlapping clustering	1
instantiations	1
tens of billions of edges	1
complex overlapping clustering problem	1
provable theoretical guarantees	1
gradient direction	1
small fraction of the training data	1
breach model integrity	1
unmodified test image	1
zero-shotcapabilities	1
Natural Language Decathlon (decaNLP)	1
particularities of a single metric	1
scalability and size-independence	1
given network instance	1
small-worldness	1
high clustering	1
heavy-taileddegree distribution	1
nontrivial topological features	1
far less planning time	1
challenging motion planning problems	1
guarantees of correctness	1
new environments and problem instances	1
motion plans	1
steering angle	1
towell-established baselines	1
better parsing and motion prediction results	1
mutually beneficial relationship	1
reliable pixel-wise correspondence	1
sceneparsing and motion dynamics	1
dense motion information	1
theywill appear	1
limited number samples	1
accuracies high	1
many times	1
unknown classes	1
known classes	1
five modalities	1
appropriate meta, audio and pulse oximeter data	1
8 million	1
almost 13 hours of recordings	1
mean absolute error as low as 3.16 bpm	1
face videos (remotely)	1
subject heart rates	1
statistically significant response	1
random accuracy	1
ground-truthed	1
cardiac pulse	1
initial baseline results	1
results both numerically and visually	1
data point's prediction	1
Random Forest's prediction path	1
specific sample	1
data-model discrepancy	1
nugget value vanishes	1
redundant points	1
variance zero	1
output valuesand	1
nugget regularization	1
covariancematrix singularity	1
diagonal	1
positive constant	1
ill-conditioned covariance matrices	1
oftenill-conditioned	1
complex problems	1
recursive and iterative versions	1
classical semantic clone detection problems	1
Matthews Correlation Coefficient greater 0.9	1
pre-specified and controllable false-positive rate	1
distance is significant	1
distance metric	1
likelihood between	1
behavioral equality	1
runtime data	1
0% syntactic similarity	1
de facto technical boundary	1
similar or equal runtime behavior	1
coefficients of 3D Morphable Model ( 3 DMM )	1
occlusions ( the 6th , 7th and 8th columns	1
3th , 4th and 5th columns	1
better view	1
reconstructed shapes	1
68 key points	1
3D face reconstruction ( even rows )	1
Dense face alignment ( odd rows )	1
itsenhanced performance	1
associated unknown parameters	1
unknown non-linear functionbelongs	1
bothinlier noise	1
user participation	1
1960 to 2017	1
similar significance	1
ever increasing size	1
number of node classification benchmarks	1
two representations	1
intrinsic features	1
two randomly perturbed versions	1
superior generalization performance	1
better evaluation performance	1
additional semantics	1
compactness of subspace	1
every two target images	1
positive relation	1
source data unavailability	1
insufficient memory storage	1
adaptive importance weights	1
individual task	1
task embedding	1
task-aware part filters	1
considerable local clues	1
handful	1
training dynamics	1
novel insights	1
long training times	1
hurdles	1
unknown class embeddings	1
benchmark datasets	1
error metrics	1
evaluation protocols	1
GZSL)	1
open-world settings	1
applicability	1
visual data and class embeddings	1
$L_1$.	1
$L_1$ and $L_2$	1
$L_2$	1
abundant annotatedcorpora	1
$L_1$)	1
deprived language	1
word and character level	1
32.0% F-score	1
22.9% event-based F-score	1
final detection score	1
temporal prediction curves	1
audio event boundaries	1
onsets and offsets	1
temporally (localization task	1
audio events (audio tagging task	1
spatial softmax	1
full spatial resolution	1
initial guess	1
number of facial landmarks	1
Numerical experimental results	1
closed-forms	1
anisotropic tensor	1
SOTV Hessian matrix	1
Frobenius norm ofthe product	1
novel regulariser	1
staircase artefact	1
first order counterparts	1
Second order total variation	1
L2, L1 or group-Lasso	1
regularization factor	1
useful values	1
corresponding prior	1
Bayesian prior	1
approximate posterior	1
Kullback--Leibler divergence term	1
Bayesian posteriors	1
Regularization terms	1
values of the parameters	1
ad hoc regularization term	1
MASS:	1
F1-score (MASS:	1
similar overall accuracy	1
AASM andR&K	1
scoring standards	1
e.g., sampling rate)	1
EEG epochs	1
transition rules	1
time-invariant features	1
next sleep stages	1
astransition rules	1
-0.73 in TER and +1.49 in BLEU	1
TER and BLEU scores	1
various teacher-forcing ratios	1
decoder state	1
two outputs	1
src context	1
important brain regions and inter-channel relations	1
proposed adjacency matrix	1
SEED and SEED-IV	1
cross-subject EEG variations and noisy labels	1
neuroscience theories	1
connection and sparseness	1
inter-channel relations	1
local and global relations	1
biological topology	1
100% sensitivity	1
false positive rate by around one third	1
various types of labels	1
10,000 whole slide images	1
pixel-level false positives and false negatives	1
high-quality pixel-level pseudo labels	1
coarse image-level labels	1
pixel-level fine labels	1
sufficient image-level coarse annotations	1
various labels	1
pixel-level pseudo labels	1
classification labels	1
challenging and realistic setting	1
semanticsimilarity computations	1
complex semantics	1
Probabilistic Labels	1
description'ssemantics	1
different interpretations	1
linguistic descriptions	1
spatio-temporal imprecision	1
Fuzzy Sets Multiple Instance Learning (FSMIL) andthe Probabilistic Labels Multiple Instance Learning (PLMIL)	1
textual cues	1
huge amount of video data	1
little damage	1
semantic offset	1
gender, religion, race	1
discriminatory stereotypes	1
estimated reward functions	1
reverse KL divergence	1
reverse KL	1
forward RL	1
discriminator's ability	1
generated experiences	1
transitioned state	1
second discriminator	1
expert's state	1
two distributions	1
expert	1
two probability distributions	1
reverse Kullback-Leibler (KL) divergence	1
state - of - theart failure rate by up to 70 %	1
head pose	1
entire face images	1
previous stages	1
landmark locations	1
intertwine motion and appearance knowledge	1
two better	1
spatio-temporal correlations	1
learning features	1
one stream	1
main actor's pose	1
physical parameter	1
training-set choice	1
input data characteristics	1
multidimensional field measurements	1
improved data quality	1
robust representation	1
effectiveness of FRSKD	1
refined knowledge	1
deployment stage	1
ranked reward	1
human best (68)	1
reasonable computational effort	1
medium-quality solutions	1
win/loss signals	1
recent impressive performance	1
decade	1
large computational resources	1
82 steps	1
good solutions	1
order of the game of Go	1
large state space	1
future research trend	1
current research status	1
principles	1
inter- and intra-observer variability	1
human error	1
extreme labor cost	1
state-of-the-artdegradation results	1
inversely scaled	1
corresponding weights	1
factorprovided	1
given layer	1
oft-overlooked degree of freedom	1
extra costs	1
domainness-specific and domainness-invariant features	1
additional supervisory signals	1
numerical magnitudes	1
demanded-specific dimension	1
less desired adaptation performance	1
explicit prior knowledge	1
onedocument	1
ideal form	1
symbolic structure	1
synthetic non-stationary time series data	1
residual errors	1
statistical changes	1
membership function parameters	1
perturbation functions	1
distribution of the data	1
time varying parameters	1
disentangled style and shape space	1
lighting , texture and image environment	1
space of style	1
blindness	1
inter-class separability	1
intra-class compactness	1
joint discriminative prototypical compactness loss	1
unknown class	1
discriminative representation	1
unlabeled target domain	1
good classifier	1
sampling rate is one-fourth of them	1
PSNR of 40.305 and the SSIM of 0.948	1
challenging sparsity	1
intervals of 4{\deg}, 8{\deg} and 16{\deg}	1
model parameters to one-eighth of its original)	1
linear bottleneck	1
inverted residual	1
social trend	1
high degree of spatial continuity	1
streaking artifacts	1
severe imaging noise	1
correlated calculations	1
lowered projection views	1
radiation dose	1
10 months	1
OpenAI Five	1
batches of approximately 2 million frames every 2 seconds	1
imperfect information	1
long time horizons	1
musical audio content	1
quantitative metrics and visual quality	1
coarse to fine	1
super-resolved features	1
blindly increasing network's depth	1
deeper architecture	1
cognitive scores	1
significant correlation	1
10 ADpatients	1
electroencephalography (EEG ) data	1
dynamic topologicalchanges	1
incremental tasks	1
transferable knowledge	1
previous anatomical structure segmentation performance	1
varying amount of incremental annotation ratios	1
minor addition per structure	1
anatomical structure	1
sufficient annotated samples	1
relatively small specifications	1
executions	1
logical specification	1
rich and exact details	1
reliable sentiment transfer results	1
content structure	1
better image sentiment transfer result	1
content-related	1
SSIM index	1
given sentiment tag	1
frontal view to profile view	1
face appearance	1
profile views	1
45 )	1
small to medium poses	1
semantic meanings	1
leaderboard	1
collected, organized, and published our data	1
10 characteristics	1
7 attributes	1
9 evaluation metrics	1
4 different attributes	1
current MRC models	1
obvious giant gap	1
great deal of redundancy	1
individual ranking scores	1
biased estimators	1
faster convergence	1
iteration complexity of $O(1/\epsilon^4)$	1
better iteration complexity of $O(1/\epsilon^4)$	1
$O(1/\epsilon^5)$ complexity	1
surrogate loss	1
convergence guarantee	1
areas under precision-recall curves (AUPRC)	1
F1-score of 39.33	1
F1-score of 40.78	1
sentence level features	1
Named Entity tags	1
different camera viewpoints	1
3D reconstructions	1
subsequent stylized velocities	1
Temporal consistency	1
desired target configuration	1
full spectrum	1
structural patterns	1
simulation features	1
smoke dynamics	1
target velocity or density field configurations	1
approximating simulation states	1
epileptiform discharges	1
pilot data	1
largeamplitude and a duration up to tens of milliseconds	1
instant	1
fifteenth rank out of thirty	1
method sixteenth out of thirty teams	1
set of features and document/text vectorization	1
complex chemical property space	1
two conditions	1
new feature space	1
genes)	1
cell types	1
92 % accuracy	1
cellular heterogeneity	1
unbiased picture	1
special orthogonal (SO) and special Euclidean (SE) groups	1
Stiefel manifolds	1
global convergence rate analysis	1
global convergence rate estimates	1
rank-deficient second-order critical points	1
elegant geometric structure	1
SDP	1
low-rank factorization	1
highquality , dense 3 D face fitting	1
different landmark markups	1
face contours and SIFT feature points	1
limited facial landmarks	1
3D face shape	1
pixel predictions and reward predictions	1
different size game levels	1
unlimited experience data	1
supervised signal	1
similar computational complexity	1
binary representations	1
look up tables	1
manual transcripts	1
68 hours	1
licensed videos	1
patent metadata	1
TSV format	1
total of 18 models	1
abstract (i.e. paragraph)	1
800 million tokens	1
68 million	1
frontal view tothe profile view	1
90 degrees	1
yaw angle is smaller than 45 degrees)	1
small to mediumposes	1
semanticmeanings of facial pixels	1
full suite ofacquisition functions	1
models and acquisition functions	1
datasetexhausting its labeling budget	1
thedata dependence	1
numerical examples	1
quality metrics	1
high imaging performance	1
fast reconstruction capability	1
state-of-the-art reconstruction performance	1
imaging capability	1
limited-angle data	1
variable conditions	1
handcrafted regularisation terms	1
enhanced image quality	1
excellent interpretability and robustness	1
multiple conditional node embeddings	1
preference similarity	1
multi-aspect preference information	1
multiple preferences	1
conditional embeddings	1
multiple behaviors	1
various preferences	1
one unique aspect	1
multiple aspects of similarity	1
low-dimension vectors	1
Clustering results	1
VQA v2	1
cluster accuracy	1
cluster entropy	1
cluster difficulty	1
10% accuracy)	1
poor performances	1
answer distributions	1
accuracy and the entropy	1
two variants	1
predicted answer distributions	1
entropy values	1
diversity of ground-truth answers	1
considered intensity measuresare	1
thepredictive parameters	1
ground motion intensity measures	1
distances and magnitudes	1
much more accurate prediction	1
soft soil conditions	1
lowsource-to-site distances	1
magnitude greater than 3.0	1
approximately 4,500 ground motions	1
shear wave velocity	1
earthquakesource-to-site distance	1
peak groundacceleration (PGA) and peak ground velocity (PGV)	1
increased rate	1
theground motion recordings	1
earthquake recordings	1
increased rates	1
single 2D image	1
3D facial geometry	1
whole 3 D facial geometry	1
arbitrary facial poses and expressions	1
dense correspondence	1
accurate alignment	1
many of these limitations	1
non-uniform illumination	1
large facial poses , expressions	1
dense correspondences	1
number of methodological challenges	1
large expressions	1
full range of pose	1
improvements of 5.8%, 0.5%, and 4.8% in the average Dice scores	1
better optimizers	1
mixture of DAGs	1
longitudinal data	1
different DAGs	1
single point in time	1
63.92%	1
99.8% rank-1 accuracy	1
better between class separation	1
within class scatter	1
single point	1
given class	1
discriminative nullspacewhere all training sample points	1
thesmall sample size (SSS) problem	1
old seen classes	1
semantic spaces	1
visual space	1
projection distance loss	1
background-foreground mean squared error loss	1
two innovative losses	1
existing knowledge preserved	1
safety features	1
less computational requirement	1
accuracy, robustness, powerconsumption and inference time	1
efficiency, robustness	1
efficient	1
gait phases	1
detected gait markers	1
Recorded EEG data	1
mean age = 22.75 years	1
n = 3	1
usability and validity	1
gait markers	1
gait- and EEG data	1
neural correlates	1
substantial performance increase	1
regular images	1
informativeinstances	1
resulting uncertainty measure	1
two novel criteriafor uncertainty	1
traditional uncertainty measures	1
geometric smoothness priorsin	1
Cartesian, spiral and radial sampling	1
arbitrary sampling patterns	1
mean SSIM 0.914	1
35%	1
one of the learned patterns	1
size 192 by 192	1
measurements and ground-truth images	1
new data acquisitions	1
acquisition time	1
sparse sampling pattern	1
long acquisition times	1
many inverse problems	1
misleading information usage problems	1
English transliterated format	1
mixed form	1
arbitrary images	1
3 DMM	1
illumination parameters	1
identity and expression	1
unconstrained conditions	1
controlled conditions	1
3D facial shape and texture	1
promise	1
high dimensional feature vector representations	1
mapped PDFs	1
code vectors	1
Probability Distribution Functions (PDFs)	1
different noise	1
codevectors)	1
theirexceptional performance	1
key concepts	1
6G)	1
Wireless Federated Learning (WFL)	1
increasing computing capabilities	1
massive volume of generated wireless data	1
new domain	1
clean labels	1
synthetic documents	1
character boxes	1
pooled output of the encoder	1
attention output	1
complex word or MWE	1
input context	1
particular word or expression	1
difficulty score	1
tracking task	1
optimal matching relations	1
old tracklet	1
predicted detection	1
two adjacent frames	1
implicit motion information	1
point-wise motion information	1
optimal hyperparameters	1
buy a yoga mat
T10	Data	246 253		Oposes
T11	Material	271 278	dataset
T12	Data	295 308	two relations
T13	Material	329 369	website of instructional how-to articles
T14	Material	375 399	human-validated test set
T15	Material	412 430	reliable benchmark
T16	Process	435 456	commonsense inference
T17	Data	465 488	gap of about 10% to 20%
T18	Data	501 512	performance
T19	Material	516 551	state-of-the-art transformer models
T20	Data	556 573	human performance
T21	Material	579 615	automatically-generated training set
T22	Process	633 653	effectively transfer
T23	Process	657 676	out-of-domain tasks
T24	Material	700 717	procedural events
T25	Data	724 753	greatly improved performances
T26	Material	757 794	SWAG, Snips, and the Story Cloze Test
T27	Data	798 825	zero- and few-shot settings
	1
step-step temporal relations	1
learn poses	1
goal-step relations	1
procedural events	1
two types of relations	1
adaptive learning selection and student learning outcomes	1
brainwave patterns	1
user records	1
varying difficulty levels	1
time-synchronized multimodal data records	1
realistic settings	1
weak prior	1
large boost in accuracy	1
BIHRLretains accuracy	1
values ofhierarchical planners	1
peak	1
imbalance ratio	1
highly imbalanced settings	1
additional hypotheses	1
point of time	1
rhythm error	1
natural transitions	1
eligible melodies	1
spectrum of bad-to-good melodies	1
melody automatically	1
85.2 %	1
state - of - theart accuracy of 93.1 %	1
standard NED features	1
correct references	1
multiple named entity mentions	1
85.2%	1
83.0%)	1
spatiotemporal features	1
spatiotemporal scales	1
entire range of temporal information atall spatial scales	1
learnspatial- and temporal-information	1
four baselines	1
interpretable Spatio-Temporal representation	1
Multivariate Time Series (MTS)	1
patient and caregiver requirements	1
low false-positive rates	1
wearable form factor and power budget	1
zero false positives and 100% sensitivity	1
8s window size	1
23-electrodes	1
around 25\%	1
statisticalclassifiers with specific features	1
given sentiment-related label	1
sentiment-bearing words	1
`weather'	1
`gun laws'	1
`work'	1
modelestimates topic-level, and sentiment-level distributions	1
topic-levelsentiment	1
sarcasm-prevalent topics	1
literal sentiment (either positive or negative)	1
sentimentsas	1
mixture of words	1
industrial needs	1
scalability, reliability andfailure tolerance limitations	1
completeness, versatility,and licenses	1
nostandard interface specification	1
correct relationships	1
coarse-to-fine distinction	1
debiasing loss	1
remarkably different relationships	1
unbiased SGG	1
coarse-to-fine mode	1
tail relationships	1
biased predictions	1
unbiased models	1
semantic abstraction	1
DER 2.92% and JER 20.84%	1
DER 5.54% and JER 27.11%	1
innovation reward bonuses	1
enhanced stability	1
node and edge attributes	1
user-defined objectives	1
valid examples	1
68.4 EM, 76.21 F1 dev)	1
second highest single model performance	1
representation viable and learning efficient	1
promising search paths	1
space of each search step	1
end word	1
start word	1
answer's sentence	1
possible answer spans	1
meaningful predictor variables	1
maximum depth	1
$1.88^{\circ}C$.	1
$2.16^{\circ}C$	1
median RMSE of $2.43^{\circ}C$	1
$2.52^{\circ}C$. PB-MTL	1
median RMSE	1
candidates' past performance	1
lake attributes	1
depth-specific temperature	1
environmental data	1
trivia questions	1
score of 89.8 % on	1
linking - specific features	1
64 % error reduction	1
high quality entity representations	1
context independent representations	1
entity - centric	1
context dependent representations	1
large motion	1
singularvalue decomposition (SVD)	1
blur kernel and image supportsequentially	1
row andcolumn sparsity	1
rank-one matrix	1
kernel andimage coefficients	1
outer product	1
large motions	1
satisfactory image quality	1
experimental details	1
choice ofthe type of measurement	1
subset of possible states	1
feasible time-cost	1
atwo-qubit situation	1
hours on a single laptop	1
POVM type	1
value of measurement	1
basis, symmetric informationally complete (SIC),as	1
$10^7$ copies	1
factorof a million speedup	1
$O(\log(n))$	1
time complexityempirically	1
learned heuristic	1
computationaltime of $O(\mathrm{poly}(n))$	1
computational bottleneck	1
particles --	1
candidate solutions	1
-of-the-art reconstruction accuracy	1
problem of analysis speed	1
vast numbers of measurements--	1
experimental front	1
unknown quantum stateby	1
general applicability	1
800% the time	1
96%	1
reasonability	1
real-world diagnosis problems	1
costly reasoning services	1
large parts	1
so-far collected measurements	1
latest (updated) system knowledge	1
best next measurement	1
possible explanations	1
true explanation	1
system measurements	1
curriculum	1
structure representation	1
semantic link	1
hierarchicalrepresentation	1
Visual Question	1
human intelligence	1
enormous performance gap	1
-level perception	1
absolute scale	1
pose estimate	1
minimalperformance loss	1
much less training data	1
2-3% inaccuracy	1
variety of computer vision tasksincluding	1
labeling effort	1
subset of the examples	1
heterogeneous problems	1
learning problems	1
mathematics perspectives	1
selected learning problems	1
heterogeneous inputs	1
mathematical perspective	1
heterogeneous properties	1
andevaluate both ROC and Precision-Recall curves	1
list of pseudo- attributes	1
output weights	1
sequential and syntactic patterns	1
sequential and syntactic information	1
intended sense	1
human action prediction problems	1
half observation	1
future high connected features	1
futureand	1
next frames	1
high connection	1
thealready present frames	1
generating acoustic features	1
normalized RMSE values	1
lower root mean square error (RMSE)	1
various types of EEG features	1
predicting electroencephalograpgy (EEG ) features	1
contextual details	1
pairwise relation	1
recording durations between ninety minutes and twohours	1
averagearea under ROC curve (AUC) value of 0.73	1
localization potential	1
temporalcharacteristics	1
inter-patientvariability	1
SOZ	1
incidence(events/time)	1
amount of training label noise	1
different hyperparameter values	1
variety of classification tasks	1
output probability distribution	1
small visual diversity	1
small diversity	1
state-of-the-art correlations	1
reference-less and multimodal	1
resulting metric	1
considered tasks	1
source text	1
generated summaries	1
corrupted states	1
attacked measurements	1
attacked-estimated states	1
excellent per-pixel representations	1
intermediate activations	1
state-of-the-art generative performance	1
link prediction, clustering, and visualisation tasks	1
constructed KG	1
interoperability	1
formal KG representation	1
fusion of data	1
social media data	1
plethora of real-life problems	1
Zh <-> En directions	1
substantially lower latency	1
naturalness metric MOS	1
similar levels of translation quality	1
different source speech rates	1
unnatural pauses	1
latencies progressively	1
seconds delay	1
vocabulary sizeis	1
much higher proportion	1
earlier results	1
referring expressions (REs)	1
higher computational efficiency	1
data augmentation policies	1
training hyper-parameters	1
architecture performance difference	1
different input types	1
neural architecture search (NAS) and hyper-parameter optimization (HPO)	1
effective predictor	1
above-chance, 72% accuracy	1
movie rating	1
evoked responses	1
ordered preference	1
consumer preferences	1
one product	1
accurate measure	1
self-report measures	1
consumer behavior	1
global convergence	1
discriminability	1
plentiful difficult knowledge	1
confusion stage	1
original training pairs	1
thedistribution bias	1
distribution bias	1
theambiguous test pairs	1
reliable distances	1
various lossfunctions and metric forms	1
extra training data	1
domain noisiness	1
range of linguistic phenomena	1
restricted lengths	1
formal grammar	1
20% relativereduction in word error rates	1
bothtime and their individual components	1
context vectors	1
new context vectorsusing time convolution features	1
https://github.com/Juyong/Caricature Face	1
input 2D caricature image	1
3D face shape and orientation	1
vertex based deformation space	1
corresponding 3D shapes	1
large diversity of geometric and texture variations	1
likeness	1
certain facial features	1
eachlayer of the GCN	1
graphicalrepresentation	1
multi-layered representations	1
degree of interaction	1
weight ofan edge	1
keyword	1
underlying structural information	1
extreme length discrepancy	1
essential characteristics	1
connectivity states	1
time interval	1
motor imagery and resting mental states	1
two states	1
total J-divergence	1
contribution of each Laplacian variable	1
motor imagery and resting states	1
real EEG data	1
different task conditions	1
connectivity patterns	1
denoised Laplacian	1
novel formulation	1
recent graph signal processing results	1
network graph Laplacian	1
different connectivity states	1
common connectivity estimates	1
detection performances	1
hypernymy and hyponymy relationships	1
efficient sliding-windowdetection	1
high detection performance	1
educated decisions	1
corresponding answers	1
annotated questions	1
up-to-date values	1
storage requirements low	1
least two features	1
entities, types and properties	1
bilevel gradient calculation	1
specifics	1
unconstrained and constrained cases	1
lower level constraints	1
matrix-vector products	1
system solves	1
lower level second-order derivatives	1
number of variables	1
$k$-nearest neighbor \cite{Murphy09}	1
boosting \cite{Slabaugh10},logistic regression \cite{Ravesteijn10}	1
overall better classification/detection performance	1
thecomplex classification boundary	1
samples on the decision boundary)extracted	1
observation uncertainties	1
various spurious imagery noises	1
desirably low false positive (FP) rate	1
High detection sensitivity	1
significant and universal performance improvements	1
difficult ones	1
completely random order	1
emerging problems	1
limited distributed data	1
sufficient samples	1
emerging learning problems	1
curse of dimensionality (CoD) problem	1
offline and discrete data	1
machine learning limitations	1
largescale problems	1
theoretical aspects	1
noises or inessential features	1
input and the hiddenrepresentation	1
Frobeniusnorm of the Jacobian matrix	1
reconstructionerror	1
much worse local optimum value	1
theJacobian matrix	1
Frobenius norm	1
ideal state	1
ideal situation	1
lowerthan a lower bound	1
corrupted input	1
general properties	1
decay function	1
positional information	1
multiple sentiments	1
another text segment	1
traditional GCN	1
weighted graph	1
improvements above the current state of the art	1
word type	1
semantic vector representations	1
Contextualized word embeddings ( CWE )	1
best, F-score of 99.75{\%} and 97.77{\%}	1
many of them	1
abnormal behavior	1
series of measurements	1
total energyconsumed	1
aggregate powerconsumption	1
Real-time feedbackat device level	1
energy consumption footprint	1
sentiment similarity	1
different correlation coefficients	1
sentiment proximity	1
lexical similarity information	1
strong baseline by6.6%	1
fundamental problem	1
multiple distortions	1
SSIM score	1
4 times video super-resolution	1
958 times fewer MACs	1
260 times fewer parameters	1
significantly fewer parameters	1
low-quality	1
couple of problems	1
continuous decision variables	1
fifteen LSGO benchmark functions	1
standard benchmark unconstrained LSGO functions	1
bunch	1
easily reproducible baseline	1
Gaussian process modelswith private pseudo-points	1
newdata and tasks	1
thesealgorithmic dimensions of VI	1
bewildering array of algorithmic options	1
better uncertainty calibration	1
advances in feature representations	1
fine-tune features	1
fast and memory-efficient	1
traditional statistical contour features	1
much as 15\%	1
latent representation spaces	1
two levels of context	1
meaningful feature space	1
fundamental frequency ($F_0$)	1
longer temporal window	1
sonic patterns	1
short sound token	1
multiple levels of context	1
engineered features	1
many flavors	1
neural events	1
onset	1
$\sim$300 ms	1
71%	1
EEG sleep recordings	1
$\sim$2.5 s, 12-16 Hz)	1
patterns of interest	1
potential argument	1
topic or search term information	1
stance	1
STL specification	1
mixed-integer linear inequalities	1
signal	1
integral and derivative	1
rich properties	1
rate of change	1
time window	1
cumulative success	1
integrals and derivatives	1
potential confusions	1
publicly available online	1
source code andpre-trained vectors	1
factorization-based word embeddings	1
wordembeddings	1
wordembedding captures	1
quality of the order-$N$ relations	1
existing wordembedding evaluation metric	1
various meanings	1
theiradvantages and disadvantages	1
low rank factors	1
interpretability of representations	1
advantages of DGCF	1
different intents	1
distribution over intents	1
finer granularity	1
diverse relationships	1
user interests	1
Learning informative representations	1
noisy settings	1
alignment labels	1
automated metrics	1
relevant parts of each training instance	1
word-level labels	1
alignment score	1
generated text	1
great syntactic skills	1
transferring performance	1
insightful justifications	1
source and target examples	1
mixture	1
Two fundamental challenges	1
entity-context diversity	1
CT and MR images	1
accurate result	1
single modality	1
model fault	1
limiting constraints	1
innate ambiguity	1
recent technical and scientific advances	1
fraction of the data	1
principled high-level Markov dynamics	1
complex nonstationary patterns	1
structured distribution	1
8-bit runs	1
energy reduction	1
2.0x speedup	1
8-bit execution	1
2.2x speedup	1
computation and storage cost	1
accuracy (=< 0.3% loss	1
various hyperparamters	1
best design decisions	1
large hyper-parameter space (bitwidth of the layers	1
questionable utility	1
deep quantization	1
arduous manual effort	1
bitwidth below eight bits	1
bitwidth	1
DNN computation	1
massive amount of computation resource	1
`https://github.com/andreYoo/VeRI_SSML_FD.git	1
promising vehicle Re-ID performance	1
unsupervised vehicle Re-ID	1
DPLM progressively	1
discriminativeness of learnt features	1
given probe image	1
adjacent feature distribution similarity	1
relative-rank consistency	1
Pair-wise similarity	1
positive labels	1
unlabelled vehicle images	1
intertask relationships	1
convergence, speed and policy quality	1
sparse rewards	1
unprecedented complexity	1
quantum leap	1
SMT recommendations	1
generated partial translationand attention history	1
decoding information	1
additional recommendations	1
https://speechlab-sjtu.github.io/WebSRC/.	1
usefulness of structural information and visual features	1
yes/no	1
text span	1
certain structural understanding	1
corresponding HTML source code, screenshots, and metadata	1
6.5K	1
scanning or capture phase	1
uniqueswitching sequence characteristics	1
quasi-stable phase synchronised states	1
theunderlying inter-electrode phase relation dynamics	1
different pathological conditions	1
topographies	1
total of 44	1
time and frequency domain	1
EEG microstates	1
stable of theorder of ms	1
multi-channel EEG recordings	1
unique phase synchronised patterns	1
phase difference	1
time average synchrony measures	1
emotion clause	1
candidate clause	1
semantic dependencies	1
indicative feature	1
clause relative positions	1
degree of reliance	1
emotion clauses	1
associated emotion clauses	1
particular emotion	1
lower power computers	1
2D convolutions	1
challenge's testing data	1
0.8673, 0.7514 and 0.7983	1
final mean DSC	1
0.8770, 0.65242 and 0.68134	1
mean dice score coefficient of 0.8862, 0.6756 and 0.6721	1
dropout of 0.2	1
0.2)	1
small rate	1
document distribution	1
synset distribution	1
synset proportions	1
topic proportions	1
entity span predictions	1
visual bias	1
image-aware word representations	1
80	1
tabular (matrix formatted) data	1
15% improvement	1
local region images	1
positional relationship	1
hand shape	1
highest recognition accuracy	1
competitive segmentation accuracy	1
latency by up to 3.5 times	1
optimization quality	1
latency regularization term	1
patient data privacy	1
noticeable visual lag	1
input layer encoding	1
new theoretical properties	1
disjoint decision classes	1
real anomalies	1
labeled anomalies	1
2.5 BLEU scores	1
WMT14 En$\leftrightarrow$De	1
5.0 BLEU scores	1
bag-of-ngrams training objective	1
reference sentence	1
model output	1
Bag-of-Ngrams (BoN) difference	1
weak correlation	1
F1 score of 37.42%on DuoRC v/s 86% on	1
near human performance	1
external background knowledge	1
narration style	1
differentlevels of plot detail	1
different versions	1
version	1
Denoising results	1
first level ofdecomposition	1
single time	1
modified wavelet coefficients	1
highest subband	1
noisymicroarray	1
wavelet domain)	1
mobile latency constraint	1
hardware platform constraints	1
layer-wise operation search space	1
higher one-shot model accuracy	1
condition number $\kappa$ and the target accuracy $\epsilon$	1
best known computational complexities	1
stochastic approximated gradients	1
best known results	1
lower computational complexities	1
deterministic bilevel problems	1
strongly-convex Bregman functions	1
outer subproblem	1
general bilevel problems	1
high computational complexities	1
class-specific foreground and background features	1
results of CFU	1
class semantic embeddings	1
Class Feature Generating Unit (CFU), Foreground Feature Generating Unit (FFU), and Background Feature Generating Unit (BFU)	1
new classification layer	1
unseen class features	1
large-scale seen domain knowledge	1
Action Recognition problem	1
preliminary classification results	1
types of relevant information	1
hundreds of command and domain entity types	1
grounded and ambiguous semantics	1
corresponding command examples	1
English textual descriptions	1
~12% absolute performance gap)	1
several baseline results	1
joint hand-object pose estimation	1
RGB images	1
interaction classes	1
unprecedented level of detail	1
ground-truth camera poses	1
6D object poses	1
ground-truth 3D poses	1
object classes	1
synchronized multi-view RGB-D images	1
large margins (e.g. +5.6% on	1
several benchmarks	1
harder ones	1
robust predictor	1
one labeled source dataset	1
robust uncertainty estimates	1
higher prediction accuracies	1
aforementioned limitations	1
predictive distribution	1
new observations	1
given data modalities	1
relational structure	1
multi-modal data types	1
graph of dependencies	1
miscalibrated precisions	1
various missing patterns	1
joint posterior distribution	1
computationally intensive nature	1
poor uncertainty estimations	1
Ad defect rate	1
2.32% decrease	1
2.03% increase in Revenue Per Mille	1
1% increased accuracy	1
ROC-AUC	1
0.14% overall increase	1
user historical behaviors	1
complementary graph information	1
pure semantic information	1
Low latency variants	1
apseudo ground truth	1
easily obtainable image level labels	1
synthetic-to-realdiscrepancy	1
thecost of laborious manual pixel-level annotation	1
pre-trained BERT word vectors	1
limited quantity	1
interventional data	1
intervention targets or types	1
perfect, imperfect, stochastic, etc.	1
certain background knowledge	1
different contexts	1
certain statistical patterns	1
36%	1
narrow enough context	1
pull requests	1
commit messages	1
resource-abundant	1
89% of the time	1
0.37m	1
mean error of 1.20m	1
90% of the time	1
current vehicle pose	1
topological and metric information	1
relative pose vector	1
similar imageand its pose	1
live image	1
one partof the global localization	1
common settings	1
(locally) differentially private CSB	1
additional price	1
corresponding non-private optimal rates	1
maximum number of feedback	1
upper bound and lower bound	1
optimal regret bound is $\tilde{\Theta}(\frac{mKB^2_1\ln T}	1
$\varepsilon$-DP	1
$B_1$-bounded smooth CSB	1
novel algorithms and matching lower bounds	1
number of base arms	1
$m$	1
$\Delta$ is the gap of rewards	1
time period	1
\Delta\epsilon})$ respectively	1
optimal regret bound is $\Theta(\frac{mB^2_{\infty}\ln T } {\Delta\epsilon^2})$ or $\tilde{\Theta}(\frac{mB^2_{\infty}\ln T}	1
either $\varepsilon$-LDP or $\varepsilon$-DP	1
$B_{\infty}$-bounded smooth CSB	1
chen2016combinatorial}	1
two common smoothness assumptions	1
additional dependence	1
stronger Local Differential Privacy (LDP) setting	1
Differential Privacy (DP)	1
classic Multi-Armed Bandits (MAB)	1
Combinatorial Semi-Bandits (CSB)	1
new test scenarios	1
domain-specific metrics	1
classification and energy estimation performance	1
two nodes	1
sum score	1
global type label similarity	1
node a global type label	1
Node type similarity	1
particularly long distance	1
node relations	1
rich structural information	1
currentstate-of-the-art performance	1
gap in performance	1
useful weakly supervised information	1
different types of semi-supervision signals	1
syntax and semantics )	1
complex characteristics	1
auxiliary features	1
naive ensembling	1
additional, auxiliary features	1
recall-oriented	1
precision-oriented	1
text spans	1
concept properties and relations)	1
15 minutes	1
classification accuracycomparable	1
kernel similarity measure	1
theoriginal space	1
kernel similarities	1
feasibility of resulting solutions	1
instances below 400 nodes	1
multiple symmetric and asymmetric instances	1
asymmetric problem instances	1
feasible solutions	1
transfer learning performance	1
backbone network performance	1
536 to 312	1
inference throughput	1
57.7\% to 32.3\%	1
76.0\% to	1
76.3\% to 82.78\%	1
loss of throughput	1
proposed QR loss	1
Cross Entropy (CE)	1
incompatibility	1
extreme scarcity	1
size, color, shape, and texture	1
variety of aspects	1
less accurate results	1
two to ten	1
90\% accuracy	1
accuracy plateaus	1
vanishing gradients	1
desired results	1
accuracy, and computational time	1
number of hidden layers	1
23.7% reduction	1
communication delay	1
vehicles' referenced longitudinal motion	1
full stops	1
finer level control	1
extra monolingual data	1
vicinal samples	1
quite expensive	1
average prediction error by 60%	1
imputation accuracy	1
coarse to fine-grained resolutions	1
multiresolution structure	1
arbitrary missing patterns	1
noisy prediction	1
consistent views	1
locally available data	1
global distribution	1
clients' data	1
stateof - the - art or competitive results	1
trained contextualized embeddings	1
randomly masked entities	1
segmentation consistency	1
concrete benefits	1
human interpretability	1
0.522, 0.719 and 0.742	1
DSC of 0.794	1
0.721, 0.793 and 0.806	1
DSC of 0.847	1
Disentangled Representations (DADR)	1
qualitative and quantitative aspects	1
dual-pixel images	1
blurry artifacts	1
high quality annotations	1
Word Error Rates (WERs)	1
recent reports	1
skepticism	1
level of accuracyis	1
0	1
false-negative rate of 0.0033 to 0	1
accuracy of 99.25% to99.98%	1
conservative	1
positive states classified asnegative)	1
given accuracy levels	1
NSC classifier	1
classification errors	1
constant time andspace)	1
given time-bounded reachability specification	1
either positive or negative	1
state$s$ of a hybrid automaton	1
local data private	1
private user information	1
thepromising results	1
original datain practice	1
resulting representation	1
sparserepresentations	1
sparse representation	1
inferior search performance	1
large quantization errors	1
low dimensional subspaces	1
aCartesian product	1
indexhigh-dimensional image features	1
drops	1
97% smaller	1
0.02% Character Error Rate (CER)	1
previous data	1
reason	1
4510 milliseconds	1
0.78 F-score	1
word-level and sentence-level information	1
context and gloss representation	1
context representation and gloss representation	1
rich lexical knowledge	1
labeled data (context)	1
low visual diversity	1
image-similarity	1
retrieved results	1
extreme viewpoint changes	1
balanced class priors	1
class prior distributions	1
different language	1
https://ningding97.github.io/fewnerd/.	1
Few-NER D	1
Extensive empirical results	1
different emphases	1
context or a part of a two-level entity type	1
4,601,160 words	1
188,238 sentences	1
few-shot setting	1
little published benchmark data	1
poorrecognition accuracy	1
lot of research	1
-of-the-art accuracy	1
1.5 times	1
one iteration	1
k tokens	1
iteration times	1
e.g., GPU).By	1
small batch size (e.g., 1)	1
syntax to semantic	1
dynamic of needs	1
improvements of up to +1.2 BLEU points	1
\textit{dynamically}	1
\textit{adaptively}	1
learning scenario	1
one (or a subset)	1
\textit{biased-MTL}	1
bilingual data	1
overlapping decision sequences	1
tree-based dependency structure	1
number of observations	1
known dependency structure	1
transformed data	1
soft label matrix	1
positive influence	1
Annotation accuracy	1
multilingual capabilities	1
2009 to 2011	1
two types of evaluation	1
realistic path	1
range of RL benchmark tasks	1
27%	1
multiple retrieved evidence	1
exact match score less than 10%	1
different ways	1
tabular data	1
tabular and textual data	1
catastrophic forgetting	1
inherent logits bias problem	1
single-pass training setting	1
document hierarchy	1
specialized understanding	1
optimality gap by a factor up to 8.61	1
larger instances	1
high-quality variational parameters	1
variational parameters	1
fixed budget of calls	1
basic quantum phenomena	1
high-accuracy	1
two independently translatedsimilarity-covariant features	1
either one conjugatelytranslated affine-covariant feature	1
stable, small and fast	1
solvers	1
divisionmodel	1
conjugatetranslations	1
lens distortion	1
inaccurate or invalid	1
coplanar repeatedpatterns	1
accurate reconstruction	1
depth error	1
depth prediction	1
wrong depth	1
strong ambiguity	1
2D projections	1
poor depth reconstruction	1
data bottleneck	1
solely 2D landmark annotations	1
success rate is 97.05%	1
verification andidentification performance	1
benchmark thermal face images	1
polar coordinate	1
answer candidate phrases	1
significant scalability advantage	1
standalone representation	1
questionencoder	1
complete independence	1
11.1 times storage saving and 5.4 times speedup	1
accurate gradient	1
updating capability	1
sign function	1
information loss of gradients	1
weight distribution	1
weights/activations	1
Information Maximized Binarization (IMB)	1
two technical contributions	1
backward gradients	1
forward activations	1
BNN performance	1
binarized parameter	1
limited information representation ability	1
great loss of information	1
32-bit one	1
significant performance gap	1
particular data	1
greater statistical significance	1
stronger resemblance	1
numerical resemblance between sets of statistical properties	1
criteria of more conventional point-to-point distance measures	1
permuted order	1
value labeling	1
time series segments	1
sheer numerical resemblance	1
broader definition of similarity	1
corresponding order	1
fluctuation of values	1
point-to-point distance measures	1
Standard similarity measures	1
Time series similarity measures	1
question-answering performance	1
various types of image and question features	1
semantic relevance	1
AU detection performance	1
large uncertainties	1
loss of each task	1
learned sample weights	1
training FE samples	1
adaptative weights	1
facial expression (FE)	1
highly correlated tasks	1
error-prone	1
time-consuming, expensive	1
accurate AU annotations	1
large number of training images	1
posteriordistribution on optimal policies	1
linear functionapproximation	1
game state	1
baseline models performance	1
length greater than two	1
28.6% mAP	1
co-learning compositions	1
consistent performance improvements	1
compositional action elements	1
dense scene composition labels	1
hierarchical activity and atomic action labels	1
multiple modalities and view-points	1
multiple viewpoints and multiple modalities of data	1
action understanding	1
optic cup/disc segmentation	1
two medical image segmentation tasks	1
dual-task form	1
task-level consistency	1
Intrinsic Consistency	1
data-level consistency	1
Extrinsic Consistency	1
Extrinsic Consistency and Intrinsic Consistency	1
different consistency schemes	1
network generalization ability	1
universal representation	1
SNP data	1
experiencelower accuracies	1
maximal accuracieswhen	1
significantly more accurate	1
thekernel matrix outputs	1
nonlinear correlations	1
SNPs, DNAMethylation and fMRI data	1
much more accurate	1
faster, more robust	1
allocated training time	1
derivative analysis and filtering analysis	1
highfluctuations, and/or	1
long transients	1
accuracyof the ultimate load disaggregation results	1
-level electricity consumption information	1
task-specific performance	1
sensitive attribute annotations	1
specific class labels	1
spurious correlation	1
neutralized representations	1
different sensitive attributes	1
ground-truth label	1
lot of instance-level annotations	1
retrieval marginalization	1
50.5 F1	1
5.5 F1 points	1
supporting evidence annotations	1
special requirements	1
corresponding entries	1
safe baselines	1
antenna tilt angles	1
high or irreversible negative impact	1
language gap	1
source language ( English )	1
another language	1
language problem	1
language universal representations	1
word-level counterparts	1
gains of up to 6.1 BLEU points and 1.3 METEOR points	1
improvements of up to 5.2 BLEU points and 0.5 METEOR points	1
complex clinical jargons	1
overall meaning intact	1
Comprehensive empirical evaluation results	1
proper priors	1
desired conditional distribution	1
relatively unimportant features	1
primary evaluation metric	1
sanity, combinatorial shortcuts	1
specific output	1
importance score of each feature	1
undesired characteristics	1
Equality, Diversity, and Inclusion	1
hope speech or not-hope speech	1
hate speech	1
global pandemics	1
serious challenges	1
high as 90% to 100% precision	1
thin section image classification	1
classification	1
Edge and colour profile	1
grid structure	1
finite number	1
60 digital images	1
users' private attributes	1
structural information and utility attributes	1
learned node representations	1
users' private information	1
users' sensitive information	1
users' privacy	1
low-dimensional feature representations	1
large source	1
accuracy of 86{\%}.	1
positive and negative	1
36K	1
opinions reviews	1
thoughts, needs	1
multilingualword embeddings	1
embeddingswith context	1
mere benchmark	1
CLTC problem	1
millions of words	1
AP@0.50:0.95 (medium) of 0.592	1
result of 0.366	1
substantially larger	1
correct business names	1
text string	1
particular text string	1
different kinds of sensing and perception errors	1
accuracy per se	1
current evaluation metrics	1
unexpected situations	1
locally normalized models	1
comparable or better accuracies	1
state - of - the - art part - ofspeech tagging , dependency parsing and sentence compression results	1
varying degrees of popularity	1
popular items	1
final recommendations	1
proportionate attention	1
race, gender	1
certain sensitive features	1
certain criteria	1
various types of reasoning information	1
vis-a-vis	1
agiven hypothesis	1
given premise	1
on-device (mobile phone) constraints	1
identified language parameter	1
Optical Character Recognition (OCR) performance	1
distinguishing feature	1
considerably high accuracy	1
20 times larger	1
large-scale OIE dataset (LSOIE)	1
size and diversity	1
n-ary tuples	1
series	1
factual propositions	1
150 abstracts	1
F-measure of 20.03	1
one of the given six categories of relations	1
set of defined features	1
explicit semantic relation	1
dependency paths	1
relative position encoding	1
word and dependency context	1
perception	1
fingers position	1
raw EMG signals	1
various hand-crafted features	1
user intention	1
statistical texture features	1
texture-related information	1
low level information	1
global statistical knowledge	1
texture features	1
precise boundary	1
high-level semantic features	1
need	1
overlapped Tele FOV	1
overlapping FOV	1
stereo information	1
first FOV	1
second FOV	1
Wide FOV (WFOV)	1
first field of view (FOV)	1
different field of views	1
real world depth	1
parsing accuracies	1
error - free action history	1
anisotropic semantic information	1
distinctive artistic style	1
ONE single model	1
different artistic style	1
wide range of artistic styles	1
weight sharing	1
best validation result	1
N (architecture, validation accuracy) pairs	1
spectral EEG features	1
complex visual features	1
spectral phase andamplitude	1
complex oscillatory patterns	1
classicalEEG frequency bands alpha, beta, and high gamma	1
later stages	1
EEG amplitude features	1
earlier stages	1
EEG phase features	1
intermediate stages	1
ConvNetsrepresent spectral features	1
valid markers	1
valid bodies	1
input motion	1
full temporal resolution	1
3D shape and pose	1
point cloud prediction	1
human motion prediction	1
degrees of freedom undefined	1
3D human pose	1
Body joint locations	1
joint rotations	1
Euclidean formulation	1
sequence 3D joints	1
future 3D joint locations	1
theclassification accuracy	1
reaching -- and many times surpassing	1
given graph and observed labels	1
scalabilityto large graphs	1
underlying network topology	1
remarkable classification accuracy atmodest computational requirements	1
BERT performance	1
small	1
competitive predictive accuracy	1
vector similarity	1
uploaded gradients	1
reputation	1
equal rewards)	1
marginalized denoising autoencoder with adaptation distribution (MDAad) and multi-class marginalized denoising autoencoder (MMDA)	1
richer feature representations	1
local relationship	1
significance performance	1
learning tasks	1
minimal degradation of accuracy	1
drum transcription and onset estimation	1
heavier counterparts	1
lighter models	1
85%	1
smaller compression ratios	1
surprising result	1
90% of the model parameters	1
terms of size, memory and number	1
individual weights	1
explicitly removing parameters	1
stunningly massive complexity	1
unprecedented accuracy	1
participants six daily activities data	1
less computational power	1
lot of computation	1
high computation	1
communication latency	1
largest gains in accuracy	1
26 % unlabeled and 92.41 % labeled attachment accuracy	1
corresponding class	1
hard voxels (ATH)	1
class-level hardness	1
anisotropic spacing	1
better visibility	1
simple window width/level	1
intensity of CT images	1
reliable uncertainty estimation	1
highly imbalanced sizes	1
low contrast	1
stateof-the-art performance	1
various types of quality criteria	1
actual problems	1
inter-annotator disagreements	1
resulting annotations	1
problematic parts (words, phrases, sentences)	1
actual issues	1
hard logic	1
different expressions	1
generated word embeddings	1
clear advantages	1
source of explicit morphological knowledge	1
subword rankings	1
meaningful subword segmentations	1
possible segmentations	1
bag-of-subwords	1
subword-based compositional word embedding	1
subword segmentation	1
\emph{without} extra contextual information	1
finite vocabulary	1
pre-trained word vectors	1
\emph{generalizing}	1
number of positiveexamples found	1
, candidate, terms	1
90.24% to 97.56%.Among the two measures	1
Average accuracy	1
HFD and SampEn	1
fatal outcomes	1
wide difference	1
significant improvement of some 67%	1
lowest absolute error	1
level of insolence	1
logs	1
offered services	1
information security	1
social security	1
public services	1
important improvements	1
59{\%}	1
tenth of seventeen submissions	1
third of fourteen submissions	1
middle range	1
F-scores between 70{\%}	1
n-grams of different lengths	1
different character sequences	1
character n-gram frequencies	1
fragility	1
far worse performance	1
several interesting findings	1
centralized settings	1
federated settings	1
noisy and clean data	1
FPR low	1
high TPR	1
Natural robustness	1
unnecessary downtime	1
False Positive Rate (FPR)	1
True Positive Rate (TPR)	1
better extrinsic event extraction performance	1
better intrinsic parsing performance	1
comparisons	1
strong dependency	1
initial samples	1
atrained DAE	1
initial data samplessynthesised	1
initial data samples	1
data-generating distribution	1
regions ofhigher probability	1
regions of low probability	1
thedata-generating distribution	1
regions of high probability	1
samples that take values in (0,1)	1
take values in [0,1]	1
binary cross-entropy (BCE).When training autoencoders on image data	1
mean-squared error (MSE)	1
two common loss functions	1
corrupted version	1
loss(function)	1
indicated factor of 2-12	1
given peaksignal-to-noise ratio (PSNR)	1
number of iterations	1
2-12 times	1
noiseis not small enough	1
mean Dice scores of 0.89, 0.81, 0.73 and mean Hausdorff distances (95th percentile) of 6.8, 12.6, 28.2mm	1
2 percent across all metrics	1
median performance	1
local image details	1
global brain feature interactions	1
tumorous volume	1
model effectiveness and robustness	1
highly related	1
opinion spans	1
real input	1
generated LR counterpart	1
real-world degradation settings	1
possible mismatch	1
HR image	1
bicubic down-sampled version	1
LR image	1
large number of paired (LR/HR) training data	1
Cycle-consistency	1
dynamic model expansion capability	1
5~6%	1
baseline by 5~7%	1
perspective of compact representation	1
representation capacity of features	1
catastrophic forgetting and model over-fitting problems	1
large amount of model parameters	1
old classes	1
new tasks (novel classes)	1
supervisions	1
model's representation capacity	1
ground truths	1
coarse-grained types	1
equivalent four	1
fine-grained entity types	1
relevant entity and domain information	1
30Hz fordatabases containing thousands of images	1
ANN searchof binary features	1
considerable accuracy improvement	1
image similarity measurement	1
repeating textures	1
previous work	1
higher precision-recall (PR)performance	1
dependence of $\tilde{\Omega}\big(1/\varepsilon^{d+2}\big)$	1
samplecomplexity scales	1
$ \tilde{O}\big(1/\varepsilon^d\big),$	1
sample path	1
covering time	1
awell-behaved MDP	1
optimal Q-function	1
$\varepsilon$-accurate estimate	1
Otime $ L $	1
arbitrary samplepath	1
discounted factor $\gamma	1
$d$-dimensional statespace	1
tight finite sample analysis	1
optimal Q function	1
single sample path	1
unknowntransition kernel	1
copying capabilities	1
produce outputs	1
input facts	1
even lowercasing	1
22%	1
tree-based classifiers feature importance scores, F scores, and Integrated Gradient (IG) scores	1
mutual information scores	1
feature scoring metrics	1
variation of the 0-1 robust loss	1
ML model robustness	1
learning accuracy	1
ML model architectures and hyper-parameters	1
best bridgepossible	1
good LWL	1
language similarity metrics	1
100 languages	1
thousands oflanguages	1
short category description	1
English labels	1
text categorization training data	1
significantly less number of parameters and training times	1
comparable or even better performance	1
learnable weights	1
scalar factor	1
number of recurrent iterations	1
code length	1
considerable training time cost	1
specific code length	1
different code lengths	1
variable code lengths	1
retrieval accuracy and speed	1
fast search speed	1
image-quality of training data	1
various levels of degradation	1
78.92%	1
sub-type classification accuracy	1
25%	1
71.87%	1
average accuracies of 80.31%	1
tedious and time-consuming task	1
spectral contents	1
three groups (A1, A2 and A3)	1
public health	1
small-scale training data	1
without masks	1
tedious and attention-intensive	1
overloading	1
fewer frames	1
3% of the views	1
less than 0.00027%	1
total map coverage	1
path length	1
camera's current position	1
next observations	1
1200x1600 HD quality image	1
average runtime of 0.0145s	1
around 21.7 MB	1
total size	1
various density	1
fewer number of network parameters	1
runtime intensive and memory inefficient	1
multi-class labels	1
different person IDs	1
visual and temporal consistency	1
classification, detection and segmentation	1
vision tasks	1
VGGNet and ResNet)	1
quantization performance	1
model capability	1
limited bitwidth	1
Gaussian-like	1
4-bit for both weights and activations	1
limited model capacity	1
Low-bit quantization	1
corresponding text plans	1
reference texts	1
information ( realization )	1
information ( planning )	1
diversity metrics.\footnote{Code	1
relevance metrics	1
generation of generic responses	1
multiple references	1
relevance clues	1
query representation	1
token-level representation	1
generation performance	1
generic responses	1
\textit{ignored}	1
supervision signals	1
weight approximation error	1
layer-wise weights	1
straightforward approximation	1
predication accuracy	1
low-bit parameter values	1
storage, computation and power consumption	1
overwhelming accuracy	1
tens of millions	1
particular target feature	1
overall forecasting performance	1
tensorial unistream vs. multistream )	1
different types of input representations	1
period of 15 years	1
daily data	1
individual patterns	1
large decision spaces	1
uncertain conditions	1
unknown function	1
function evaluations	1
objective and/or constraints	1
superior uncertainty calibration	1
comparable predictive performance	1
high-quality experimental data	1
well-calibrated uncertainty estimates	1
minimal training overhead	1
three of four languages	1
significant gains of up to 2 BLEU	1
formulation	1
EEEC_Agent functions	1
fuzzy rules	1
theexcessive number of fuzzy rules	1
driver reaction time	1
road surface situations	1
non-linear factors	1
precise mathematicalmodels	1
English prompts (input source sentences	1
English data-points	1
60 million	1
around 130 million	1
number one	1
final outcome	1
(word2vec) word embeddings	1
team name	1
Subtask A (MessagePolarity Classification	1
input graph structure	1
input structure	1
sharper details	1
detailed facial characteristics	1
global outline	1
frontal coarse HR face and prior information	1
facial geometry guidance	1
authentic details	1
247 and 223	1
lower frame rates	1
restoration quality	1
Video Super-Resolution	1
high-resolution clean image	1
hint of interesting open problems	1
classifier discrepancies	1
output level	1
internal features representation	1
input (image) level	1
data fitting specific requirements	1
huge amount of labeled data	1
subgraph	1
Hausdorff distances ($95\%$) of 26.57525, 4.18426, and 4.97162	1
average Dice scores of 0.78751, 0.91290, and 0.85461	1
incomplete inputs	1
either TD or TI input	1
reliable predictions	1
speech content	1
personalized system behavior	1
his/her speech input	1
accuracy-speed trade-off	1
reduced search cost	1
three-party trade-off between accuracy, computational complexity, and memory requirements	1
fast and accurate predictions	1
sentence-level optimum	1
ground truth sequence	1
different but reasonable translations	1
generated sequence	1
strict matching	1
ground truth words	1
next word	1
target words sequentially	1
certain correlation and signal to noise ratio (SNR) range	1
better detection performance	1
much milder assumptions	1
single layer	1
Bayesian priors	1
large set of generic localized community label constraints	1
multiplicity	1
unknown arbitrary heterogeneous structure	1
high ROC-AUC (over 97.5%)	1
benign query image	1
perturbed query im-age	1
embedding dis-tances	1
top-K re-trievals	1
perturbed query person image	1
embedding distancesbetween	1
perturbed examples	1
context inconsistencies	1
context inconsistency	1
range of automatic metrics	1
objective and subjective evaluations	1
46.80%	1
mean dice accuracy of 87.315%, 77.04% and 70.22%	1
67.90%	1
mean dice score of 89.78%, 82.53% and 76.54%	1
number of days of overall survival	1
segmented brain tumor data	1
zero-mean and unit variance	1
internal covariate shift	1
operating parameters	1
serious threats	1
increasing complexity	1
synthetic and real datas	1
traditional GPR data interpretation	1
GPR synthetic data	1
internal defect structure	1
lower costand better predictive performance	1
layerwise mean	1
thelayerwise variance	1
loss in performanceby	1
trainingdata	1
meansand covariances	1
preliminary research	1
inactive lifestyle's health risks	1
daily movements	1
person's daily physical activity level	1
activities	1
adopted sedentary lifestyle	1
meaningful description	1
millions of images	1
every object's visual appearance	1
fine-grained changes	1
recent successes	1
changes in quality, codecs, sizes, shapes, etc.	1
subtle, salient visual details	1
trusted sources (attribution)	1
Matching images	1
powerful stories	1
classic MAPF benchmarks;(ii	1
new constraints	1
compatible and optimal paths	1
k-robust planning	1
variety of pairwise symmetry breaking constraints	1
k delays	1
unexpected events	1
9 classes	1
applicable ICD-O morphology codes	1
considerable lag	1
tumor specific data	1
world averages	1
reporting lag	1
impact	1
Timely cancer reporting data	1
256*256*144 image	1
low (within 20 seconds	1
vessel data fidelity	1
seed point location	1
top 3 winners	1
2nd highest	1
proposed algorithm kappa value	1
classification rate	1
4.98% longer	1
FBCSP (1st winner in the BCI Competition IV	1
37.22% less	1
proposed algorithm average computation time	1
classification accuracy comparison	1
signal energy	1
optimal EEG signals	1
experiment trial	1
EEG MI data	1
multi-class MI classification accuracy	1
qualitative and quantitative metrics	1
element - level and the structure level	1
data - structure	1
:https://github.com	1
unsafe expert data	1
safe policy	1
proposed LGAIL	1
theoretical interpretation of LGAIL	1
safety concerns	1
expert ones	1
unconstrained saddle point problem	1
safety-critical scenarios	1
expert behaviors	1
streamer affect	1
uncontrolled ('in-the-wild') conditions	1
significant set of challenges	1
player behaviour	1
streamer's emotional state	1
low WSD capability	1
81{\%}?93{\%} accuracy	1
2016 WMT submissions	1
number of submissions	1
based features	1
overall classification accuracy	1
statisticallysignificant features	1
fourteen different features	1
local and globalscales	1
theself-similarity	1
single learned policy	1
kind of expert selection behavior	1
principle of optimality	1
control Hamiltonian	1
MT quality	1
highrecall	1
intrinsic and extrinsic evaluations	1
given open-endedquestion	1
plausible answers	1
deeper semantic understanding	1
natural language questionsabout images	1
asystem's visual understanding	1
4.74% and 1.43%	1
79.15% and 71.14% accuracy	1
two standard benchmarks	1
various network settings	1
shared feature representations	1
diverse feedback	1
hard baseline	1
conventional local features	1
1.5 F1	1
gold antecedent spans	1
marginal likelihood	1
span embeddings	1
distributions over possible antecedents	1
updatesentence-level attention	1
user's feedback	1
incomplete or ambiguous information	1
detailed context information	1
ranking problem	1
pool of basic questions	1
reasonable noise level	1
level of noise	1
basic question	1
increasing levels	1
state-of-the-art of 45%	1
increase in mean F-score	1
factor of two	1
potential of this representation	1
face and gestures	1
student problem outcome	1
student learning outcomes	1
relatively smooth	1
similar connections	1
downstream architecture search efficiency	1
less effective search performance	1
architecture representations	1
discrete encodings	1
current baselines	1
bounded error	1
target successor feature function	1
source successor features	1
successor features	1
zero-knowledge proofs	1
variety of properties and constraints	1
input checks	1
potential defenses	1
range	1
aggregated model	1
gradient updates	1
confidentiality	1
ephemeral updates	1
95% performance	1
4.3x reduction in computation	1
global prioritisation	1
early exit probability	1
anytime prediction	1
substantial increase in computational cost	1
equal importance	1
related concepts	1
borders between what	1
mechanistic interpretations	1
physics to biology	1
ordered spatio-temporal patterns	1
many difficult discrete problems	1
producestochastic outputs	1
mutation distribution	1
expensive fitness functions	1
surrogate fitness functionto	1
theparameters and topology	1
rich intertwined history	1
communication perspective and privacy perspective	1
existing FL problems	1
detailed comparisons	1
fundamentals of FL	1
various energy constraints	1
privacy-sensitive data	1
communication inefficiency	1
high latency	1
quantity and privacy-sensitive	1
excessive amounts of data	1
computing and sensing capabilities	1
cross - sentence dependency enriches information	1
entire input document	1
current input word	1
crosssentence dependency	1
cross - sentence dependency	1
within the top 6%	1
wheat head detection results	1
0.5510 weighted F1 score	1
noisy translations	1
considerable degree of diversity	1
private patch	1
common knowledge	1
unbalanced sizes	1
annotated QA data	1
increasing awareness	1
data-hungry	1
orthographic information	1
suffix information	1
one domain	1
English requirements	1
possible English translations	1
random STL formula	1
publicly available informal requirements and formal specifications	1
free English sentences	1
informal requirements	1
logical formulas	1
extensive expertise	1
rank 1	1
30 FPS and 306M memory	1
task 3.2	1
78.7\% F2 score	1
31 FPS and 306M memory (rank 1)	1
59.1 mAP	1
aesthetic classes	1
3 classes	1
lowercase and non-lowercase	1
key spatial invariance property	1
human's hand-eye coordination behaviors	1
absolute spatial location	1
varying conditions	1
offline demonstration data	1
visuomotor skills	1
unlabeled source data	1
discriminability-generalization bias	1
general cognitive capacities	1
photo-realistic	1
corrected version	1
26.7% and 5.4% label mistakes	1
label inconsistency	1
label consistency	1
relationship between label (in-)consistency and NER model performance	1
training set and test set	1
right information	1
coreference evaluation metrics	1
heuristic loss functions	1
''''''``event''''''''	1
observed agreement of .7	1
inter-annotator agreement kappa of .6	1
cross-linguistically	1
''''''``existential''''''''	1
''''''``pleonastic'''''''', ''''''``event''''''''	1
abstract pronouns	1
various components	1
extensive qualitative insights	1
observed graph dynamics	1
temporally evolving structural information	1
interleaved dynamics	1
topological evolution	1
-- dynamics	1
evolving graph information	1
static graph settings	1
difficult questions	1
reasoning and commonsense knowledge	1
question and visual content	1
accuracy prediction	1
manually annotated test data	1
halving and querying abilities	1
near-optimal spheres	1
input distribution	1
volume of version space	1
hypothesis and input distribution	1
hypothesis distribution	1
target-dependent label complexity gap	1
initial hypothesis	1
version space	1
Vapnik-Chervonenkis (VC) dimension	1
hypothesis edges	1
Sign language linguistics characteristics	1
sign features representation	1
Sign representation	1
whole meaning	1
high scalability and efficiency	1
knowledge within node labels	1
node feature	1
Recursive attention and Jumping Knowledge (JK) attention	1
different scales of knowledge	1
underlying correlations	1
multi-scale knowledge	1
unique needs	1
feature combinations	1
higher-order patterns	1
dependency parsing	1
word-selecting objectives	1
word order information	1
out{''}	1
second best result bymore than 22%	1
Ourmethod ranked 1st in the 3DFAW Challenge	1
Z coordinate	1
one foreach landmark	1
2D heatmaps	1
X,Ycoordinates	1
X,Y (2D) estimation and (b) Z(depth) estimation	1
95.9 % and 94.1 %	1
UAS and LAS	1
Stanford dependencies	1
2 - 21	1
unjudged documents	1
quantitative as well as qualitative insights	1
PICO criteria	1
defining elements	1
ever-greater demand	1
theaccuracy rates	1
84\% of accuracywith the F-measure	1
TL settings	1
imagescontaining hundreds	1
compositionsproviding	1
subcellular level	1
[mask].	1
artificial symbols	1
pretrain-finetune discrepancy	1
alignment information	1
replaced fragment	1
ensembling of weights	1
multiple adversarial losses	1
historical weights	1
exponential moving average (EMA)	1
multi-scale outputs	1
domain invariance	1
better prediction	1
ensembling weights	1
pooling layers	1
feature and output spaces	1
new testing domains	1
energy savings	1
lifetime	1
8.95X saving of energy	1
adaptively changing network size	1
computing precision	1
low precision computing	1
computation energy	1
energy and bandwidth limitations	1
original and reconstructed videos	1
mere changes in trajectory graphs	1
45%	1
different number of pixels	1
number of pixels	1
different camera intrinsics	1
accurate, and robust	1
distance prediction	1
causes of the distance uncertainty	1
predicted heights	1
robust distance prediction	1
two heights	1
projected visual height	1
physical height	1
representative and stable variables	1
single variable	1
explicit depth information	1
target word embedding	1
nearest sense embedding	1
dictionary definition, or gloss	1
rare or unseen	1
uniformly distributed	1
86.08%, 83.99%, 82.70%, and 72.60%	1
average accuracies	1
neural signatures	1
existing observations	1
best accuracy of 86.65%	1
four profiles	1
recognition accuracies	1
4, 6, 9, and 12 channels	1
Four different profiles	1
interval of a few days	1
positive, neutral and negative	1
less than 0.1% communication cost	1
initial model weights	1
leaked distilled data	1
accuracy and communication performance	1
93% to 99% performance	1
three orders of magnitude less	1
total communication cost	1
specific model weights	1
distilled data	1
images or sentences	1
poorly distributed	1
ideal circumstances	1
unwieldy model weights	1
tens of communication rounds	1
94.2 F 1	1
93.6 F 1	1
91.8 F 1	1
bottom - up constituent information and top - down lookahead information	1
constituent hierarchy	1
lookahead guidance	1
rich features	1
post-order and pre-order traversal	1
types of questions	1
geographic questions	1
conversation content and external data	1
new movies	1
users{'} ratings	1
movie recommendation conversations	1
{``}similar{''}	1
ratings	1
user{'}s sentiment	1
user{'}s interest vector	1
whose preferences	1
limited or no data	1
highlyflexibility	1
RGP extensionwhere variational parameters	1
RGP layers	1
autoregressive states	1
deep structures	1
different formulations	1
recurrent GP priors	1
dementia detection performance	1
higher penalty	1
discourse representation	1
syntactic complexity	1
deletion errors	1
artificially generated ASR errors	1
controlled amounts	1
architecture security	1
decision-making recommendations	1
users' feedback	1
2% anomalous images	1
convolutional latent variable	1
class-specific threshold	1
anomaly	1
pixel coverage	1
small sample size	1
distributional semantics	1
standard precision/recall/F1-measure metrics	1
reference classification	1
Mathematics Subject Classification (MSC)	1
mathematical content representations	1
noisy high-dimensional attributes	1
vice versa	1
links and node attributes	1
F1 score of 63.4	1
learnable entities-dependent threshold	1
global threshold	1
multiple possible relations	1
sentence-level counterpart	1
F1 scores of 0.92, 0.82, and 0.97	1
normal or abnormal	1
session recording	1
useful metadata	1
94.66 F1	1
PTB of 94.25 F1	1
new state - of - the - art numbers	1
rescoring results	1
candidate outputs	1
better confidence intervals for scores	1
Small World	1
large architectures	1
navigation performances	1
robust high-level navigation skills	1
complex topologies	1
complex manoeuvres	1
scale of millions	1
developer-specified model testing criteria	1
1.3%-9.8%	1
1.2x-14.1x and final model accuracy	1
participant data	1
training quickly	1
poor model and system efficiency	1
device capabilities	1
thousands to millions	1
end goals	1
edge data	1
spatially preserved object detection information	1
image and time domaincues	1
comparativeanalysis	1
error rate by 22.4% comparedto the winning solution	1
data from PolEval 2018	1
aggregation functions	1
time series representations	1
discriminatory sub-series (intervals)	1
aggregate values	1
state-of-the-art classification accuracy	1
classification accuracy and efficiency	1
positive correlation	1
variants of MTL	1
supervised training signal	1
highly specific	1
MTL objective	1
overall survival	1
patient risk	1
histopathological growth patterns	1
superiority and generalization	1
clean labeled data	1
{Unsupervised Domain Adaptation } (UDA)	1
rich labeled data	1
diagnostic difficulties	1
mislabeling labels	1
limited labels	1
common information	1
feature graph	1
topology graph	1
rich information of topological structure	1
hundred sentences per second	1
highly data - efficient	1
domain specific , complex , and inefficient	1
42.47 and 37.50 BLEU points	1
end-to-end trainable flexibility	1
mean per joint position error at 42.39 on the validation dataseton	1
3D joints	1
2D joints	1
3D poseestimation	1
recently released NuScenes real-world driving data	1
lidar data	1
data sparsity and noise characteristics	1
clustered radar data	1
occupancy grid mapping	1
severe weather conditions	1
long range sensing	1
speed of 0.14 second per frame and J&F measure of 75.9%	1
one forward pass	1
video object tracking task	1
ofthem	1
theperformance to a non-trivial extent	1
empirical distribution $P(predicate|subject,object)$	1
query label	1
kind of weighted KNNso	1
weighted KNN.The validity	1
train samples	1
user required image	1
color, shape, textureto	1
semantic gap	1
high level feature	1
color, texture and middlelevel feature	1
Low level features	1
low, middle and high	1
three types	1
interesting scene elements	1
theoretical considerations	1
small subset of the data	1
minimax rate	1
asmall number of features	1
reasonable choices of algorithm parameters	1
large amount of realistic training data	1
standard decomposition	1
zero pronouns	1
robust policies	1
convenience	1
decentralized one	1
significantly poor	1
100,000 total clips	1
likenesses modified	1
two identities	1
cloze objective	1
variety of language understanding problems	1
robust correlation	1
intra and inter-class correlations	1
trained performance	1
GPU computation	1
learning and recognition performance	1
apparent gap	1
training (seen) data and real (unseen) data	1
considerable gap	1
pre-defined 3D features	1
learnt features	1
proposed interpolated depth images	1
Velodyne data	1
variable density	1
98% attack success rate by only 33 queries	1
high attack success rate	1
prior-guided gradients	1
transferable priors	1
attack efficiency	1
set similarity	1
attack effectiveness	1
returned labels or confidence score	1
top-k	1
Electron Microscopy and MRI brain images	1
superlative behavior	1
desired class labels	1
procurement of EEG signals	1
analytical ones	1
low, medium or high	1
two cognitive styles	1
two different cognitive styles	1
presented problem	1
experimental methodologies	1
convenience of OpenMatch	1
top-ranked empirical results	1
surplus labor	1
corresponding ranking results	1
complicated experiment instructions	1
fixed training condition	1
-data	1
significantly less training data	1
much more heterogeneous	1
NIST2016 Speaker Recognition Evaluation (SRE)	1
bounded system size	1
new information	1
many variants	1
resulting features	1
sensory state's information	1
tone marks	1
intonation patterns	1
focus information	1
speaker 's intention	1
concept of focus	1
discriminative metric space	1
neighbor relationships	1
similarity subgraphs	1
local neighbor relationships	1
original data points	1
better comprehensive performance	1
redundant computational cost	1
global geometry	1
to20\%	1
final one	1
asubstantial improvement	1
Probability ofImprovement	1
large number of hyper-parametersgoverning	1
increasing quantity	1
MRI images	1
far the most detrimental effects	1
combinations of these factors	1
ambient noise	1
considered metrics	1
every real-world scenario	1
interfering events	1
target classes	1
two spatial formats	1
spatial room impulse responses	1
real conditions	1
real recordings	1
deep appearance metric	1
detector confidence	1
appearance metrics	1
real-time performance	1
tracking formulation	1
Siamese configuration	1
embedding function	1
total time	1
relaxed search space	1
computational expense	1
relative gains of 10.38% and 12.40% in minDCF and EER	1
every condition	1
different SNR levels	1
various noise types	1
competitive accuracy results	1
best trade-off between accuracy and execution time	1
best mAP	1
traffic sign image sizes	1
number of floating point operations	1
running time	1
memory allocation	1
mean average precision (mAP)	1
key metrics	1
driver safety	1
unknown labelestimation	1
useful 'weakly'supervised information	1
given labels andthe estimated labels	1
interesting open challenges	1
challenges and future directions	1
two futuristic variants	1
8, 6, and 4 bit precisions	1
without Batch-Normalization layers	1
ZeroQ and DFQ	1
FP32 model layer statistics	1
Retro-Synthesis Data	1
quantization loss	1
discoveries	1
universals	1
terms of feature-values	1
language universals	1
UNIVAUTO -LRB- UNIVersals	1
provided learner response frequencies	1
decoding and filtering strategies	1
model architecture and training decisions	1
acceptable translations	1
variety of metrics	1
variant scales	1
mini-batch training performance	1
layer normalization	1
medical image data	1
based onelectroencephalographic (EEG ) recordings	1
anatomical and functional differences	1
impression of the bodyof knowledge	1
human labor costs	1
efforts from 2.2% segment label to 40 points label	1
representative points	1
efforts	1
small fraction (about 2.2%) ground truth points	1
near supervised performance	1
inconsistency mask	1
uncertain points	1
scarce labels	1
computingcorrelation values	1
translation-invariant local transformations	1
reliable correlations	1
large degree of image variations	1
differentbackgrounds, clutter	1
noisy features	1
faster training and prediction times	1
number of inducing points	1
parameters of	1
good prediction performance	1
large number of inducing points	1
latent function	1
$q$	1
parameters of an approximate posterior distribution	1
$M \ll N$ inducing points	1
cubic cost with respect to $N$.	1
number of training instances N	1
poor scalability	1
non-parametric nature	1
80.46% in terms of F-score	1
76.60% in terms of F-score	1
given gold mentions	1
NER predictions	1
wet-lab protocols	1
3.25 in intent prediction (accuracy) and slot filling (f1-score)	1
0.57{\%}	1
50% of samples	1
pixel space	1
sample diversity	1
model certainty	1
decoupled aspects	1
sample selection criteria	1
compositional semantic interpretation	1
logical form -RRB-	1
Intrinsic and extrinsic evaluations	1
data noise	1
different type of data quality	1
well-fitdomain data	1
domain relevance	1
experimental STEMdata	1
non-rectangular scanning trajectories	1
absolutescanning/imaging speeds	1
imaging and manipulation modes	1
dynamicrange of STEM	1
order parameterfields	1
atomic level	1
appropriate choice of likelihood	1
information criteria	1
task of semanticsimilarity	1
semanticsimilarity	1
various evaluation metrics	1
category mask	1
binary bitsdistribution	1
representative intra-class identity	1
inter-class diversity	1
Classification lossis	1
fullyexploiting inter-class diversity and intra-class identity	1
Bioinformatics online	1
Supplementary data	1
https://github.com/lingluodlut/Att- ChemdNER	1
Data and code	1
F-scores of 91.14 and 92.57%	1
tagging consistency	1
document-level global information	1
tagging inconsistency problem	1
feature engineering	1
pairs of imageswith differences	1
perimeter and fractal dimension	1
objects area, axis ratio	1
histogram modes delineation	1
relaxation parameter	1
previous related images	1
subjective evaluation	1
lab subjective tests	1
subjective tests	1
conventional objective metrics	1
objective metrics	1
subjective (perceptual) quality	1
highest localization accuracy of 0.43	1
Top-1 localization error of 48.65\%	1
parallel sliding window	1
multiple local maximum	1
gradient weights	1
image-level class labels	1
different local maximum responses	1
accurate samples	1
total variationdistance	1
constructed coresets	1
DPP	1
thediversity property	1
discrete $k$-DPPs	1
expensive cubic-complexity matrix operations	1
4.1% macro F1-score	1
Knowledge Graph (KG) Embeddings	1
state-of-the-art results (in terms of accuracy)	1
66 % accuracy	1
45 % accuracy	1
70-leaf topic hierarchy	1
preliminary labels	1
unlabeled documents	1
approximate labels	1
OpenAI transformer models	1
entailment functions	1
importance weights	1
distracting information	1
relation classes	1
query entity types	1
one relation	1
query entities	1
words choice	1
expression style	1
relation extraction accuracy	1
predefined relation classes	1
spectral properties	1
two additional loss terms	1
activation maps	1
leap in performance	1
linear rate	1
depth the exponent	1
analytically and empirically	1
image statistics	1
various layers	1
natural statistics	1
natural image statistics	1
modifiederror functions	1
one winning class	1
pool of several classes	1
sharp definitionof classes	1
overlapping distributions	1
insufficient input information	1
meaningful margins	1
flexible priors	1
one hidden layer	1
deeper representations	1
user preference	1
potentially problematic characteristics	1
significant discriminative information	1
significant 22.5% improvement	1
average accuracy of 77.9%	1
combined outputs	1
channel cross-covariance matrix	1
jointvariability	1
long context	1
minimal encoding	1
document-level context	1
selected examples	1
Document-level context	1
87.10{\%}	1
accuracy of 86.22{\%}	1
correct and incorrect options	1
one of the available options	1
missing word	1
gender imbalances	1
gender discriminatory formulations	1
brain signals	1
Frechet inception distance	1
Inception score	1
architectural choices	1
time seriesdata	1
overall results	1
Scientific papers subtask	1
double hints	1
implicit topology end-to-end	1
sophisticated relationships	1
additional human annotations	1
visual hints	1
answer-awareness and region-reference	1
rich correlations	1
referential and meaningful questions	1
image and potentially other side information (e.g. answer type or the answer	1
learning feedback	1
theoretical formulation	1
optimal performances	1
Behavioral Cloning	1
precise spike timing	1
experimental evidences	1
degrees of freedom	1
number of constraints	1
target-based naturally	1
biologically plausible	1
task queries	1
event identity	1
Event Centric Knowledge Graphs (ECKGs)	1
participants, time and place	1
original audio	1
high acoustic similarity	1
adversarial samples	1
potency	1
upto 980%	1
Word Error Rates (WER)	1
significant vulnerability	1
retrieval effectiveness by up to 2%	1
velocity	1
different pacing functions	1
different input spaces	1
challenge (1)	1
conversation response ranking	1
difficulty of training instances	1
batches non-uniformly	1
sampled uniformly	1
alcoholic VERPs	1
temporal pattern	1
lead-weights (featureswith attributes	1
visually evoked responsepotentials (VERPs)	1
quasi-constant mutation rate	1
convergence controlledmutation	1
subset sizesare	1
numeric attributes	1
MMX-BLXexploit andMMX-BLXexplore	1
later experiences	1
BKT and PFA's standard knowledge estimates	1
correctness predictions	1
student knowledge	1
problem correctness	1
actual plan	1
user 's plan	1
intended meaning	1
pragmatic rules	1
component	1
useful responses	1
subsequent utterances	1
underlying task-related plan	1
mixed-resolution measurements	1
measurement types	1
quantized measurements	1
dithering noise	1
power constraint	1
proposed tractable form	1
resource allocation optimization problem	1
matrix dimensions	1
associated mean-squared error (MSE)	1
mixed-resolution, 1-bit quantized and continuous-valued, data	1
physical constraints	1
quantized data	1
subsequent estimation performance	1
many physical advantages	1
high-quality ML models	1
set of idiosyncratic requirements	1
extreme expressions and poses	1
ground truth 3DMM parametersfor	1
adisentangled representation of 3DMM parameters	1
3DMM parameters	1
bounding box locations	1
data-agnostic ranking scores	1
training proceeds	1
search time by approximately 2.4X	1
strong ranking correlation	1
competing baselines	1
fast estimates	1
usefulness of the features	1
training or validation error	1
user and product information	1
user{'}s overall sentiment	1
classical baselines	1
word level and sentence level information	1
small number of aspect-related keywords and aspect ratings	1
symmetric group	1
characteristic pathologies	1
single embedding vector	1
distilled embeddings	1
anchor)	1
different class	1
negative embedding	1
positive embedding	1
strong occlusion	1
sample document	1
deep factual knowledge	1
performance differencebetween	1
recurrent attention	1
acertain question	1
ambiguous constructions	1
sense of humor	1
~90% accuracy	1
highaccuracy of an SSMVEP	1
ERD index values	1
classification accuracy >85%)	1
sufficiently clear SSMVEP pattern	1
sustained event-related desynchronization/synchronization (ERD/ERS)in	1
classification accuraciesof 88.9 $\pm$ 12.0%	1
20% to 50%	1
LUBM and NELL KGs	1
expert domain knowledge	1
logical entailments	1
low-dimensional vector space representations	1
discretized distribution	1
multimodal posteriors	1
short timescales	1
deterministic outputs	1
future behavior	1
future locations	1
predictive models	1
maximal voltage deviation	1
settling time	1
startup time	1
conformance	1
complex specifications	1
specifications of interest	1
F1-score of 91%	1
amendment relationship	1
daily jobs	1
different due dates and obligations	1
associated amendments	1
master agreements	1
:http://calla.rnet.missouri.edu/qprob/.	1
Qprob ranks	1
official CASP result	1
probability densitydistribution	1
true quality scores (i.e. GDT-TS scores	1
protein featurevalue	1
absolute error	1
significantly smallerestimation errors	1
OwARR and OwARR-SDS	1
half of thecomputational cost	1
amount of subject-specific calibration data	1
new subjectwith zero or very little subject-specific calibration data	1
laboratory settings	1
maximalerror estimation	1
SSIM values of 0.54 to 0.88	1
non-linear function	1
additional prior knowledge	1
maximal error bounds	1
output domain	1
input data space	1
induced approximation errors	1
(vanilla and) exotic derivatives	1
polynomial structure	1
peculiar nature	1
high convergence rate	1
English word order	1
dependency length	1
optimal layout	1
total dependency length	1
, height, width, and orientation)	1
high variety and complexity	1
76.1% vs 73.7% UAR	1
best test set result	1
Area Under ROC Curve (AUC) of 80.7%	1
Unweighted Average Recall (UAR) of 74.9%	1
testing capacity	1
complete lockdowns	1
concise representations	1
77.0% Top-1 accuracy	1
HourNAS	1
3 hours (0.1 days)	1
computational resource constraints	1
extremely fast NAS	1
hourglass	1
overall network complexity	1
major volume	1
current state-of-the-art performances	1
aggregators	1
graph structure information	1
node label	1
expressive capability	1
current representation vector	1
neighboring nodes information	1
mean-pooling)	1
aggregated neighboring nodes information	1
nodes features	1
model-dataset combinations	1
different inference patterns	1
decoy facts	1
relationship patterns	1
inductive abilities	1
benchmarks	1
local-to-global dynamics	1
complex spatial and temporal dynamics	1
rich underlying semantic structure	1
1.2% on average and 3.3% at most	1
good accuracy performance	1
knowledge (i.e., parameters)	1
insufficient parameterization problem	1
insufficient parameterization	1
66% F1 onSQuAD 2.0	1
86% F1	1
50,000 unanswerable questions	1
correct answerto	1
$10\%$ performance gain	1
$5\%$	1
unlabeled data samples (semi-supervised FSL)	1
transductive FSL)	1
additional unlabeled data	1
shot learning performance	1
merrier	1
meta-training vs regular multi-class, currently regular wins	1
bigger is better)	1
FSL performance	1
significant performance advances	1
unseen during training)	1
(typically $1$ or $5$) examples per novel class	1
example induces	1
logical form entries	1
time-consuming and expensive task	1
final similarity score	1
three kinds of relation scores	1
pixel-level and part-level similarities	1
part-level metric	1
distribution distance (i.e., Wasserstein distance, Kullback-Leibler divergence)	1
distribution-level similarity metric	1
part-level, pixel-level, and distribution-level similarities	1
part-level features	1
pixel-level similarity	1
smaller feature space	1
three distinct level similarity metrics	1
single level	1
attribute information	1
12\% improvement	1
gaze	1
described locations	1
enhanced diversity	1
, up to 22% improvement	1
lower bits	1
various network architectures	1
distribution level	1
distribution level and sample level	1
real training data	1
heavy dependency	1
FP32 ones	1
batch normalization (BN) statistics	1
21.30 macro F1	1
37.57 macro F1	1
=100	1
beam width	1
n=10)	1
n-Best sequences	1
checkpoint	1
various training stages	1
graph node connections	1
boundary score map	1
backbone features	1
long-range contextual features	1
dynamic personal interests	1
user-POI matrix sparsity	1
semantic contents	1
extreme user-POI matrix sparsity	1
manual quality annotation	1
meaning errors	1
important meaning errors	1
fluent translation outputs	1
DAVIS 16, DAVIS 17	1
expected similarity	1
previous frame's feature --	1
minimal change	1
unnecessary computations	1
changes in appearance	1
high-quality segmentation	1
3D GPR image	1
migration accuracy	1
underground target depth prediction	1
0.112 average error	1
average accuracy of 92.64%	1
DepthNet	1
labeled GPR images	1
synthetic GPR data	1
real GPR data	1
proposed DepthNet	1
GPR scan data	1
B-scan data	1
hyperbola features	1
B-scan of GPR image	1
next character	1
ambiguous histories	1
perplexity and predictive accuracy	1
ambiguous history	1
language-modeing challenges	1
original meaning	1
gist	1
rewriting rules	1
300k data points	1
longer time horizons	1
fixed keyframes	1
target distortions	1
transition length	1
future keyframes	1
animation constraints	1
temporally-sparse keyframes	1
layer-wise propagation pattern	1
local factor	1
locality	1
\textbf{D}eoscillated \textbf{G}raph \textbf{C}ollaborative \textbf{F}iltering~(DGCF)	1
layer-fixed propagation pattern	1
bipartite structure	1
fix propagation pattern	1
high-order signals	1
cold-start issue	1
High-order information	1
Collaborative Filtering (CF) signals	1
domain-specific and domain-invariant latent variables	1
domain-invariant latent variables	1
domain-specific latent variables	1
three mutual information regularization terms	1
domain-invariant information	1
proper nouns	1
efficient approximation	1
sufficiently accurate results	1
known Information Criteria	1
long-term history	1
relevant past motions	1
historical motion sub-sequences	1
current motion context	1
pose similarity	1
frame-wise attention	1
past motion	1
future human poses	1
intent specifications	1
network safety shielding	1
certain Key Performance Indicators (KPIs)	1
high-level safety specifications	1
efficiently estimate model parameters	1
three types of variables	1
context type	1
part of the model design	1
tagging results	1
accuracy of 0.964	1
hundreds of them	1
previous findings	1
English efficiently	1
corresponding geodesics and distance function	1
Fisher information metric	1
formal intersections N ~ = IAi	1
regular languages	1
100-fold speedup	1
generation problem	1
time exponential on the size	1
OTP 's optimal surface forms	1
two simple families of permissible constraints	1
universal generator Gen	1
0.2 BLEU points	1
special syntax	1
2.5+ BLEU points improvement	1
OOV problem	1
fixed number	1
Memory and time constraints	1
less than 2% of the pixels	1
Jaccard scores	1
two types of annotations (grid and points)	1
sparse ones	1
meta-training	1
sparse labels	1
sparse labeling	1
96.67% Accuracy	1
pre-trained ImageNet weights	1
own, visual features	1
End-to-End	1
theanalysis of such features	1
real patterns	1
relatively sparse	1
pairwise differences	1
Transitive Global Translations (TGT)	1
Global Counterfactual Explanation (GCE)	1
represent	1
groups of points in that representation	1
16systems	1
highest overall average F1 score	1
overall average F1score of 79.99	1
research gaps	1
year 2000 to 2018	1
electronic format	1
analyzable, editable and searchable data	1
practical worth	1
ubiquity	1
Documentation and code	1
bar	1
control problems	1
better regression models	1
corrupted sample points	1
monotonic convergence behavior	1
non-negative constraints	1
posterior standard deviation	1
GPR model's predictive error	1
observed labels	1
independent variances	1
additive Gaussian noise terms	1
real-valued noisy labels	1
time domain features	1
63:41%	1
increased accuracy of 76:19%	1
happy, relaxed, sad, and angry	1
frequency domain features	1
total of 21	1
record electroencephalography (EEG ) data	1
enhanced multimedia content (mulsemedia)	1
viewers a more realistic and immersing feel	1
Patterns of ambiguity	1
raw parallel data	1
~25% accuracy gain	1
ground-truth relationship triplets	1
semantic feature vector	1
combination of object-level visual features	1
high-level understanding	1
greater number	1
larger sentence representations	1
adversarial classifiers	1
optimal number	1
learned sentence representations	1
unwanted biases	1
respective entailment classes	1
interesting patterns	1
STL formulas	1
interesting document behaviors	1
specified formulas	1
document behaviors	1
time or user behaviors	1
drop or rise	1
timed position	1
admissible action	1
given situation	1
partial observability	1
accumulated reward	1
textual feedback	1
combinatorially large	1
High-speed 3D object recognition function	1
3D point	1
2D coordinate	1
point cloud data	1
3d object detection	1
node whose function	1
3D point coud data reconstruction	1
19.39-86.47%	1
trueresponse speed	1
root mean square estimation error by10.02-19.77%	1
thespatial filters	1
EEG signal quality	1
17subjects during a 5-month period	1
sessions of sustained-attention psychomotor vigilance task data	1
onEEG -based response speed estimation	1
two common spatial pattern	1
theoretical rigor	1
0.93 and AUPRC over0.60 (compared to 0.14 by chance)	1
binary classification AUROC	1
predictionbeing native or not	1
estimated probability	1
tight confidence intervals with half range around 25% ofiRMSD and confidence level at 85%	1
one third targets	1
starting points	1
global optimum (or nativestructures	1
solution quality (e.g.interface RMSD or iRMSD)	1
high-dimensionalspace	1
monodepth model derived results	1
overall increase of 14% in relative depth accuracy	1
scene attributes	1
object labels	1
object bounding boxes	1
geometrical features	1
classification one	1
course relative depth	1
depth per pixel	1
stereo image data	1
scene dependent	1
accurate depth information	1
3D depth	1
bothtextual and multimodal additional data	1
auxiliary objective	1
visual featuresand	1
MOTA score of 32.1	1
high relative motions	1
locality and visual similarity	1
affinity matrix	1
2Dshape representations	1
knownobject categories	1
frequencies of occurrence	1
style markers	1
suitability map	1
final desired product	1
instances of the extracted criteria and property values	1
values)	1
land use suitability criteria	1
bylaw and regulation documents	1
criteria and values	1
associated patterns	1
robustness property	1
source patterns	1
target signal	1
true patterns	1
typical assumptions	1
interpretable patterns	1
model interpretability	1
strong empirical results	1
total cost	1
convergence rate of $O(\frac{\sqrt{d}}{\sqrt{K}})$ and an $O(d\epsilon^{-2})$-approximation guarantee	1
properly control cost	1
hyperparameter optimization (HPO) solutions	1
positive definite metric	1
measure preserving property	1
learning proposals	1
nonlinear SSM	1
semantic description	1
entry point	1
wich exact textual entity	1
highly polysemic	1
decodable information	1
brain responses	1
majority ofparticipants significantly	1
correctness and robot type	1
high-resolution EEG	1
robot's visual similarity	1
singletrials of electroencephalographic (EEG ) recordings	1
usefulteaching signal	1
robot performance	1
thehuman's perceived correctness	1
local task	1
diverging choices	1
local tasks	1
good engineering acumen	1
machine learningtechniques and morphological features	1
correctMT output	1
limit cut analysis results	1
varying levels of imbalance	1
set of parameterdependent cuts	1
node degrees	1
imbalancedcluster sizes	1
minimum size constraints	1
minimum cutpartitions	1
cut sizes	1
cluster sizes	1
cut (RCut) or normalized cut (NCut) objectives	1
specific graphconstructions	1
structural integrity	1
improvement of up to 10.5% in F-score	1
resulting logical forms	1
soundness	1
better semantic type assignments	1
detailed semantic representation	1
rich role structure	1
probability of generating texts	1
source documents	1
expert optimal assumption	1
suboptimality $O(\sqrt{H}/N)$ with high probability	1
rewards only	1
arbitrary 3-state MDPs	1
suboptimality $O(1/N)$	1
subsampled observations	1
given reward function	1
value estimation problem	1
larger sharp rate $\Theta(|\mathcal{S}|H^2/N)$	1
unknown-transition setting	1
$\Omega( H^{3/2}/N)$ when $|\mathcal{S}|\geq 3$	1
minimax suboptimality	1
suboptimality	1
upper bound $O(|\mathcal{S}|H^{3/2}/N)$	1
MDP transition	1
$N$ length-$H$ trajectories	1
dataset	1
statistical limits	1
minor overhead	1
functionally identical	1
channel values	1
bell-shaped distribution	1
F1-score of $0.781$.	1
eighth position	1
F1-score of $0.919$	1
fourth position	1
several priors and constraints	1
situ priors and constraints	1
accuracy of 69{\%}	1
parallel German translations	1
approximate ones	1
time quadratic in the maximum demonstration length L	1
marginals	1
Relative Entropy IRL	1
MaxEnt IRL	1
previous heuristic derivation	1
generalized MaxEnt formulation	1
many consistent reward functions	1
given expert demonstrations	1
non-committal reward function	1
Maximum Entropy (MaxEnt)	1
imbalanced structures	1
algorithm level	1
locations of absent datapoints	1
weights ofthe empirical similarity function	1
concept ofabsent data	1
imbalancedstructure of the training data	1
empirical similarity function	1
underrepresented class	1
public ground truth	1
calibration errors	1
RGB and depth sensor synchronization	1
estimated 3D map and camera trajectory	1
theta-diapason	1
increased values of spectral density	1
beta rhythm	1
increased values	1
noncooperative decision	1
specific aspects	1
main metric	1
natural-sounding and flexible output	1
training data (zero-shot	1
F1 scores between 0.52 and 0.60	1
lexical text	1
sarcasm, and +3.0 points	1
+3.4 points	1
+1.2 points for PP-attachment	1
age, gender, and personality traits	1
known user factors	1
user uniquely	1
Imagenet top-1 error	1
enough signal	1
four times lower	1
two orders of magnitude lower	1
internal activations	1
average Dice OverlapCoefficient of 95.4%, 91.6% and 89.6% for	1
poten-tial gradient vanishing problem	1
volume-wise labels	1
whole volumetric data	1
manually collected data	1
Cohen's quadratic kappa (k) score of nearly 18%	1
biopsy-level scoring	1
patch-level patterns	1
gigapixel whole slide images	1
global Gleason score	1
Gleason grades	1
tedious and prone-to-error pixel-level annotations	1
high time-consuming and subjective task	1
new ideas	1
wide range of types	1
diverse	1
RobotSlang dialog-based navigation instructions	1
1k minutes	1
nearly 5k utterances	1
dialog and visual observations	1
Localization from Dialog History (LDH)	1
Commander instructions	1
navigation goals	1
well differences	1
weightingscheme	1
precision andrecall based metrics	1
validity and usefulness	1
theoretical foundations	1
perceived difference	1
individual metrics	1
changes inthe relative weights	1
measured differences	1
standard metric combination criteria	1
Unanimous Improvement Ratio (UIR)	1
system rankings	1
relative weights	1
weighted combination measures	1
sort of weighted combination	1
single qualitycriterion	1
post-processing hyper-parameters	1
accurate prediction	1
coarse nucleus proposals	1
correlation and differences	1
respective high-quality features	1
variation of post-processing hyper-parameters	1
additional cognitive load	1
MR-MTS	1
MR-MTS data	1
sampling rate	1
various sampling rates	1
multivariate time series observations	1
Multi-Rate Multivariate Time Series (MR-MTS)	1
question representations	1
appealing results	1
A	1
better knowledge	1
residual error	1
T.	1
learning capacities	1
substantial gap	1
putative correspondence	1
sparse geometry	1
common failure modes	1
collected feedback	1
alternative metrics	1
qualitative radiologist evaluations	1
fully-sampled data	1
7,299 clinical brain scans	1
Bayesian rules	1
physics	1
holistic baselines	1
few-shot learning objective	1
graph generator	1
strong data-efficiency	1
previous unseen 3D action class	1
imaging acquisition parameters	1
volumetric and radiomic results	1
concomitant reproducibility	1
different acquisition and reconstruction parameters	1
reproducibility of histogram- and texture-based features	1
volumetric reproducibility	1
given outcome variable	1
significant change in volume, density, or texture metrics	1
Reconstruction conditions	1
5 Run Length Matrix	1
13 Gray Level Co-occurrence Matrix	1
5 histogram features	1
Typical texture analysis metrics	1
nodule volume per thickness	1
0.6-5.0 mm	1
range of thicknesses	1
iterative-reconstruction kernels	1
reduced-dose and full-dose data	1
12.5%, 25%, and 50% of protocol dose	1
8 thicknesses	1
10 kernels	1
acquisition/reconstruction conditions	1
CT raw data	1
slice thickness	1
reconstruction kernel	1
routine ranges of radiation-dose	1
volume-, density-, and texture-based features (outcome variables)	1
reproducibility	1
couple of entities	1
latent medical knowledge	1
F1=0.710 vs. 0.222	1
F1=0.848 vs 0.691	1
previous best	1
clinical narratives	1
thequestion is unanswerable	1
unanswerable or not	1
morphology induction results	1
sufficiently similar semantically	1
`` all ''	1
valid affixes -LRB- `` ally	1
number of problems	1
stemand-affix statistics	1
11B parameters	1
large number of synthetic examples	1
novel action categorieswithout	1
average of 4.1 % bit rate reduction	1
SSIM measurements	1
speed up	1
extrasignaling bit	1
low bit rates	1
ringing and contouring effects	1
block bounders	1
position-dependent features	1
distributed representation	1
Position-dependent features	1
character-level and word-level features	1
erroneous documents	1
challenging test	1
polysemous names	1
entity disambiguation capabilities	1
accuracy to 83.84%	1
4-class MI	1
77.35% classification accuracy	1
outstanding accuracy	1
reduced latency	1
vast amount of memory and computational resources	1
general one	1
better correlation	1
information retrieval document base (called index)	1
candidate and reference summaries (called queries)	1
object shape, position or size	1
high-level priors	1
conformity	1
non-differentiable rewards	1
impressive recent advances	1
maximal fluctuating margin	1
segment lengths	1
Thirteen different segment lengths	1
average sensitivity, specificity and precision of 88.80%, 88.60% and 88.69%	1
temporal and spatial discriminating features	1
essential seizure features	1
considerable variations	1
nonseizure state	1
seizure state	1
labor-intensive and error prone	1
recent progress	1
30.4%	1
comparable inference latency	1
1.63% higher	1
1.49x speedup	1
0.53% higher	1
6.35x inference speedup	1
3.47% higher accuracy	1
inference latency of only 16.5 ms	1
76.67% top-1 accuracy	1
much lower latency and higher accuracy	1
latency constraint	1
hardware diversity	1
significantly less data	1
practitioner's opinion	1
design ofthe representation	1
relevant aspectsnecessary	1
extensive collection	1
relative algorithm performance	1
65%	1
ten times more	1
four times more	1
arbitrary label shift	1
asymptotic sample complexity	1
importance weighting	1
class proportions	1
ROUGE-2 F-measure	1
manual evaluations	1
92% classification accuracy on average	1
asatisfied result	1
categories of outliers	1
outliers in traffic dataautomatically	1
one normal type (inliers) andmultiple abnormal types (outliers)	1
various types of traffic data	1
variety of traffic situations	1
set of realistic simulation data	1
abrupt or illegalstop on	1
abnormal driving pattern	1
severity of congestion	1
traffic situations	1
congestions regularly acrossspace and time	1
heavy traffic flows	1
privacy of training data	1
fitness value	1
initial face	1
random composition	1
target face	1
search path	1
search parameters	1
independent segments	1
inefficiency of rounding policy	1
Rounding confidence score	1
linear additive streaks	1
rain degradation classification	1
wealth of temporal redundancy	1
rain streaks	1
light transmittance	1
Tweet segmentation	1
localized events	1
concise presentation	1
small word limit	1
social media data specifically twitter data	1
97.27% accuracyand 0.13 MAE	1
suggested method's performance	1
threemeasurement parameters: accuracy, mean absolute error (MAE)	1
two kernels	1
eye state	1
even supervised parsing performance	1
strong relationship	1
unsupervised parsing performance	1
standard tagging metrics	1
various measures	1
around 4x gain	1
loss of 3% to 12% SSIM accuracy	1
56% gain	1
energy constraint	1
optimal number of scales	1
different scale	1
patch distribution	1
huge memory	1
energy consumed (compute)	1
image generation accuracy	1
m-way affinities	1
first theoretical evidence	1
larger values of m	1
m-uniform hypergraphs	1
large sample behavior	1
general setting	1
random m-uniform hypergraphs	1
uniform hyper-graphs	1
multi-way affinity relations	1
infinitely large sample size	1
global proximity structure	1
high-order object-object and tag-tag proximities	1
essential similarity information	1
object-tag links	1
mixed strategies	1
saddle point	1
crisp numbers	1
imprecise numbers	1
Rectangular Fuzzy gamewith pay-off	1
Management Sciences	1
20{\%}	1
least 5.5 F1 measure	1
augmented WordNet glosses	1
basic sense embeddings	1
sense relations	1
sense knowledge	1
substantially bettervariational distributions	1
value ofstochastic second-order information	1
atleast one order of magnitude faster	1
second-orderinformation	1
astationary point	1
CC instance	1
corresponding node	1
negative weight edges	1
cycle inequalities	1
integer linear program (ILP)	1
thorough analysis	1
textual words	1
better video captioning	1
properties of Turkish	1
role of video context	1
parallel English-Turkish descriptions	1
videos	1
top-1 error of 16.37% and top-5 error of 7.4%	1
CIFAR-100 and ImageNet	1
top-1 test error of 2.47% with 3.63M parameters	1
prediction of its fitness	1
performance prediction	1
majority of the gradient information	1
next generation of architectures	1
one generation	1
search time significantly	1
high search time	1
word topic and character topic	1
two distinct types of topics	1
two long-term self-adaptive thresholds	1
short-term historical data points	1
upcoming data point	1
timely anomaly alerts	1
classification F1-score of 0.873	1
patient inter-variability	1
complex frequency patterns	1
main feature	1
activation differences	1
ictal class	1
larger contribution	1
signal waveforms	1
visual interpretation	1
relevant frequency patterns	1
seizure-level	1
larger time scale	1
input signals	1
insufficient interpretability	1
error decay curves	1
several weaknesses	1
impressive sampling efficiency	1
various quantitative evaluation metrics	1
dense motion trajectories	1
sparse motion trajectory	1
long-term global pose dependencies	1
>50	1
long-term (> 6000 ms) human motion trajectory	1
temporal pose variations	1
large as well	1
variable speed	1
bi-directional and multi-scale dependencies	1
long-term temporal dependencies	1
pedestrian trajectory prediction	1
error category	1
criteria of fluency and adequacy	1
short and long sentences BLEU scores	1
System level Pearson's correlation	1
single and multiple reference translations	1
automatic evaluation metric BLEU	1
syntactic errors	1
lexical errors	1
morphological errors	1
unnecessarily translated words	1
several categories	1
fluency and adequacy	1
error types	1
reliability of agreement	1
criteria of adequacy and fluency	1
short and long sentences	1
superiority of MILD	1
trade-off between efficiency and accuracy	1
approximate image similarity measurement	1
extracomputational complexity	1
featurematching directly	1
image similarity	1
well-defined centroids	1
highdimensional binary feature descriptors	1
lot of popularity	1
3 rd highest SSIM	1
depth map	1
illumination setting	1
relative error reduction of up to 21{\%}.	1
label and data bias	1
data bias and label bias	1
default labels	1
little or no overlap	1
emphasis onclustering features	1
theamount of supervised data	1
linguistically motivated features	1
standardshared task evaluation data	1
state of the art resultsacross five	1
various types of clustering features	1
clustering semi-supervised features	1
competitiveness	1
assigned weights	1
distribution of data	1
different distribution of data	1
varying performance	1
different specialization	1
data observations	1
linear or non-linear dependencies	1
task completion rate of over 90 %	1
n-best output	1
major improvements	1
grammar or lexicon	1
schema	1
logical forms or data base queries	1
reasonable coverage	1
accurate and e?cient	1
automatically extracted rules	1
structures of depth one or more	1
contextual and lexical information	1
decision tree	1
proper structure	1
completeness and depth	1
syntactic information e?ciently and reliably	1
state-of-the-art with less than 0.12 times parameters	1
less bias	1
left-handedness	1
right-handedness habit	1
spatiotemporal dependencies	1
advanced representation	1
sub-joint trajectory	1
joint trajectory	1
highest magnitude	1
intersection of race and gender	1
constituent minority identities	1
unique emergent biases	1
emergent intersectional biases	1
intersectional biases	1
variance of effect magnitudes	1
tested biases	1
magnitude of overall bias	1
sentence templates	1
pre-defined social and intersectional biases	1
dynamic word embeddings	1
English static word embeddings	1
statistical regularities	1
implicit human biases	1
higher sensitivity or robustness	1
high detection sensitivity	1
real-time micro-predictions	1
5 seconds	1
0.377 precision with 0.725 recall on test data	1
1\% of the data	1
Dota 2 gameplay features	1
five-second window	1
accurate death predictions	1
span of seconds	1
highly complex	1
massive amounts of telemetry data	1
outlier score	1
dependent variable	1
one of the regression problems	1
target variable	1
target class	1
50,000 triples	1
2-2.5 times	1
conjunction boundaries	1
syntactic relationships	1
higher precision	1
large problems	1
notion of sharing incentive	1
envy-freeness, strategy-proofness	1
Pareto optimality	1
small number of linear programs	1
allocations	1
Meta Types	1
Dominant Resource Fairness	1
meta-type	1
resource A \emph{or} B	1
1 unit	1
commute limitations	1
location constraints	1
subset of the total supply	1
Leontief utilities	1
heterogeneous demands	1
communication load	1
global feedback	1
limited amount of data	1
\url{https://st.qcri.org/demos/livetranslation}.	1
significantly better translations	1
third stage	1
queried target labels	1
second stage)	1
uncertainty and diversity criteria	1
first stage)	1
quite expensive and time-consuming	1
conditional shift problem	1
$i.e.$	1
conditional relations	1
marginal feature distributions	1
excellent empirical performances	1
transferable feature	1
syntactic , semantic , discourse , domain and heuristical knowledge	1
high as 97.6%	1
F score	1
high imbalance ratio	1
time series classification's performance	1
imbalance problem	1
poor class separability	1
Skewed distribution	1
achievescomparable or better performance	1
informativeness ofthe examples	1
amount of trainingexamples	1
amount of labeled training data	1
functional scope (e.g. further motor types	1
controller interlocking time	1
modular setup	1
Atari classics or Go	1
theJPEG-2000 codec	1
random, but properly regularized distributionsuffices	1
previous stage	1
test imagesduring	1
trainingset	1
true reflection	1
NIFTY 50	1
AIC criteria	1
final forecast	1
total of 729 model parameter combinations	1
20x more parameters	1
level of performance	1
four layers	1
exciting potential	1
topology static	1
existing designs	1
numeric operations	1
proof granularity	1
input representation	1
coefficient configurations	1
unique proof steps	1
fully simplified (i.e., in the normal form) polynomial	1
normal form	1
lexicographic order	1
sum of monomials	1
simple normal form	1
Transformers' abilities	1
multiple well-defined steps	1
comparable prediction results	1
crack-like features	1
labour cost	1
consistently appreciatedcontent	1
primitives of AAFcan	1
picture	1
95% Hausdorff distance (in millimeter) of 5.2176, 17.9697 and 13.4298	1
average Dice Similarity Coefficient (DSC) of 0.8828, 0.8433 and 0.8177	1
369 challenge training cases	1
low-level details	1
image segmentation challenge	1
uncertainty measures	1
patient overall survival (OS)	1
performance on test data	1
feature weights	1
2018 until 2021	1
visual quality scores	1
different standards	1
relevant and recommended versions of video quality metrics	1
generally accepted metrics	1
classical methods	1
scanning settings	1
training setting	1
superior image reconstruction performance	1
much less trainable parameters	1
one of the subproblems	1
intuitions and experience	1
traditional designs	1
wide range of biological relevant parameters	1
diffusion constant	1
Ribosome Transport model with Diffusion (RTD)	1
120% (goal progress)	1
16% (relative measure on success rate)	1
navigation policy	1
environment-agnostic representations	1
overfit training data	1
task of MDA	1
noisy source data	1
consistent data structure	1
Tensor-Low-Rank (TLR) constraint	1
high-order correlations	1
proposed baselines	1
thorough evaluation	1
little prior information	1
user listening and interaction behaviour	1
track metadata	1
approximately 3.7 million	1
listening sessions	1
160 million	1
Music Streaming Sessions Dataset (MSSD)	1
many important machine learning problems	1
past action proposals	1
action instances	1
1-shot classification accuracy	1
intracranial EEG (iEEG ) recordings	1
subject-invariant features	1
limited recordings	1
long labeled recordings	1
generated style	1
larger levels	1
arbitrarily sized	1
single example	1
p ~	1
competition, and results	1
challenge tracks	1
properly constrained	1
spherical motion assumption	1
large deviations	1
soft prior	1
efficient and robust	1
camera distortion	1
fundamental matrix	1
small baseline	1
accurate reconstructions	1
prior camera intrinsic calibration	1
accurate camera poses	1
trust, classification, big data	1
second level	1
high confidence or trust value	1
k trustful ones	1
two levels of decision	1
big data problem	1
huge amount number of features	1
relevant and non-redundant features	1
previously published results	1
nearly 5%absolute improvement	1
wordboundary tags	1
languageswhere word boundaries	1
$42.8\%$ positives and $6.3\%$ negatives	1
$1.4\%$ improvement	1
robust accuracy	1
$2.6\%$	1
empirical evidences	1
adversarial vulnerability	1
data and class representation	1
competitive detection and attribute recognition results	1
numerous attributes	1
fork	1
scales of gradients	1
number of attributes	1
aggregates attribute predictions	1
pedestrian attributes	1
realistic spatio-temporal features	1
promising abilities	1
initial human locomotion frames	1
4D human motion prediction	1
locomotion types	1
latent vectors	1
low error bound	1
motion captures	1
generalization and factorization abilities	1
single latent space vector	1
dense 3D shapes	1
temporal aspect	1
resulting fairness, flexibility, and efficiency	1
q-FFL	1
novel optimization objective	1
aggregate loss function	1
74.05 BLEU score and 86.25 Rogue-L score	1
ROUGE-1,2,L and BLEU	1
315000 question, factoid answer and full length answer triples	1
full length answer	1
conversational experience	1
unnatural reading experience	1
best model performances	1
substantial differences	1
human performances	1
5,109 passages	1
23,000 human-generated question-answer pairs	1
answering questions	1
single sense	1
Recent psycholinguistic evidence	1
necessary meaning differences	1
ground-truthspatial locations	1
increasing levels of detail	1
phrase category	1
Visual Search and Image-textco-reference resolution	1
document-level quality scores	1
reading comprehension test	1
absolute labels	1
time and budget constraints	1
missing labels	1
data errors	1
classification loss and image-question complementary (IQC) loss	1
similarity between visual and textual cross-modal features	1
answer accurately	1
accurate answer	1
non-asymptotic guarantees	1
unknown number	1
functional connection probabilities	1
theunknown smoothness	1
group memberships	1
class membershipsbetween two consecutive time points	1
functions of time	1
connection probabilities	1
particular stage	1
Early Modern period	1
various genres and publication dates	1
unseen historical data	1
average accuracy of 89.44{\%} and 83.16{\%}	1
gold standard Early Modern German data	1
lemmas, and POS tags	1
word tokens	1
various MNAR settings	1
pseudo-label assignment threshold	1
high-precision	1
low-recall	1
biased labeled data	1
predictability	1
different temporal dynamics	1
much weaker	1
trajectoryafter	1
six consecutive locations	1
discrete steps	1
spatialprocessing	1
visual signals and motion dynamics	1
fills-in' information	1
physical stimulus	1
Web crawled data	1
parallel training data	1
target customer data	1
average	1
word/structure distribution	1
general parallel data	1
communication efficient	1
FedAvg, +3.5% on FashionMNIST compared to FedProx, +8.4% on MNIST	1
+10.6% on	1
absolute test accuracy	1
efficiency of FlexCFL	1
convergence and complexity	1
balance between accuracy	1
training divergence	1
clients' optimization directions	1
divergences	1
distribution shifted training data	1
non-IID, imbalanced (statistical heterogeneity)	1
kinematics	1
continuous CV-labels	1
human-coded labels	1
accuracy of 82% and a Cohen's Kappa of 0.53	1
accuracy of 81% and a Cohen's Kappa of 0.49 for AU6	1
agreement	1
distal facial EMG and Computer Vision (CV)	1
exact source	1
EMG measurements	1
17 % improvement	1
featuresweresortedbytheirlearnedweights	1
predicate voices	1
functional words	1
words , semantic categories	1
various constraints	1
case roles	1
additional computation	1
Superior experimental results	1
proposed minimax loss	1
normalized inner product	1
Feature Redundancy Loss (FRL)	1
redundant features	1
feasible solution	1
regularization objective	1
Nash equilibria	1
minimax loss	1
uniqueness of the features	1
producing inter-class invariant features	1
high inter-class similarity	1
competitive detection performance	1
previously learned sound events	1
minimal training data	1
previously learned knowledge	1
previously learned ones	1
new sound events	1
data storage size and training and inference times	1
selected configurations	1
larger frame rates	1
input size	1
mel-spectrogram representations	1
similar robustness	1
2.43x speedup	1
excessive computing power	1
high perturbation values	1
testing data	1
visually imperceptible perturbations	1
short, noisy and colloquial nature	1
3.9 and 4.1 average improvement in F1 and EM	1
target dataset	1
task-level similarities	1
high-quality extractive reading comprehension datasets	1
large-scale high-quality ERC training data	1
effectiveness and generalization capabilities	1
subword frequency	1
highly correlated word and labels	1
in-domain performance	1
weak name regularity	1
real-world situations	1
reward hacking	1
unsafe states	1
different initial state distributions	1
value of information	1
tractable proxies	1
off-policy data	1
initial states	1
user's reward function	1
rewards and unsafe states	1
unknown unsafe states	1
unknown reward function	1
unknown dynamics	1
user's objectives	1
zero-shot translation performance	1
off-target translation occurrences	1
model gradients	1
thousands of sentence pairs	1
gradient level	1
decoder outputs	1
representation level	1
representation-level and gradient-level	1
collocations of V-N type	1
proposed features	1
V-N type	1
concepts of SoftRelation and Fuzzy Soft Relation	1
Rough SetTheory	1
impreciseness, uncertainty and vaguenessin data	1
numberDecision Making Problems	1
effectiveness, practicability, and scalability of EnsemFDet	1
real transaction data	1
diverse node sizes	1
number of returned suspicious nodes	1
relaxed constraints	1
imperfect textual input	1
error-free to erroneous text	1
high diversity and performances exceeding training data	1
high-performance regions	1
existing boundary	1
diversity and performances	1
domain of the training data	1
high-performance	1
performance measures	1
model size smaller than 500KB	1
accuracy of 96.7\%	1
accuracy of 81.9\%	1
ASC accuracy of 76.9\%	1
ten classes	1
anomalous time points	1
short term and long term dependencies	1
low dimensional embeddings	1
snapshot	1
spectrum of the Laplacian matrix	1
graph snapshots	1
attack efficacy	1
text quality	1
attack baselines	1
user's recent topical interests	1
target context	1
given target context	1
user's writing style	1
several key desirable properties	1
user posts	1
safety and integrity	1
competitivewith SVD	1
latent representation of words	1
item similarities	1
baseline policy	1
new policy	1
suboptimal rankings	1
optimal ranking	1
possible document rankings (i.e., actions)	1
F1: 0.3894 at submission time, F1: 0.4235 with later found parameters	1
spatial and sequential features	1
separate embeddings	1
network architecture and parameters	1
probabilistic parameterization	1
headword annotation	1
word history	1
ourparsing accuracy	1
new connections	1
syntactic structureof	1
extremely expensive	1
thesurrogate values estimates	1
policiesare	1
modest number of runs	1
domain perspective	1
resulting optimal policies	1
MDP policies	1
tradeoffs	1
space ofalternative policies	1
thehelp of popular machine translation and summarization evaluation metrics	1
well formed comprehensive story like summaries	1
corresponding latent representations	1
variable length	1
theincoherent input text	1
independent descriptions	1
originality and brevity	1
higherlevels of creativity	1
improvements in model performance	1
Mahalanobis distance metric	1
feature importances	1
High-dimensional prediction	1
instruction	1
thestructural prediction	1
thewhole target-side context	1
sequenceof complex structure	1
linear word sequence	1
word by word	1
three parameters	1
time and computational constraints	1
tuned parameters	1
identified optimal hyper-parameters	1
changing rhythms	1
high amplitude pseudo-periodic oscillations	1
qualitative observation	1
neural network's output power spectral peak	1
best combination of these parameters	1
'datapoint'	1
eight hyper-parameters	1
8 - 13 Hz rhythms	1
resting state alpha rhythm	1
summariesof the inferred labels	1
distant hop information	1
every propagation step	1
aspecific instantiation of HOPF	1
existing differentiable kernels	1
memorylimitations	1
larger hops	1
theattribute and label information	1
aggregatemulti-hop neighborhood information	1
multiple hops away	1
higher order	1
newly introduced entity types	1
entity lexicons	1
job titles	1
around 9{\%}.	1
pronunciation rules	1
audio recordings	1
assistance of graph labels	1
category of each node	1
proposed consensus loss	1
various possible settings of WSGC	1
additional labels	1
graph-level side information	1
edge connections	1
Bleu score metric	1
lemma-to-lemma translation probabilities	1
full parse	1
training data scarcity	1
low-resource conditions	1
quantity, quality	1
easily computable functions	1
Different synchronization measures	1
synchronization patterns	1
interictal,preictal, ictal and postictal states	1
brainwavesynchronization patterns	1
0.5--0.8\%	1
different types of syntactic information	1
sentential syntactic and semantic properties	1
https://youtube.com/user/kritiksoman)	1
limited annotated data	1
small and very small data annotation budgets	1
better and more robust performance	1
around 10 million	1
760,000 humangenerated questions	1
intelligence	1
intelligent	1
reduction of 8.2x and 3.9x in terms of computational cost and number of parameters	1
different accuracy-efficiency trade-offs	1
88.5% and 46.6%	1
level of heterogeneity	1
communication pattern	1
{\it communication efficient}	1
full batch and mini-batch local computation models	1
best possible optimization and communication complexity	1
provably fast	1
non-convex problems	1
problem structure	1
strong and unrealistic assumptions	1
identically independent distributed (i.i.d)	1
extremely efficient	1
scrubbing sensitive PHI data	1
RevOpiD shared task	1
past TREC evaluations	1
list question data	1
original answers	1
additional members	1
expected answer	1
previous unsupervised state-of-the-art results	1
true or not	1
negative sample	1
false negative ones	1
minor improvement or even performance drop	1
samples (negative samples	1
(positive samples)	1
anchor	1
augmented versions	1
dynamic number	1
BWE based word similarity	1
random solutions	1
non-accumulative linear degradation function	1
important patterns	1
low computational costs	1
meaningful representation	1
raw	1
available run-to-failure measurements	1
Remaining Useful Life (RUL) prediction	1
first evidence	1
specificcortical waveforms	1
alpha bandnetwork integration results	1
falling consequences	1
spectral power	1
overall activity	1
low to highfrequencies	1
Generalized spectral variation	1
perturbation epochs	1
pseudorandom binary stimulation phases	1
85 Hz	1
visual dependencyand functional dynamics	1
compensatory neuromuscularreactions	1
upright posture	1
afraction of trainable parameters	1
SSIM and mean absolute error (MAE) loss	1
trainablestructuring elements	1
series of erosion and dilation operators	1
problem (instance)specific	1
operator kernel	1
shape and size	1
varying level of experience	1
word similarities	1
prepared data	1
implementation details	1
comparable runtime	1
much smaller storage requirement	1
superior quantitative inference accuracy	1
un-controlled	1
maximum performance	1
fairly represented	1
Word Error Rate	1
perplexity numbers	1
hundreds of millions of parameters	1
parameter-efficient	1
much better perplexity scores	1
handful of extra parameters	1
small number of domain token embedding parameters	1
generic counterparts	1
diverse domains	1
complex models	1
-specific random historical effects	1
factor-specific historical effects	1
historical effects	1
data structure	1
EEG and EMG data	1
(EEG )	1
functional relationship	1
different psychophysiological measures	1
link	1
phonemic and graphemic information	1
underlying syllable structure	1
stably reproducible	1
individual variability	1
subject and group level	1
highest averaged accuracy, 93.056% and 88.57% (PhysioNet Dataset), 96.24% and 80.89% (High Gamma Dataset)	1
generalized features	1
decoding performance	1
network patterns	1
hidden syntactic feature vector	1
one million articles	1
number of novel numerical strategies	1
fidelity measure	1
Structural Similarity Index Measure (SSIM )	1
alternative visual quality measures	1
subjective judgement	1
Euclidean-based metrics	1
acceptable memory overhead	1
similaror better quality	1
computational demand	1
rise in popularity	1
amounts of three-dimensionalimages	1
ever-growing sizes	1
artistic, semantic and photo-realistic	1
input content	1
stylized output	1
favorable generalizability	1
various difficulty levels	1
low level	1
sub-policy	1
textual goals	1
set of subtasks	1
complexity and variety of training tasks	1
unintended negative consequences	1
volume of data	1
trust-sensor research results	1
HMI and human-machine trust relationship	1
least accurate predictions	1
large number of variables	1
EEG and GSR data	1
well, or better	1
levels of trust	1
psychophysiological sensors and measures	1
GGFI and FFMI	1
discriminative defects	1
lack of generalization ability	1
probability of optimization success	1
solution quality	1
better convergence properties	1
structural and semantic similarity	1
long runtimes	1
inefficient ANNs	1
ANN topologies and weights	1
suitable topology	1
label commonness	1
geometric guidance loss	1
target probabilistic labels	1
source ground-truth labels	1
proposed label space	1
high label-commonness	1
sample-level weighting	1
class-level and sample-level	1
subset of classes	1
system score	1
significant BLEU score improvement	1
subset of source tokens	1
dramatic improvements in performance	1
arbitrarily high-dimensional feature vectors	1
enhanced expressiveness	1
suitable regularization and initialization schemes	1
desired invariance	1
ordering of their indices	1
Tensor Ring	1
compact Tensor Train (TT) format	1
order of which	1
exponential computational and memory cost (Curse of Dimensionality	1
features (variables)	1
inherent ordering	1
valuable source knowledge	1
final gain	1
high relatedness	1
certain patterns	1
high-resource	1
valuable knowledge	1
accuracy of 91.5\% and 62.1\% on training and validation datasets	1
51.5\% for the training and 51.7\%	1
highest correlation	1
handcrafted image-based and radiomics features	1
spatial and temporal intra-tissue inhomogeneity	1
performance and special propertiesof	1
argument role labels	1
term occurrence pattern	1
document or a query	1
term weights	1
documentfor	1
relevance score	1
user-dependent and item-dependent biases	1
expected value	1
samples of latent factors	1
observations and parameters	1
prior constraint	1
regularization	1
extreme sparsity	1
item in that space	1
factor vectors	1
image and question embeddings	1
data sample level	1
problematic behavior	1
fast-changing landscape	1
lower dimensions	1
variety of fine-grained ways	1
activity types	1
forecasted motion	1
control parameters	1
various future possibilities	1
predicted future motion	1
power consumers' privacy	1
co-modeling capabilities	1
weighted averaging the parameters	1
local load data	1
local model parameters	1
potential risks	1
inadequate load data	1
massive load data	1
customer's power consumption patterns	1
suffix trees	1
space efficient representations	1
'}	1
efficient search functionality	1
extremely small memory or disk footprints	1
novel data structures	1
11-year span	1
evolving trends	1
high-level visual features	1
complex and evolvingvisual factors	1
past feedback	1
users' fashion-aware personalized rankingfunctions	1
evolution	1
preferences	1
thedimensions of people's preferences	1
few-shot ranking accuracy	1
target-domain ranking accuracy	1
synthetic weak data	1
large number of weak supervision signals	1
correct class label	1
triplet constraints	1
similarity relationships	1
image embeddings and class embeddings	1
distribution embeddings	1
semantic descriptions of classes	1
relational neighborhood samples	1
novel holistic knowledge	1
data and code publicly available	1
inter-sentences and intra-sentence relations	1
long contexts	1
discrete answer information	1
high-quality questions	1
five rounds	1
many pressing questions	1
prefrontal high-betacurrent density	1
anhedonia severity	1
significantnegative correlations	1
Prefrontal upper alpha current density changes	1
current source densities	1
alpha and high-beta current source densities	1
EEG source activities	1
EEG asymmetries	1
target measures	1
two fMRI andtwo EEG activity measures	1
antecedents/consequences	1
counterfactual statements	1
continuous low-dimensional representations	1
optimal number of clusters	1
best specification	1
continuous or non-continuous data	1
discriminant pieces of information	1
precise representation	1
conversational goals	1
discourse content	1
pragmatic information	1
ellipsis	1
thepatient private data	1
patientrelated informationbecome	1
descriptor of its contents	1
information s	1
near real-time	1
approximately 170ms	1
0.07%	1
average transmission latency of 110ms	1
data corruption	1
release 15)	1
full potential	1
data rates	1
extensive knowledge	1
NER objective	1
bilingual word embeddings (BWE{'}s)	1
output order	1
order loss	1
ordered output	1
every single word	1
relation triggers	1
several linguistic characteristics	1
similar content	1
legal and illegal text	1
magnitude	1
themissing link	1
retrieval services	1
common interests	1
research problems	1
value-added effects	1
partly overlapping	1
bibliometrics / scientometrics / informetrics	1
EXPTIME-completeand partial observability	1
full observability	1
finite interpretation	1
LTL synthesis isEXPTIME-complete	1
existing claims on complexity	1
finite rather than infinite traces	1
LTL formulasinterpreted	1
2EXPTIME-completeproblem	1
logicalspecification	1
correlation of 0.61, 7th	1
12th in overall performance	1
lexical similarity measures	1
dependency graph similarity and coverage features	1
word alignment-based similarity score	1
large hypergraphs	1
hyperedges in only a couple of minutes	1
high quality embeddings	1
15% in accuracy	1
non-binary relations	1
graph embeddings	1
kNN slightly outperformed SVM	1
roughly comparable	1
ODS F-score of .762	1
(ODS F-score of .815)	1
edge map	1
CNNs producesharp boundaries	1
Highly imbalancedcategories	1
intuitive impressions	1
long-tail relations	1
4.1% F1 on average	1
New York Times	1
large-scale textual information	1
semantically proximate relations	1
infrequent or evenunseen relation types	1
first-order andsecond-order entity proximities	1
meanings of relations	1
sufficient trainingdata	1
relation prototypesfrom	1
sufficient annotations	1
long-tail issue	1
entity relations	1
total time budget	1
number of models	1
low-dimensional feature vectors	1
hyperparameters)	1
underlying dialog structure	1
missing node values (desired answers)	1
underlying dialog structures	1
node with missing value	1
unknown graph structures (relations in dialog	1
partially observed nodes	1
underlying semantic dependencies	1
reasonable answer	1
corresponding shadow-free images and shadow masks	1
large set of synthetic shadow images	1
background color	1
global background color	1
implicit data	1
latent user-item and item-item relations	1
intrinsic characteristics	1
latent item-item relations	1
user-item relations	1
complex interests	1
time translations	1
naturalistic hand action speed of $~1\,$Hz	1
HemCNN's decoding capabilities	1
one order of magnitude faster	1
4.2 mm compared to 6.5 mm	1
average TRE	1
better target registration error (TRE)	1
best graph matches	1
vessels bifurcations compliance	1
organ's transformation	1
65 mm	1
intra-operative nonrigid deformations	1
different topology and shape	1
image modalities differences	1
limited details	1
pre-operative information	1
preoperative and intra-operative images	1
real MR images	1
better reconstructions results	1
subproblems	1
three simpler subproblems	1
original complex problem	1
tree sparsity	1
gradient sparsity	1
Wavelet sparsity	1
standard $K$-sparse data	1
$\mathcal{O}(K+K\log n)$	1
tree-sparse data	1
$\mathcal{O}(K+\log n)$	1
MR scanning time	1
small number of measurements	1
good quality	1
relation information	1
relation triples	1
different knowledge graphs (KGs)	1
accuracy of 89 %	1
dictionary and text data	1
best correction	1
spelling mistakes	1
LTL expression	1
language commands	1
95%	1
environment MDP	1
LTL specification	1
product Markov Decision Process (MDP)	1
different levels of abstractions	1
non-Markovian reward functions	1
types of commands	1
hierarchical abstractions	1
Abstract Markov Decision Processes (AMDPs)	1
before)	1
temporal language	1
word before	1
``floor''	1
spatial abstraction	1
second floor	1
citation network datasets	1
widely adopted social network datasets	1
labels of a specific task	1
valid adjacency matrix	1
sparsity constraint	1
data and tasks	1
directions, and minibatch sizes	1
update frequency	1
worse sample and communication complexities	1
similar trade-off curve	1
sample and communication complexities	1
local minibatch sizes	1
local update frequencies	1
trade-off curve	1
{\it near-optimal} sample and communication complexities	1
$\tilde{\mathcal{O}}(\epsilon^{-1})$ communication rounds	1
$\tilde{\mathcal{O}}(\epsilon^{-3/2})$ samples	1
WN's and the server's directions	1
desired solution	1
minimum number of samples	1
local update frequency	1
minibatch sizes	1
WNs' and the server's update directions	1
86.84% score	1
numerous application potentials	1
scratch on10-15x more	1
SLU performance	1
million sentences	1
generation quality	1
low-quality generated data	1
one-to-many mapping	1
input passage	1
motion-aware feature	1
good anomaly detection performance	1
several empirical results	1
linear time in the size of the data	1
certain conditions)	1
guarantee bounds on approximation errors	1
qualityof	1
empirical performance	1
Topic Signature	1
relevant word senses	1
TSWEB)	1
Topic Signatures	1
new and accurate semantic relations	1
current content	1
intrinsically robust	1
end-to-end performance	1
speech recognition performance	1
additive noise	1
varying levels	1
ungrammatical and ill-formed	1
effectiveness and soundness	1
tensor parameter	1
3-order tensor	1
proposed CDML	1
nonlinear geometries	1
general curved forms	1
cumulative arc length	1
traditional linear distance metric	1
intrinsic distances	1
underlying geometries	1
projected feature spaces	1
\emph{e.g.,}\ Euclidean distance)	1
fixed distance functions	1
pairwise distance	1
appropriate metric	1
three axes	1
stat-of-the-art performance	1
semantic composition	1
person, location, organization	1
predefined semantic types	1
human error rate	1
anapproximately 85 percent reduction	1
pathologist's AUC	1
whole slideimage classification AUC of 0.966 and a tumor localization score of 0.733.Combining	1
score of 0.7051	1
whole slide imageclassification	1
area underthe receiver operating curve (AUC) of 0.925	1
theconsidered search space	1
optimal and suboptimal solutions	1
finitetime	1
final equilibrium	1
solutions over time	1
ordered phase	1
oneentry (randomly chosen)	1
higherfitness	1
`partialimitation'	1
costfunction (e.g. the length of a path	1
number ofcities	1
famousproblem whose search space	1
90.01% on	1
69.9% of the F1 score	1
problem statements	1
widespread awareness	1
edge weight distributions	1
two assumptions	1
unweighted adjacency matrix	1
edge weight distribution matrix	1
sources of information	1
conditionally independent	1
subjects' apparent skin tone	1
age and gender annotations	1
likenesses	1
average of 15 videos	1
45,000 videos	1
age, genders, apparent skin tones and ambient lighting conditions	1
much improved performance	1
higher-resolution (15-minute) data	1
low-resolution (hourly) interval data	1
low-resolution data	1
much useful information	1
data whose resolution is lower than expected	1
High-resolution data	1
Outstanding performances	1
considerable performance improvement	1
semantic gaps	1
novel and diverse characteristics	1
latent topics	1
\url{https://github.com/v-mipeng/LexiconNER	1
fully labeled data	1
task loss	1
maximal weights	1
weights over various dimensions	1
nuanced relationship	1
memory inefficient	1
unified dimension	1
items, contextual information	1
motion capture data	1
benchmarksthat	1
scoring script	1
13 submitted results	1
degree of excitement and calm	1
pleasant and unpleasant (or positive and negative) feelings	1
real-value sentiment score	1
classical ACL	1
capabilities profiles	1
progress niches	1
task space	1
trivial or unfeasible	1
task sampling distribution	1
value of safety constraints	1
potential large discrepancy	1
costly or dangerous	1
long-term reward	1
1-shot and 5-shot defect segmentation settings	1
distinctive representations	1
segmentation loss	1
anomalous ones	1
sufficient normal (defect-free) training images	1
limited anomalous ones	1
severity of anomality	1
defect-free	1
learning NAC	1
baseline one	1
comparison results	1
comparison information	1
promising performance predictor	1
search efficiency and performance	1
inaccurate	1
validation performance	1
difficult task	1
reasonable GPU budgets	1
locality property	1
population diversity	1
individual performance	1
sufficient performance	1
uncertain empirical benefits	1
conceptual complexity	1
excessive bias	1
deeper layer of bias	1
overt bias indicators	1
occupational and personality stereotypes	1
asymmetrical gender markings	1
overt and covert gender bias	1
covert biases	1
overt indicators	1
20 nouns	1
\url{https://github.com/ShannonAI/fast-knn-nmt	1
standard NMT model	1
two times slower	1
$k$NN-MT	1
two-order faster	1
Fast $k$NN-MT	1
decoding efficiency	1
previously selected reference source tokens	1
target tokens	1
query token	1
significantly smaller datastore	1
two-order slower	1
datastore	1
significant performance boosts	1
Code, model and data	1
extreme motion	1
large structural variations	1
vast amount	1
structural and view-angle disparities	1
target video	1
source video	1
source and target video clips	1
three orthogonal factors of variation including motion, structure, and view-angle	1
invariance properties	1
heterogeneous knowledge	1
permutation-robust representations	1
two basis vectors	1
semantic similarity/dissimilarity	1
semantically similar or dissimilar	1
Domain Heterogeneity	1
Label Heterogeneity	1
two essential challenges	1
have	1
worldwide scale	1
another task (head pose estimation	1
<= 100 calibration samples	1
redirection distortions	1
gaze representations	1
redirection loss	1
redirection variable	1
input and target images	1
gaze representation difference	1
gaze annotations	1
low dimensional gaze representation	1
improvement of 5.7{\%}	1
rival discriminator	1
scarce annotated data	1
rich annotated data	1
offline ASR results	1
under-resourced conditions	1
system real-time capable	1
second decoding pass	1
amount of transferable knowledge	1
online performance	1
high cost and complexity	1
isolated preference	1
expressiveness and interpretability	1
latent preference factors	1
high-order relationships	1
clicks	1
user{'}s latent preference factors	1
high-order connectivity	1
news information	1
new interesting research paths	1
cross-lingual features	1
SRL annotations	1
complex temporal patterns	1
image super-resolution	1
optimal models	1
options	1
case frame information	1
known syntactic and semantic constraints	1
one interpretation	1
intended interpretation	1
shots	1
huge gap	1
multiple camera configurations	1
1.5 meters height, 90 degrees horizontal field of view (HFOV)	1
limitations of datasets	1
fixed camera configuration	1
natural language instructions and visual information	1
given malicious objective	1
adversarial faults	1
DNN model vulnerabilities	1
severe threat	1
hardware reprogramming flexibility	1
atleast two orders of magnitude faster	1
single imagessignificantly	1
unlimited possibilities	1
training stage	1
published literature	1
particular frame	1
single inputimage (a video frame	1
largequantities of unlabeled videos	1
practical point of view	1
FITBO inheritsthe performance	1
output space	1
fewer constraints	1
choice of kernels	1
often-prohibitive computationaloverhead	1
-of-the-art performance	1
calibrated continuous position uncertainties	1
multiple discrete traffic behaviors	1
multimodal probability distribution	1
lidar sensor data	1
lethal dangers	1
one time step	1
happiness difference	1
scalar happiness value	1
sensory data	1
long-range dependency problems	1
syntactic and semantic dependency graph information	1
research papers	1
huge rate	1
concept level	1
primary content	1
terms of F-measure	1
\textit{sample-imbalance} problem	1
detecting accuracy	1
\textit{task-specific},\textit{low}	1
\textit{singlescale} high level feature	1
\textit{only} $3\times3$ sliding-window feature	1
terms of PSNR and SSIM metrics	1
demosaicing andsuper-resolution	1
accumulation	1
artifactsintroduced	1
-resolution	1
resolution limitations	1
Boththese tasks	1
demosaicing and super-resolution	1
image reconstruction quality	1
human quality judgment	1
pre-trained CNN features	1
convolutional layers	1
frequency and orientation selectivity	1
orientation selectivity	1
contrast sensitivity	1
basic human visual perception characteristics	1
pre-trained deep CNN features	1
underlying reason	1
efficient representations	1
significant perceptual quality improvements	1
computation time drastically	1
F1 to 83.1 ( 5.1 point absolute improvement	1
F1 to 93.2 ( 1.5 point absolute improvement )	1
86.7 % ( 4.6 % absolute improvement )	1
MultiNLI accuracy	1
GLUE score to 80.5 % ( 7.7 % point absolute improvement )	1
one additional output layer	1
degree of modularity	1
MNIST with multiple attributes	1
stage and the degree	1
biasing factors	1
intermediate task	1
progression function	1
Different progression functions	1
task complexity	1
agent's performance and learning speed	1
Curriculum	1
event arguments roles	1
enhanced local information	1
much higher computation consumption	1
classification feature	1
58%	1
80.7%	1
F-Score	1
multimodal and error correction components	1
three types of realistic noise	1
unseen types	1
\textbf{30} FPS	1
ODS F-measure of \textbf{.806}	1
fast speed (\textbf{8} FPS	1
ODS F-measure of \textbf{.811}	1
\sArt results	1
rich convolutional features	1
useful convolutional features	1
multiscale and multi-level information	1
edges and object boundaries	1
various scales and aspect ratios	1
richer convolutional features (RCF)	1
adequatebut not fluent	1
good translations	1
fluent and adequate) output	1
errorful (disfluent or inadequate) output	1
notjust intrinsic quality	1
intrinsic quality	1
even higher task performance correlations	1
combination of measures	1
typologically driven language distance measures	1
previous standard isomorphism measures	1
language similarity scores	1
individual spectra	1
several isomorphism measures	1
four different tasks	1
monolingual embedding space similarity	1
monolingual embedding spaces	1
(dis)similarity	1
several issues	1
fair time	1
quantitative results	1
quantitative performance	1
SSIM and PSNR metrics	1
visually-plausible outputs	1
synthetic and real noise	1
file structure	1
8GB	1
3 days	1
author?s code	1
https://umbcvision.github.io/Universal-Litmus-Patterns/.	1
MNIST, CIFAR10, and Tiny-ImageNet	1
`clean' or `corrupted'	1
universal patterns	1
concept of Universal Litmus Patterns (ULPs)	1
trivial trick	1
high correlation (of 0.99)	1
cut-off mark	1
detection probability	1
existing IDS	1
defensive capabilities	1
improvement of 2.0 % in BLEU\/3 .5 % in TER -LRB- abs	1
2.3 % better	1
2.1 % better	1
NFQI's performance	1
group structure	1
shared structure	1
slightly different dynamics	1
unknown or noisy state dynamics	1
stochastic rewards	1
implicit bias	1
thezero-shot transfer problem	1
significant dropin performance	1
i.e. questions),and	1
theother (i.e. answers	1
i.e.questions)	1
input to output	1
open problems	1
hot sub-topic	1
human expertise	1
explanatory depth	1
explanation	1
external cultural expectations	1
beliefs and motivations	1
particular datum	1
individual decision	1
increased concern	1
inductive ZSL and inductive GZSL	1
close to human performance	1
15% more	1
high interannotator agreement	1
difficult argument annotations	1
corresponding stance	1
spans of tokens	1
task as Argument Unit Recognition and Classification (AURC)	1
fine-grained level of sequence labeling	1
sentence segmentation errors	1
Option Gain	1
user feedback	1
intended semantic queries	1
semantic queries	1
twist	1
Riemannian Geometry	1
point of reference	1
mistakes	1
unscientific history	1
Fairness & Justice, Humans & Tech, and Privacy	1
four key themes	1
State	1
https://github.com/ bonaventuredossou/ffr-v1	1
low-resourceness, diacritical, and tonal complexities	1
language barriers	1
narrative and representations of commonsense knowledge	1
narrative	1
story models	1
statistically significant difference	1
FBCSP by about 25%	1
cross-subject classification ability	1
cross-subject performance	1
cross-subject classification performance	1
subject-independent features	1
high intra-subject and cross-subject variability	1
poor SNR	1
subtle inferences	1
categorical label	1
probabilistic scale	1
subjective probability assessments	1
categorical labels	1
1.1% in MRR	1
1.4% in MAP	1
positive and negative answers	1
differentiable representations	1
semantic and syntactic similarity	1
factoid question	1
Syntactic similarities	1
explicitly learn features	1
large number of training examples	1
band power features	1
mental motor images	1
significantly smaller makespan	1
scheduling makespan	1
arbitrary many tails	1
one head	1
corresponding quotient graph	1
roughly equal size	1
given number	1
hypernodes	1
acyclic hypergraph partitioning problem	1
acyclicity constraint	1
efficient parallelizations	1
data flow and execution dependencies	1
complex high-dimensional data	1
computationally faster	1
various synthetic distributions	1
benchmark experiments	1
noise variance	1
obtained expression	1
higher-order derivatives	1
additional regularization terms	1
class of densities	1
model distribution	1
full space support	1
clear latent structures	1
low-labeled data regimes	1
thousands of recordings	1
contrastive predictive coding	1
limited access to labels	1
relatively shallow models	1
specialized expertise and human processing time	1
amount of labeled data	1
advantages and disadvantages on different test cases	1
various evaluations	1
high demand	1
official or unofficial splits	1
several previously reported results	1
actual state	1
accuracies of 97.0 % (ESC-10), 91.5 % (ESC-50) and 84.2 % / 85.4 % (US8K mono / stereo)	1
overall progression	1
discrepancy of how results	1
past successes	1
lot of progress	1
accuracy of 87.75%	1
toexponentially lower	1
various high dimensional robotics control problems	1
provided annotations	1
reliable spatio-temporal features	1
large temporal distances	1
robust appearance cues	1
suitable latent representation	1
required appearance invariances	1
neighboring frames	1
straight-forward spatio-temporal cues	1
sort of domain knowledge	1
high attack success rate over 93%	1
decision variables	1
sort	1
carefully manipulated adversarial examples	1
converging rates	1
higher saturating speed	1
equal performances	1
learned information	1
active features	1
significantimprovement in energy-efficiency	1
larger ones	1
small classification problems	1
feature information	1
classification hierarchy	1
tree of classifiers (nodes)	1
originalclassification problem	1
characteristic features(color/texture)	1
consensus	1
-scale problems	1
thecompute and energy requirement	1
outstanding image recognition orclassification performance	1
minimal increase in latency	1
6.2% relative WER reduction	1
personalized bias	1
latency impact	1
much better computational efficiency	1
comparable or better performance inclassification accuracy	1
intra-domain structures	1
limited or no labels	1
\textit{Target Shift}	1
re-weighted joint distribution	1
estimated joint distribution	1
domain invariant	1
label distribution	1
representation of the data	1
0.504 to 0.620	1
57 %	1
recall and precision of deep learning object detection outcomes	1
labor-intensive high-quality annotations	1
high-resolution whole slide images (WSI)	1
clinical and imaging phenotypes	1
hidden regularities	1
local consistency	1
spatially discounted correlation	1
extrapolated results	1
geometry supervision	1
curve boundary	1
wider FoV	1
blank area	1
coherent semantics	1
rectification results	1
radial distortion	1
obtained image	1
user answer	1
Dialogue context	1
input word-graph	1
compositional semantics	1
relation fact classification	1
relationfact ranking	1
i.e. confidence prediction	1
different learning objectives	1
precision of UKGE	1
uncertain relation facts	1
confidencescores	1
bothstructural and uncertainty information	1
natural characterization	1
confidencescore	1
relations facts	1
structured knowledge	1
deterministic Knowledge Graphs (KG)	1
interesting phenomenons	1
users' accuracy	1
VQA system's attention values	1
altered images	1
counterfactual images	1
mental model	1
training time by up to 40%	1
57%	1
overall training time	1
classic FL	1
changing network bandwidths	1
limited computational capabilities	1
FL efficient	1
growing concerns	1
86.8%)	1
20%)	1
significantimprovement over a simple baseline	1
F1 score of 51.0%	1
dependency and constituency trees	1
Signal-to-Distortion Ratio	1
real audio data	1
modeling domain	1
sparsity or low-rankness	1
clipped measurements	1
Dynamic range limitations	1
performance of the nUV measure	1
terms of AUC scores	1
4-13% increase	1
nUV measure	1
well known mutual information (MI)	1
particular problem	1
ideal binning	1
smooth non-linear distortions	1
strong morphological consistency	1
model's confidence	1
model's knowledge	1
noisy labeled data	1
discourse phenomena	1
sentence to document level translations	1
limited training samples	1
different compression ratios	1
privileged knowledge	1
EEG representations	1
parallel texts	1
translational equivalences	1
discontinuous constituents	1
feature constraints	1
recognized input string	1
different possible translational equivalences	1
reach	1
variety of challenging MAPF instances	1
thirty times	1
four orders of magnitude	1
pairwise colliding paths	1
specialized constraints	1
symmetries efficiently	1
unacceptable runtimes	1
space of possible collision resolutions	1
several classes of pairwise symmetries	1
target locations	1
pairwise symmetry	1
Anonymous URL	1
broad applicability of SCORE	1
structural context	1
contextual structural data	1
multi-turn dynamics	1
unstructured language utterance	1
formal language (e.g., SQL, SPARQL)	1
average Area Under the Curve (AUC) of 98.12% which is 1.62% higher than state-of-the-art (SOTA)	1
medical data	1
intelligent, reasonable, and human-like	1
VQAmodel uncertainty	1
thequestion is visual or not	1
capitalof Argentina	1
comprehensive summary of recent NER papers	1
(ReCoNLL, PLONER )	1
category relationships	1
lens of our proposed measures	1
generalization abilities	1
large body	1
achievestate-of-the-art data efficiency	1
long-termplanning	1
first-order optimality	1
expected long-term cost	1
control sequence	1
model errors	1
-term predictions	1
state space or control constraints	1
toobey limitations	1
automatic and human evaluation metrics	1
setting of discriminator	1
natural and human-written	1
perspectives of content and linguistic respectively	1
two specific attributes	1
real medical data	1
latent reward	1
appropriate policy	1
arbitrarily complicated state spaces	1
approximate posterior distribution	1
high stakes	1
small tabular setting	1
cross-modal querying performance	1
% and 69.40%	1
new baselines	1
97.15%	1
accuracies of 90.07% on the UrbanSound8K	1
quantitatively better results	1
SSIM of 0.893	1
Synthesizing target poses	1
associated textual mentions	1
unobserved facts	1
plausibility	1
syntactic textual relations	1
additional entity type information	1
support instances	1
incompatible feature embedding problem	1
large-scale labeled data	1
informative prior knowledge	1
question of which	1
different levels of local-global topology	1
timestep	1
consecutive snapshots	1
averaged number of changed edges	1
degree of changes	1
accuracy of 90.8%, sensitivity of 94.5%, and specificity of 86.0%	1
chest CT scans	1
considerably fewer parameters	1
diagnostic results	1
epidemic curve	1
implemented fairness	1
appropriate fairness definition	1
existing fairness metrics	1
hands-on guidance	1
ethical standards and legal requirements	1
appropriate fairness metric	1
specific situation	1
right kind	1
uniformly accepted notion of fairness	1
redirect links	1
entity surface forms	1
high-quality hash codes	1
supervised 'label information'	1
'label information'	1
somesupervised semantic 'label information'	1
range of evaluation measures	1
temporal dimension	1
error rate by more than 70%	1
much fewer number of parameters	1
different distribution shifts	1
synthetic OoD data losses	1
optimal architecture parameters	1
OoD data	1
generated OoD data	1
significant data -RRB-	1
discussion patterns	1
structural and lexical characteristics	1
' availability	1
work efficiency	1
LPIPS metric	1
LR to HR (SR task	1
other	1
LR images (degradation task)	1
means and variances	1
unpaired data	1
LR domain	1
HR domain	1
one domain to another domain	1
paired low resolution (LR) and high resolution	1
alternating phases	1
long-horizon	1
navigation problems	1
original action space	1
joint control signals (positions, velocities, torques)	1
$\href{https://github.com/lmb-freiburg/Multimodal-Future-Prediction}{\text{this https URL.}}$	1
multimodal distributions	1
good estimates	1
ground-truth distribution	1
predicted multimodal distributions	1
multiple modes	1
several samples	1
single hypothesis	1
future states	1
Gaussian prior representations	1
scoring function	1
additional approximation	1
parameterisable distributions	1
underlying probabilistic semantics	1
variational distributions	1
entities and relation types	1
intractable distribution	1
analytical approximation	1
society's estimate	1
harm	1
legal advice	1
court's preferences	1
two quantities	1
court's preferred measure	1
specific degree of unfairness	1
Legally Grounded Fairness Objectives (LGFO)	1
weighted combination of measures	1
intuitively desirable aspects	1
number of formally incompatible operational measures	1
maximum response and multiple check	1
maximum response	1
class-wise parameter values	1
one class of interest	1
$+1.9$ AP$^{\text{mk}}$ Cityscapes	1
$+1.1$ AP$^{\text{bb}}_{75}$ COCO	1
$+2.7$ AP$^{\text{bb}}_{75}$ VOC	1
localization and classification performance	1
spatially and semantically consistent feature representation	1
semantic image-level representations	1
regional representations	1
solely learning global representations	1
additional implemented features	1
practical choices	1
12 languages	1
production-readysystems	1
weeks	1
large number oftraining configurations	1
conditional distributions	1
Jensen-Shannon divergence	1
feature and its label	1
class-level discriminative features	1
target error	1
alternative upper bound	1
target error upper bound	1
ideal joint hypothesis error	1
matching marginal distributions	1
number of features by about 70 %	1
2 statistics	1
performance gain of about 1.1 -- 1.5 % absolute in word error rate	1
word n-gram features	1
factored morphological features	1
word ngrams features	1
state-of-the-art oncaption diversity	1
learning signal	1
interms of n-gram metrics	1
small number of additional model parameters	1
dialogue dynamics	1
semantic decoding and context modelling parts	1
original document	1
instance information	1
subset of relevant features	1
improvement rate of 20.8{\%}	1
Contextualized Word Embedding	1
unlabeled target domain data	1
compact and semantically meaningful contrastive samples	1
visualization results	1
topological heterogeneity	1
adequate augmentation variances	1
representative structures	1
probability distribution of graphs	1
original semantic structures	1
improvement in recognition rate	1
particular feature	1
different levels of weightsto	1
Research Laboratory (ORL)	1
different kinds of facial features	1
new SOTA result of 81.3%	1
global optimal	1
least 7.5x less samples	1
notable margins	1
state-of-the-art ImageNet performance	1
sampling space	1
top architectures	1
limited samples	1
architecture-performance pairs	1
heavy computation costs	1
average individual accuracies	1
single DNN	1
five benchmark datasets name-ly	1
final class labels	1
remaining samples	1
one-seventh of the data	1
architecture and intrinsic properties	1
new data instance	1
`` Umlautung ''	1
German morphology	1
well-known problem	1
non-concatenative morphology	1
morphonology and nonoconcatenative morphology	1
different problem instances	1
least-squarescost	1
novel Riemannian metric	1
anatomically plausible	1
overall geometric and clinical metrics	1
plausible ones	1
anatomically implausible results	1
close but correct shape	1
anatomically inaccurate cardiac shapes	1
large spectrum of valid cardiac shapes	1
smooth manifold	1
anatomically plausible results	1
anatomical plausibility	1
high levels of precision	1
GTEA\cite{li2015delving}	1
object similarity measurement	1
constituent steps	1
energy and computational efforts	1
early predictions	1
comparable accuracies	1
prediction speed	1
either binary or multiclass classification problems	1
minimal resources	1
less resources	1
fast predictions	1
learning rule	1
induced Riemannian distance	1
Riemannian natural metric (affine-invariant metric	1
poor results	1
non-Euclidean geometry	1
curved Riemannian manifold	1
global property	1
two folds	1
{\em TopoResNet-101}	1
{\em persistence statistics} (PS) and {\em persistence curves} (PC)	1
two families of topological features	1
persistent homology	1
Google Landmark Recognition and RetrievalChallenges 2021	1
much fairer coverage	1
contributors' demographic information	1
anonymized Google Maps user contribution statistics	1
relevances	1
fair relevance	1
fair worldwide representation	1
co-segmentation quality	1
conventional RGB videos	1
motion capture (i.e., 3D skeletal) data	1
generic problem formulation	1
different style	1
publicly available unlabeled auxiliary data	1
novel double distillation training objective	1
old classes and new classes)	1
much lower testing time	1
nearly 3 times smaller in size	1
high testing accuracy of 99%	1
current cybersecurity dataset (UNSW2015)	1
normal or attack-oriented	1
network packet behavior	1
excellent representation	1
meaningful pace	1
low power, memory and processing capabilities	1
ellipses	1
scopes	1
total dependency structure	1
shorter form	1
conjunctive structure	1
left and the right	1
subtle , similarity	1
structural ambiguity	1
stateof - the - art results	1
letterlevel patterns	1
three times of the sentence length	1
maximal length	1
forest structure	1
constituent	1
mentions recursively	1
possible semantic roles	1
predicate semantics	1
given predicate	1
candidate senses	1
two subtasks	1
predicate-argument structure	1
efficiency by 45.9%	1
small computational budgets	1
state-of-the-art trade-offs between performance	1
various tasks and computation resources	1
optimal architectures	1
multiple feature resolutions	1
computation budgets	1
multiscale image contexts	1
searching strategy	1
multiscale contextual information	1
segmentation, detection, and pose estimation	1
High-resolution representations (HR)	1
average of 72.3% accuracy (SD 0.038)	1
4.5%	1
98.5% accuracy	1
5-point Likert scale	1
real-world wellbeing	1
step 1	1
size of the training data	1
emotional trajectories	1
Time series data	1
series of baselines	1
12 challenge attributes	1
4 scenario attributes	1
different attributes	1
730K bounding boxes	1
600K frames	1
total of 1,400 TIR sequences	1
specific burst	1
ground truth RGB data	1
real RAW images	1
ground truth data	1
high quality RGB images	1
\url{https://github.com/taohan10200/IIM}.	1
loss on binary predictions and labels	1
instance more accurately	1
threshold map	1
structured instance maps	1
centers and the number of components	1
crowd counts	1
non-overlapped	1
instance in IIM	1
density maps	1
coarse prediction	1
head's position	1
relevance of responses	1
presenthuman-like responses	1
convolutional deepstructured semantic neural network-based features	1
agent's trajectories	1
conditional distribution	1
substantial density	1
given trajectory	1
estimating density	1
posterior modes	1
given intent	1
turn right or move forward	1
said variance	1
situation	1
possible agent's future behavior	1
motion prediction problem	1
comfort	1
overall safety	1
71X and 25X energy efficiency improvement	1
3X and 31X frame rate improvement	1
original ORB descriptor pattern	1
high perceptual quality	1
low image-domain distortion	1
similar bit-rates	1
different points of the perception-distortion curve	1
MSE, MS-SSIM	1
different losses: a) MSE, b) MSE and MSSSIM	1
reconstructed image (code-domain distortion	1
encoder outputs	1
cycle loss term	1
low entropy	1
reconstruction losses	1
encoder output	1
two objective terms	1
word alignment	1
combination of both IBM4alignments	1
3 different language pairs	1
23rd position	1
13th among 15	1
faithful stylization	1
significantly better quality	1
detailed styles	1
significant drawbacks	1
inability	1
normal data	1
multiple pyramid levels	1
normal class	1
majority of the data	1
local phonetic and distant semantic features	1
final MinDCF and EER of 0.065 and 1.45% respectively	1
maximum expected imposter mean score	1
AAM-softmax speaker prototypes	1
enrollment data	1
domain-level	1
speaker prototypes	1
speaker distances	1
varying phonetic overlap	1
large degree	1
latent dimension	1
different random initializations	1
object representations	1
(empirical) human choice probabilities	1
variety of criteria	1
embedding value	1
object concept embeddings	1
naturalistic data	1
vehicularGPS information	1
effectivelyextract vehicle encounters	1
primary driving scenarios	1
primary vehicle encounter category	1
effectiveness and safety	1
~10x (e.g. ~256 2x2 TPUv2 x days / 20,000 GPU x hour -> 2,000 GPU x hour for MNAS	1
half of the searching time	1
simply designed off-policy correction factor	1
strict fairness	1
100% hitting ratio	1
block similarity function	1
searching time by 2 times	1
searching time by 4 times	1
architecture knowledge	1
different experiments	1
sampled generation	1
huge computational resources	1
better convergence	1
disentangling structure and appearance space	1
sketch features	1
structure features and appearance features	1
additional appearance information	1
test categories	1
label semantics	1
semantic role labeling (CoNLL-2005 and CoNLL-2012	1
task-relevant information	1
nested named entity recognition	1
25 % error reduction	1
overall Fa5 of 86.07 % on the English test data -LRB- 92.31 % on the development data -RRB-	1
substantially richer context features	1
minimal context information	1
named entity types	1
degree, betweenness, structured relation type(s)	1
triple	1
given document	1
linear in complexitywhen	1
discretized problem dimensionalityexponentially	1
thediscretization of the action space	1
continuous action space domain	1
compared baselines	1
duration over 1,000 hours	1
temporalstructures of videos	1
present	1
throughput per Watt	1
power consumption by 62.7\%	1
sufficient battery lifetime	1
human intention recognition accuracy	1
prominent results in terms of accuracy	1
Experimental Philosophy	1
mixed	1
Scientific Prediction	1
high-order interactions	1
tensorswith 2^160 entries	1
number of underlying parameters	1
factorized format called TensorTrain (TT)	1
anexponentially large tensor of parameters	1
training and processing time	1
improved accuracies	1
communication volume	1
much better scalability	1
small problem instances	1
close approximation of the optimal solution	1
constrainedversion	1
NP-complete problem	1
execution dependencies	1
computed metrics	1
several degrees of class entanglement	1
labeled neighboring points	1
votes	1
ML stage	1
filters and topological descriptors	1
topological information	1
substantial part	1
anomalous' input	1
users' profile information	1
trustworthy meta-information (e.g. age and gender)	1
scoring accuracy	1
input\/output pairs	1
likely sentence	1
task 's search space	1
terminal symbols	1
noisy phoneme sequence	1
data splits, metrics, and benchmark results	1
practical motivation, technical background	1
original work	1
scales much higher	1
stop-words	1
POS patterns	1
CoNLL-2003 and over 10%	1
2% in F-score	1
aver-agely	1
gold path	1
smaller feasible re-gion	1
learn-ing ability	1
gold path (ground truthlabel sequence)	1
thenumerous possible paths	1
every possible label	1
equiva-lently multi-labeled	1
unlabeled tokens	1
la-beled	1
comprehen-sive knowledge	1
ac-cessible data	1
large amountsof fully annotated training data	1
https://github.com/cruvadom/Logit Separation	1
new batch losses	1
number of classesis 400,000	1
speedup	1
binaryclassification accuracy	1
fast SLC	1
least 20% relative accuracy improvement	1
principle	1
novel batchloss functions	1
Principle of LogitSeparation	1
output logit forthis class	1
theclass of interest	1
specific class	1
overall areaunder the ROC curve of 0.89	1
less than 1ms withhigh recall	1
motion artefacts	1
synthetic artefact severity	1
relatively low number	1
high number ofgood quality images	1
health problemscreates	1
cross-sectionalpopulation data	1
high-quality imaging	1
poor quality CMR images	1
Good quality	1
entity-aware representations	1
first (or the second) entity	1
complicated assumptionson the density	1
bandwidthnorm, bandwidth determinant and density smoothness	1
explicit constants	1
rigorous derivation of bounds	1
even bounded	1
sufficient decay	1
\emph{magnitudes of bandwidth eigenvalues};in	1
certain balancebetween the \emph{kernel decay}	1
arbitraryinvertible matrix	1
missimportant but subtle points	1
simplified or overly conservative assumptions	1
truedensity	1
adensity function	1
low variance	1
sides	1
control variates	1
imaginary cumulative rewards	1
imaginary rollouts	1
real trajectories	1
accurate global models	1
many on-policy samples	1
6.79% relative	1
relative reduction	1
OOV issue	1
Attention CTC	1
remaining words	1
hard alignment issue	1
context weighted inputs	1
current input	1
current output	1
improvements in translation quality	1
30 billion	1
-LRB- -RRB- 1 million words	1
large vocabularies	1
improved efficiency	1
equivalence classes	1
mean Perceptual Evaluation of Speech Quality (PESQ)	1
signal-to-noise ratios (SNR)	1
speech enhancement performance	1
spectrum in the graph Fourier domain	1
set of shift operators	1
terms of representation capacity	1
latent hierarchies	1
Poincar\'e embeddingsoutperform Euclidean embeddings	1
parsimoniousrepresentations of symbolic data	1
theunderlying hyperbolic geometry	1
n-dimensional Poincar\'e ball	1
hyperbolicspace --	1
symbolic data	1
current bounding boxand the ground truth box	1
current bounding box	1
full image	1
terms of performance and computational resources	1
naturallanguage based text description	1
?fixed combination	1
good and more robust results	1
static, predetermined query functions	1
querying uncertain, anomalous and randomly selected observations	1
uncertainty score and anomaly score	1
suitable each observation	1
resulting query observations	1
overall classi?cation performance	1
network connections	1
large amounts of effort	1
15, '16, '17 and '20 Challenges	1
appearance and geometry	1
ROC-AUC metric	1
score of 0.9378	1
asymptotically unbiased prediction	1
various noises (or perturbations	1
pre-defined constraints	1
certain types of noise	1
regular input	1
practical success	1
original matrix \textbf{Y}.	1
feature matrix \textbf{A} and weight matrix \textbf{X}	1
highestaverage overall accuracy	1
72.85% for AMRITA_CEN)	1
average overall accuracy of 70.65%	1
76.79%for IIITH and 75.79% for AMRITA_CEN	1
75.60% which	1
average overall accuracy (averaged over all three languagepairs	1
observation probabilitiesof	1
word level features	1
many of the search space dimensions	1
similar accuracies	1
heuristics or empirical intuition	1
graph domain	1
type of data	1
absolute order	1
relational information	1
3D ground truth	1
0.8+	1
cross-correlation	1
SSIM of 0.7+	1
1 to 4	1
full volumetric anatomy representations	1
underlying 3D information	1
human anatomy	1
prior knowledge (or mental maps)	1
high-resolution volumetric images	1
Real-world settings	1
best supervised results	1
59 % accuracy	1
standard form	1
user-friendly experience	1
number of tuials	1
information transfer rate	1
experinental results	1
steady state visual evoked potential (SSVEP) uuder data-linited condition	1
days	1
Average Query Weighted Value (AQWV) scores	1
GIZA translation tables	1
summary form	1
query in English	1
complementary mask supervision	1
trident mask branches	1
large varying scales	1
background noise's interference	1
pixel-level masks	1
network coefficients	1
reduced-dimensional space	1
one validation	1
binary crossentropy and categorical crossentropy	1
rise	1
comments, reviews	1
- statuses	1
theincreasing amount of textual data	1
sound analysis of the results	1
various combinations and permutations	1
available vector space representations	1
news instances	1
goodwill	1
either of them separately	1
person re-id performance	1
jointpooling in both dimensions	1
informative frames	1
quantum states	1
input-dimension	1
task overfitting	1
STP graphs' structures	1
personalized user preferences	1
independent user visit sequences	1
local view	1
POI-POI relationships	1
preposition	1
locative PPs	1
characteristic feature	1
image retrieval results	1
initial query	1
image retrieval performance	1
Geometric Moment	1
Global Color Histogram	1
Local Color Histogram	1
Average RGB, Color Moments	1
texture, color, intensity and shape	1
image descriptors	1
unique descriptors	1
similar challenges	1
several types of small features	1
EoE disease activity	1
accuracy of 94.8%, sensitivity of 94.3%, and specificity of 95.14%	1
accuracy of 98.5%	1
mean absolute error of 0.611 eosinophils	1
mean intersection over union (mIoU) of 0.93	1
4345 images	1
100M pixels	1
concentration	1
elevated numbers	1
Product of Experts (PoE) framework	1
respective uncertainties)	1
near state-of-the-art performance	1
annotated question pairs, (Qgiven, [Qpast, Answer]	1
knowledge base information	1
relevant past resolved questions	1
entity name variations	1
{``}Manchester United{''}	1
{``}Reds{''}	1
shared need	1
Reds?{''}	1
unanswered question	1
number of unanswered questions	1
significant percentage	1
various categories	1
8-bit baseline	1
area by 26%	1
near-full-precision accuracy	1
8-bit activations	1
37% area saving and 24% energy saving	1
per-vector scaling support	1
area and energy overheads	1
low precision	1
better inference accuracy	1
per-vector scaling	1
low-bitwidth integers	1
per-vector scale factors	1
single dimension	1
small vector of ($\approx$16-64) elements	1
separate scale factor	1
quantization-related accuracy loss	1
individual elements	1
effective precision	1
many dimensions	1
coarse granularity	1
precision too aggressively	1
Excessive quantization	1
low-bitwidth integer values	1
floating-point weights	1
model memory footprint	1
game score improves from 0.1 to 0.6	1
success improves from 1% to 25%)	1
PointGoal Navigation (SPL improves from 0 to 64)	1
realistic tasks	1
n't scale	1
game score drops from 0.6 to 0.1	1
three-agent Google Football-based 3 vs. 1	1
success drops from 58% to 1%)	1
SPL drops from 55 to 0)	1
present-day Embodied AI results	1
shaped rewards	1
carefully shaped rewards	1
great successes	1
physiological correlates	1
lungs' diffusing capacity	1
small-vessel blood volume	1
two well-known measures	1
value of the Pi10 parameter	1
percentage of the predicted forced expiratory volume in one second (FEV1\%)	1
accuracy of CNR	1
relative error	1
known ground-truth	1
vessel radius	1
airway wall thickness	1
airway lumen	1
cross-sectional measurement	1
arterial and venous changes	1
increased airflow resistance	1
dual constraints	1
-oriented latent representations	1
pose-adjusted glimpsesis	1
pairwise joint kernel measures covariance alonginputs and across different latent signals	1
load signatures	1
multiple electrical parameters	1
appliance information	1
missing of ground-truth data	1
insufficiencyof electrical parameters	1
related information	1
open data	1
prediction power	1
verb `` take ''	1
attribute optimally	1
different ideas	1
high morphological heterogeneity	1
offline distribution	1
partial coverage condition	1
reward-free exploration step-by-step forward in time	1
$\gamma$ being the discounted factor	1
$A$	1
rank of the transition matrix (or dimension of the ground truth representation	1
$d$	1
A^4 d^4 / (\epsilon^2 (1-\gamma)^{2})	1
sample complexity from $\widetilde{O}( A^9 d^7 / (\epsilon^{10} (1-\gamma)^{22}))$ for FLAMBE to $\widetilde{O}	1
low-rank MDPs	1
linear MDPs)	1
low-rank transition matrix	1
sample efficient manner	1
suspiciousness rankings	1
memory bugs	1
bug type	1
major resource factor	1
real-worldconversational search scenarios	1
exploratory capabilities	1
available Linked Data	1
wealth	1
advanced, expressive,and engaging user requests	1
Semantic Web and Information Retrieval domains	1
related challenges	1
outstanding superiority	1
optimized features	1
EEG pattern features	1
subclass relationship	1
subclass a unique label	1
intrinsic distribution structure	1
suboptimal decoding accuracy	1
true EEG sample distribution	1
underlying data structure	1
better decoding accuracy	1
strong seq2seq baselines	1
output text	1
fast at inference time	1
higher position	1
better and more robust contextual representation	1
real input noise	1
computation time and performance	1
Capacitated Vehicle Routing	1
negative effects	1
arbitrary changes	1
MDP	1
problem parameters	1
distributional knowledge	1
jobs in scheduling problems	1
combinatorial problem	1
combinatorial problems	1
range of few points	1
TDA features	1
5\%	1
conventional features	1
exclusive information	1
different distance resolutions	1
different blocks	1
TF-IDF vectors	1
high dimensional time series	1
word embedding space	1
word embeddings and TF-IDF vectors	1
underlying representations	1
conceptual spaces	1
numeric data	1
consistent accuracy improvements	1
certain characterized patterns	1
unintended propensity	1
so-called ``shortcuts	1
easy or hard	1
epistemic uncertainty minimization	1
current Cartesian Position	1
desired movement dynamics	1
physical capabilities	1
end-effector movement, orientation, and gripper width	1
slightly flawed	1
certain solutions	1
number of geometric properties	1
original factors	1
recovered (compressed) factors	1
original high-dimensional factors	1
low-rank matrix or tensor factorizations	1
latent language knowledge	1
diverse data	1
expensive cost	1
terms of PSNR, SSIM and visual quality	1
image edges	1
linear-rate convergence rate	1
parameters of Tikhonov and TV regularization terms	1
residual noise	1
small parameter sharpens edge	1
larger parameter of regularization item	1
spatially fixed parameter	1
similar compression ratio	1
1.02 million	1
best deletion	1
average Perplexity	1
previous one	1
coherent subsequence	1
intermediate sequence	1
arbitrary sentence	1
different style requirements	1
syntactic labels	1
high success rate	1
appropriate stopping point	1
appropriate stopping criterion	1
training episodes	1
Differential Entropy of Q-tables (DE-QT)	1
cumulative reward	1
non-transparent	1
reduction in performance	1
accuracy and labeling cost	1
relaxed queries	1
new criteria	1
binary question	1
predicted labels	1
labeling efficiency	1
desirable performance gain	1
optimization methods	1
informative sparse samples	1
faster adaptation speed	1
specific types	1
extended task	1
Visual Object Tracking (VOT)	1
selected clauses	1
noisy clauses	1
aspect sentiment	1
transparency w.r.t	1
attacker's and service provider's distributions	1
best guess	1
query results	1
200,000	1
degree of similarity	1
paired terms	1
-LRB- correctly or erroneously -RRB-	1
row	1
confusion matrices	1
predicted and hypothesis embedding	1
target domain sample	1
hypothesis embedding	1
target domain prediction	1
locally linear representation	1
gaze space	1
gaze directions	1
linear relationship	1
inter-personal diversity	1
subject-independent gaze estimation error	1
inter-personal difference	1
imperceptibility and nonspecificity	1
abstract meaning	1
adequate evidences	1
exactly one of the categories	1
different categoriesfrom	1
single and ensemble settings	1
better parameters	1
highest confidence score	1
certain answer	1
multi-choice	1
task specific	1
given passage and question	1
set of options	1
unit	1
propagated errors	1
0.25 (1.95{\%}	1
word based translation accuracy	1
77.4{\%}	1
12.83 BLEU score	1
76.4{\%}	1
6.29 BLEU score	1
CIDEr evaluation metric	1
higher sentence lengths	1
15 words	1
sentences of smaller length	1
limited performance gains	1
increase in network depth	1
length of sentences	1
Network complexity	1
8.3 to 1.4 BLEU points	1
audio content (pauses)	1
actual, more realistic testing conditions	1
ideal, sentence-like segmentation	1
manually segmented data	1
efficient computation	1
Real-world measurement noise	1
seed	1
small seed	1
many hardware constraints	1
approximate distance	1
day-to-day chores	1
daily routines	1
lot of problems	1
-LRB- c	1
F 1 score of 91.73	1
new state - of - the - art F1 score of 87.95	1
carefully handcrafted features	1
region representation	1
nearly linear complexity	1
high subsequence enumeration complexity	1
efficiency and effectiveness challenge	1
macro averaged F-1 of 74.7{\%}.	1
third place out of 8	1
macro averaged F-1 of 74.6{\%}.	1
third place out of 6	1
new baseline translation results	1
9.58 vs. 21.80 BLEU-4 Score	1
state-of-the-art sign language recognition and translation results	1
recognition and translation performances	1
ground-truth timing information	1
recognition and translation problems	1
gloss level tokenization	1
individual signs	1
lower model complexity	1
final classification decision	1
importance of each channel	1
Satellite Image Time Series (SITS)	1
complexity indicators	1
high noise levels	1
scope of the problem	1
noisy (corrupted) labels	1
generalization and robustness	1
7.2 points in the F1	1
ten NE classes	1
7.9 points in the F1-scorefor the total scenario	1
samehyperparameters	1
word-leveland character-level representations (embeddings)	1
automatically learned features	1
end-to-end system performance	1
Actual Query Weighted Value	1
detection metric	1
corresponding binary relevance judgments	1
queries of several types	1
limited amounts of annotated training data	1
representingannotator-generic and -specific information	1
noisysequence labels	1
lower cost in a short time	1
agreement and contrast	1
meta-relations	1
assigned ranks	1
set of numerical scores	1
fewer ambiguities	1
background labels	1
spatially adjacent	1
refined instance classifiers	1
object detection problem	1
image-level annotationsto	1
HR disparity	1
finer SR result	1
HR features	1
HR representations	1
stereo image super-resolution and disparity estimation	1
richer details	1
high-resolution (HR) features	1
SR performance	1
result of each problem	1
stereo settings	1
sequence of reweighted Rayleighquotients (IRRQ)	1
problem of computing Piecewise Flat Embeddings (PFE)for one particular index value	1
notion thatall partitions	1
Cut costs	1
family of Compassionately Conservative Balanced (CCB)	1
balanced cut costs	1
weakly connected	1
lower values	1
offline and online settings	1
limiting distribution-free behavior	1
recent theoretical advances	1
Time Series Segment Clustering (TSSC)	1
sense homogeneous	1
three effective feature alignment losses	1
feature selection vector	1
part of the features	1
issue of partialness	1
default setting	1
identical label space	1
consistent key feature representations	1
EmbedKGQA{'}s effectiveness	1
sub-optimal constraint	1
sparse KGs	1
multi-hop KGQA	1
right answer	1
Answering over KG	1
typed edges	1
medical health records	1
manual effort	1
domain expert time	1
100% of the available training data	1
50% of available training data	1
F1 score of model (0.734)	1
time to annotate data	1
effective increase in performance	1
limited amount of EHR training data	1
discrete curriculum	1
random training sequence	1
ASR performance metrics	1
level of difficulty	1
training sequence	1
low data scenarios	1
terms of accuracy and time	1
positive and negative polarities	1
fine-grained morpho-syntax labels	1
interpretable operation labels	1
important associations	1
operation representations	1
word token	1
frequent adjacent operations	1
space of valid operations	1
character by character	1
whole word form	1
linear kernel	1
convolution properties	1
predicate argument information	1
blockchain agnostic	1
simple smart contracts	1
heavy reductions	1
peer consistency	1
1-hot label predictions	1
heavily compressed 1-bit soft-labels	1
imbalance of power	1
mere soft-labels	1
long utterances	1
pattern compositions	1
basic graph patterns	1
certain level of abstraction	1
billions of statements	1
low-quality deepfakes	1
86.97% accuracy	1
source domain data	1
new types of deepfake	1
new types of deepfakes	1
improvement of 19.9 F-measure points	1
news data	1
35.3 F-measure points	1
relative effectiveness	1
large gazetteers	1
inconsistent capitalization	1
brevity of expressions	1
many complications	1
baseline performances	1
large Knowledge Graphs (KG)	1
24K images	1
18K	1
word's morphology	1
significantly greater performance	1
KGCP	1
integrated summary	1
defined settings	1
different source document formats	1
unstructured information	1
subjective information	1
true casing and punctuation normalization phase	1
varioussystem and data preparations	1
Various elements	1
dependency path embeddings	1
linear space	1
various vector space embeddings	1
linear representation	1
ROUGE 's	1
final transfer performance	1
parallel corpus size	1
extra discussions	1
competitive F1 scores	1
weights in the opposite direction	1
modified loss function	1
whose accuracy	1
PSNR and SSIM	1
superior FID	1
desired attributes	1
tailored losses	1
perceptual structure, appearance, and style	1
three attributes	1
missing hair structure details	1
hair structure differences	1
generated outputs	1
several automated metrics	1
non-conversational QA data	1
new information (the answer)	1
previously gathered information	1
high classification accuracy	1
feature dimension	1
Classification accuracy	1
RC data	1
real timeperformance	1
raw depth data	1
4	1
dimension of embedding	1
94.89% and 92.79% in metric Hits@1	1
efficient model TransE.	1
known facts	1
fewer assumptions	1
NVF orDQ	1
perceptually-masked image quality metrics	1
mean square error (MSE)	1
covariance term	1
specifically anti/symmetric SSIM derivedNVF	1
termDissimilarity Quotient (DQ)	1
NVF	1
normalisederror or noise visibility function (NVF)	1
human observer scores	1
near linearcorrelation	1
intrinsic quadratic nature	1
difference of variances	1
previously enigmaticstructural covariance	1
contrast orvisibility function	1
real underlying simplicity	1
three heuristic factors	1
Structural Similarity Index (SSIM )	1
PSNR of 52.11 and a SSIM of 0.9969	1
model generalization and performance	1
one model	1
different Bayer patterns	1
various Bayer patterns	1
baseline generic LM	1
perplexity reduction of 14.23 % compared	1
enhanced sentence representations	1
results on par or better	1
sentence context information	1
lacking orthographic standards	1
additionalaspect (iii)	1
lemmatization performance	1
token-lemma ambiguities	1
visual feature saturation	1
key frames	1
CTC loss	1
discriminative power	1
short-term and long-term information	1
efficient visual and contextual information	1
optimized visual features	1
chain rules	1
Connectionist Temporal Classification (CTC) loss	1
long-temporal information	1
spatial and short-temporal information	1
runtime measures	1
3 seed initializations	1
cell architecture	1
NAS-Bench-101, NAS-Bench-201	1
search turnaround time	1
computational problem	1
neural architecture variations	1
high quality speech data	1
tens of thousand hours	1
prediction accuracies	1
giant strides	1
less than ten minutes	1
one seizure	1
days of EEG recordings	1
change-points	1
significant number	1
sensitivity and specificity	1
considerable number	1
prudent attitude	1
rigor	1
trials and errors	1
unjustified and immature results	1
elephant bite	1
mathematical rigor)-exist	1
programming capabilities	1
two basic subfields	1
one theory	1
medical imaging	1
Automatic Target Recognition (ATR)	1
limited number of observations	1
EQA accuracy	1
3.6% (48.59% vs 44.98%)	1
4.2% (68.99% vs 64.73%)	1
much additional computational cost	1
guide of extracted semantic features	1
local semantic features	1
complicated vision conditions	1
local details	1
answering and navigation accuracy	1
research interests	1
user's questions	1
time-consuming measures	1
Degree centrality	1
effectiveness of each centrality measure	1
entity popularitymethod	1
Degree, HITS, PageRank, Betweenness andCloseness	1
overlapped speech segment proposals	1
equivalence bound of Cohen's $d=0.3$.	1
large scale (125 participants	1
Super-Resolution : SSIM: $0.06-0.08$ and PSNR: $1.43-4.46$.	1
Monet-to-Photo: FID $3.57-4.40$	1
FID $13.36-68.66	1
following ranges	1
differences between $F_V$ and $F_A$	1
Super-Resolution (super resolution)	1
three different instances	1
intended image translation task	1
$F_V$'s architecture	1
comparable functionality	1
inference APIs	1
acquired meta-knowledge	1
base-level	1
performance faster	1
fewer data	1
situation types and idiosyncrasies	1
word sense-specific idiosyncrasies	1
situation types	1
mapping information	1
i.e. semantic concepts	1
core meaning	1
CoNLL format	1
NER labeling	1
document-level	1
open challenges	1
latest research trends	1
existing surveys	1
new heights	1
advanced performance	1
amount of research literature	1
entities and the semantic relations	1
thebenefits and limitations	1
specializedsolution	1
andEntity Resolution (ER)	1
word specificity	1
distribution information	1
semantic-related features	1
potential meanings	1
specificity information	1
NER task faces	1
eachsample and token	1
limitedsurrounding textual contexts	1
average accuracy as high as 97.40%	1
Accuracy results	1
methodology's performance	1
rank of top performing submodels	1
discrimination and difficulty	1
image-like shape	1
better NER predictors	1
https://sesame-pt.github.io --	1
massive size	1
large enough dataset	1
performance results	1
certain drawbacks	1
fine-grained opinion information	1
high-quality audios	1
massive video data	1
large cost	1
labeled, training data	1
27.6 F1 score	1
61.3 F1 score	1
Arabic Reading Comprehension Dataset (ARCD)	1
span of text	1
fine-grained namedentity knowledge	1
coarse-grained typedentities	1
named entity-related knowledge	1
average f-measure of 75%	1
named entity categories	1
thenew patterns	1
tuple value score	1
seed pattern	1
word andthe context features	1
predefined categories	1
added background knowledge	1
cumulative contributions	1
baselines by a good margin	1
SoTA results	1
training label	1
unknown target language task distribution	1
source language task distribution	1
state-of-the-art (SoTA) results	1
low RAT problem	1
false entity labels	1
low precision and recall problems	1
low precision, recall and ratio of annotated tokens (RAT)	1
preprocessed versions	1
in-domain results	1
arbitrary input data	1
OCR errors	1
contextualized string embeddings	1
Named Entity Recognition (NER ) on historical data	1
CNN accuracy	1
25%, 50% and 75%	1
enhanced classification results	1
DL input parameters	1
Kolmogorov-Smirnoff test distance	1
similar classification performance	1
4-28% over K-SVD	1
learning time by 36-93%	1
small batches	1
lot of the training data	1
real-time operation	1
traditional batch DL	1
sparse representations (SR)	1
detailed insights	1
increase of 120% in accuracy	1
performance superior	1
Temporal KG embeddings	1
desired performance	1
factor of 340x	1
buckets of structural complexity	1
Temporal KGs	1
temporal scopes (start and end times	1
Temporal Knowledge Graphs (Temporal KGs	1
near start-of-the-art performanceon	1
high score)from incorrect ones (low score)	1
correct triples	1
correctness ofKG triples	1
exponential in the length	1
new texts	1
bilingual training texts	1
211,564 annotations	1
word simplicity	1
long-standing misconceptions	1
various morphological, semantic and lexical word properties	1
Lexical Simplification needs	1
regression error and log likelihood	1
covariance structure	1
lower prediction error	1
multiple structural breaks	1
statistically significant changes and non-changes	1
theoretically justified thresholds	1
future changes	1
47.62 FPS real-time processing performance	1
20.7% FLOPs	1
least 52.4% parameters	1
realistic face details	1
answer visualization experience	1
agreement (or lack thereof)	1
Question Answering experience	1
ensembling strategies	1
accompanying papers	1
Answering Dataset (SQuAD) and Natural Questions (NQ)	1
2.3 points	1
deep policy	1
expert policy data	1
real human trajectories	1
real reaching trajectories	1
Electromyography (EMG) inference robustness issues	1
known intents	1
new forms	1
learned intents	1
interaction progresses	1
new forms of known intents	1
11.5 fps	1
superior features	1
re-ID performance	1
inferior features	1
low-quality proposals	1
parallel structure	1
comprehensive empirical evaluation	1
gold labels	1
gold label	1
least one permutation	1
almost all (98.7%) examples	1
word-order invariant	1
particular permutations	1
suite of metrics	1
permuted examples	1
novel evidence	1
accuracy of 47.53\%	1
high generalization capacity	1
cross-dataset evaluation results	1
Grad-CAM visualizations	1
3.28 $\times$ $10^{6}$ FLOPS	1
total of 1.65M model parameters	1
0.51\% and 5.34\%	1
one of the five	1
specific expression	1
spatial orientation pattern	1
extreme poses, illumination, and occlusion conditions	1
syntactic rules	1
morphology and syntactic parsing rules	1
lexical categories	1
syntactic parsing rules	1
Extensive evaluation	1
, 449 types	1
much more fine-grained event types	1
38 types	1
capacity and flexibility	1
Graph Classification setting	1
internal dependency	1
explicit word boundary and tenses information	1
forward and backward AEs	1
AE	1
representation distance	1
backward AE	1
original class	1
forward AE	1
confusing class	1
clean image	1
student model	1
adversarial examples (AEs)	1
attention knowledge	1
example-level scores	1
kinds of data	1
small and higher-quality finetuning data	1
NER classifiers	1
0.51 to 0.70	1
artefact, time period, place, context, species {\&}	1
{\textasciitilde}31k annotations	1
rigorous annotation guidelines	1
around 60,000 (658 million words	1
3 and 5 points	1
MRR and MAP scores	1
strong signal	1
incident titles	1
high precision of 0.96	1
2 months	1
data-types	1
incident reports	1
bag-level features	1
robust hierarchical pooling of features	1
single centroid	1
bag-level embeddings	1
instance-	1
instance relations	1
instance and slide level features	1
performance numbers	1
Expanding training data	1
observed pauses	1
low coverage bias or LCB)	1
estimates of their quality	1
high potential	1
task performance score	1
automatic translation metrics	1
expensiveness	1
11%- 21% fewer	1
0.4%-3.6% higher accuracy	1
accurate graph representation	1
graph distance	1
graph topology information	1
graph correlation information	1
sub-optimal search results	1
reduced representation capacity	1
inaccurate encoding representation	1
large inconsistency	1
small quantities	1
manual labeled data	1
56{\%}	1
existing NLU features	1
unacceptable cost	1
labelling data	1
high demands	1
13 types	1
$\sim$6,000 tweets	1
terms of F$_1$ measure	1
examples and statistics	1
previous training step	1
label confidence	1
correct or noisy one	1
noise-rate	1
hypergeometric distribution	1
noise samples	1
noise distribution and instance-level confidence	1
high noise rate settings	1
underlying noise distribution	1
variety	1
instance-level confidence statistics	1
certain size	1
output length	1
50 times longer	1
certain length	1
-lengthening inputs	1
novel output-sizemodulation problem	1
acertain length	1
undesirable length	1
daily-life	1
little-data condition	1
motor imagery classification accuracy between 60% to 80%	1
new sessions	1
optimal parameters	1
new state-of-the-art NER and POS performance	1
large linguistic distances	1
SSIM of $0.913\pm0.045$.	1
high-resolution (HR) details	1
patient's psychological and physical conditions	1
Longer scan time	1
longer scan time	1
image of such resolution	1
high spatial resolution	1
microstructure	1
competitive state-of-the-art performance	1
state-of-the-art lexical overlap features	1
syntax and lexical semantics	1
paraphrase	1
similar parameter numbers	1
highly competitive performances	1
strong representation power	1
parallel state	1
various limitations	1
conclusions and lessons	1
number of correct ones	1
number of incorrect answers	1
evaluation score between 0 and 1	1
completely multilingual	1
evaluation simple and completely automatic	1
single document	1
F1 score by over 10%	1
Prototypical networks' loss and metricloss)	1
anovel combination of loss functions	1
limitations ofsimple keyword spotting baselines	1
limited training data availability	1
lone keywords	1
small number of instances	1
bag-of-vector embeddings ofdependency graphs	1
theusefulness of this representation	1
specific tree or graph structure	1
minimal nonparametric extension	1
bag-of-vector embeddings	1
arbitrary linguistic structures	1
fixed-length word vectorsto	1
F-score of 65.02	1
F-score of 56.72	1
sparse and non-linear relationships	1
noisy texts	1
knowledge across domains	1
domain unique knowledge	1
missing classes	1
label-level	1
feature-level	1
individual source domain	1
unseen domain's annotated data	1
high generalization ability	1
constrained multilingual ASR	1
unconstrained LID	1
constrained LID	1
data profile	1
imbalances in data distributions	1
human affective expressions	1
one of the best results	1
0.586 accuracy	1
patient overall survival (OS) prediction	1
standard Cartesian space images	1
music representation	1
cover versions	1
query tracks	1
complex musical variations	1
widely used metrics	1
one of two	1
empty constituent	1
-LRB- 1 -RRB-	1
linguistic form	1
interclausal coherence	1
variety of facts	1
labeled NER data	1
close to state-of-the-art NER performance	1
consistent word level named entity tags	1
characters and outputs tag probabilities	1
weakly supervised signals	1
additional improvements in accuracy	1
additional data labels	1
real-world sensor data benchmarks	1
accuracy and training time	1
varying amounts of data availability	1
usefulontology	1
several challenges	1
PAC Identifiable	1
lost accuracy	1
dis-incentivizing	1
global model's prediction accuracy	1
strict privacy guarantees	1
Local DP	1
highly sensitive settings	1
tighter Differential Privacy (DP) constraints	1
various dimensions of benefits	1
somewhat sparse	1
two key properties	1
expression power	1
directed hypergraph structures	1
10.5%, 3.5%, 9.0%, and 13.2% on Office, Office-Home	1
mean classification accuracy	1
category-wise semantic structures	1
shared embedding space	1
low-level discriminative features	1
sensitivity and specificity are 90% and 89%	1
accuracy rate of 89.47%	1
distribution difference	1
group-level features	1
higher accuracy rate	1
diagnosis results	1
objectivity and accuracy	1
$F_1$ scores	1
$2.27\%$--$3.75\%$	1
generated sequences	1
extra labeled sequences	1
label efficiency	1
human annotations	1
queried samples	1
instance-label correspondence	1
prediction score	1
instance and label	1
nodes and edges state	1
instance and label relationship	1
task of MLIC	1
images and their labels	1
real-world efficacy	1
true and false negatives	1
non-entity	1
tokens, entities or otherwise	1
WSJ	1
flnal F-score of 0.865	1
number of extra lexical and frequentistic features	1
chunker output	1
tagger output	1
Wasserstein space	1
Riemannian structure	1
sample quality metrics	1
insufficiently fast	1
posterior approximation	1
robustness and accuracy	1
pseudo label quality	1
additional meta-objective	1
quality assessment	1
large-scale annotations	1
NER performances	1
real-world clinical data	1
enough clinical data	1
domain data	1
word and subword level	1
different pretraining choices	1
\url{https://github.com/napsternxg/TwitterNER	1
2nd best submitted solution	1
{\textasciitilde}1.15{\%}	1
F1 score of 47.3{\%}	1
7.08{\%} over ST	1
base-line	1
increase of 8.2{\%}	1
baseline (35.1{\%} F1	1
F1 score of 1.2{\%}	1
pre-trained resourced	1
solution [ST]	1
high dimensional	1
lexicon based features	1
global context predictions	1
updated gazetteer features	1
considered features	1
limited contextualization	1
sloppy spelling	1
noisy, user generated data	1
proper syntax	1
news corpus data	1
historical literatures	1
correct colors	1
modern time	1
automatic colorization	1
nationalities, and garment types	1
42 labels	1
1,353,166 images	1
image colorization	1
classification and semantic parsing features	1
accurate colorization	1
semantic	1
fine grained semantic understanding and prior	1
diverse high fidelity clothing colorization	1
pixel-level visual appearance and output-space	1
discriminators	1
pixel label distributions	1
various resolutions	1
MAP point estimate	1
best-fit Gaussian (mean and covariance)	1
Rauch-Tung-Striebel (RTS) smoother	1
efficient derivative-free batch formulation	1
Gaussian cubature	1
analytical derivatives	1
blocks efficiently	1
non-zero blocks	1
block-tridiagonal	1
mode	1
point estimate	1
state and data	1
joint likelihood	1
posterior efficiently	1
mean and (inverse) covariance	1
input transformations	1
small threshold below	1
change in lighting conditions	1
88.32 (90.49 with BERT)	1
F1 score of 92.22 (93.40 with BERT)	1
current sentence representation	1
wider context	1
weight of edges	1
less reliable	1
tokens whose representations	1
noise information	1
wider range of dependencies	1
word and sentence	1
local context information	1
local context dependencies	1
kinds of information	1
likely distance	1
concrete phrases	1
average variation of information improvement of 21.3%	1
neuronal shapes	1
number of nodes	1
neuron morphology	1
biologically inspired geometric constraints	1
split errors	1
segment labels	1
input segmentation	1
local and global context	1
merge errors	1
lowercomputational cost	1
significantly better predictions	1
poor unimodalapproximation	1
Gaussian approximationto the posterior distribution	1
highflexibility	1
small amount of data	1
concepts of AL	1
overview	1
labeled traffic data	1
Quality of Service (QoS) provisioning and security services	1
Network Traffic Classification (NTC)	1
least 60% reduction	1
substantially low number of acquired pool points	1
considerable efficiency boost	1
suitable acquisition functions	1
model uncertainties	1
labels on-the-fly	1
resource-friendly	1
user behavior over time	1
real-time incoming data points	1
discriminative local cues	1
less computation	1
body parts features	1
particular attribute	1
three goals	1
screenshot image case	1
74% character-level accuracy	1
astructured schema	1
image text and metadata	1
screen data	1
increasingpsychological breadth	1
scale of seconds	1
life experiences	1
publicly https://github.com/oravus/seqNet	1
presented comparison	1
two different modalities	1
data richness	1
performance variations	1
given metric span	1
similar ``metric span	1
``sequential representations''	1
scene appearance	1
91.2% accuracy	1
classification accuracy over 98%	1
Mel-frequency Cepstral Coefficient (MFCC) features	1
one or more languages	1
baseline by 10{\%}.	1
F1 score of 63.76{\%}	1
short turns separately	1
tag input	1
tensor structure	1
data or little data	1
experimental settings	1
accuracy impact	1
OVA system accuracy	1
number of data points	1
advantage of asynchrony	1
proposed objective	1
bounded pose regression loss	1
small windows	1
learning objective	1
difficulty of the training data	1
Bencmark (FDDB)	1
246k Bytes)	1
256x reduction in model size	1
runtime feature map memory	1
2.16x and 18x more savings	1
convolution, batch normalization and quantization layers	1
fixed-point	1
floatingpoint data	1
lots of floatingpoint data	1
significant memory savings	1
1 or 2 bits	1
memory saving	1
e.g. 8-bits)	1
relative low bits	1
remarkable savings	1
low bits fixed-point	1
dependency parses	1
constituency parses	1
fine-grained POS	1
four different types	1
BRC task	1
much LOGIN	1
possible complementariness	1
predicate embeddings	1
Attract & Repel loss	1
nodes and edges	1
input order	1
direction awareness	1
essence	1
Higher-order contexts	1
visually or semantically similar	1
inter-object relationship	1
underlying challenges	1
results (0.59 F-measure)	1
specific linguisticresource or encoded rule	1
-crafted features	1
little to no cost	1
noisy human responses	1
much lower cost	1
gather data	1
fourteen million labels	1
``richer dark knowledge	1
sufficient and representative data	1
two types of prosodic information	1
certain lexical and structural ambiguities	1
significantly lower F1 scores	1
precision andrecall	1
feature sparsity	1
named entity (NE) andcontext variability	1
key capabilities	1
text instances	1
31,791 question/answer pairs	1
86% performance	1
best knowledge	1
unsupervised ODQA	1
huge demand	1
nearly 30{\%} relative improvement	1
baseline system	1
MT ineffective	1
non-accessible formats	1
Bidirectional Encoder Representations from Transformers (BERT) model	1
skeletonbased and deep features	1
complementary capabilities of deep features	1
numerous unlabeled corpus or labeled NER training data	1
overlapping ratios	1
varying object movement patterns	1
inconsistent lighting conditions	1
many practical issues	1
completeness and median error	1
reparameterized depth values	1
real-world depth maps	1
finite projective camera calibration matrices	1
multiple satellite images	1
suitable properties	1
generalization, specification, and drifting)	1
Translation quality	1
generalization, specification	1
CLIR results 5{\%} (nDCG)	1
error rate by 12{\%} (HTER)	1
CLIR performance	1
generalization, specification, and drifting types	1
ambiguous translations	1
translation quality and Cross-Lingual Information Retrieval (CLIR) performance	1
1.32 +/-	1
0.509 mm	1
1.10 +/-	1
mean +/- std over all patients	1
0.543 mm	1
1.17 +/-	1
average ASD	1
average symmetric surface distance (ASD) metric	1
result of NMAR	1
metal artifact	1
CT image	1
surgical outcome	1
superior performance of 35.8 % and 17.7 % in Fmeasure	1
web statistics	1
principal eigenspace similarity	1
query words	1
87.74, 86.34, 79.31, and 94.68	1
state-of-the-art F1 scores	1
l-gram	1
layer l	1
pyramid shape	1
bottom to top	1
quantitative and qualitative analysis	1
16% improvement	1
vocabulary distribution	1
strong evidence	1
Pearson and Spearman correlations	1
knowledge representation model accuracy	1
knowledge representation	1
accuracy gains of up to 2.2 percentage points	1
SoTA performance	1
named entities accurately	1
start and end tokens	1
language-dependent	1
itscustomization advantages	1
past dependencies	1
Point Cloud Segmentation (PCS)	1
published benchmarks	1
ideal masks	1
intelligibility gains	1
six values of signal-to-noise ratio (SNR)	1
three non-stationary acoustic noises	1
target speech and noise signals statistics	1
lower noise proportion	1
adaptive information	1
noise statistics	1
noise masking elements	1
time-domain	1
noise components	1
accurate instance-levelsegmentations	1
object detector outputs	1
latter task	1
finite-stateness	1
unviolable finite state constraints	1
phonological data	1
types of constraints	1
violable rankable constraints	1
abstract morpheme signatures	1
inviolable lexical constraints	1
inflectional morphology	1
morphophonological alternations	1
Optimal morphology	1
statistical significance of the results	1
lesser number of support vectors	1
better Gmean scores	1
various disciplines	1
empirical results of the performance	1
one-classclassifier	1
different kernels	1
promising outcomes	1
slowest setting	1
terms of both PSNR and MS-SSIM	1
state-of-the-art learned video compression performance	1
bit-rate	1
independent cross entropy	1
conditional cross entropy	1
previous latent representations	1
Probability Mass Function (PMF)	1
compressed outputs	1
global layout	1
richer semantic representation	1
complex documents layout	1
semantic visual features	1
Many consistent, weak inconsistent, and strong inconsistent examplesare	1
favoritism orunfairness to any coefficient	1
percentage	1
coefficient	1
\alpha-D	1
parameters \alpha	1
particular values	1
general solution	1
particular non-null solution	1
null-solution	1
inorder	1
right-hand side of each preference	1
coefficientsin	1
non-nullpositive parameters	1
asystem of linear and or non-linear homogeneous and or non-homogeneous equationsand or inequalities	1
degree ofinconsistency)	1
degree of consistency	1
homogeneouslinear equations	1
anynumber of preferences	1
0.830 and 0.994 F1-scores	1
handcrafted dedicated features	1
two of the subtasks	1
new performance bar	1
improved NER performance	1
explicitly modeling morphological boundaries	1
gold morphology	1
morphological boundaries	1
token boundaries	1
1000km trajectories	1
80k lidar point cloud	1
150 minutes labeled Trajectory	1
1501 and Duke MTMC	1
considerable accuracy subsequently	1
lower costs	1
better annotation quality	1
correct labels	1
low overall annotation quality	1
varied costs	1
diverse quality	1
queried labels	1
noiseless answers	1
single labeler	1
anyadditional manual effort	1
thecompetitive result	1
SOTA result	1
accuracies above 63 % and 81 %	1
human judgements closely	1
known sentiment carriers	1
prior sentiment polarities	1
unknown words ' semantic properties	1
20 F1 absolute	1
coarse labels	1
new lines of research	1
larger NER typeset	1
PER, LOC, ORG, MISC)	1
scene class prediction	1
scene class	1
test remote sensing image	1
refined descriptions	1
spatial structure patterns	1
object spatial correlation	1
two unique characteristics	1
known and unknown)are	1
twopatterns (or anomalies)	1
stage two	1
2%IoU improvement	1
tasks dedicated heads	1
early shared encoders	1
MTL setup	1
whole setup	1
real flight data	1
tens of fault scenarios	1
many hours of raw data	1
13 minutes of post-fault flight time	1
total of 66 minutes of flight in normal conditions	1
processed data	1
representation vectors	1
specific and relevant information	1
sentence boundary	1
noisy text descriptions	1
parts of its text-description	1
rapidpace	1
minibatch step	1
KGC models	1
true fact triplets	1
higher score or probability	1
16$\times$ weight size reduction	1
comparable feature extraction quality	1
flexible bitwidth support	1
better model accuracy	1
minimal direct quantization loss	1
final DNN model accuracy	1
higher loss	1
DQL	1
coefficient data	1
Minimizing direct quantization loss (DQL)	1
complex and non-convex	1
quantization bitwidth	1
computing and/or storage cost	1
evaluation code	1
tasks (binary/multi-class, ordinal regression and multi-label)	1
data scale (from 100 to 100,000)	1
primary data modalities	1
0.8 BLEU points	1
discontinuous rules	1
misclassifications equally	1
Categorical Cross Entropy (CCE)	1
one sample	1
0.6 F1 score	1
low-resources	1
normalized embeddings	1
around 10% improvement	1
81.8%, 53.2%, and 71.7%	1
four system results	1
five system results	1
cross interactions	1
node matching	1
graph matching structure	1
co-occurrence	1
essential side-information	1
User and item attributes	1
5%AUC increase	1
complexoptimization problem	1
large scale improvements	1
specific degree distribution information	1
Log Normal distributions	1
detailed distributions	1
limited L1 orFrobenius norms	1
theutilization of sparsity	1
vast performance improvement	1
Link Prediction literature	1
mutual node friendship information	1
low ranknature	1
linkformation and descriptive user node features	1
structure, and attribute information	1
richer structure information	1
attribute space	1
target node	1
complex interdependency	1
analytical test cases	1
academic test cases	1
multiple layer structure	1
power of representation	1
non-stationary functions	1
current baselines on both BLEU and METEOR scores	1
inputs concurrently	1
generated response	1
answer verbalization	1
low embedding dimensions	1
scope and accuracy of the resulting data	1
e.g., 'education', 'company', 'government')	1
affiliation types	1
Study (e.g., 'neural networks', 'machine learning', 'artificial intelligence')	1
N to M relations	1
research dynamics	1
incompleteness	1
particular user interface styles or conventions	1
task specific gazetteers	1
additional labeled data	1
pretrained context embeddings	1
relatively little labeled data	1
context sensitive representations	1
ZSL and generalized ZSL settings	1
maximum response consistency	1
transfer loss	1
PRR branch	1
Constrained Part Attention (CPA) branch	1
raw image data	1
appearance relationships	1
direct embeddings	1
much smaller amount of training data	1
either speed and accuracy	1
$4,484$	1
features with semantical connotations	1
gridded texts	1
semantic meaning and spatial distribution	1
interested texts	1
Extracting key information	1
moderate computational overhead	1
various replay memory capacities	1
lower-dimensional representation space	1
image inputs	1
learned contexts	1
knowledge distillation regularization term	1
individual context	1
set of output heads	1
concept of context	1
non-stationary	1
temporally correlated	1
competent control policies	1
query latency	1
2x speedup	1
30x compression	1
best retrieval performance	1
ranking-oriented loss	1
query encoder and PQ index	1
query encoding and Product Quantization	1
severely decayed retrieval performance	1
tremendous memory usage and time cost	1
impressive ranking performance	1
target-private classes	1
clues of transferability, diversity, and uncertainty	1
source classes	1
informative target samples	1
small budget of target data	1
label set assumptions	1
source-target label set relationship	1
rich prior knowledge	1
long training example	1
short sentences}.	1
strongly biased	1
\textit{dataset length-bias}	1
quality degradation	1
underlying cause	1
certain point	1
F1 scores of 37.4 and33.6	1
onclean and noisy data	1
F1 scores of 76.7 and 83.2	1
shortestdependency path embeddings	1
shortest dependency path (sdp)	1
8.1{\%} higher	1
weighted context words	1
KB triples	1
salient triples	1
open RE	1
relational triple	1
diverse relation expressions	1
important relational triples	1
linguistic patterns	1
5.80% and 12.21% relative improvement	1
value	1
inference imperative	1
new slots, values, and domains	1
domains, slots, and values)	1
limited amount of labeled semantics data	1
slots edit F1 score	1
realistic environmental noises	1
noise-robustness	1
two inadequate settings	1
large amount of in-house data	1
Automatics Speech Recognition (ASR) outputs	1
groups of credibility indicators	1
indicators	1
blog level	1
information about individual blog posts	1
post level	1
two groups of indicators	1
textual credibility indicators	1
total of 120	1
best fit	1
fixed parameter settings	1
neural structures and learning parameters	1
dropout rate	1
slight variation of hyper parameters	1
laborious trails	1
tremendous expert knowledge	1
suitable GNN structure	1
unstructured network data	1
grid-like data	1
realistic image degradation	1
$\times$2, $\times$3 and $\times$4 scaling factors	1
10-100 times higher	1
little quantization error	1
quantized properties	1
individual properties	1
compact codes	1
one specific property	1
unacceptable computational complexity	1
Long-term motion synthesis and Interaction-based motion retrieval	1
Short-term motion prediction	1
structural plausibility	1
positive implications	1
several minutes	1
unrealistic pose patterns	1
data publicly available	1
densification	1
improved EL	1
Entity similarity	1
densified KG	1
co-occurrence statistics	1
KG density	1
Degree of connectivity	1
superior effectiveness	1
features similarity	1
query identity	1
type of threat	1
imperceptible amount of noise	1
99.06% and 89.59% accuracy	1
features at different granularity	1
specific layersto	1
vector of activation	1
Ki67 scoring	1
proliferation status	1
psychological research	1
incomplete and fragile representation problems	1
attention variation	1
better sentence representations	1
relative difference of up to 11.9{\%}.	1
independent variable	1
gender and age	1
analysed information	1
additional speaker-related information	1
emotional hypothesis	1
controllable attribute	1
task labels	1
controllable attributes	1
model's prediction	1
-0.5% more BD-BR gain	1
prediction information	1
additional BD-BR gain of -1.3%	1
frame level and block level	1
decoder side	1
encoder side	1
available ones	1
Quantization Parameter (QP)-map	1
reconstructed signal	1
normative prediction signal	1
frame type	1
limited gold data	1
complementarity	1
limited evaluation	1
stronger correlations	1
knowledge learned	1
limited fine-tuning data	1
coherence degrees	1
coarse judgement	1
quantifiable dialogue coherence metric	1
Quantifiable Dialogue Coherence Evaluation (QuantiDCE)	1
predicted coherence scores	1
Likert-type multi-level coherence scores	1
coherent vs. incoherent)	1
substantially reduced training time cost	1
exploration efficiency	1
confusion	1
sparse reward problem	1
higher-dimensional perspective	1
ASR and NMT tasks	1
encoder representations	1
pretrained parameters	1
pretraining the encoder parameters	1
appropriateness	1
margin of > 18% F1 score	1
accuracy of 54% and F1 score > 63%	1
subclass (640) level	1
CPC overlap	1
technological features	1
highest p2p similarity	1
CPC assignment	1
patent	1
Cooperative Patent Classification (CPC)	1
patent data	1
embedding distance measures	1
SBERTs efficiency	1
in-domain supervised patent claims data	1
patent embedding quality	1
resulting p2p similarity	1
patent-to-patent (p2p) technological similarity	1
Subjectivity Bias	1
Biased Ratings	1
lexicon dimension	1
appropriate distance measures	1
last feature	1
compact in number of terms	1
sentiment)	1
different subjectivity dimensions	1
discourse understanding accuracy	1
single understanding result	1
user utterance	1
understanding result	1
accessibility	1
different time periods	1
one of the time-critical factors	1
low data availability	1
contrastive relations	1
bigger impact	1
nearly 4% of F1-score	1
proper text formatting	1
1.3% absolute F1 score	1
text formatting	1
correct text formattings	1
tight storage budget	1
Class-Incremental Video Classification (CIVC)	1
limited storage and computing resources	1
arbitrary adversary goals	1
unknown training settings	1
pixel-level and semantic-level	1
cross-domain topological relations	1
new unlabeled target domain	1
84\% of the knowledge	1
collected ground-truth data	1
15 clients	1
various qualities	1
different types of errors	1
supplemental references	1
given contracts	1
token level and phrase level	1
highest F1 score	1
chunking labels	1
dependency parsing labels	1
rich linguistic features	1
result of Subtask 1	1
results of Subtask 2	1
token labels ({``}Action{''}, {``}Entity{''}, {``}Modifier{''} and {``}Others{''})	1
SubTask 2	1
malware actions and capabilities	1
language similarity measure	1
confusion matrix	1
well-averaged	1
classification factors	1
structure of confusion matrices	1
low-resource setting	1
different modeling design choices	1
subscription	1
specific contextual conditions	1
appropriate skill	1
undisambiguated SCF data	1
potential and limitations	1
subcategorization frame (SCF) distributions	1
undisambiguated corpus data	1
image-level visual features	1
mutimodal features	1
shared representation	1
entity-related features	1
visual and textual information	1
mapping relations	1
image-level features	1
complementary contextual information	1
average ranking	1
9 distinct evaluation metrics	1
1.19% for Precision	1
0.52% for F-measure	1
intra-image optimal	1
object position	1
specified interval	1
object size	1
inter-image optimization	1
background choice	1
background information	1
object's position and size	1
different generated background images	1
limited generalization	1
AV up to 67%	1
obstacle miss detection probability	1
JRC operation functions	1
two different functions	1
radar detection and data communication functions	1
limited prior knowledge	1
Useful conservative claims	1
feasible, sound arguments	1
certain ranges of required reliability and prior beliefs	1
dangerously optimistic biases	1
major source of doubt	1
practically verifiable	1
safety claims	1
over-optimism	1
strong expectations of safety	1
Prior knowledge	1
involuntary misuse	1
rigour	1
AV type	1
AV	1
debut	1
safety and reliability claims	1
estimated ~13% word error rate	1
Diarization Error Rate (DER)	1
27% relative improvement	1
~0.90/~0.95	1
acoustic level diarization	1
overall system's performance	1
ATC command types	1
gold standard data	1
unknown label indices	1
text extraction errors	1
noisy training data	1
typos and/or OCR mistakes	1
exact location	1
gold standard NER data	1
corresponding entity or non-entity label	1
case numbers	1
names of courts	1
effectiveness and merits	1
sentence-level attention	1
event detection oriented embeddings	1
Document-level information	1
least an order of magnitude more efficient	1
limited computational power (1 GPU	1
large amount of computational resources	1
previous learning step	1
fixed capacity	1
new concepts	1
capacity saturation	1
23.35 BLEU score	1
WER of 11.61%	1
task specific features	1
distinct moments	1
one hyper-parameter	1
noisy examples	1
reliable data	1
several hyper-parameters	1
identity-label annotation	1
time-consuming task	1
false positive rate of 1	1
90% detection	1
15 frames per second	1
extremely high detection rates	1
fast performance	1
low false positive rates	1
many desirable features	1
modest false positive rates	1
highly skewed	1
\url{https://github.com/DawnHH/DLSR-PyTorch}.	1
$\times 4$	1
$\times 2$ and 18G Multi-Adds	1
merely 68G Multi-Adds	1
PSNR, SSIM, and model complexity	1
feature connections	1
lightweight and accurate SR structure	1
lightweight operations	1
heavy computations	1
supplementary training data	1
discourse tasks	1
fair, comparable, and interpretable assessment	1
commonly used metrics	1
test size automatically	1
varying size	1
existing scores	1
informativeness of these evaluation measures	1
different aspects of model performance	1
multiple different scores	1
$1,280,000$	1
$6,392$ without any annotations	1
consistent and differential information	1
inherent problem	1
rich semantic contexts	1
cross-modal auto-encoder and the depth-contour estimation	1
hierarchy features	1
encouraging cross-lingual transfer performance	1
multilingual synthetic data	1
language-independent features	1
target-language synthetic data	1
language-specific features	1
synthetic labeled data	1
translated data	1
ground-truth 3D correspondences	1
weather and season variations	1
day-night	1
viewpoint and appearance changes	1
deeper knowledge systematicallyboosts accuracy	1
depth of knowledgethey	1
four categories	1
almost negligible running time	1
theoretical approximation bound	1
-level end-goals	1
protected health information	1
traits	1
Anatomy, Medical Condition, Medications, Protected Health Information (PHI) and Treatment, Test and Procedure (TTP)	1
dependencies, pipeline configurations	1
high degree of mismatch	1
reasonable recognition performance	1
much adaptation data	1
Wallstreet Journal (WSJ) data	1
speech recognizer's performance	1
similar contextual representations or output label distributions	1
two input views	1
input views	1
external contexts	1
set of semantically relevant texts	1
document-level contexts	1
commercial SLU data	1
anauxiliary domain	1
logical forms	1
efficacy of FAIL	1
extension of FAIL	1
near-optimal reset distribution	1
tabular reinforcement learning settings or settings	1
number of unique observations	1
relevant parameters	1
number of samples	1
observation distributions	1
Integral Probability Metric	1
large-scale MDPs	1
difficult tasks	1
7{\%} improvement	1
ROUGE-2 score of 0.72 and a ROUGE-SU4 score of 0.71	1
exact and well-formed {`}ideal{'} answers	1
wide variety of question types	1
task 5b	1
88.4\% coverage	1
classification accuracy of 82.0\%	1
local tissue changes	1
decent size	1
associated medical images	1
highly specialized domain knowledge	1
many types	1
heart structure	1
severe variations	1
1 in every 110	1
formal understanding	1
logical understanding	1
normative dimension	1
Inferential relations	1
conceptual relations	1
QA model	1
original news articles	1
named entity recognition	1
freely available news summary data	1
source of training data	1
domain/language	1
declarative counterparts	1
highest accuracy about 99%	1
accuracy of 95.77%, 97.27% and 91.07%, 99.74%	1
four frequency bands	1
fusion result	1
5% ~ 25%	1
original EEG signals	1
accuracy of 93.53% and 95.86%	1
high arousal and high valence (HAHV)	1
low arousal and high valence (LAHV)	1
high arousal and low valence (HALV)	1
low arousal and low valence (LALV)	1
arousal valence plane	1
decision level	1
research hotspots	1
construction quality	1
HTML density	1
varying entity types	1
variants and models	1
datasets	1
13.2{\%}	1
0.9{\%}	1
increased F1 performance	1
two free text segmentation granularities	1
five datasets	1
discarded tags	1
constraint map	1
latent intents	1
certain needs	1
discriminative appearance and shape	1
semantic object classes	1
NER performance improvements	1
industrial corpus creation	1
30-fold reduction in confidence interval over the best previous result	1
0.096%	1
81.956% +/-	1
winnability of Klondike	1
0.1% or better	1
95% confidence interval of +/-	1
academic literature	1
particular game	1
'patience'	1
ignorance	1
challenging task	1
different types and duration	1
novel interaction paradigms	1
image representation mapping	1
two different representation learning schemes	1
two different loss functions	1
target space	1
set covariance matrix	1
target representation space	1
sample covariance matrix	1
better image representations	1
hand-crafted feature	1
theoretical feasibility	1
strictly bounded by a finite constant	1
RBCS-F	1
regret	1
model exchange time	1
final model's quality	1
sufficiently large	1
personal sensitive data	1
privacy issue	1
proposed transportability measures	1
lightweight domain similarity measures	1
several instances of increasing complexity	1
NLP system performance	1
change in performance	1
well-established statistics	1
utilisation of metrics	1
sub-area	1
environment perception challenges	1
set of generalization functions	1
Pareto optimal solutions	1
small set ofso-called regularization samples	1
generic patterns	1
manual annotationstep	1
MCT part	1
semantic classifier loss	1
DFMN loss	1
MCT loss	1
multiple heads	1
(theoretically infinite) long-rangedependencies between labels	1
linear-chain hidden structure	1
non-linear node potentials	1
audio representation	1
$F_0$, duration and linguistic features	1
{\it $<$source,target$>$}	1
shading and textures	1
illumination constraints	1
underlying diffuse color	1
illumination color uniformity	1
observed pixel colors	1
illumination-based constraints	1
two types of fairness notions	1
outlier detection validity	1
sensitive pattern	1
intrinsic cluster structure	1
subgroup-invariant	1
learnable representation	1
unfairness	1
societal concerns	1
statistical bias	1
complexity of phenomena	1
human endeavor	1
direct binary or indirect detailed	1
teacher feedback	1
state action reward state action (SARSA)	1
extensive demonstration information	1
predefined goal	1
specific objective	1
large number of learning trials	1
environment states	1
nuances	1
40.8{\%}	1
marginal gains	1
base level	1
different performance	1
personal interests	1
interests of a user	1
Bidirectional Encoder Representations from Transformers (BERT), Micro Text Classification (Micro TC)	1
natural language statements	1
one document	1
manually labeled training data	1
different regions and acquisition conditions	1
LP images	1
oblique views	1
considerably distorted	1
LP	1
high-performance real-time processing	1
efficiency and productivity	1
one massively multilingual model	1
model capacities	1
various domains	1
multiple individual tasks	1
original model size	1
impaired measurements	1
times of occurrence	1
GNSS signal	1
potential variance jumps	1
least square estimate	1
positioning accuracy	1
GNSS measurement noise	1
VE tasks	1
high-coherence semantic interpretations	1
suitable word sense	1
lemma)	1
considerable drop in accuracy	1
relevant baselines	1
related but different distributions	1
support and query instances	1
handful of labelled data	1
positive, negative and neutral	1
rapid rate	1
basis of their polarity aspositive, negative or neutral	1
various text forms	1
large number of user data	1
near-minimal risk	1
upper problem	1
novel algorithmic insights	1
rigorous connections	1
zero error	1
best (model, architecture) pair	1
near-minimal validation sample size	1
upper-level problem	1
true test loss	1
risk and hyper-gradients	1
refined properties	1
role of train-validation split	1
right hyperparameters	1
a-priori	1
zero loss	1
train-validation splits	1
statistical aspects	1
validation data (upper-level problem	1
various hyperparameters	1
training data (lower-level problem	1
unequal length dimensions	1
varying number of dimensions	1
general time series extrinsic regression problems	1
recent values	1
future value	1
predictor time series	1
univariate or multivariate time series	1
single continuous value	1
photoplethysmogram (PPG) and accelerometer data	1
specific problems	1
scenarios, applications	1
social events	1
research agenda	1
small datasets	1
huge parameters	1
expressability limit	1
parametric models	1
different segmentation standards	1
8 x faster test time speeds	1
dramatic 14 - 20x testtime speedups	1
O(N ) time	1
length N	1
expressive and accurate	1
time and energy costs	1
intra-class compactness and inter-class separation	1
center loss	1
sparse formulation	1
estimated weights	1
irrelevant features	1
discriminative power of learned features	1
softmax loss	1
inter-class similarities	1
significant intra-class variations	1
vector size of 1500	1
vector sizes of 100	1
Continuous Bag of Words and Skip Gram	1
2.5 BLEU points	1
human-judged quality	1
translationese output	1
typical errors	1
true distribution	1
best approximation	1
corresponding quantile values	1
quantile fractions	1
quantile fraction axis (i.e., the x-axis) and the value axis (i.e., y-axis)	1
randomly sampled	1
C51, QR-DQN	1
side	1
distribution function	1
return value side	1
probability side	1
true continuous distribution	1
estimated distributions	1
expectation of total returns	1
6.51% improvement	1
average accuracy of 73.78% on	1
accuracy significantly	1
effectiveness and state-of-the-art performance	1
compact	1
coupled graph keys	1
Wasserstein discriminant loss	1
inter-graph structural relationship	1
corresponding key	1
graph correlation	1
dictionary space	1
input graphs	1
one modality	1
key	1
cross-modal similarity	1
intrinsic structure	1
20% increase	1
significant computationalexpense	1
90.3% on average	1
test accuracy by 26.7%	1
bigger value	1
devices' value of training	1
amount of training load	1
affordable training workloads	1
historical training tasks	1
complete information	1
training task	1
lot of stragglers	1
systems heterogeneity	1
resource-constrained	1
pretext	1
capability and short-comings	1
multilinguality and domain-specific information	1
different KG embedding spaces	1
multiple KG embeddings	1
low dimensional vector spaces	1
words and Knowledge Graphs (KG)	1
Slot Filling performance	1
size of labeled training dataand	1
output summary	1
information redundancy	1
segmentation robustness	1
NMT robustness	1
grammatical structure	1
input transcripts	1
well-formed training and evaluation data	1
strong state of the art performance	1
learned classes	1
image class	1
Few-Shot Incremental Learning (FSIL)	1
large amount of training data per class	1
classes incrementally	1
86.3% on	1
i.e., 72.1% and 47.0% for binary and nine-class classification	1
cross-subject emotion recognition accuracy	1
80 subjects	1
inter-subject differences	1
inter-subject correlation	1
morpho-syntactic information	1
sets of features	1
pairs of values representing indexes of first and last character	1
plain text	1
original format	1
web services	1
semantic level	1
pre-trained embedding space	1
fully annotated training images	1
third in terms of F1 out of 13	1
sixth in terms of MAP	1
47.22 MAP and 42.37 F1 score	1
67.27 Accuracy and 47.25 F1 score	1
44.62 MAP	1
around 30 points	1
77.47 MAP and 80.57 Accuracy	1
Question Similarity subtask (B)	1
Answering performance	1
high data collection costs	1
coarse predictions	1
domain-shared features extraction	1
manual label	1
large amount of manually labeled data	1
~6.5 increase in F1 score)	1
unavailability	1
corresponding causes	1
Twitter NER performance	1
type of named entities	1
two evaluations	1
two classifiers	1
or-thonormality	1
new type of regularizer	1
non-isolated minima	1
general problem	1
inarbitrary distance measures	1
training and prediction costs	1
weighted rank loss	1
different ranks	1
scanned receipt data	1
purchase behavior	1
expense policies	1
detailed analytics	1
19% accuracy improvement	1
weighted alternative	1
SLR performance	1
different cue features	1
summarizedvalue of remark	1
value and sentiment value	1
aspect value clubbed	1
Aspect value	1
various levels and weights	1
product based reviews	1
online ratings	1
anonymization validity	1
Quantitative and qualitative results	1
original image contents	1
high similarity	1
identity vectors	1
face identity	1
utility of the data	1
people's identities	1
recall)	1
6-19%	1
human rationale (precision)	1
~40-80% words	1
adversarial datasets	1
model's rationale	1
deeper and more complex	1
distribution sample	1
visual transformations	1
train and test distribution	1
training signals	1
ZSL, DG	1
classes and scenarios unseen	1
new images	1
severe performance degradation	1
8 percentage points	1
increase in performance	1
higher recall but lower precision	1
high precision but comparatively low recall	1
performance levels	1
every new domain	1
52.99{\%} strict micro-F1 score	1
78.85{\%} strict micro F-score	1
lexicon features	1
character, word, pre- fix and suffix information	1
0.164 and 0.169 accuracy	1
chemistry and Math knowledge	1
real-world chemical calculation questions	1
kind of formal representations	1
formatted representations	1
recall of 91%	1
98% attack detection rate	1
hazardous driving decisions	1
fake depth measurements	1
alarming consequences	1
Canonicalization-infused Representations (CaRe)	1
OpenKG embed- dings	1
Open Knowledge Graphs (OpenKGs)	1
nodes and relation phrases (RPs)	1
relative feature relevance	1
general interpretation rules	1
PFI versus CFI dichotomy	1
extreme reference points	1
Conditional Feature Importance (CFI)	1
remaining feature variables	1
Permutation Feature Importance (PFI)	1
either gender or naturalnessseparately	1
improvedperformance significantly	1
speakers and tasks	1
large mismatch	1
harmonizing optimization metrics	1
VMAF score	1
better visual quality	1
advantages of both PSNR and MS-SSIM	1
Harmonize optimization metrics	1
best visual quality or overall performance	1
certain aspects of human perception	1
different metrics	1
two most popular evaluation metrics	1
Peak signal-to-noise ratio (PSNR) and multi-scale structural similarity (MS-SSIM )	1
existing strong baselines	1
unpredicted relation types	1
calculations	1
predicted relational components	1
triplet tensor	1
sentence contained relations	1
final triplet extraction result	1
shared embedding parameters	1
5% accuracy on Q->A, 3.5% on QA->R, 5.8% on Q->AR	1
homogeneous graph)	1
interpretable reasoning paths	1
persuasive reasoning paths	1
convincing reasoning paths	1
popular NEL formats	1
annotation guideline	1
https://illuin-	1
1.0 version of our dataset	1
exact match ratio of 82.1	1
F1 score of 92.2	1
1.1 version	1
60,000+ samples	1
1.0 version	1
25,000+ samples	1
20 possible combinations	1
foreground	1
preference	1
significant preference	1
majority choice	1
highest scores	1
actual user ratings	1
different amount of context	1
facial displays	1
33.18 {\%} (F1 score)	1
classifier variability	1
Imputation hyperparameter $p_{miss}$	1
white noise	1
randomly masked vectors	1
higher quality samples	1
class weights	1
strong class imbalance	1
manual design effort	1
cross-language similarity	1
inter-assessor agreement	1
respective human judgments	1
language-independent and language-dependent features	1
speed-up of 7x and 6% word error rate reduction (WERR)	1
order of magnitude improvement	1
90.8% precision	1
80% recall	1
accuracyof FND	1
traffic sign detector (TSD)	1
traffic sign	1
anycritical sign	1
input audio sequence	1
vectorrepresentation of fixed dimensionality	1
Audio Word2Vecfrom audio data	1
significantly lowercomputation requirements	1
good degree	1
sequential phoneticstructures	1
vectorrepresentations	1
set of canonical forms	1
full sentences	1
improvement of 39{\%} and 37{\%}	1
27{\%}.	1
CoNLL 2003	1
13{\%}	1
highly efficient results	1
heterogeneity of uncertainty	1
25{\%}	1
two different levels, i.e., representation level and task-specific (i.e., label) level	1
word label	1
changing illumination conditions	1
planar rotations	1
local histograms of oriented gradients (HOGs)	1
initial set of potential object poses	1
specific orientation	1
chosen answer	1
answers and their reasons	1
cognition task	1
image and correct answer	1
LF execution accuracy from $70.6\%$ to $75.6\%$	1
coverage from $80\%$ to $96.2\%$	1
two publicly available datasets	1
LF execution accuracy	1
grammar coverage	1
Knowledge Graph and conversational contexts	1
supervision data	1
wide range of queries	1
quantization bits	1
Hessian trace order	1
optimal ratios	1
different channels of activations and weights	1
relative sensitivity order	1
mixed-precision quantization	1
Hessian traces	1
neural network weights	1
Second-order information	1
excellent cross-lingual transfer learning capabilities	1
hand-crafted features or post-processing rules	1
diverse linguistic heterogeneity	1
100x reduction of communication cost	1
high-quality domain consensus knowledge	1
toxicity nature	1
slot classes	1
fine-grained results	1
toxicity and game-specific aspects	1
utterance, token, and dual levels	1
rich contextual chatting history	1
utterance and token-level patterns	1
1.9K	1
chat logs	1
12K conversations	1
45K utterances	1
deeper understanding	1
single utterance level	1
superior or comparableperformance	1
prediction accuracyvia	1
many-to-one constraint	1
constraint of PLL problem	1
theinstance and label relationship	1
-to-label matchings	1
instances and theircandidate labels	1
set of candidate labels	1
trainingexample	1
two-fold preference	1
two kinds of document-level sentiment preference information	1
inter-aspect sentiment tendency	1
contextual sentiment tendency w.r.t	1
intra-aspect sentiment consistency	1
contextual sentiment consistency w.r.t	1
two kinds of sentiment preference information	1
sparse delayed feedback	1
recentexperiences (trajectories)	1
small memory	1
internal reward signal	1
corresponding skill policies	1
multiple levelsof temporal abstraction	1
action selection policies	1
sparse delayed rewardfeedback	1
huge state spaces	1
high as 1 million images	1
recognition quality	1
retrieval quality	1
local region descriptors	1
indexing descriptors	1
40000 images	1
better policies	1
Reward Machines (QRM)	1
reward function structure	1
?}	1
75-80 %	1
average improvement in the range of 2-5 %	1
officially recognized 12	1
block, text-line and word level	1
3 feature vectors	1
essential and relevant features	1
size of the feature vectors	1
large dimension	1
document images	1
Informative description	1
training information	1
97{\%}	1
POS tagging accuracy	1
negative class	1
one or more positive examples	1
examples called bags	1
consistent performance improvement	1
`practice	1
previous $n-1$ learning problems	1
domain $n$	1
$1^{st}$ thing	1
$n^{th}$ thing	1
accumulated experience	1
different motivating intuitions	1
syntax, structure and semantic improvements	1
4 point absolute improvement in BLEU score	1
7% absolute improvement	1
classifier performances	1
Matthew's coefficient of correlation (MCC), F1, Cohen ?	1
sensitivity and precision	1
obtained scores	1
open-access EEG data	1
wide range of performance metrics	1
higher speed	1
3.5%-3.6% strict relation F1 improvement	1
0.4%-1.9% F1	1
packed levitated markers	1
better span representation	1
core sub-tasks	1
provably theoretical guarantees	1
Rising Bandits	1
relatively small hyperparameter space	1
much smaller hyperparameter space	1
huge hyperparameter space	1
low-efficiency problem	1
CASH problem	1
relevant translations	1
translation effectiveness	1
vague or short queries	1
content of interest	1
long-duration	1
image size of 320x240	1
frame rate of 15-20 fps	1
good segment and tracking results	1
reconstructive and adversarial translation aspects	1
reconstructive capabilities	1
metrics SSIM (Structural Similarity Index) and FAD (Frech\'et Audio Distance	1
generalised performance	1
musical timbre	1
vocal timbre	1
realistic generations	1
minimal loss in quality	1
continuous hyper-parameters	1
extremely large variety	1
truly novel solutions	1
local optima)	1
new architecture patterns	1
higher Spearman{'}s rank correlation values	1
high levels of accuracy	1
question and answer texts	1
provided training data	1
retrieval of information	1
variety of biomedical topics	1
higher quality preference vector	1
natural language and numerical evaluations	1
restaurant reviews	1
individual evaluations	1
opinions and criteria	1
numerical ratings	1
pre-defined numerical or linguistic terms	1
color textures	1
input, one front view and one back view	1
various states	1
uneven label distribution	1
fine level	1
path information	1
coarse level	1
target entity pair	1
useful entity representations	1
within and across sentences	1
score from 1-5	1
IQ score	1
Kappa value of 0.54	1
three raters	1
exchange level	1
Interaction Quality (IQ)	1
angry	1
slightly angry	1
non-angry	1
emotion label	1
Automatic Speech Recognition (ASR), Spoken Language Understanding (SLU) and Dialog Manager (DM) properties	1
total of 46 parameters	1
quality, emotion, and task success labels	1
35,000 TimeML-based time expressions	1
fine-grained semantic classes	1
2 million tokens	1
appreciable performance	1
consistent performance trends	1
3%-13% absolute F1 points	1
overfitting issues	1
Gaussian-distributed embeddings	1
generalized objective	1
class-specific attributes	1
inter-token distribution distance	1
suboptimal performances	1
class-specific semantic features	1
generic temporal constraint	1
oscillation	1
different scene interpretations	1
temporally localized motion estimates	1
compact description	1
pre-training quality	1
Masked Language Modeling (MLM), Masked Object Classification (MOC), Masked Region Feature Regression (MRFR), and Image Text Matching (ITM)	1
Masked Face Detection Dataset (MFDD), Real-world Masked Face Recognition Dataset (RMFRD) and Simulated Masked Face Recognition Dataset (SMFRD)	1
large number of face samples	1
facial security checks	1
accuracy and fairness metrics	1
classification accuracy and fairness scores	1
skewed data distributions	1
accuracy vs fairness trade-off	1
mental and emotional health conditions	1
higher individual accuracy scores	1
fair decisions	1
intuitive representation	1
powers of CULP	1
multiple labels	1
multi-label data	1
labels in near constant time	1
proper class node	1
high level features	1
vastly different generalization capability	1
different training data	1
similarity of global features	1
intra-class differences	1
extracted latent features	1
inpainting traces	1
increasing threats	1
visually plausible results	1
performance accuracy of 98.71%	1
richer analytical framework	1
Organization, Location, Date and Time, Term, Designation and Short forms	1
following categories	1
existing information	1
word-level good/bad labels	1
sentence-level direct assessments and post-editing effort	1
following formats	1
10,000	1
human labels	1
(MT) Quality Estimation (QE)	1
\url{https://github.com/hijkzzz/pymarl2}.	1
mitigated bias	1
traditional embeddings	1
2% decrease in performance	1
debiased embeddings	1
cooccurrence statistics	1
syntactic ambiguities	1
anaphora references	1
cooccurrence patterns	1
distribution of utterances	1
SLU model	1
exit points	1
latency and computational complexity issues	1
higher latency	1
added costs	1
better modeling capacity	1
named entity recognition and resolution	1
common challenges	1
scores of 9	1
63.76% and 71.61% for	1
social media challenges	1
Twitter data	1
code-switched social-media data	1
GitHub https://git.io/JY0kk	1
five languages	1
low-resourced	1
combined accuracy of 87%	1
attributes and values	1
correct relation	1
discharge summary records	1
shortest inference delay	1
latency metric	1
model's inference delay	1
delay of computation tasks online	1
devices' profile	1
current network condition	1
large-scale ASR and MT data	1
cascaded ST counterpart	1
comparable or even better BLEU performance	1
state-of-the-art BLEU scores of 18.3 and 25.2	1
pre-training knowledge	1
representation inconsistency	1
speech-to-translation data	1
alternative variations	1
inverse tone mapping results	1
GAN losses	1
reduced inpainting quality	1
sufficient quality	1
hallucinated)	1
Low Dynamic Range (LDR) image content	1
High Dynamic Range (HDR) information	1
Market-1501 and DukeMTMC-reID	1
high-level parameters	1
source classification and triplet loss signal	1
shared low and mid-level parameters	1
noisy pseudo-labels}.	1
labeled source data and pseudo-labeled target data	1
erroneous pseudo-labels	1
different domain	1
data of interest (target data)	1
performance preservation	1
strong performances	1
\url{https://github.com/neulab/spanner}	1
three languages	1
different systems' outputs	1
complementary advantages	1
sequence labeling	1
feature map cues	1
nature of imbalance	1
whole images	1
imbalances of quality	1
image realism	1
unsupervised word representations	1
character - based word representations	1
two sources of information	1
approximate 0.07% WER decrease	1
1.48* speedup	1
high-precision values	1
quantized numerical range	1
Winograd convolution	1
heavy-tailed noise	1
skewed noise	1
complex noise	1
additive hypothesis spaces	1
mode-induced metric	1
mean squared error (MSE) criterion	1
Mutation NER performance	1
double-annotation	1
single-annotator labels	1
similarity-based and confidence based	1
different types of rankings	1
seventeen hundred	1
benchmark setup	1
Counterfactual statements	1
Discourse structure	1
IBM TUSZ preprocessed data	1
state-of-the-art weighted F1 score of 0.945	1
trainable neural plasticity	1
electrophysiological data	1
clinical domain	1
broad class	1
exceedingly well	1
interactional patterns	1
turn-based	1
language IDs	1
estimates of their quality ({\it low coverage bias} or LCB)	1
comprehensive analysis	1
subtle inter-class differences	1
large intra-class differences	1
design (or style)	1
thedifferent aspects of DGP	1
induced challenges	1
nonstationary functions	1
astationary covariance	1
16.43%	1
audio-only genre-classification accuracy	1
audio-based results	1
rhythmic visual patterns	1
new visual features	1
low-level visual features	1
music related information	1
music related	1
mood or genre	1
2-3x	1
fewer decisions	1
context size	1
novel graph structure	1
already-visited sentences	1
strong overall accuracy	1
Markov assumptions	1
discontinuous spans	1
unpredictable unnecessary yet inconsistent visual contents	1
form of privileged information	1
previous and current video frames	1
domainspecific knowledge	1
domain specific semantics	1
linguistic variation	1
distributed word representations	1
scarceannotated data	1
amounts of annotated training data	1
large amounts ofannotated labeled data	1
CoNLL, MUC	1
contentrequires	1
best tokenizer	1
number of examples of each word	1
enough examples	1
morphological knowledge	1
6% of the training data	1
over-reliance	1
marked performance	1
geometric priors	1
target of the phrasedatabase	1
kind of language unit	1
consequent structural and semanticambiguities	1
standard parsing rules	1
machine-readabledictionaries	1
user datadistribution	1
Morphosyntactic Tagging of Tweets (MTT)	1
three new tasks	1
German Dialect Identification (GDI) {--}	1
results and the findings	1
token level F1 score	1
Dice per case	1
multi-level features	1
neighboring high-level semantic information	1
discriminative low-level localization details	1
low-level and high-level features	1
F1 score of 83%	1
F1 score of 82.3% on this classification task	1
unanswerable questions	1
total of almost 80,000 questions	1
17,000+ unanswerable questions	1
60,000+	1
significant scientific breakthroughs	1
30% fewer	1
\geq2% mAP	1
70% FLOPs	1
similar FLOPs	1
\geq2% higher	1
model computation complexity	1
low-resolution input	1
Semantic Segmentation Super-Resolution (SSSR), Single Image Super-Resolution (SISR) and Feature Affinity	1
extra computation costs	1
large computation budgets	1
high-resolution input	1
semantic space and semantic path	1
semantic path	1
new dimension	1
strengths and drawbacks	1
computationaltreatment of sentiments and opinions	1
computationaltreatment	1
vast resourcesof data	1
Ideasand opinions	1
day-to-day life	1
given novel task	1
optimal network connections	1
particular novel tasks	1
certain saturation point	1
smaller ones	1
novel tasks	1
many small tasks (meta-tasks	1
Pareto optimal candidates	1
business requirements	1
many resource/hardware constraints	1
predefined objectives	1
resource and hard-ware constraints	1
BLEU score 14.9	1
second best result	1
BLEU scores 7.7 and 13.7	1
constrained amount of ground truth labeled data	1
Known Classes	1
Zero-Shot Classes	1
shortest distance between points	1
Zero-Shot Class	1
thenew classes	1
task predictions	1
holistic view	1
characteristic features	1
modality-specific	1
modality gap	1
commonalities	1
modality-invariant	1
two distinct subspaces	1
distributional modality gaps	1
incidents and security-wise scoring	1
three order of magnitude	1
incident scoring	1
alert graph partitioning	1
APTs -- RANK	1
increasingly impractical number	1
supernet predictive ability	1
incongruence	1
discrete architecture space	1
discrete space	1
non-negligible incongruence	1
differentiable space	1
discrete search space	1
supernet weights and architecture parameters	1
number of OBJ polarity values	1
cause-effect relations	1
syntagmatic patterns	1
connotative values	1
document's semantic orientation	1
objective and subjective expressions	1
various latency settings	1
best student architectures	1
network's output distribution	1
favorable speedups	1
IQA baseline	1
current performance levels	1
comprehensive knowledge embedding	1
two patterns (graphs)	1
derived graph structure	1
another semantically	1
natural and intuitive relevancy	1
relation pattern	1
speed-up of 7x and 6% Word Error Rate reduction (WERR)	1
enhanced convergence speed	1
training convergence speed	1
almost an order of magnitude improvement	1
inherent complexity	1
state-of-the-art mIoU accuracy	1
baseline counterpart (MinkNet42 \cite{choy20194d})	1
12\%)	1
robust prediction	1
semantic boundaries	1
varying sparsity	1
global contexts	1
valuable 3D topology and geometric relations	1
accurate environmental perception	1
range of competitive baseline methods	1
confusing event labels	1
relational message	1
event labels	1
uncertain word boundaries	1
specified types	1
15 of them	1
Arabic Dialect Identification (ADI), German Dialect Identification (GDI), and Cross-lingual Dependency Parsing (CLP)	1
ranking of models	1
different splits	1
model parameter initialisation seed	1
choice of hyperparameters	1
training setup	1
course of many thousands	1
patient healthcare	1
significant time and financial costs	1
small and medium size featured	1
unimodal data	1
bimodal data	1
representative context	1
results on test data	1
validation accuracy	1
{`}Overtly Aggressive{`}, {`}Covertly Aggressive{`}	1
three predefined classes	1
Aggression levels	1
added difficulty	1
NTU RGB+D (action recognition, early prediction) and PKU MMD (action detection	1
layer reuse	1
high intraclass similarity	1
Low interclass	1
complementary disciplines	1
zero-shot and few-shot settings	1
corresponding slot description representations	1
slot value contextual representations	1
related slot description representation	1
slot value representation	1
semantic meaning	1
noisy ASR output	1
learned vectors	1
realistic few-shot test data	1
unrealistic data distribution	1
none-of-the-above, aka NOTA	1
target categories	1
realistic scenario	1
in-built biases	1
external open-domain trigger knowledge	1
small scale of training data	1
equal or higher accuracy	1
image and question features	1
model support	1
prediction uncertainties	1
behavior and failure modes	1
weak points	1
monotonicity constraints	1
previous impressions	1
purely cooperative	1
SMAC and PP;(3)	1
expressive power of QMIX	1
Maximum Entropy	1
Subtasks A (Message Polarity Classification )	1
F1-score of 0.822	1
negation knowledge	1
useful domain specific information	1
promising adaptation results	1
various strengths and weaknesses	1
variety of datasets	1
often incomplete	1
character substitution problem	1
F1 and (avg.)	1
(avg.)	1
boost of+15.2 NER F1	1
significantgain in performance	1
low-resourcedlanguages	1
resource-richlanguages	1
simulation and experimental results	1
inlier measurements	1
geometric consistency of rotation measurements	1
incorrect orientation measurements	1
repetitive structures	1
feature mismatches	1
outlier poses	1
also 3-D points	1
relative rigid body transformations	1
global SfM	1
computer vision) and Simultaneous Localization and Mapping (SLAM, in robotics)	1
synthetic SR data	1
nearly 9.0% of ASTER and MORAN	1
13%of CRNN	1
misalignment problem	1
character boundaries	1
authentic and challenging	1
different focal length	1
poor recognition accuracy	1
detailed content information	1
existing baselines	1
large gains (up to +49{\%} F1	1
24M tokens	1
context and gazetteer features	1
feature overuse	1
including gazetteer features	1
realistic evaluation data	1
extra features	1
movie names	1
low context	1
FaceNet and 9.90% (x4)	1
EER of 8.9% (x3)	1
Equal Error Rate (EER) of 8.7% for FaceNet and 10.05%	1
sharp quality	1
factor of x3	1
2,170,142 to 28,654 parameters	1
Sharpness metric	1
correspondingly large number of parameters	1
data acquisition conditions	1
e.g. periocular verification	1
supervision	1
domain-specific supervision	1
large amount of labelled data	1
$<$.70 F1	1
mediocre evaluation scores	1
$>$.85 F1	1
Active Learning and text classification results	1
geographic coordinates	1
reliable statements	1
overview of this data	1
soil information	1
processing speed by about 10 times	1
competitive performances	1
complex linguistic conditions	1
expression-related visual information	1
textual feature	1
varying content	1
different semantic levels	1
AFS adaptively fuses features	1
diversity and complexity issues	1
tag distributions	1
handcrafted gaze and textual features	1
better classification performance	1
combination of automatically learned text and gaze features	1
gaze information	1
eye-movement/gaze data	1
text subtleties	1
eye-movement patterns	1
traditional text-based features	1
behavioral data	1
IL and ILFO	1
exponential sample complexity separation	1
standard IL problem	1
ILFO problem	1
certain well studied notions	1
MDP dynamics	1
idea of optimism	1
access to actions	1
expert demonstrations	1
increasing amount of attention	1
many standard test cases	1
patterns of missing data	1
statistical integrity of attributes	1
internal representation of data	1
derived completed data	1
incomplete cases	1
amount of available training data	1
precision-recall tradeoff	1
Open IE tuples	1
eight times fewer parameters	1
seven times faster	1
11.6 megabytes	1
storage, processing power, and memory	1
energy expensive	1
non-processing and memory intensive and efficient energy-consuming	1
reduced storage size	1
practical data	1
single scale (patch size)	1
large anomaly	1
sparsely represent images	1
patch size	1
few-shot learning capabilities	1
generalisation and reproducibility issues	1
intrinsic and penalty graphs	1
distribution gap	1
distributions of training and test data	1
desired objective	1
state-of-the-art outcomes	1
generalizable features	1
implicit strength	1
magnitude and extent	1
largeamount of information	1
positive, negative or neutral	1
thebasis of their polarity	1
text forms	1
new source of opinion	1
sparsity issues	1
noisy sentences	1
500,000	1
speech	1
unreliable inputs	1
prior context assumption	1
state-action value	1
prior regularization term	1
prior policy	1
100+	1
600+ stars	1
40,000+ downloads	1
less than 10% of the training data	1
95% of the previous best performance	1
Sentence Embeddings	1
Textual Similarity	1
querying data	1
adversarial noise	1
low labeled data regimes	1
Local Distributional Smoothness	1
transfer quality	1
important linguistic features	1
single language $L_2$	1
$L_1$	1
good performance predictor	1
aggregated syntactic similarity	1
2-4 times	1
particular syntactic features	1
almost 30	1
surprisingly good results	1
little or no data	1
increasing amount of evidence	1
initial data	1
23 and 33 points higher thanthe best baseline	1
scale, DeeSIL performance	1
largeramounts of initial data	1
minute	1
limited memory budget	1
twoaforementioned challenges	1
in- crease recognition capacity	1
two com- plex challenges	1
budget	1
kinds of initial weights	1
HMTL and SL	1
13%	1
rotation and puzzling	1
one training session	1
huge number of labels	1
Head View point labels	1
time intervals	1
different windows sizes	1
comparable baseline	1
3% increase	1
73% accuracy, 60% kappa, 3% higher	1
3rd position	1
'verb'	1
1st position	1
Temporal Hard Norm Alignment (T-HNA) and Min-Entropy Consistency (MEC)	1
new multi-stream consistency losses	1
state-of-the-art performance level	1
performances in terms of precision	1
model precision	1
learning paradigms	1
excellent learning model performances	1
logic	1
stronger control	1
number of inference steps	1
interpretability and controllability	1
required difficulty levels	1
robustness of SLU	1
refined slot-value pairs	1
supervision signal (reward)	1
predicted values	1
inefficient representation	1
SLT performance	1
GT glosses	1
increase of over 16 BLEU	1
current state-of-the-art by over 5 and 7 BLEU respectively	1
sign language glosses	1
named entities and word sense annotations	1
accuracy of roughly 70{\%}	1
training and testing grounds	1
wide range of genres	1
extrapolative knowledge representation	1
SE information	1
important semantic information	1
three Semantic Evidences (SEs)	1
relation, entity and triple level	1
plausibility of observed triples	1
h from (?, r, t)	1
(h, r, ?)	1
unseen triple (h, r, t)	1
extrapolation scenarios	1
700 images	1
classification specificity of 96.67%	1
patch-level output	1
image-level results	1
effective distinguishing features	1
weakly supervised learning missions	1
manual mitotic count	1
considerable differences	1
0.963 to 0.979	1
predicted and the ground truth mitotic count	1
mitotic density	1
highest mitotic density	1
overall distribution	1
potential difference	1
mitotic figures	1
known high inter-rater disagreement	1
uneven mitotic figure distribution	1
brain imaging reports	1
two sources	1
system's performance	1
insufficient overlapping samples	1
prohibitive communication and computation effort	1
model architectures	1
samples or features	1
adverse reactions	1
therapeutic indications	1
Product Characteristics	1
Spanish drug Summary	1
overall precision	1
subset of them	1
purpose or meaning	1
different roles	1
temporal and spatial information	1
task of VQA	1
new questions	1
initial baseline	1
nearly 13{\%} relative improvement	1
scanned digital text	1
around 20%	1
high predictive performance	1
lower runtimes	1
original setup	1
pretty much the same performance	1
predictive performances	1
pipeline runtime	1
meta-feature dimension	1
several meta-features	1
meta-representations	1
best alternative	1
F1-score of $0.50$ and $0.82$ on ADE Span Detection (Task 1b)	1
F1-score of $0.46$ and $0.90$ on ADE Classification (Task 1a) and Profession Classification (Task 7a)	1
Stacked Heterogeneous Embeddings and linguistic features	1
thebest or second best EL accuracy	1
queries/ tweets vsnews documents	1
differentannotation conventions	1
enoughtraining data	1
otherengineered features	1
context-aware mention embeddings	1
contextualsimilarity scores	1
mutual dependency	1
publicly released our code	1
infinite amount of labeled data	1
sampled training data	1
Inter-LADA	1
Intra-LADA	1
10,000 + times faster	1
4 to ON 2 L	1
ALM and equivalent derivations	1
N L.	1
much larger than feature length	1
noised information	1
9.58 and 18.13	1
19.26 BLEU-4	1
upper bound for translation performance	1
>1K and >99K words	1
67K signs	1
.95M frames	1
spoken language translations and gloss level annotations	1
spatial representations	1
end-to-end and pretrained settings	1
different word orders	1
93.33 for Maithili	1
96.25 for Bhojpuri	1
96.73 for Bhojpuri, 93.33 for Maithili and 95.04	1
lower baseline F1-scores	1
coarse-grained annotation labels	1
22 entity labels	1
sizes 228373, 157468 and 56190 tokens	1
total of 22	1
superior reasoning performance	1
visual objects	1
visual relationship	1
absolute location	1
basic attributes	1
four types	1
high confidence levels	1
Named Entity Sequence Classification (NESC)	1
confidence levels	1
reliable confidence level	1
growing nature	1
user item ratings	1
theonline information	1
Semantic type	1
7{\%}	1
Pharmacological Substance, Sign or Symptom	1
one or more of the	1
amount of bachelors	1
EA models	1
good generality	1
sampling quality	1
sampling bias	1
one KG	1
less annotation cost	1
scope of these under-explored tasks	1
hardness of our benchmark	1
every format	1
intermediate common format	1
question format	1
external numerical knowledge	1
Two of the new types	1
four existing question types	1
diverse formats	1
single format, task, dataset or domain	1
question formats	1
numerical reasoning capabilities	1
(https://github.com/chauhanshweta/Kangri_corpus)	1
non-commercial usages	1
Translation with Explicit ORdering (METEOR) score of Statistical Machine Translation (SMT) and Neural Machine Translation (NMT) results	1
Bilingual Evaluation Understudy (BLEU) score and Metric	1
respective state-of-the-art performance	1
score map	1
four different directions	1
spatial refinement	1
two encoded features	1
multimodal input	1
similar conditions	1
low-light night time driving scenarios	1
formalontology	1
overall average improvement of 5 BLEU points	1
high-quality parallel data	1
sufficient quantities	1
complex morphology	1
universal characteristic	1
large percentage	1
near state-of-the-art (SOTA) performance	1
significance of context	1
pipeline's results	1
clear edges	1
weak supervision signals	1
real production settings	1
large amounts of unlabeled data	1
rich unlabeled data	1
translated training data	1
margin of 3.72% F1	1
state-of-art	1
noisy linker	1
ideal scenarios	1
generated SPARQL silhouette	1
precise relation	1
test entities and relations	1
structured query languages	1
state-of-the-art classification error	1
generalized information	1
intrinsic properties	1
PAD generalization capability	1
acquisition sensors	1
NER accuracy gaps	1
various degradation levels	1
NER accuracy drop	1
questionable output	1
target tasks	1
source knowledge	1
task-oriented metric spaces	1
4 seconds	1
intra-rater agreement (IRA) of an expert of 72.4% and 82%	1
channel- and segment-level performance	1
LOSO CV mean BAC of 73.6%, 77.2%, and 81.8% at channel-, segment-, and EEG -level	1
LOIO CV mean balanced accuracy (BAC) of 71.9%, 75.5%, and 82.0% at channel-, segment- and EEG -level	1
best overall results	1
segment- and EEG -level	1
detections	1
time-consuming and subjective	1
benefits of KGs	1
outstanding progress	1
robustness by 33.3%	1
better user experience	1
undesired dead-ends	1
error-rate by 3.8%	1
fused representations	1
relevance/executability aspects	1
extracted meaning	1
affinity metric	1
specific intent	1
relevant/executable	1
user information-state	1
ambiguous intents	1
expected results	1
multiple options	1
best intent	1
user requests	1
algorithmic advances	1
scattered research	1
useful	1
input signal	1
intermediate representation	1
designed features	1
prediction and classification decisions	1
hand-engineered acoustic features (feature engineering)	1
stable performance improvements	1
high generalizability	1
knowledge embeddings	1
Connection information	1
large number of connections	1
pre-trained Knowledge Graph Embeddings (KGE)	1
semantic and syntactic relations	1
4.9 billion tokens	1
words appear	1
vector space representations	1
Word Embeddings (WE)	1
gloss-level tokenization	1
advantages of sign-level tokenization	1
efficiency in terms of time and space	1
5 points in BLEU-4 and 8 points in ROUGE scores	1
frame-level and gloss-level tokenization	1
two main input tokenization levels	1
enormous advancements	1
pipeline{'}s results	1
optimal prediction threshold	1
medical claims data	1
available features types	1
high imbalance	1
large sample size	1
true and false positive rates	1
best balance	1
Model performance	1
true negative rate high	1
low area under the precision-recall curve	1
six different disease outcomes	1
four different time windows	1
demographic information	1
SED performance improvement	1
0, 10 and 20 dB SNR	1
22.3 %, 12.8 %, 5.9 % improvement over benchmark model	1
SNRs	1
0, 10 and 20 db SNR	1
Task 2 sounds event data	1
DCASE 2018	1
DCASE 2019 task 1 acoustic scene data	1
first step and second step attention weights	1
better T-F level information	1
noisy recordings	1
chosen auxiliary task de-noises internal T-F representation	1
input TimeFrequency representation (T-F) reconstruction	1
traditional MIL setup	1
Weakly Labelled Audio data	1
lower layer	1
slot filling performance	1
linguistic expertise	1
semantic and syntactic features	1
distributed word representations (word embeddings)	1
textual content	1
new levelof complexity	1
explainability of EVE	1
71%accuracy	1
similar objects and sentence structures	1
improvement of up to 5.5 F1 percentage points	1
document-level multi-task annotations	1
number of mentions	1
traditional mention-level evaluation metrics	1
net improvement of 18.86% and 4.61% F-1	1
reliable metric	1
WiSeBE and standard metrics	1
precision, recall, F-score or classification error	1
second part	1
features at various scales	1
lightweight nature	1
lesser parameters	1
increased computational complexity	1
improved embedding representation	1
bidirectional transformers	1
abstract and meaningful hidden feature vectors	1
richer input representations	1
intermediate input representations	1
clean and complete data	1
Incomplete data	1
Stacked Denoising Bidirectional Encoder Representations	1
github tutorial	1
https://metasrgan.herokuapp.com/ Check	1
Super-Resolution	1
efficiency, performance	1
fifty times smaller	1
20$\%$	1
arbitrary scale magnifications	1
arbitrary scale, high fidelity Super-Resolution	1
arbitrary scale factors	1
every integer scale factor	1
storage and energy costs	1
different scale factors	1
perceptually realistic single image Super-Resolution	1
significantly distinct feature distribution	1
low zero-day detection rate	1
attack behaviour	1
learnt attributes	1
significant risks	1
Zero-day Detection Rate	1
zero-day attacks	1
known attacks	1
known attack (seen) classes	1
network data features	1
ML model performance	1
non-existence	1
new attack traffic	1
attack classes	1
useful patterns	1
synthetic speech quality	1
synthetic speech data	1
NLU performance	1
Massive amounts	1
diversity of data	1
value of the benchmark	1
dataset similarity	1
Performance gains	1
12.8% average accuracy	1
increasing dissimilarity	1
high degree of visual similarity	1
theoretical arguments	1
criterion of cumulative regret	1
sub-samples	1
potential of hyperparameters	1
large hyperparameter search space	1
---}	1
high proportion	1
77.4\% accuracy	1
Hyper-parameter	1
low performance correlation	1
variant input types	1
pretrained embeddings	1
translational assumptions	1
slight complexity	1
85-87{\%}.	1
inter-annotator agreements	1
conventional annotations	1
Japanese traffic rules	1
Ontology contents	1
domain, range, and subClassOf	1
several RDF properties	1
relation annotations	1
argument entity mentions	1
domain and range links	1
link but a node	1
meta-weights	1
labeled data limitation	1
best F1 score of 0.84984	1
audio data	1
zeroshot E2E performance	1
Audio-Text	1
already available ASR and NLU training data	1
end-to-end training data	1
better optimized	1
smaller, faster	1
class prototypes	1
decent performance	1
constrained training setting	1
performance discrepancy	1
sufficient examples	1
many constraints	1
individual patient's risk	1
accurate cancer survival predictions	1
important patterns and features	1
better interpretability	1
patient-level	1
WSI-level information	1
WSI	1
imaging features	1
Whole Slide Images (WSIs)	1
discriminative patch labeling	1
ATENE metric	1
used evaluation metric	1
ASR errors importance	1
seriousness	1
relevant measures	1
error seriousness	1
serious errors	1
concept of Continual Learning (CL), Representation Learning (RL), and Knowledge Distillation (KD)	1
learning dynamics	1
limited evaluation settings	1
linked data	1
continuous stream	1
50%-56%	1
model-size	1
accuracy gains of up to 11%	1
current state of the art results	1
accuracy of 0.9433 (for NER ), 0.9090 (for POS )	1
2.39 MB in size	1
near perfection	1
F1-score of 0.3738	1
F1-score of 0.8662	1
standard error rate (SER) of 0.7159	1
high-level of inconsistency	1
labeled and unlabeled aspects	1
different features (labeled aspects, unlabeled aspects, and linguistic features	1
classifiers	1
aspects already labeled	1
intense human effort	1
high level of detail	1
mean accuracies and F1 scores	1
substantial absolute improvements of 7.87%, 20.15%, and 10.99%	1
large and consistent performance gains	1
recent benchmarks	1
2.5 accuracy score	1
10 F1 on average for NER	1
40 languages	1
Language Heteroscedastic/Homoscedastic Uncertainty (LEU/LOU), Evidential Uncertainty (EVI)	1
Three different uncertainties	1
high-quality silver labels	1
remarkable zero-shot performance	1
strong QG baselines	1
adapted affine coupling structures	1
continuous input embeddings	1
invertibility and exact density estimation properties	1
translation model performance	1
specific contribution	1
series of evaluation metrics	1
improvement of 4.19dB on PSNR and 5% on SSIM	1
much more satisfactory de-raining results	1
original low-quality embedding	1
de-raining results	1
generator (decoder)	1
latent optimal one	1
unsatisfactory output	1
blurry results	1
image-to-image translation formulation	1
valuable POS category	1
essential features	1
difficulty and cost	1
true performance and capacity	1
intra-life novelty	1
amaximum training score of 80,000 points	1
DeepCSdoubles A2C performance	1
DeepCS matchesthe performance	1
episode	1
manydifferent states	1
initially non-rewarding states	1
across-training novelty	1
current episode	1
-life novelty	1
across-trainingnovelty	1
prior training episodes	1
extremely low	1
random action sequenceleads	1
less than 0.5\% EER	1
sentence-level Accuracy, Precision, Recall, and F1-Measure	1
severe class imbalance issue	1
token dependencies	1
bidirectional context information	1
error positions	1
deep issues	1
test accuracy	1
standard performance indicators (accuracy, loss)	1
channel sizes	1
admist trials	1
trained weights	1
channel-size optimization	1
channel size	1
micro-search space	1
heavy computational resources	1
global search-space perspective	1
optimal network configurations	1
number of model parameters	1
larger counterparts	1
higher alignment	1
alignment metrics	1
highest alignment	1
integrated gradients	1
model sensitivity	1
three alignment metrics	1
actual model behavior	1
human expectations	1
flexible structural pattern	1
positive and negative links	1
positive links	1
non-Euclidean nature	1
Graph or network data	1
least two to three times	1
numerical results	1
afew steps	1
principal singular subspaces	1
partial SVDs	1
singular value decomposition (SVD)	1
nuclear norm minimization(NNM) problems	1
potential advantages	1
nuances of language	1
vast nature	1
orders of magnitude lower	1
large cone angles	1
low number of projection angles	1
high noise	1
accurate CCB CT reconstructions	1
substantially faster	1
2D slices	1
reconstruction artifacts	1
acquisition speed	1
high throughput CT scanning settings	1
low training data requirements	1
trade-offs between speed and reconstruction quality	1
F-score of 0.743 and 0.658	1
last utterance	1
last one, two or three	1
zero context	1
two categories	1
inherent defects	1
training data distribution	1
imperfections	1
cross-domain wording and phrasing style	1
extreme diversity	1
geometric structural information	1
superior or equivalent performance	1
8% of the model size	1
high memory cost	1
improvise performance	1
important heads	1
importance of a head	1
certain importance score	1
under-utilized	1
greater performance	1
0.93 at ~20% the amount	1
0.95 angular similarity	1
set of probabilities whose sum is 1	1
conventional classification labels	1
absolute values of zero and one	1
new form of labeling	1
probability distribution of grasp types	1
object images	1
physical state probability	1
system robustness	1
user diversity	1
signal quality	1
intended motion	1
physical interaction capabilities	1
best trade-off between accuracy	1
LightCNN-29 and Local Phase Quantization (LPQ) descriptor	1
\textbf{14\%}	1
least performance difference	1
2.1x faster	1
rank-5 and rank-10	1
\textbf{1.85\%}	1
best-performing ResNet-50	1
maximum rank-1 accuracy	1
six hand-crafted features	1
training time by as much as 48%	1
amount of learnable parameters	1
11.7%	1
classification tasks	1
weight calculation	1
optimal weights	1
violence class	1
final classification scores	1
weighted sum of classification scores	1
Blood, Motion, and SentiBank features	1
audio and visual features	1
movie ratings	1
violent content	1
micro-averaged F1-score of 26.78% on the subtask	1
different training iterations	1
winning solution	1
number of inherent properties	1
higher-order label dependencies	1
particular answer	1
safety-critical	1
predicted answer	1
2400 sketch-photo pairs	1
triplet loss and classification loss	1
several key limitations	1
28{\%}	1
CRF baseline	1
F1 -measure of 72{\%}.	1
F1 -measure of 75{\%}	1
top 1	1
symptoms and signs	1
F1 -measure of 66{\%}	1
reasonable performance (accuracy: 83.02%, precision: 80.82%, recall: 83.02%, F1-score: 80%)	1
high confidence consistently	1
dramatic accuracy gain	1
much less number	1
temporal processing capability	1
analog values	1
reduced performance	1
99\% to 0\% on real world data	1
expected predictive loss on-line	1
linear time and constant space complexity	1
predictive and the changepoint (CP) posterior	1
several state-of-the- arts	1
set-level and instance-level	1
translating instances	1
geometric or semantic artifacts	1
set-level constraints	1
correct correspondences	1
10th out of 17	1
84.7{\%} accuracy	1
de-identification artifacts	1
training times 30 times shorter	1
short training and execution times	1
relevant performances	1
carbon footprint	1
expensive computational costs	1
increasingly more extra-data	1
data format	1
formal translation outputs	1
multi-scale defects classification and detection results	1
proposed method achieves 98.70% (F-measure), 88.07% (mAP), and 73.29% (IoU)	1
2129 of which	1
Faster RCNN+FPN	1
importance of each pixel	1
similar semantic features	1
network deepens	1
feature vanishing	1
rest classes	1
approximately 0.45\%)	1
Weak classes	1
Weak and Strong classes	1
bad performance	1
generalization capacity	1
embedding vectors (Glove, BERT)	1
names of persons, locations, quantities, organizations or percentages	1
superior computational efficiency	1
state-of-the-art classification performance	1
fixed-sized vector representation	1
reference distribution	1
quadratic to linear in the number	1
dissimilarity	1
node embedding distributions	1
explicit bounds	1
optimization ease	1
accurate modeling	1
shared inductive biases	1
salient features	1
competitive or state-of-the-art performance	1
Attention Modulated Image Quality (VTAMIQ)	1
Image Quality Assessment (IQA)	1
significantly reduced computational cost and memory consumption	1
par performance	1
inaccurate approximation	1
vastly distinctive	1
activation and weight distributions	1
two difficulites	1
feasible accuracy-efficiency trade-off	1
skip mappingsworks	1
gated identity functions	1
etween image and texture quality	1
brain image texture	1
PSNR (Peak Signal to Noise Ratio), SSIM (Structural Similarity) and NRMSE (Normalized Root Mean Squared Error) metrics	1
image texture detail	1
available image data	1
\url{https://github.com/djiajunustc/Voxel-R-CNN}.	1
speed of 25 FPS	1
real-time frame processing rate, \emph{i.e}.	1
higher detection accuracy	1
RoI features	1
fraction of the computation cost	1
comparable detection accuracy	1
coarse voxel granularity	1
slightly different viewpoint	1
high computation overheads	1
point-level features	1
precise point positions	1
domain-specificvocabulary	1
conventional, time-consuming featureengineering	1
either randomassignments or automated word embeddings	1
heavily time-consuming	1
LSTM -Sharp (383 GFLOPs/Watt)	1
low power dissipation	1
resource budgets	1
different LSTM models	1
1.5x, 2.86x, and 82x speedups on average	1
model's characteristics	1
LSTM computation	1
adaptiveness	1
diverse configurations	1
computation pattern	1
-0.13 TER and +0.40 BLEU score	1
-4.52 TER and +6.81 BLEU score	1
TER and BLEU score	1
APE problem	1
fixed range	1
value of each component	1
( 3 , 2 , 1 , 8 )	1
hash code	1
composition of basis vectors	1
basis vectors	1
significant sacrifices in performance	1
large storage or memory footprint	1
massive number of parameters	1
sampling scores	1
two measures	1
higher effect	1
strong expandability	1
appropriate anomaly detector and run-time parameters	1
expandability	1
input time series	1
adaptive selection of detectors and run-time parameters	1
time series representation	1
appropriate detector and run-time parameters	1
time series characteristics	1
different time windows	1
types of anomalies	1
abnormal data	1
approximate value estimates	1
maximum and minimum operators	1
critic objective	1
underestimation	1
significant underestimation bias	1
reinforcement signals	1
value functions	1
version of Dropout	1
good regularizers	1
detailed analysis of model performance	1
predecessor's identified disadvantages	1
MT performance	1
common evaluation metrics	1
short-distance	1
26.73% bits-reduction	1
terms of both PSNR and MS-SSIM metrics	1
larger pixel range	1
models' semantic abilities	1
task-specific information	1
token vectors	1
equally valuable information	1
BERT 's hidden states	1
internal functioning	1
Transformer s (BERT )	1
1 billion	1
Recall@100 of 0.94 in 3.4 ms	1
floating-point distances	1
standard8-bit sub-quantizers	1
3 to6 times speedup	1
Distance Computation (ADC)	1
short codes	1
fast answers	1
in-RAM storage	1
compresseshigh-dimensional vectors	1
lowresponses times	1
performance and training speed	1
transfer capability	1
strong generalization abilities	1
action restriction	1
importance weight	1
requirement of different observation and action configurations	1
3 vs 3 or 5 vs 6	1
diverse levels of difficulty	1
fixed input and output dimensions	1
restricted model architecture	1
every new task	1
lead	1
92.7{\%} accuracy	1
Aristo Tuple KG	1
8.0%	1
7.0% with ConceptNet	1
instance of BiCAM	1
lexical level knowledge	1
challenges and limitations	1
hardware cost estimation strategies	1
search strategy	1
four key dimensions	1
knowledge containing both structures and appearances	1
reliable structures	1
diverse appearances	1
excessive randomicity	1
actual semantic information	1
monolithic feature	1
adequate diversities in appearance	1
generated results	1
regions of interest (ROI)	1
57.3% mIoU	1
video frame features	1
grayscale images	1
high compute capacity resources	1
kinds of knowledge or skill levels	1
machine and human performance	1
mean-reciprocal-rank	1
set of candidate answersand	1
number ofsophisticated baselines	1
total of ~1.2	1
~120k images	1
objectiveevaluation of individual responses	1
general test ofmachine intelligence	1
question accurately	1
100 units and 400-450 degrees	1
length of the path and turning angle	1
accuracy by 7%-30%	1
convergence speed and accuracy	1
learning and autonomous decision-making capability	1
artificially constrained	1
headings	1
Top-1 accuracy within 3% to 26%	1
Top-1 accuracy between 2% to 8%	1
224x224 resolution	1
number of models' weights	1
classification part	1
extracted feature map	1
relative position representations	1
recurrent information	1
feed-forward information	1
critical component	1
personal nuances	1
many train-able parameters	1
considerable amount of labelled data	1
one or more sensors	1
significantly less parameters	1
cell-level	1
new single model state-of-the-art result	1
one, two, and three dimensional data	1
wide range of shapes	1
Fourier space	1
low frequency images	1
arbitrary shape	1
sample specific features	1
Deep Fool and Uniform Noise	1
learned functions	1
hard linguistic phenomena	1
final inference decision	1
linguistically challenging	1
NLI pair	1
challenging linguistic phenomena	1
generalization difficulties	1
theoretical guarantees of MAML	1
$\epsilon$-FOSP for any $\epsilon>0$.	1
small desired level of accuracy	1
positive $\epsilon$ after at most $\mathcal{O}(1/\epsilon^2)$ iterations	1
$\epsilon$-first-order stationary point ($\epsilon$-FOSP)	1
nonconvex settings	1
first theoretical guarantees	1
nonconvex loss functions	1
gradient norm	1
best achievable accuracy	1
overall complexity	1
real proprietary data	1
SSIM of over 0.8	1
real seismic data	1
fundamental shift	1
non-image like	1
highly unstructured	1
raw seismic data	1
5D convolutions	1
least 5D.	1
seismic data	1
large-scale, spatially irregular time-series data	1
required subsurface prediction (gigabytes)	1
Raw seismic data (terabytes)	1
timelines to a few minutes	1
year of human and computational effort	1
false positiverate/hour from 0.8/hour to 0.77/hour	1
accuracy over state-of-the-art from 86.83% to89.84% and specificity from 87.38% to 89.64%	1
mean point ofcovariance matrices	1
tangent space	1
clustering covariance matrices	1
Inter-subject variability	1
7.9% and 5.8% margin	1
original missing values	1
random drop values	1
given incomplete data	1
extra missing values	1
incomplete time-series data	1
incomplete time series data	1
extra 3D CNN features	1
-of-art	1
input spatial locations	1
sparse connectivity	1
model number of parameters	1
high-dimensionality video representations	1
finer motion patterns	1
higher spatial resolutionfrom	1
low-spatial resolution	1
highlydiscriminative information	1
Olinear-time	1
OFL-NTK	1
Onon-convex	1
Oyarn-level	1
Olow-dimensional	1
O95.50%)	1
OSpeech-to-text	1
Osecond-order	1
Olower-level	1
Ohigh-fidelity	1
Oin-depth	1
resultant vector representations	1
one-hot ID feature	1
non-sematic features(such	1
noise and information redundancy	1
graph representations	1
best lemmatisation F1-score	1
inherently lossy annotation projection	1
2.5-5x faster	1
100-250x faster	1
well-preserved	1
parallelism	1
co-occurrence features	1
high-accuracy SR	1
various viewpoints	1
pixel-wise aligned visible and thermal images	1
low-cost channel (visible/depth)	1
different spectral domains	1
model quality and stability	1
average relative degradation of 4.6%	1
several orders of magnitude	1
query-candidate sentence-pairs similarities	1
sentence-pair scores	1
sentence vectors	1
sentence-to-vector mapping	1
query sentence	1
sentence B	1
pair of sentences (A and B)	1
low-confidence ones	1
-confidence tracklets	1
high-confidence	1
Theasymmetric pairwise terms	1
discriminative visual features	1
visual appearanceinformation	1
unary termsestimate tracked objects' displacements	1
unary and pairwise terms	1
DCCRF	1
symmetric way	1
individual object's movementsand inter-object relations	1
faster levels	1
slowly	1
slower levels	1
sequences of up to 1000 frames	1
slower intervals	1
higher levels	1
tested datasets and image resolutions	1
terms of speed	1
novel nuScenes Object Detection benchmarks	1
object's orientation	1
labeled ground truth data	1
three angles	1
full 3D description	1
geometric constraints	1
3D bounding box keypoints	1
additional regression and classification parameters	1
level of model accuracy	1
5.2 hours	1
13.2% WER	1
7.6% WER	1
much larger scale	1
batch size 3X as large	1
much larger batch size	1
large mini-batch size	1
\url{https://github.com/we1pingyu/CALD}	1
2.9/2.8/0.8 mAP on average	1
individual information	1
unique challenges	1
three appealing benefits	1
original and augmented data	1
limited budget	1
1.36 and 1.16 FID scores	1
intolerant memory and computation consumption	1
huge number of parameters	1
AUC of 0.951 and an F1 score of 88.0%	1
real ones	1
superiority of BOND	1
recall and precision	1
highly incomplete and noisy distant labels	1
edges of that graph	1
plane geometry	1
set of fundamental postulates	1
set of given premises	1
mathematical claim	1
questions and answers	1
syntactic and semantic features	1
accuracy of 62.6{\%}	1
reasonable and diversified story endings	1
designed human and automatic evaluation metrics	1
human-generated or machine-generated	1
story endings	1
story ending	1
story context	1
pure MLE training objective	1
Maximum Likelihood Estimation (MLE)	1
average of 1.2{\%}	1
BERT variation	1
sentiment or emotion-specific biases	1
two orders of magnitude	1
rescore windows	1
number of Vector Quantization levels	1
number of speedup techniques	1
approximating scores	1
substantial end-to-end speedup	1
significant portion of computation time	1
merits and superiority	1
Chinese character features	1
ancient times	1
Chinese character structure	1
semantic and boundary information	1
general validity	1
data diversity	1
large search spaces	1
long search time	1
optimal data augmentation policies	1
less than 20 minutes	1
IPA vowel chart	1
good parallel	1
small amount of annotated paired data	1
total number of distinct representations	1
representations phoneme-synchronized	1
phoneme sequences	1
sequences of representations	1
primarily unpaired audio data	1
mismatching tagsets	1
multilingual BERT embeddings	1
respective experimental results	1
thresholds flexibly	1
post-processing and text detection performance	1
high aspect ratios	1
Pixels-IoU (PIoU) loss	1
different sentiment	1
similar sentiment	1
superior effectiveness andefficiency of CCQ	1
paired and partially paired data	1
reconstruction and quantization errors	1
intra-modal similarity and inter-modal correlationthrough	1
compact binary codes	1
theisomorphic latent features	1
composite quantizers	1
-maximal mappings	1
substantial loss	1
threshold embeddingsinto binary codes	1
hash codes	1
queriesacross content modalities	1
KDD Cup	1
ranked 7th	1
20 episodes/100 evaluations	1
five years	1
small number of observations	1
cost volume	1
different scales and locations	1
enough multi-scale features	1
broad application capability	1
several state-ofthe- arts	1
set-level andinstance-level	1
learned instancepairs	1
instancelevel correspondencescould	1
false positives(e.g. geometric or semantic artifacts)	1
set-level constraintscannot	1
correct correspondenceswithout paired data	1
MOS drop	1
MOS of 3.83 and 3.54	1
mel-spectrograms	1
phonetic features	1
gaps	1
non-parallel	1
Time elastic kernelDynamic	1
interesting noisereduction capability	1
time axes	1
single medoid or centroid estimate torepresent each categories	1
classification error rates	1
45time series datasets	1
aligned samples	1
averaging ofthe time of occurrences	1
Dynamic Time Warping measure	1
alignment paths	1
probabilistic distributions	1
kernel alignment matrices	1
heavy computational costs	1
sub-optimalsolution	1
long time series	1
publicly available dataset (NEU ATR)	1
CT volumes	1
material types	1
material signatures	1
limited proof	1
similar global batch size	1
absolute improvement of 3.13% over the state of the art	1
top-1 accuracy of 40.03% on ImageNet22K	1
ImageNet22K	1
14 million	1
learned architectures	1
significant computational burden	1
1.1% on average	1
BERT's performance	1
0.5% F1	1
almost no parameters	1
models' performance	1
AOR performance	1
total reward of any policy	1
thisapproximate observation function	1
knownonly approximately	1
totalcollected reward of optimal policy	1
tonovel views	1
best next action	1
corresponding belief MarkovDecision Process (MDP)	1
thequality of their solution	1
label uncertainty measures	1
optimal trajectories	1
overall size	1
inherent drawbacks	1
spatio-temporal features	1
achieved results	1
educational purposes	1
risky situation	1
technical performances	1
SPE baseline	1
10% mAP improvement	1
significant 5% mAP	1
speed and time	1
two architectural choices	1
motion cues	1
set predictions	1
spatial and motion modalities	1
spatial and motion streams	1
spatial or motion features	1
inter-relations	1
uncertain or even negative effects	1
text and image	1
formal training and evaluation benchmark	1
accurate and effective real-time performance	1
low latency solution	1
small temporal windows	1
2D pose representations	1
computational and energy requests	1
overall generalization capability	1
minimal architectural priors	1
1st and 2nd in average performance	1
major feature	1
dimensional sentiment on valence and arousal	1
phrase-level ones	1
benefit	1
substantial margins of up to 2.1 BLEU	1
sentence and document level data	1
object detection performanceon	1
state-of-the-art interms of PSNR, SSIM and the subjective visual quality	1
high-level task performance	1
atmospheric light	1
transmission matrix	1
average performances	1
high imbalance and high dimensionality problems	1
high dimensional datasets	1
synthetic samples' labels	1
credibility	1
Inaccurate labels	1
privacy noise	1
F1 scores of 75.32 and 64.85	1
fine-tuned the pre-trained BERT model parameters	1
Answering Dataset 2.0 (SQUAD 2.0)	1
Bidirectional Encoder Representations from Transformers (BERT )	1
machine capabilities	1
complex form	1
First Order Statistical features	1
scan signals	1
total of 5681 measurements	1
18-40 GHz	1
grain surface types	1
sensitive customer data	1
natural assumption	1
feasibility and near-optimality	1
nature of its optimal solutions	1
constrained optimization problem	1
constrained optimization problems	1
audio and text input modalities	1
audio embeddings	1
log Mel energies	1
baseline systems	1
2.2{\%} BLEU on average	1
3.6{\%} BLEU improvement	1
4.8{\%} BLEU	1
6.8{\%} BLEU over our last year{'}s submission	1
important hyperparameters	1
model dimension	1
fine-tuning	1
respect metrics	1
masked language modeling objective	1
contextualized sentence embeddings	1
document-level dependencies	1
contextualized source sentence representations	1
surrounding sentences	1
cross-sentence dependencies	1
Code and model weights	1
overall accuracy of 90% and sensitivity of .857, .9, and .942	1
validation accuracy of over 89.3%	1
slice-level classification accuracy of over 94%	1
chest Computed Tomography (CT) scan images	1
list of research questions	1
literature andresults	1
raw psychiatric data	1
legal and ethical restrictions	1
health data	1
patient privacy	1
patientconfidentiality and identity	1
medical science	1
9th, 14th, and 22nd places	1
0.91393, 0.6300, and 0.57607 macro F1-average	1
toxicity	1
tweet	1
Sub-task A	1
substantial improvement of 20.67% in terms of NDCG@10	1
L2RS outperforms	1
BERT sentence embedding, topic vector, and perplexity scores	1
wide range of textual information	1
linguistic and semantic legitimacy	1
statistical analysis and classification scores	1
specificity of 0.80	1
best sensitivity of 0.87	1
attention, working memory, and executive function	1
different cognitive performances	1
efficiencies	1
resting-state EEG	1
standard FL baseline	1
priority of criteria	1
client-specific criteria	1
clients' actual data	1
better global model	1
behaviors and preferences	1
photo	1
text messages	1
visited locations	1
new regulations	1
automatic and human assessments	1
valid poems	1
poeticness criteria	1
final translations	1
pretrained different variations of BERT	1
initial translations	1
two pieces of literature medium-less	1
notice able gap	1
philosophy, wisdom, speech	1
variation characterization	1
previous and subsequentframes	1
neighboring joints	1
efficient representation	1
consecutive frames	1
thegraph structure	1
multiple observations	1
thespatio-temporal variation	1
irregular graph-structured data	1
limitedexpressive power	1
baseline ViT	1
e.g., ResNet 101	1
discriminative and efficient transformer variants	1
low-level design choice	1
fewer computational cost	1
local correlations	1
visual representation ability	1
88% mAP	1
76% mAP	1
0.014s per volume	1
98% true positive rate and 1.5% false positive rate	1
object detection performance	1
63.88 and 100	1
visual only and audio only featuresresults	1
PCA space	1
isolated word utterance	1
city names	1
audio and visual speech features	1
weak performance	1
Intra-Speaker dependency, and Inter-Speaker dependency	1
conventional context modeling	1
long-distance dependency	1
Intra-Speaker and Inter-Speaker dependencies	1
binary version	1
influences	1
codeis publicly accessible	1
best distance measure	1
accuracies by more than 10%	1
significantlyimproved classification accuracies	1
64 out of 84	1
quantitatively much lower	1
ground-truth alignments	1
distinct neighborhood structures	1
locally similar structures	1
point-wise local structuralinformation	1
entirelydissimilar local structures	1
sensible matchings	1
boundary and temporal consistency constraints	1
local non-linear distortions	1
over-analyzing empirical data	1
cost and value	1
accuracy measures	1
depth and breadth	1
much analysis	1
higher ROI	1
fewer iterations	1
higher F1 accuracy	1
40% of training data	1
achievable benefit	1
analysis investment (cost)	1
Much? analytics	1
decision support	1
Return-on-Investment (ROI)	1
efficiency and quality of solutions	1
meta-model's Neural Tangent Kernel (NTK)	1
function spaces	1
computational inefficiency and sub-optimal solutions	1
whole inner-loop optimization path	1
number of simple explanatory examples	1
Term Frequency - Inverse Document Frequency in Class - Relevance Frequency)	1
term weighting calculation	1
Term Frequency - Inverse Document Frequency)	1
weight of terms	1
numerical feature vectors	1
Von Neumann information	1
`Eigenrank'	1
large quantities of manually annotated ground truth data	1
two main algorithmic challenges	1
local texture details	1
rich global information	1
richer high-frequency details	1
clarity	1
performance by 3% on average than those	1
predicted offsets	1
best post-eval F1 score	1
F1 score of 0.6753	1
union/intersection	1
combination of predicted offsets	1
significant improvement by 8%	1
traditional acoustic features	1
ASV	1
audio sentiment	1
dependent utterances	1
cepstrum coefficient	1
utterance-level labels	1
representative features termed Audio Sentiment Vector (ASV)	1
homogeneous acoustic features	1
effectiveness of acoustic features	1
OffensEval 2020	1
transferability of instances	1
Translation Embedding Distance	1
additional semi-supervised labels	1
bias w.r.t	1
epistemic uncertainty	1
calibrated estimates	1
Concrete Dropout variant	1
effective approximation	1
WQL properties	1
tabular settings	1
action-value	1
estimated action-values	1
Q-Learning performance	1
maximum action-value	1
78.39{\%}	1
first subtask	1
F1 score of 74.89{\%}	1
relation holds	1
subtask 1.2	1
clean (subtask 1.1) and noisy data	1
RoBERT a	1
much better	1
behavioral information	1
models' behavior	1
reasoning capability	1
reasoning abilities	1
fine-grained insights	1
184K examples	1
predictable behavior	1
simple features (sans multi-lingual features	1
fixed - length vector	1
best Accuracy of 93%	1
best Accuracy of 95%	1
best classification performance	1
Confusion Matrix, ROC Curve	1
architecture performance	1
several performance graphs	1
True Positive Rate, False Positive Rate, Accuracy	1
several performance metrics	1
extent of damage	1
identical amount of computational resource	1
feature Complexity and variational Dropout (FSCD)	1
better tradeoff between effectiveness and efficiency	1
significant loss	1
system efficiency	1
matching, pre-ranking, ranking, and re-ranking stages	1
various types of noisy labels	1
conservative predictions	1
superior stability	1
flat minimum	1
conflict-free and biased	1
SGD noise	1
extra capacity	1
Open-set samples with Dynamic Noisy Labels (ODNL)	1
inherent noisy labels	1
non-toxic	1
open-set noisy labels	1
closed-set noises	1
example choices	1
absolute $10\%$	1
average AUC-ROC score	1
increasing advantage	1
absolute $6\%$ AUC ROC score	1
target label	1
target input	1
BERT	1
BERT encoder	1
new slot values	1
state operation	1
much betterthan	1
extensibility and flexibility arealso	1
overfitting automatically	1
n't end-to-end	1
n't temporal fusion	1
robust and accuracy	1
video andaudio information	1
submission deadline	1
preciseboundary definitions	1
training accuracy	1
morediscriminative features	1
deep semantics	1
theshallow visual appearance	1
large labelleddataset	1
hand-craftedfeatures	1
human-labeled	1
datapoints	1
InfoGAN labels	1
active learner predictions	1
disentangled class category representations	1
human labeling budget	1
concept of disentanglement	1
various architectures	1
$L_2$ regularization	1
large learning rates	1
similar hyperparameter settings	1
auxiliary losses	1
additional saturating nonlinearities	1
real-valued, continuous parameters	1
multivariate binary state	1
given objective	1
binary vector of weights	1
additions	1
-1(0)	1
two possible values	1
1-bit representation of parameters	1
full-precision floating point counterparts	1
highly compressed	1
all-sided improvements	1
BSBDV 2017	1
cascade classifiers	1
cascade stages	1
discriminative representations	1
stronger classifiers	1
C-RPNs	1
mining hard samples	1
poor adaption	1
serious data imbalance	1
RTL implementation and design feedback	1
errors of 6.71% and 10.05%	1
vertical and horizontal routing congestion	1
routability oriented bottlenecks	1
relevant high-level source code	1
Place and Route	1
post-implementation details	1
Routing congestion estimation	1
higher abstraction level	1
development time	1
external word embeddings	1
expression of time, currency and others	1
names of locations,organizations	1
percentage expressions	1
quantity expressions	1
predefined categories called tags	1
2.21 F1 score	1
terms of Recall	1
first runner up	1
terms of F1 score	1
fourth runner up	1
range of other linguistic tasks	1
real world applications	1
file sizes	1
within 5\% of the best result	1
0.94 F1-score	1
Bidirectional Long Short Term Memory	1
real or fake news	1
F1-score of 0.967	1
topical distributions	1
real-world socio-political impact	1
truthful information	1
velocity and volume)	1
recovery rate: 78%)	1
within 5% WER increase	1
best SSL performance	1
950h more unlabeled data	1
recovery rate of 92%	1
10.4% word error rate (WER) reduction	1
475h labeled data	1
25% of the original labels	1
1.9kh manually transcribed training data	1
pseudo label errors	1
elliptical knots	1
raw timber images	1
63.63%	1
average intersection over union of 73.05%	1
precise locations	1
Gaussian function	1
elliptical shape	1
visual characteristics	1
number and types	1
objects' distances	1
accurate object proposals and distance estimations	1
radar information	1
accurate object detection and distance estimation	1
long expressions	1
small improvement	1
subtask consistency	1
large improvement	1
underlying question logic	1
significant nondifferentiability	1
functions composing	1
highest F1-score of 66.99%	1
tremendous effects	1
metric definitions	1
classifier's self-reported and measured probabilities	1
generalized mean ($\rho$ equals 0, 1, and -2/3	1
three recently-proposed classifier quality metrics	1
\url{https://github.com/facebookresearch	1
simple Python	1
multi-machine high-performance version ("PolyBeast"	1
MonoBeast)	1
macro averaged F1 score of 0.902	1
annotated contains relations	1
contains relation	1
macro-averaged F1 score 1.0	1
TAG{\_}ID, ROOT{\_}ID, BIO tag	1
result of BERT	1
free style	1
definition, word level BIO tags	1
terms and their definitions	1
expense	1
limited representational capacity	1
different degrees of language-specific knowledge	1
two components	1
75.83% mIOU	1
75.7% top-1 accuracy	1
strong future relationship	1
smaller parameter space	1
DQN and Double DQN	1
classical data	1
time and space complexity	1
risks	1
pernicious tendency	1
linguistic fluency	1
results both with and without BERT	1
connecting sentiment	1
entire detected spans	1
solution end-to-end	1
entire opinion triplet	1
limitations of the existing works	1
span-level semantics	1
overlapping aspect/opinion spans	1
three opinion factors	1
corresponding opinion term/span	1
opinion target or aspect	1
amount of flickering pixels	1
15 percent faster	1
similar or slightly worse accuracy	1
required FLOPs	1
basic version	1
66 percent longer	1
inference time of one video frame	1
large parameter count	1
temporal image information	1
low-resolution	1
unreliable quality	1
model accuracy high	1
regularization function	1
trade-off between accuracy and memory footprint	1
Ternary quantization	1
resource requirements	1
Low bit quantization	1
NukeBERT pretrained weights	1
Nuclear Question Answering Dataset (NQuAD)	1
non-annotated data	1
highly matured literature	1
surpassing human performance	1
average 88\% for NN	1
utmost accuracy	1
average 82\%	1
worse case	1
multi-forward prediction parameters	1
achieved accuracy scores	1
dissimilar backgrounds of playing experiences	1
exploratory feature analysis and tuning hyper-parameters	1
match outcome	1
named entities	1
query intent (i.e. store lookup	1
store location	1
say a location and a non-location	1
Target store locations	1
new state of the art accuracy	1
admissible actions	1
simple	1
combinatorially large action space	1
https://github.com/ tensorflow/tpu/tree/master/models/official/mnasnet/mixnet	1
<600M FLOPS	1
typical mobile settings	1
new state-of-the-art 78.9% ImageNet top-1 accuracy	1
MnasNet [26] (+1.3%), ProxylessNAS [2] (+2.2%), and FBNet [27] (+2.0%)	1
ShuffleNetV2 [16] (+3.5%)	1
(ImageNet top-1 accuracy +4.2%)	1
multiple kernel sizes	1
better accuracy and efficiency	1
benefits of multiple kernel sizes	1
analytical and empirical perspectives	1
rationality	1
substantial improvements (about 16.0\% relative improvement on average)	1
final embedding	1
weighted sum of the embeddings	1
reasons of its effectiveness	1
Bitfusion baseline	1
possible reached speedup	1
4 percentage points	1
error gain	1
small SRAM size	1
0.5 percentage point increase	1
energy saving	1
maximum possible speedup	1
80\% and 64\%	1
1.5 percentage point increase in error	1
12x	1
8x	1
optimization potential	1
hardware efficiency and inference error	1
optimal compression method parameters	1
application constraints	1
hardware model	1
Transformer performance	1
fine-grained look	1
log-average Miss Rate (MR) of 29.74 %	1
good generalization ability	1
best basis	1
improved annotations	1
recently released annotations	1
recently published improved annotations	1
reference DCNN	1
one reference	1
higher robustness	1
channel boosting	1
spatial exploitation, depth, multi-path, width, feature-map exploitation	1
seven different categories	1
intrinsic taxonomy	1
depth and width of architecture	1
spatial and channel information	1
architectural innovations	1
powerful learning ability	1
exemplary performance	1
ground truth cluster labels	1
better intra-cluster and inter-cluster distances	1
Normalized Mutual Information	1
4%-15% improvement	1
3%-11% improvement on Accuracy	1
semantic categories of data	1
EEG topography	1
wide range of time and frequency domain features	1
electroencephalogram (EEG ) time-series information	1
over-fitting uncertain facial images	1
subjectiveness	1
ambiguous facial expressions	1
first convergence guarantee	1
$\epsilon$-first-order stationary point	1
iteration and sample complexity	1
convergence properties	1
large number of possible trajectories	1
exact gradients	1
realized MDP	1
stochastic policy gradient	1
one step	1
97.30 F1	1
95.43 F1	1
91.96 F1 on	1
GCDT	1
ubiquitous word embeddings (Glove)	1
https://github.com/PencilAndBike/Single-DARTS .git	1
essential point	1
network weights and architecture parameters	1
zeroes and poolings	1
small search costs	1
http://www.github.com/viplabB	1
$mAP$ of 5.5% and 47.1%	1
$5.9\times$ faster	1
$2.5\times$ faster	1
latency of 16 milliseconds	1
size greater than 10k$\times$10k	1
highly inefficient and computationally expensive	1
pertinent information	1
smaller sizes	1
varying scales	1
stopping and early stopping environment	1
terms of accuracy and Information Transfer Rate	1
communication rate	1
certain criterion	1
stimulation sequence	1
stopping)	1
Signal-to-Noise Ratio (SNR)	1
a.k.a. iterations	1
multiple stimulation sequences	1
P300 evoked potential	1
electrical responses	1
additional artificial outputs	1
control commands	1
user's brain activity	1
continuous minimization problem	1
image discrete identity	1
overall precision, recall, and F1	1
patterns in performance	1
TMR metrics	1
weak spot	1
multiple entity types	1
type-confusable mentions	1
token/type combination	1
whose tokens	1
tough mentions	1
Tough Mentions Recall (TMR) metrics	1
macro-F1 score of 0.83	1
better BLEU scores	1
ranks 15th	1
around 95 million	1
data privacy problems	1
242K identities	1
WebFace260M track	1
InsightFace track	1
limited knowledge	1
classical setup	1
sample efficiency and modularity	1
technical and organizational constraints	1
growing subfield	1
37 times fewer parameters	1
relative perplexity of 1.59	1
BLEU score of 63.8 and a METEOR score of 83.0	1
T5 achieving slight edge	1
faithfulness metrics	1
faithfulness and relative perplexity	1
naturalness and faithfulness automatically	1
5 metrics	1
voice message	1
standard induced alignments	1
word alignment error rate	1
wrong alignments	1
fixed player	1
unstable and suboptimal behavior	1
target values	1
empty	1
expert example buffer	1
bad, neutral or good state	1
value of a state from {-1, 0, 1}	1
state values and action advantages	1
30% contaminated data	1
CAE+)	1
combination of reconstruction and classification errors	1
different strengths	1
data labels	1
data feature space	1
machine learning model's test error	1
part-whole information	1
source representation	1
pre-determined size	1
\textsc{CapsNMT}. \textsc{CapsNMT}	1
promising customization capabilities	1
informative summaries	1
aspect and/or sentiment	1
specific user needs	1
opinion summary	1
summarization time	1
gold-standard summaries	1
novel spatial and temporal consistency losses	1
deep spatial and temporal features	1
grid cell	1
object category and motion information	1
motion behavior	1
environmental states	1
new state-of-the-art WSOD results	1
consistent spatial supervision	1
different transformations	1
bounding boxes	1
object-level labels	1
window size	1
length prediction errors	1
input lengths	1
average translation results	1
3.22 points	1
reference ones	1
output lengths	1
certain window size	1
random noise	1
exact target sentence lengths	1
length-aware positional encoding (PE)	1
output sequence lengths	1
limited modeling	1
consistent evaluation metrics	1
high-quality transcription results	1
individual instruments	1
music transcription difficult and time-consuming	1
low-resource''	1
fine-scale pitch and timing information	1
musical notes	1
higher overall image quality	1
detailed texture	1
much lower UFLoss value	1
higher SSIM	1
comparable NRMSE	1
faithful contrasts	1
Quantitative metrics	1
improved overall image quality	1
finer textures	1
high-order statistics	1
perceptual similarity	1
reconstruction fidelity	1
TF-IDF weightings	1
WordNet sense embeddings	1
two different contexts	1
F1 score of 94%	1
+8%	1
F1-score of 50%	1
F1-score of 61%	1
Task-1)	1
0.802 ms	1
average retrieval time	1
0.864	1
mean average precision above 0.857	1
free curves	1
size and shape variation	1
histopathological whole slide images (WSIs)	1
auxiliary diagnosis information	1
IMF metric	1
state-of-the-art VLP performance	1
visual relation	1
specialized characteristic of each objective	1
visual relation and inter-modal alignment	1
mean absolute performance difference of 63% between repeated and non-repeated data	1
test-time answers	1
60-70%	1
competencies	1
full picture	1
single aggregated test set scores	1
novel answers	1
completely novel questions	1
novel question formulations	1
simply memorizing questions	1
number of competencies	1
tweets data	1
macro F1-score of 90.59	1
second place (2nd)	1
OffensEval-2)	1
6.6 points	1
0.5 false positive per image	1
69.1 sensitivity	1
3.9 points	1
z direction	1
final Top-1 accuracy	1
pretrained weight	1
shallow one	1
several interesting yet previously unknown properties	1
good representations	1
of73.97% and EM score of 64.95% on	1
high probability	1
short answerlength	1
15.16%	1
start-index output	1
hardware-friendly	1
Differentiable Dynamic Quantization (DDQ)	1
dynamic range (minimum and maximum discrete values) and stepsize (interval between discrete values	1
precision (bitwidth)	1
many tedious hyper-parameters	1
characteristic lengthscales	1
sample path families	1
sample paths	1
expectation operator	1
integral	1
finite dimensional distribution	1
covariance function (covariance matrix)	1
mean function (mean vector)	1
infinite-width cases	1
proofs	1
tensor nodes	1
$\alpha_{i}$ in the product	1
infinite limit of at least one of the bond dimensions	1
width of each model	1
infinite-width limit	1
new state-of-the-art detection performance	1
multiple anchors/features	1
corresponding features	1
bag	1
representative anchors	1
anchor bags	1
two pillars	1
single input	1
additional inputs	1
86.9519% score	1
feature misalignment issue	1
finer segmentation results	1
traditional MPC	1
disturbance distributions	1
safer therapy decisions	1
optimal therapy decisions	1
full state information	1
MPC-computed demonstrations	1
neural-network insulin policies	1
unified generative formulation	1
sentiment class indexes	1
pointer indexes	1
subtasks	1
opinion terms	1
corresponding sentiment polarities	1
orders of magnitude	1
running and prediction times from minutes to milliseconds	1
tens or hundreds	1
best machine learning pipeline	1
description embeddings	1
reasonable classification performance	1
AutoML performance	1
computation time from minutes to milliseconds	1
dataset and function descriptions	1
distribution ofelongation time	1
effective production rate	1
translation efficiencyand the accuracy	1
sequence length	1
elongation time islog-normal distribution	1
translation elongation time	1
available ribosome number	1
molecular level	1
BiDAF and BERT QA baselines	1
QG-generated data	1
existing articles	1
new state-of-the-art performance w.r.t	1
QA training data	1
e.g., BLEU)	1
traditional evaluation metrics	1
two semantics-enhanced rewards	1
given answer	1
4.4\% on average in four	1
student model capacity	1
KD's limitations	1
Teacher's Predictions (PTP)	1
Shuffled Parameter Sharing (SPS)	1
smaller in absolute size	1
teacher model's level of performance	1
47*	1
energy-efficient solutions	1
much more efficiency	1
computation and memory-intensive processing patterns	1
https://sites.google.com/view/goalconditioned-il/.	1
available expert trajectories	1
state-space	1
many goals	1
different reward	1
wide range of configurations	1
considerable supervision	1
desired configuration	1
desired task	1
pre-trained Word Embeddings	1
state-of-the-art vector representations	1
morbidity types	1
common healthcare tasks	1
patient's health state	1
clinical results, images	1
ever-increasing number	1
animation-ready	1
pre-defined mesh topology	1
key points	1
large deformation	1
artifacts and self-intersections	1
pre-trained PCA space	1
registration result	1
parametric mesh representations	1
detailrich implicit functions	1
good ends	1
plausible face deformations	1
advantage of 3DCaricShop	1
rich annotations	1
comparative model performance	1
insignificant training cost	1
coreference information	1
entity annotations	1
modelling limitations	1
long sequences	1
long term ones	1
short term predictions	1
predictions;(iv)	1
sequences of poses in parallel	1
long term elements	1
less computational intensive	1
previous predictions	1
disentanglement scores	1
mathematical understanding	1
global content	1
minor spatial variations	1
resulting spatial content control	1
random noises	1
content feature vectors	1
challenging weakly supervised action segmentation problems	1
discriminative prototypes	1
true function	1
effective kernel	1
hierarchical DGP structure	1
low fidelity data	1
synthetic and high dimensional data	1
approximate marginal likelihood	1
lower-fidelity data	1
implicit functions	1
conditional DGP	1
marginal prior	1
fixed lower fidelity data	1
latent GPs	1
plenty of low fidelity observations	1
hierarchical structure of DGP	1
compositional character	1
diverse criteria	1
bigram features	1
multiple segmentation criteria	1
continuous characters	1
limited memory usage	1
complete face representation	1
requirement	1
powerful generative capability	1
benefits of its training stability	1
source image	1
face representation	1
Face Swapping (or MegaFS for short)	1
enough and representative face swapping images	1
politics, economics	1
DeepFake threats	1
positive applications	1
\url{https://github.com/PaddlePaddle/Research/tree/master/KG/	1
absolute improvement of 21.0% in H@10	1
contextual meanings	1
sequences of entities and relations	1
contextual nature	1
different graph contexts	1
intrinsic contextual nature	1
symbolic entities	1
orders ofmagnitude faster	1
entailmentrelation	1
thresholded attention maketoken-level predictions	1
training dataexplicitly	1
unnecessary information and noise signals	1
entire context information	1
previous context	1
already learned	1
particular information	1
F1 score of 0.8730	1
subset of the highest performing features	1
variety of lexical features	1
thebest results	1
forbetter NER results	1
word sequence information	1
sequence of input characters	1
official competition deadline	1
additional results	1
n-gram features	1
first place	1
using audio features	1
High classification performance rates	1
feature values	1
node and edge-level features	1
temporal citation counts	1
genealogical relations	1
Temporal importance	1
novel node and edge-level features	1
knowledge structure	1
information concepts	1
hidden or unpublished connections	1
27.52% which is 5.12% better	1
mean Average Precision (mAP) metric	1
superiority of the performance	1
generated proposals	1
start and end of each action	1
fifty percent cases	1
similarities and dissimilarities	1
resulting values	1
decision result	1
vast quantities of knowledge	1
sparse combination	1
thousands	1
minor losses	1
greater than 1000x improvements	1
significant algorithmic and performance challenges	1
per-example basis	1
et, fi, hu)	1
English or a small number	1
network output	1
multi-level information	1
expressive representations	1
global contextual relations	1
generated representations	1
diverse spatial context	1
local and global levels	1
local pairwise importance	1
two separate tasks	1
real test data	1
10^{-3}$ {\mu}m$^{-1}$ and 0.932	1
$1.16 \times	1
RMSE and SSIM	1
structural similarity (SSIM ) index from 0.625 to 0.920	1
$1.21 \times	1
10^{-3}$ {\mu}m$^{-1}$	1
$2.55 \times	1
root-mean-square error (RMSE)	1
synthetic test data	1
$100^\circ$	1
real scanned chlorella data	1
multi-category data	1
synthetic ellipsoid data	1
sufficient real data	1
limited angle data	1
certain tilting angles	1
high attenuation	1
limited angular range	1
1.9 F1 points	1
4 million more examples	1
prior results	1
associated research documentation	1
joint goal accuracy of 53.97%	1
unseen slot types	1
possible values of slots	1
descriptions of slots and services	1
Schema-Guided State Tracking track	1
notable improvement	1
76.096%	1
Top1 accuracy of 66.512%	1
batch size of 2	1
wide generalizability	1
robust stability	1
BN, Instance Normalization (IN), Layer Normalization (LN), GN, and Positional Normalization (PN)	1
different batch sizes	1
noisy nor confused statistic	1
number of feature instances	1
hyper-parameter G	1
channel, height and width dimension	1
noisy/confused statistic calculation	1
extra computation	1
new trainable parameters	1
i.e., GPU	1
extreme large batch sizes	1
small batch sizes	1
medium and large batch sizes	1
effective solutions	1
ranked second	1
macro F1-scores of 0.216, 0.235, 0.054, and 0.043	1
2 to 20	1
radiomic features	1
fewer radiomic features	1
accuracy was 100%	1
8 radiomic features	1
best classification results	1
2, 4, 8, 12, 16 and 20 highly ranked features	1
optimal number of features	1
validity ofthe claims	1
significanteigen-values	1
raw Fisher Discriminant Ratio (FDR)	1
less complex features	1
opening, stanzas and closing --	1
simpler but wisely chosen smallnumber of features	1
musical content	1
52% fewer	1
83% fewer parameters	1
~1% better mIOU	1
96% fewer parameters	1
neural architecture representations	1
searchable features	1
design space	1
neighbor point	1
weak representation power	1
neighbor-kernel correlation	1
kernel point	1
kernel relationship	1
cutting-edge performance	1
significant decreases	1
$p<0.05$	1
21 of the 26	1
$3.5$ times the number of parameters	1
traditional training and transfer settings	1
two suitable baselines	1
total duration of over 65 hours	1
84181 audio recordings	1
top-1 error rate of 24.0%	1
top-1 error rate of 2.45% and 15.80% within 10 minutes	1
one epoch	1
extremely fast convergence speed	1
near one-hot distribution	1
tractable variational lower bound	1
intrinsic properties of architecture	1
55{\%}	1
39{\%}	1
final f1-score	1
fifth out of ten	1
tweet input vector representation	1
detailed experimentation results	1
named entities (NEs)	1
1000 images	1
makeup suggestions	1
general colorization	1
colorization results	1
privacy configuration	1
utility of BERT	1
privacy and utility implications	1
even text embeddings	1
medically critical visual details	1
better quantitative performance	1
3rd dimension	1
synthetic and real chest CT images	1
2-dimensional low-dose CT images	1
3 dimensions	1
MATLAB code	1
Gaussian Linear Unit, Parametric Deformable Linear Unit, Soft Root Sign (SRS)	1
Parametric ReLU , ELU, Adaptive Piecewice Linear Unit, S-Shaped ReLU , Swish , Mish, Mexican Linear Unit	1
activations	1
ReLU s	1
F1 score of 0.7138	1
digitized images	1
color representation	1
clinical deployment phase	1
laboratory conditions	1
accuracy and decoding speed	1
ASR output semantically	1
private features	1
shared semantic representations	1
BERT-large	1
accuracy within 1% of the floating-point baseline	1
mathematical aspects	1
high throughput integer instructions	1
color corrected underwater images	1
Underwater vehicles perception	1
accuracy and the computation cost	1
pretrained weight vectors	1
56.04 BLEU	1
consistent results	1
66.21 BLEU	1
set of RDF triples	1
aconsistent baseline	1
Python code style	1
53,62% of accuracy	1
asentence embedding	1
thegenerated answers	1
2% with Test F1 to 96.5	1
60% and performance	1
large one	1
multiple semantic scales	1
different visual concepts	1
\emph{similar}. %	1
quite \emph{different}	1
small semantic scale	1
much smaller one	1
``Elk''	1
large semantic scale	1
``Plants''	1
``Animal''	1
multiple scale problem	1
higher flexibility	1
Larger dynamic range	1
basic quality	1
new fundamental characteristic	1
GLGE publicly available	1
GLGE-Easy, GLGE-Medium, and GLGE-Hard	1
task difficulty	1
$70\%$ performance gain	1
competitive or better performance	1
implicit feedback matrix	1
critical role of smoothness	1
empirical successes	1
theoretical underpinnings	1
high performance improvements	1
Recurrent Rationals	1
self-regularized version	1
higher learning capacity	1
fixed activation functions	1
computational responsibility	1
standards	1
model choice	1
persistently superior performance	1
significant differences	1
Anchored Ensembling	1
Concrete Dropout NN	1
two different approximations of Bayesian NNs (BNNs)	1
distinguishing traits and particular strengths	1
much of the recent progress	1
extracted dimensions of LDA	1
early and late exits	1
performance imbalance problem	1
late exits	1
significantly worse	1
efficiency-performance tradeoff	1
certain resources	1
superior performances	1
point cloud scans	1
different RIFs different importance	1
rotation invariant point cloud features	1
Spherical Signals (SS), Individual-Local Rotation Invariant Features (ILRIF) and Group-Local Rotation Invariant features (GLRIF)	1
three kind of Rotation Invariant Features (RIFs)	1
viewpoints or motorcycle types	1
common defect	1
acceptable performances	1
ranking second	1
mAP 29.69	1
larger inputsize	1
speed of 21 fps	1
theoriginal SSD	1
TSE and TSESE conditions	1
three conditions, i.e., text (T), text+SHAP explanation (TSE), and text+SHAP explanation+source and evidence (TSESE)	1
good performance (accuracy: 0.938; areas under the curve: 0.985	1
good performance (accuracy: 0.972; areas under the curve: 0.993)	1
984 claims	1
Transformers)	1
misinformation	1
associated risks	1
best current state-of-the-art of 7.49% (25% improvement)	1
5.68% log-average miss rate	1
commonly used augmentations	1
low object resolution	1
higher detection performance	1
direct bounding box predictions	1
object center and scale	1
pedestrian representations	1
good invariance properties	1
semantic quality	1
invariant representations	1
semantically meaningful	1
additional capability	1
partial or extra label annotations	1
uncertainty of labels	1
positive, negative, or unknown	1
state of the labels	1
masked labels	1
set of target labels	1
visual features and labels	1
complex dependencies	1
objects, attributes or other entities	1
performance on news plateaus	1
time and space	1
breakthrough ideas	1
event-level predictions	1
1D-DETR	1
frame-level predictions	1
good trade-offbetween speed and accuracy	1
constraint parameters	1
constrained measures	1
potentialfor accuracy gains	1
significantly differentfrom its unconstrained counterpart	1
constrained measure	1
less than 10-15% oftime-series length	1
constraint parameter	1
DTW and LCS	1
global constrainscan	1
Longest Common Subsequence	1
dynamicprogramming, Dynamic Time Warping (DTW )	1
tworepresentative time-series distance/similarity measures	1
constrainedmeasures	1
quadratic timecomplexity	1
appropriatedistance/similarity measure	1
repeatedmeasurements in time	1
series of values or events	1
5-10\% error reduction	1
CTCpredictions	1
69.2% accuracy	1
RMN captures	1
various linguistic dimensions	1
power of RNN	1
excellent result	1
realistic serverless settings	1
statistical and systems challenges	1
commercial competition	1
regulation restrictions	1
user-side privacy concerns	1
massive amount of real-world graph data	1
state-of-the-art level representations	1
TA activity	1
median AUC of 0.84 (95% CI: 0.80 to 0.88	1
TA envelope	1
median area under the operating characteristic curve (AUC) of 0.95 (95% confidence interval, CI: 0.93 to 0.98	1
multiple amplitude and spectral features	1
short-duration, high-voltage activity (bursts)	1
Trace alternant (TA)-a characteristic pattern	1
suriin ang performance	1
ay mataas na compute and memory requirements kaya	1
ay gipit	1
high compute and memory requirements	1
additional supervisions	1
terms of both computation and memory	1
different complexities and scales	1
77{\%}	1
accuracies of 81{\%}	1
projected data	1
better accuracies	1
important joints, frames and features	1
length and orientation	1
diversity of the data	1
model layers and input data	1
clinic knowledge	1
good consistency	1
sample distribution	1
20% data	1
678 videos	1
6,836 images	1
progressively labeled data	1
final annotations	1
confident labels	1
label correlations information	1
complicated features	1
expensive annotations	1
complex feature behaviors	1
promising test mAP of 0.45	1
high-quality segmentation mask	1
Hebrew MD	1
shared-task results	1
single disambiguated path	1
sequence of indices	1
symbolic knowledge	1
submitted results	1
translation tasks	1
design effort	1
similar resource constraint	1
extensive evaluations	1
design-time effort	1
different levels of quantization	1
accuracy-performance trade-off	1
number of bits	1
concept of weighted entropy	1
, 1%)	1
tight accuracy loss constraint	1
low-cost quantization	1
tight resource constraints	1
results really close	1
interesting transfer abilities	1
best single-modality detection results	1
GAN generated images	1
real thermal data	1
less than 50\% of available real thermal training data	1
limited amount of labeled thermal pedestrian images	1
realistic thermal versions	1
78% and 39% attack accuracy	1
average attack accuracy of 75% and 41%	1
6 and 20 classes	1
IMDB Movie Reviews	1
average attack accuracy of 97%	1
unintended features	1
constrained computational resources	1
reduced training time	1
medical knowledge	1
corresponding support sentences	1
large-scale training data	1
accuracy of 98.4%	1
features of interest	1
common attributes	1
grand average	1
open set	1
infinite classes	1
longer dependencies	1
two types of features	1
linear sequences	1
100% vehicle collision rate	1
end-to-end safety impact	1
3D-printed	1
physical-world realizable	1
victim positions	1
different object types	1
90% success rate	1
non-differentiable cell-level aggregated features	1
much security guarantee	1
security and safety critical	1
{\textgreater}80{\%}in the F1 score	1
20 POS tags	1
{\textgreater}90{\%}	1
theaccuracy score	1
0.94{\%}	1
1.6{\%} and 2.7{\%} higher	1
accuracy score	1
93.36{\%}	1
automatically learnt features	1
conversational words	1
exclusive tags	1
accuracy by approximately 10%	1
contextual meaning	1
Manually extracting features	1
content and context features	1
people's opinions	1
sheer volumes	1
quality of posts	1
news and views	1
dense visual features and sparsesemantic representations	1
global temporal structure	1
local contextual temporal knowledge	1
temporal informationamong video frames	1
memory and time	1
ST gradients	1
discrete variables	1
back-propagate gradients	1
Straight-Through (ST) gradients	1
NAS efficiency	1
computationally-efficient	1
binary and orthogonal constraints	1
Orthonormal Encoder (OnE) and Orthogonal Encoder (OgE) respectively	1
relaxed version	1
strict orthogonal constraint	1
binarize input data	1
dimensionality)	1
novel formulations	1
binary quantization loss	1
dropout uncertainty	1
new measure of uncertainty	1
learned \textit{mutually}	1
necessarily\textit{fixed}	1
discriminative and relevant features	1
\textit{collaborative}	1
mapping of interest)	1
proposed \textit{fixed} VGG loss	1
ImageNet images distribution(\textit{e.g.,} satellite images	1
distribution far	1
generated high resolution images	1
errorbetween	1
objective loss function	1
large upscaling factors	1
finer texture detailswhen	1
precision and efficiency	1
mean computation time of 0.1 seconds per test frame detection	1
Average Precision (AP) of 91%	1
fusion of image and temporal motion cues	1
gestures and skill level	1
promising experimental results	1
consistent accuracy improvement	1
label aware	1
theoretical upper bound	1
quite different terminologies	1
precise and abundantextractions	1
positive samples	1
path-level features	1
shortest dependency paths	1
higher-level features	1
8.4 BLEU and 2.3 BLEU	1
24.3 BLEU	1
55.0 BLEU	1
translation information	1
F1 of 87.18	1
new state of theart performance	1
confident outputdistributions	1
unitary transition matrices	1
faster convergence rates	1
orthonormality of CNN parameters	1
less running time per iteration	1
Cayley SGD	1
Cayley ADAM	1
momentum	1
orthonormality constraints	1
complex preexisting RL code	1
search efficiency in terms of time and compute	1
replay data	1
thehighest F-score value	1
arelatively large margin	1
Thestate-of-the-art performance	1
multi-scale context	1
1/9 and 1/2000 parameters	1
\href{https://github.com/ZitongYu/CDCN}{https://github.com/ZitongYu/CDCN}.	1
6.5% HTER	1
0.2% ACER	1
boosting performance	1
powerful network structure (CDCN++)	1
robust modeling capacity	1
intensity and gradient information	1
intrinsic detailed patterns	1
dynamic features	1
different illumination)	1
centrality-aware user representations	1
interaction data	1
limitation and sparsity	1
group and user representations	1
preference aggregation strategy	1
users' personal preferences	1
non-uniform influences or weights	1
personal preferences	1
people's daily social life	1
spatial-temporal relationships	1
weighted cross-entropy losses	1
off-road predictions	1
nearby trajectories	1
physical relationships	1
possible motions	1
GPT2 perplexity	1
lexical quality	1
lexical distance	1
syntax quality	1
F0.5 by 3.7 points over the best result	1
highest reported score	1
Shared Task	1
random initializations	1
$F$ score	1
considerably lower amount of labeled data	1
substantial amount of labeled data	1
expected average overlap (EAO) metric	1
bounding box overlap	1
first frame	1
sequential properties	1
tabular representation	1
input data scarcity	1
safety and reliability requirements	1
quicker processing time ($\approx$ 165 ms)	1
85.3\%)	1
high computational cost ($\approx $ 402 ms)	1
best accuracy (up to 86.0\%)	1
algorithms' performance	1
-10 dB to 30 dB SNR	1
3.5$\times$ speed up (Galaxy N10+)	1
run-time memory footprints	1
8.3$\times$ reduction	1
less than -0.5 BLEU	1
11.8$\times$ smaller model size	1
statistical property	1
, under 3 bits	1
extremely low number of bits	1
Transformer weights	1
vastly different contributions	1
inference computations	1
given number of quantization bits	1
memory overhead	1
heavy computation load	1
course and severity	1
edge and node features	1
single-cell RNA sequencing data	1
additional edge feature	1
Forman-Ricci curvature	1
new edge features	1
highest value of its perplexity	1
semantic labelling	1
semantic classes	1
similar labels	1
purely semantic data	1
appearance probability	1
semantic for example)	1
similar behaviors	1
eld of work	1
scaling overhead not exceeding 8%	1
16 IPUs	1
higher compute power	1
higher communication bandwidth	1
30x faster	1
computational architectures	1
sharp convergence guarantees	1
communication-efficiency property	1
lower dimension	1
count sketch	1
Communication complexity	1
increase in dice score of up to 2 points	1
Liver and lesion segmentation data	1
cascaded two- and three-dimensional	1
previous errors	1
noisy false-positive predictions	1
higher target recall	1
good balance between accuracy and computation cost (FLOPs)	1
O(NK)	1
quadratic O(N2) complexity	1
query features	1
high-resolution spatial input	1
competitive FID score of 11.3	1
fool rate of 34%	1
fool rate close to 50%	1
different magnification factors	1
various noise levels	1
pure Gaussian noise	1
image Super-Resolution	1
accuracy over 90%	1
Mathematics Word Problems	1
POS (Part of Speech) tags	1
mathematical word problems	1
real-time multi-object speed	1
3X faster multi-object run-time	1
91.0%)	1
83.7% J&F), DAVIS 2017 (83.0%)	1
different complexities	1
single object	1
multiple times computing resources	1
detection capacity	1
Average Precision (AP) values of 0.8479, 0.7161 and 0.9085	1
event images	1
unique ID number	1
BBoxs of the current and previous video frames	1
Bounding Box (BBox) results	1
common weakness	1
baseline performance report	1
adversarial life cycle	1
differentiated contributions	1
inter-modal	1
differentiated context preference	1
sequential and feed-forward structures	1
accurate emotional predictions	1
differentiated multi-modal emotional behaviors	1
Several asymptotic properties	1
high-dimensionaldata	1
better trade-offbetween sensitivity	1
imbalanced ratio ofsample sizes	1
high-dimensionalsetting	1
imbalanced data issue	1
decision boundarytowards	1
largersample size	1
low-sample size data	1
thehigh-dimensional	1
behavioral and physiological data	1
biometric and behavioral data	1
attention level	1
status along time	1
learned word embeddings	1
rare word	1
recent results	1
state-of-the-art accuracy 71.57\%	1
jointly answer, question and image representation	1
complex cross-modal relations	1
different attack methods	1
classification boundary	1
anchor of triplet loss	1
Triplet Loss (AT$^2$L)	1
noisy objects	1
discriminative embedding space	1
novel concept of inter-image separability	1
input orders	1
salient and common visual patterns	1
group of relevant images	1
optimal gap of 0.004% for TSP50 and 0.39% for TSP100	1
improved performances	1
TSP training solutions	1
combinatorial TSP	1
many industry problems	1
efficiently NP-hard problems	1
better heuristics	1
cutting planes	1
83.5 and 88.4 f1 CONLL score	1
two levels of word and phrase	1
CONLL 2003 score	1
previous state of the art results	1
semantic Categories	1
cascade form	1
greater likelihood	1
latter's first moments	1
posterior and marginal distributions	1
modern DGNs	1
Continuous Piecewise Affine (CPA) property	1
(Amortized)	1
posterior and likelihood expectation	1
Variational Autoencoders (VAE s)	1
one or more modalities	1
expressed sentiment	1
worst-case suboptimality	1
improved practical benefits	1
log factors	1
finite-time regret bound	1
best arm	1
regret and sample complexity	1
existing baselines (UCB and TS )	1
exploration efficacy of TS	1
arm	1
true mean reward	1
doubly adaptive TS	1
optimal in the worst case	1
sequentially collected data	1
good statistical properties	1
inference accurately	1
non-iid data	1
data collected so far	1
true mean reward of each arm	1
$20\%$ occlusion	1
around $22.25\%$ increase	1
$l_1$-norm and the squared $l_2$-norm regularized least-squares estimates	1
image pairs	1
occlusion error vectors	1
DFVs	1
linear span of an occlusion error dictionary (OED)	1
class dictionary (CD)	1
linear span	1
original occlusion-free image	1
SDBE	1
deep feature vector (DFV)	1
{``}checkpoint agreement{''}.	1
recent monolingual data	1
nature	1
higher noise levels	1
genuine)	1
another class	1
images or data points	1
bare minimum computation	1
costing lives	1
incredible pace	1
everyday lives	1
practical impacts	1
one 1080Ti	1
0.5 and 4 GPU hours	1
trainability and expressivity	1
flexible and superior trade-off	1
network's test accuracy	1
training and any label	1
spectrum of the neural tangent kernel (NTK)	1
drastic portion of the search cost	1
ResNet 85%, FCN 75%, CNN 72.5% and MCDCNN 28.5%	1
nearest centroid SoftDTW classification 77.5%, Deep Learning	1
Novice, Intermediate or Expert	1
VR data	1
multiple clinical experience levels	1
clustering result	1
Weighted Graph Node Clustering via Gumbel Softmax (WGCGS for short)	1
ongoing research results	1
graphs	1
one graph or more graphs	1
morphology and semantics	1
FastText word embeddings	1
second one	1
out-of-vocabulary entries	1
character level information	1
character level embeddings	1
DPG in performance	1
great extendability	1
complex strategiescompete	1
morelocal optima	1
action-Q-value space	1
anapproximated policy gradient	1
Sampled Policy Gradient (SPG)	1
81.53%	1
81.03%	1
87.6%	1
Dice Scores of 91.19% whole tumor	1
less GPU resources	1
higher Dice scores	1
morphological indicators	1
time and effort	1
utterance embeddings	1
clustering accuracy	1
10% gain	1
seed data	1
90% sensitivity and 100% specificity	1
84% higher	1
average referencemontage	1
normalized waveletpower	1
short washout period	1
eyes closed and eyes open conditions	1
resting, 21-channel EEG	1
properties ofelectroencephalograms (EEG s)	1
mounting evidence	1
better parameter utilization	1
specific hierarchy levels	1
hierarchically organized labels	1
one or more labels	1
BERT 's over-parameterization and under-utilization issues	1
certain aspects of BERT	1
fine-grained grammaticality distinctions	1
near-human performance	1
think I ate	1
fine-grained view	1
high segmentation performance	1
annotation effort	1
maximum Dice value	1
different acquisition settings	1
14 and 24	1
Monte Carlo samples	1
overall uncertainty measure	1
target anatomy	1
manually label images	1
real cost	1
data and ground truths	1
millions of unlabeled examples	1
farhigher performance	1
much higher performance	1
costs(power, latency, silicon area, MAC count	1
higher inference	1
original Sliding Shapes	1
200x faster	1
13.8 inmAP	1
two different scales	1
amodal RPN	1
3D and colorfeatures	1
geometric features	1
objectness from geometric shapes	1
3D object boundingboxes	1
fullextent	1
metric form	1
F1-measure	1
morphological and the orthographic information	1
implicit knowledge	1
vanillapolicy gradient, TRPO and PPO	1
theposterior variational parameter distribution	1
competitive GEC quality	1
grammatically incorrect text	1
true corrections	1
grammatically incorrect ones	1
human-generated and synthetic text	1
many different tasks	1
realistic texts	1
terms of various metrics	1
previous works and competitive baselines	1
less important modalities	1
much useless information	1
dense Gaussian sampling	1
entry sampling	1
extensive numerical results	1
unique limit point	1
Kurdyka-Lojasiewicz property	1
global convergence and worst-case complexity bounds	1
alternating minimization	1
first- and second-order variants	1
Grassmann manifold	1
original matrix	1
recovery problem	1
algebraic variety	1
nonlinear structure	1
greatly improved efficiency	1
exceptionalbalance between computation time and tightness	1
speed-tightnesstrade-off	1
Asingle parameter	1
monotonicity and continuity constraints	1
DTW boundary condition	1
similar computationtime	1
popular Keogh lower bound	1
new class of lower bounds	1
pruning effectivenessfor NN-DTW	1
warping window	1
smaller warping window sizes	1
tight	1
DTW warping window sizes	1
existing lower bounds	1
different trade-offs between computation time	1
Differentlower bounds	1
training set size	1
lower boundsearch	1
costly DTW computations	1
effective and tight lower bound	1
quadratic complexity	1
expensive tocompute	1
forecasting, regression	1
effective lower boundsfor Dynamic Time Warping (DTW ) distance	1
uppercased (+5.88 point)	1
0.42 points	1
Unified Case LM (UniCase)	1
coverage maximization	1
mean of feature	1
catastrophic forgetting issue	1
catastrophic forgetting problem	1
single particular task	1
either static or dynamic graph settings	1
Jaccard indices	1
75% for training and 35%	1
respective semantic map	1
output channels	1
one channel and six	1
six channels	1
existing artifacts	1
skin lesion boundary	1
F1 and especially Recall	1
important information	1
future and previous words	1
bidirectional structures	1
rules and linguistic characteristics	1
unstructured data	1
Cyber Security data	1
discriminative and robust feature embeddings	1
different levels (i.e., scale, region, and task	1
robust re-id features	1
high computational overhead	1
close or very far	1
spectral densities	1
quadratic terms	1
single-channel	1
well known Spectral Mixture (SM) kernel	1
spectral domain	1
time and phase delayed components	1
cross channel dependencies	1
multiple output variables (also called channels, tasks	1
ASR posterior probabilities	1
ASR recognition errors	1
weighted prediction	1
query point	1
local GP models (LGP)	1
online approximation	1
NYU Depthdataset	1
overall learning efficiency	1
role of sparsity	1
estimated structured labels	1
three labeled images).Specifically	1
competitivedetection accuracy	1
extremely labor intensive	1
classification logits	1
retrieval score	1
re-rank predictions	1
ArcFace loss	1
half of the free parameters	1
improvements of 11.1{\%} BLEU	1
1.3{\%} BLEU improvement	1
39.6{\%} BLEU	1
accuracy of 81%	1
possible spelling errors	1
$F_1=0.624$of average	1
char-grams	1
large set of features	1
final mean false error loss of 0.09	1
F1-score of 89.12	1
precision of 77.76, recall of 93,32	1
accuracy of 86.43	1
best of signal processing and statistics	1
sleep irregularities	1
localized time-frequency information	1
30 seconds long epochs	1
similar hand trajectories	1
similar signs	1
96% recognition rate	1
sign labels	1
1.5K	1
top winning solutions	1
different demographics	1
large diversity of signs	1
PSNR of 29.70	1
1.4 times speedup	1
average result	1
0.3 dB in PSNR	1
3.3 times speedup	1
22.5% of its MACs	1
6.8 times and 2.9 times speedup	1
7.5% and 30% of its multiplier-accumulator operations (MACs)	1
0.11dB and 0.28 dB in PSNR	1
Half Instance Normalization Block (HIN Block)	1
above-mentioned metrics	1
network traffic flow datasets	1
thedatasets through measurements of precision, recall, and F1 measure	1
distribution of a certain feature	1
generating random values	1
less population	1
numerical features ofeach class	1
traffic flow patternsand Kernel Density Estimation (KDE)	1
precision, recall, and $\mathrm{F_1}$ measure	1
lot more populated	1
Network Traffic Classifier (NTC)	1
type of management service	1
Propbank benchmarks	1
new state-of-the-art or competitive results	1
linguistic tasks performance	1
Part-Of-Speech (POS) tags, constituent and dependency syntactic parsing, span and dependency semantic role labeling (SRL)	1
multiple linguistic tasks	1
language representations	1
attention diversity	1
fine-grained alignments	1
textual semantics	1
grounded multilingual multimodal representations	1
$1\%$ and $0.3\%$ respectively	1
state-of-the-art pruning results	1
inner network knowledge	1
high-level structure	1
associated computational cost	1
importance of neurons	1
$\ell_1$-norm sparsification	1
fake information	1
current malady	1
improved products quality	1
gains in productivity	1
highly flexible	1
significant cost	1
complex real world images	1
regularisation	1
certain causal structure	1
underlying relationship	1
battery measurements	1
variable dependencies	1
available range	1
Charge capacity, voltage etc)	1
battery parameters	1
electrochemical properties	1
higher energy density	1
nature of the data	1
parliament proceedings and customer service phone calls	1
37.2%	1
past conversational context	1
model uncertainty estimation	1
richness of soft labels	1
increased sensitivity	1
consistent soft predictions	1
3.3%	1
p=0.001)	1
Dice score of 2.0%	1
multimodal brain tumor segmentation challenges	1
multiple sclerosis brain lesion	1
three features	1
traditional Dice loss	1
regression loss function	1
binary predictions	1
soft ground truth labels	1
detrimental approximation	1
single hard label	1
ill-defined	1
contrast	1
Diffusion Wavelets	1
Warping on Wavelets (WOW)	1
multiscale manifold latent structure	1
high-dimensional real-world data	1
recent experiences	1
log space	1
old action samples	1
action samples	1
Sampled Policy Gradient (SPG) and Proximal Policy Optimization (PPO )	1
EEG information	1
normal and abnormal EEG patterns	1
time, frequency or space domain	1
simple architecture	1
large variability	1
normal and abnormal (i.e., artifactual or pathological) EEG patterns	1
high-resolution color images	1
3D scene geometry	1
six measures	1
basic requirement	1
small number of known evaluation measures	1
Evaluation measures	1
distribution over ordinal classes	1
Ordinal Quantification (OQ)	1
highly positive, positive, neutral, negative, highly negative	1
elements in both modalities (visual and sound	1
one modality (visual or audio)	1
bestrepresentation from both LSTM s.	1
common elements	1
one or both modalities	1
different extracted features	1
spatiotemporal knowledge	1
varying electrode order	1
Spatial information	1
distinct window sizes	1
electrode orders	1
varied window sizes	1
0.0316 and 0.0179	1
F1-score of baseline results	1
spotting performance	1
metric F1-score	1
overlap rate	1
one video	1
proposed LTP patterns	1
local temporal pattern (LTP)	1
exact-match accuracy and F1 scores	1
human and baselines	1
56,000 profiles	1
190,000 job titles	1
occupational data mining and analysis problems	1
career trajectory modelling	1
employee churn prediction	1
localization and classification accuracy	1
network architecure	1
part of the image	1
shannon entropy	1
good classification accuracy	1
clean examples	1
Task B.	1
NE features	1
dependency features	1
training confidence values	1
effectiveness of lexical, part of speech, dependency, and named entity (NE) features	1
English Language track	1
Tasks A {\&} B	1
higher diversity	1
failure-revealing test cases	1
large space of test input parameters	1
critical corner-case test scenarios	1
growing capabilities	1
six conference publications	1
trends	1
number ofstandard datasets	1
Dice score of around 86\%	1
mIoU rate of over 99\%	1
precision, recall, Dice score, and mIoU)	1
predicted segmentation results	1
2\% gain	1
new regularization term	1
around 900	1
TV-UNet	1
suitable regularization term	1
570,000 death	1
12 million	1
new constraint target	1
role of conversation context	1
different task objectives	1
$-0.78$ and $+1.23$ in terms of TER and BLEU	1
conservativeness penalty	1
conservativeness factor	1
handengineered domain knowledge	1
medical research	1
higher level of comprehensiveness	1
quality and diversity	1
attention distribution	1
degenerated attention distribution	1
high level of abstraction	1
high ROUGE scores	1
current state-of-the-art equivalents	1
better decision of entailment type	1
premise again	1
model{'}s ability	1
entailment type	1
two sentences (premise and hypothesis)	1
quickly	1
specific predictions	1
discourse-level features or features	1
next word's identity	1
many types of information	1
extent of this performance loss	1
natural spelling errors	1
CRF performance	1
subset of the CRF features	1
weighted average F-scores of 65.62 and 54.16	1
92.30% and 3.48%	1
94.50% and 2.65% on	1
BLEU-4 and Word Error Rate (WER)	1
robust and fault-tolerant	1
different unit error probability (UEP)	1
fault-tolerance(anti-noise ability	1
corresponding continuous MLLP	1
discrete CRS	1
discrete solution	1
continuous version	1
strong expressive ability	1
Concept Rule Sets (CRS)	1
potential risk	1
much better performance	1
accuracy $6$--$7\%$ higher	1
five frequency bands	1
different interpolationmethods (model 2)	1
knowledge of EEG sensorspatial configuration	1
faster convergence time	1
topic coherent	1
corresponding sentiment	1
whose prior knowledge	1
terms of parameter size	1
11.5x to 17.0x smaller	1
12.7x to 29.3x faster than BERT in inference time	1
good trade-off between efficiency and effectiveness	1
search constraints	1
search hints	1
task-independent	1
huge parameter size	1
one (or more) captions	1
checkpoints	1
significant amounts of compute time	1
theacross-cohort prediction accuracy	1
theinfluences of confounding factors	1
models' sub-optimal performance	1
existence ofconfounding factors	1
high-reliability requirement	1
raw input data	1
disease status	1
0.9% mAP	1
1.4% and 2.0%	1
original results	1
78.2% and 74.0% top-1 accuracy	1
fast computations	1
single stage (knowledge	1
different learning capacities	1
laborious and time-consuming	1
Collecting labeled data	1
fundamental drawback	1
logloss of 0.662 and accuracy of 77.1%	1
logloss of 0.195 and accuracy of 93.8%	1
synchronized recordings	1
90.50% and96.6%	1
compression rate of 125X and 200X	1
maximum compression of 26X with SSD512 on GermanTraffic Sign Detection Benchmark (GTSDB)	1
6.7X and 4.9X	1
multiple methods	1
filter weights	1
filtersusing sparsity statistics	1
improved globalthreshold	1
aligned phonetic information	1
magnitude spectrogram	1
phonetic information	1
huge potential	1
term of both of MS-SSIM	1
testing result	1
compression ratio 20	1
better quality	1
compression ratio 80	1
high as 40	1
multi-scale structural similarity (MS-SSIM )	1
99% similarity	1
detail information	1
customized skip connections	1
OCT images	1
speckle noise	1
learned HypE embeddings	1
geometrical translation, intersection, and union	1
positive first-order queries	1
entities	1
translation, intersection and union queries	1
simpler queries	1
intersection and union	1
simple translation operations	1
multi-hop queries	1
hierarchical nature and semantic information	1
query embedding	1
Euclidean space	1
entities and relations)	1
baseline of only	1
Transformer structures	1
character-aware relations	1
generic visual features	1
higher-level comprehension abilities	1
character names	1
multi-modal vectors	1
question embedding	1
text vectorfeature	1
visual tensor features	1
MD-sketch	1
global spatial context	1
multi-dimensional sketch({MD-sketch})	1
activation tensor	1
fiber	1
outer-products	1
spatial location	1
thevisual and textual representation	1
outer products	1
temporal sequence	1
spatial structures	1
Visual Question Answering (VQA)image descriptors	1
drastically different structure	1
4.44% and 3.31% ER	1
mixup augmentation	1
23.29% and 4.94% ER	1
100% of the available labeled data	1
18.02% and 3.25% error rates (ER)	1
Environmental Sound Classification (ESC-10), UrbanSound8K (UBS8K), and Google Speech Commands (GSC)	1
remaining 90\%	1
10% of labeled data	1
unified toxic spans	1
toxic remarks	1
noisy tablet recordings	1
signal modeling performance	1
multi-channel spatial clustering	1
spatial separation performance	1
relatively arbitrary microphone configurations	1
global score	1
dictionary information	1
disease Named Entities (NEs)	1
several related challenges	1
low overhead	1
unnecessary system communication load	1
automatic evaluation results	1
NMT system training architectures	1
remarkably stable	1
different reward function shapes	1
appropriate measure	1
vanishing gradients problem	1
logarithmic form	1
kind of reward function	1
inexact update rules	1
theoretical insights	1
discrete variables/constraints	1
certain $\textit{stationary points}$.	1
iterates of $\texttt{ADMM -Q}$	1
discriminative multi-modalfeatures	1
question-independent kernels andquestion-dependent kernels	1
thetextual and visual relationship	1
multi-modal features	1
visual spatial information	1
high-level textual and visual features	1
volumetric MR data	1
super-resolve	1
anisotropic bicubic interpolation baseline	1
quantitative image metrics	1
anisotropically downsampled versions	1
anisotropic super-resolution	1
high edge fidelity	1
PSNR and SSIM (Structural SIMilarity) metrics	1
factors of 4 and 8	1
in-plane MR image resolution	1
super-resolved version	1
low resolution (LR) images	1
patient discomfort	1
High Resolution (HR) Magnetic Resonance (MR) images	1
thepractical implications	1
learning complexity	1
factorof two	1
computationally demanding	1
significantly reduced computational effort	1
different cutting configurations	1
high as 99% accuracy	1
highest average classification rate	1
cutting configurations	1
three out of four	1
detection accuracies	1
acceleration signals	1
used time series	1
non-parallel examples	1
emotional and physical states	1
(Local- DIFFI)	1
different mechanical faults	1
modularity	1
time and frequency domains	1
vibration features	1
labeled historical data	1
training accuracy and speed	1
training iteration more than 200%	1
almost lossless training accuracy	1
magnitudes of gradients	1
channel dimension	1
layer-wise gradients	1
different magnitudes	1
channel-wise gradient distributions	1
training stability	1
gradient distribution	1
forward one	1
approximately twice more computation	1
low bit-width (e.g., INT8) quantization	1
average F-score of 0.78	1
alpha state	1
established optimal criteria	1
best set-up	1
different electrode set-ups	1
demonstrated power	1
comfortable location and performance	1
cumbersome and obtrusive nature	1
magnitude times faster	1
high performance architectures	1
Within less than half GPU day	1
given inference budgets	1
positively correlates	1
network expressivity	1
enormous computation	1
\url{https://github.com/hzwer/arXiv2020-RIFE }	1
much better speed	1
artifacts on motion boundaries	1
https://github.com/unicamp-dl/Lite-T5 -Translation	1
nine days	1
winning submission	1
common representations	1
advantages and disadvantages	1
different descriptions (orviews)	1
state-of-the-art works	1
Overall sensitivity, false prediction rate, and area under receiver operating characteristic curve reaches 93.5%, 0.063/h, 0.981 and 98.8%, 0.074/h, 0.988	1
limited classification ability	1
high-accuracy prediction	1
size of this training data	1
minimal improvements	1
three training sentences	1
limited available training data	1
sense bias	1
many practical challenges	1
computing resources	1
ideal conditions	1
high-level sense distinctions	1
potential limitations	1
context-sensitive semantic nuances	1
better word representation	1
predefined SQL syntax	1
query SQL	1
predefined schema relations	1
question words	1
schema entities	1
web-crawlers' accuracy	1
emotional connotations	1
music emotions	1
famous novel {``}	1
total of 436	1
cross-lingual embeddings	1
usable models	1
large amount of resources	1
multiple word embeddings	1
Question Answering (QA), Word Sense Disambiguation (WSD), and Information Retrieval (IR)	1
{`}word embeddings{'}	1
Dense word vectors	1
similar evaluation cost	1
eachimage descriptor	1
different descriptorstypes	1
theinput feature	1
computational and memory efficiency	1
theimage descriptors	1
73.4% images	1
four spatial andhorizontal contrast features	1
color basedsegmentation of vehicle images	1
open sourced	1
localization error	1
regression loss	1
KL divergence lossapproximately	1
groundtruth Gaussian	1
proposed Gaussian	1
theKullback-Leibler (KL) divergence	1
image plain	1
2D Gaussian distributions	1
lesion bounding ellipses	1
elliptical geometry	1
various baselines	1
document- and sentence-level event factuality information	1
problem statement	1
additional gender prediction objective	1
persons' IDs	1
Fill-in the Identity	1
input sequence-length	1
number-of-hidden-layers	1
enhanced complexity	1
activation-function	1
input-vector	1
pruning/padding-length	1
embedding-size, number of hidden layers	1
altered hyper-parameters	1
op-code sequence representations	1
different hyper-parameters	1
essential hyper-parameters	1
default configuration	1
inherent differences	1
visual elements	1
question and image	1
visual and textual features	1
EAE's performance	1
fraction of its parameters	1
10x the parameters	1
sufficient knowledge	1
distinct memories	1
learned parameters	1
declarative knowledge	1
semantic segmentation performance	1
semantic segmentation and depth estimation tasks performance	1
complementary and mutually dependent	1
tasks' performance	1
semantic pseudo-labels	1
cross-task relationships	1
semantic and depth predictions	1
task dependencies	1
visual task relationships	1
0.3% of Top-1 accuracy	1
full-precision models ofResNet-32,44,56 by 0.04%, 0.16%, 0.36%	1
16x smaller	1
scaling factors	1
ternaryvalues (2-bit weights)	1
ternary assignment	1
verylittle accuracy degradation	1
theprecision of weights	1
Trained Ternary Quantization (TTQ)	1
limited power budgets	1
performance threshold Jaccard Index (IOU) 92%	1
manually segmented	1
dermoscopic images	1
limited images	1
pre/post -processing of the images	1
additional specifications	1
CAIS	1
global utterance	1
local contexts	1
specific (slot and intent) global utterance representations	1
local context representations	1
enriched features	1
slot-specific and intent-specific features	1
tradeoff between classification performance	1
DG bounds	1
PAC-style generalization bound	1
source-domain samples	1
good candidates	1
sufficiently learned features	1
labeling inconsistency	1
several keen observations	1
corresponding performance	1
ten independent runs	1
dimensionality of extracted feature space	1
jet tail)	1
diversity and robustness	1
air currents	1
single model	1
meteorological features	1
90% ofperformance	1
possible stylistic information	1
$n$-grams	1
distortions	1
remarkable photo-realistic details	1
high-fidelity outputs	1
textural details	1
faithful reconstruction precision	1
restriction	1
distance-based reconstruction errors	1
domain-specific image super-resolution	1
order of magnitudefaster	1
sized problems	1
low-rank+sparse matrixseparation	1
existingtime complexity bounds	1
optimal number of observations	1
ofthe corrupted entries	1
small number ofits entries out of which a few	1
improvement of 1.4 mAP	1
ResNet50 baseline	1
$1.3\%$ top-1 accuracy improvement	1
many different models and scales	1
near-optimal memory complexity	1
two previouscomplete guarantees	1
significantbecause (i)	1
outlier magnitudes	1
lower bound assumption	1
standard RPCA assumptions	1
simple-ReProCS	1
alow-dimensional subspace	1
equivalent model size	1
2.6% in accuracy	1
Efficient-B0	1
20% fewer	1
15% fewer	1
0.9% higher accuracy	1
421$\times$ less search cost	1
per-FLOP or per-parameter accuracy	1
nearly constant	1
memory and computational costs	1
input resolution and number	1
spatial and channel dimensions	1
$10^{14}\times$	1
10%, 35%, and 58.5% better	1
3.32%)	1
4.62%), NER (6.66%)	1
0.41%)	1
single representation	1
barrier	1
expertise knowledge	1
written form	1
fifty	1
fifteen hours	1
close	1
color bias	1
CycleGAN baseline	1
network's validation performance	1
accumulated knowledge	1
past encoders	1
exponential moving average	1
number of task	1
better and more robust representations	1
generative colorization	1
complex architecture	1
outputs halfway	1
final outputs	1
three layers	1
fewer datasets and computational resources	1
target model efficiently	1
double that of traditional baselines	1
approximately 20%	1
Sharpe ratios	1
query's characteristics	1
sub-optimal strategy performance	1
extreme ends	1
ranking accuracy	1
competitive and viable alternatives	1
accuracy by 0.28%, 1.64%, 0.34%, 4.5%, and 3.27% compared to DARTS	1
0.56%, 0.50%, and 0.39%	1
approximations	1
numerous approximations	1
superior classification performance	1
open licenses	1
best reported BERT -based results	1
state-of-the-art NER results	1
restructuring examples	1
different predictions	1
new opportunitites	1
single-sentence context	1
scope	1
generalization error of MAML	1
$m$ and number of samples per task	1
algorithmic stability	1
total variation distance	1
resulting generalization error	1
unseen task	1
$\mathcal{O}(1/mn)$.	1
expected excess population loss	1
strongly convex objective functions	1
two points of view	1
$n$ data points	1
$m$ tasks	1
generalization properties	1
higher-quality rankings	1
growing numbers of parameters	1
increasingly heavy computational burden	1
every modality	1
potential connection	1
accurate survival predictions	1
gene expression data	1
whole slide images (WSIs)	1
highest number	1
different interpretations and opinions	1
example	1
group of truelabels	1
code publicly available	1
much higher frame rate	1
pose estimators	1
human pose similarity	1
multi-person identity association	1
paths	1
new regularizer	1
inference calculations	1
around 10% absolute gain	1
consistentperformance gain	1
considerable extra coverage (over 99%)	1
best combination	1
true conditional p.d.f.	1
best estimate	1
41,000 trips	1
reliable MDVSP solutions	1
delay-tolerant vehicle schedules	1
travel time of each trip	1
probability density function (p.d.f.)	1
Multiple Depot Vehicle Scheduling Problem (MDVSP)	1
uncertainty of travel times	1
key piece of information	1
service attributes	1
invariability	1
local approximation	1
50% fewer parameters	1
1 BLEU point	1
inefficiency issue	1
smoother trajectories	1
incomplete observations	1
high-level options and low-level trajectory planner choices	1
sub-goals	1
generalization and safety guarantees	1
autonomous driving problem	1
uncertain and dynamic conditions	1
Planning safe trajectories	1
eleventh out of fifteen	1
twelfth out of sixteen	1
PP-OCR	1
7% higher	1
precision of PP-OCR v2	1
Experiments on real data	1
simple principles of remembering states	1
Go-Explore 's exploration efficiency	1
practical potential	1
orders of magnitude improvements	1
promising states	1
derailment	1
detachment)	1
sparse and deceptive feedback	1
high-level reward function	1
Visualization of dialogue embeddings	1
explicit NLU and dialogue states	1
supervision information	1
dialogue turn	1
dialogue embeddings	1
turn embeddings	1
Dialogue embeddings	1
turn embedding	1
eachperson with positions and sizes	1
95160	1
whole trajectory	1
object features	1
F1 score of 32.82 %	1
.4606 CCC	1
MuSe-Stress	1
.4717 CCC	1
MuSe-Wilder	1
Concordance Correlation Coefficient (CCC) of .4616 CCC	1
user-generated reviews	1
`physiological-emotion'	1
novel aspect	1
valence and arousal	1
four orders-of-magnitude fewer FLOPs per query	1
two orders-of-magnitude faster	1
pre-compute document representations offline	1
expressiveness of deep LMs	1
fine-grained similarity	1
query and the document	1
single relevance score	1
computational cost by orders of magnitude	1
fast-paced advances	1
potential user bias	1
average 26% more	1
63% of EMG artifacts	1
expected EEG features	1
average, about 75%	1
realistic efficacy	1
independent components (ICs)	1
inter-related	1
information stored	1
knowledge graph (KG)	1
interaction	1
statistically significant respectively	1
mean-differences	1
immense potential	1
Classification accuracy, specificity, and sensitivity	1
105	1
Composite Dice score of 91.23	1
marginally higher dice scores	1
corresponding MAML loss	1
strongly convex task losses	1
MAML loss function	1
approximate stationary point	1
linear convergence rate	1
MAML ODE	1
specific discretization	1
manually chosen step size	1
continuous-time limit view	1
almost 10x online inference speedup	1
even higher	1
balanced encoder-decoder depth	1
computational parallelism	1
1st in Emotion Classification sub-task	1
macro F1 score of 0.5528	1
Pearson Correlation Coefficient of 0.533 on sub-task I	1
overall level of emotion	1
distress score	1
empathy score	1
third place out of 736	1
0.6344 and 0.6289	1
extreme imbalance	1
class size	1
half of the pulling operations	1
lower pulling frequency	1
training nodes	1
classical synchronous SGD	1
local model	1
communication complexity	1
highly distributed data	1
accuracy of 96%	1
4-6%	1
TL performance	1
writing style	1
error by 14%	1
91% accuracy	1
abundance of resources	1
Top-10 ranking	1
90{\%} accuracy	1
Top-10 and Top-5 ranking level	1
87{\%} and 74{\%} accuracy	1
matching sign	1
20 signs	1
sign language proficiency	1
various degrees	1
average trajectories	1
body and finger joint positions	1
(spoken language) glosses or phonological features	1
potential matching signs	1
recorded sign	1
information about a sign	1
full sign	1
number of trainable parameters	1
frozen weights	1
unpredictable behaviours	1
established relationships	1
average of 60%compared	1
output sentence	1
coverage penalty	1
wordpieces)	1
low-precision arithmetic	1
finaltranslation speed	1
many of theseissues	1
bothaccuracy and speed	1
many of the weaknesses	1
correlation information	1
novel descriptors forElectroencephalogram (EEG ) and facial images data	1
autobiographical memory deficits	1
AD symptoms	1
cognitive domain impairments	1
associated costsand	1
's care	1
High rate	1
limited sideinformation	1
type and relation alias information	1
founded andco-founded	1
otherrelevant side information	1
delicate designs	1
good balance of realness and fidelity	1
high-quality references	1
accurate geometric prior	1
low-quality inputs	1
realistic and faithful details	1
(a=80.8%, {\sigma}=0.001) accuracy	1
environmental variables	1
Heart Rate Variability HRV	1
time-stamped and geo-tagged	1
pre-specified urban path	1
e.g. self-reported valence	1
individuals' perceived responses	1
EDA, HR, HRV, Body Temperature, BVP and movement)	1
urban environmental factors	1
multi-sensor data	1
collected (for the first time	1
personal characteristics	1
term 'DigitalExposome'	1
broad applicability	1
LSR performance	1
robust minimum	1
historical output distribution space	1
training trajectory	1
copies'	1
current model's output distributions	1
constant larger proportion	1
softer temperature	1
KD regime	1
large image scales	1
small object detection problem	1
0.1% loss	1
measured inference latency	1
2.7% better accuracy	1
4x FLOPs reduction	1
freeinghuman labor	1
model size, speed	1
power budgets	1
limited computation resources	1
current industry practices	1
research problem	1
research background	1
domain and language-specific	1
implicit and explicit user feedback	1
arbitrary topics	1
great commercial potential	1
3rd out of 8	1
88:95% F1 score	1
32.3 BLEU scores	1
33.0 BLEU scores	1
possible invalid transitions	1
different valid transitions	1
e.g., 5x5->3x3	1
smaller kernel sizes	1
convolution->separable convolution	1
efficient types	1
small search space	1
limited search/transition space	1
skip or null connection	1
efficient operations	1
+30%	1
new record of 82%	1
optimal driving policy	1
latent state information	1
high dimensional spaces	1
super-human-level performances	1
many complex policies	1
complex road geometries	1
diverse scene perceptions	1
several dynamic factors	1
tumor core	1
$p<0.05$)	1
local structural as well as global contextual information	1
contracting and expanding paths	1
intensity inhomogeneity	1
spatial dissimilarities	1
effectiveness and practical value	1
improved volume segmentation Intersection over Union (IoU) - up to $12.6\%$.	1
isotropic convolutions	1
existing 3D DCNNs	1
full field-of-view	1
64.3% accuracy and 43.4% final metric	1
, orientation)	1
semantically meaningful dimensions	1
30\% less real data	1
comparable or better accuracy	1
classifier performance	1
method's validity	1
improved vehicle make and model classification accuracy	1
downstream classifier performance	1
extremely black	1
highly specialized	1
wide variety of arenas	1
top-tier performance	1
Robotic Scene Segmentation Challenge 18 (ROBOT18), Brain Tumor Segmentation Challenge 18 (BRATS18), and Retinal Fundus Glaucoma Challenge (REFUGE18)	1
number of the images	1
context information comprehensively	1
different perceptual levels	1
individual loss functions	1
$k=4$	1
classification-calibration condition	1
$k=-1$,Hinge-Logitron	1
relatively large $|k|$.	1
additional $k$-throot stabilization function	1
generalized $k$-th order hinge-loss	1
choice of parameters	1
polynomial parameterization	1
extendedexponential function	1
extended logarithmic function	1
parameterized functionestablished	1
extended logistic loss function	1
smoothly stitchedfunction	1
loss function of it	1
exponential loss	1
logistic loss	1
squared hinge loss, logistic loss, and exponential loss	1
various convex surrogate loss functionssuch	1
zero-one lossfunction	1
inherent non-convex and non-smooth structure	1
number of characters	1
~10x faster inference	1
conditional classification likelihood	1
regions of interest	1
co-ordinates	1
prohibitive inferential and memory costs	1
4000 x 3000 dimensional images	1
224 x 244	1
images of small dimensionality	1
approximately or nearly average score	1
MOS of 2.56 and a Sim of 56.46%	1
mean opinion score (MOS) of 2.87 in naturalness and a speaker similarity percentage (Sim) of 75.37% for Task 1	1
cyclically reconstructed spectra	1
converted acoustic features	1
+1 BLEU score improvements	1
hand, input, and model state	1
different components	1
comparable results performance	1
significant margin (3%-4% mAP)	1
current frame detection results	1
object queries	1
Temporal Query Encoder (TQE)	1
multiple frame spatial details	1
feature memories	1
spatial object queries	1
ROUGE-1/-2/-L F1 score of 35.58/18.47/33.32	1
generated slogans' quality	1
brief company description	1
company's focus	1
generated slogans	1
cyber anomalies	1
precision, recall, F1-score, and accuracy	1
$k$-means	1
highly model-specific	1
approximation guarantees	1
hardware or human resource constraints	1
area under the curve was 0.83 and 0.74	1
75.4% and68.2%	1
final feature vector	1
original feature vectorand	1
high learning capacity	1
2D imagesbecause	1
vector form	1
imbalanced distribution	1
highdimensional features	1
amount of redundant information	1
unrelated redundant information	1
overlapping relations	1
4th and 18th	1
language behaviors	1
77% accuracy	1
online available data	1
extra money	1
customer's loyalty	1
customer satisfaction	1
multifarious needs	1
customer's needs	1
lot of money	1
Customer satisfaction	1
1 BLEU score on average)	1
improved translation performance	1
typological features	1
type of languages	1
high - level representations	1
partial weights	1
style , terminology , and sentence structure	1
unique and internal characteristics	1
arousal and 91.1% accuracy	1
91.3% accuracy	1
good behaviour	1
variant of DILATE	1
multiple future steps prediction	1
much worse	1
Named Entity Recognition (99 languages)	1
within-language performance	1
quality of representation	1
explicit cross-lingual signals	1
good cross-lingual performance	1
pretrained word embeddings	1
60.34{\%}	1
performance of 76.29{\%}	1
one of the mention types	1
second layer	1
resulting vector	1
characters	1
PharmaCoNER Tracks	1
3x measured speedup	1
8x computation reduction	1
3.3%, ranking 1st	1
fast and accurate	1
diverse design space	1
low-resolution voxelization	1
small instances	1
limited hardware resources	1
first, second and third fastest	1
efficiency track	1
main ranking objective	1
dialogue length	1
problem of robustness	1
latent variable dialogue representations	1
data-efficient solutions	1
little generalisation power	1
smaller data	1
everyday life	1
large margin of 9% with 10% less computation cost	1
61.6% ImageNet	1
different bit-widths	1
time cost	1
lower bit	1
large number of quantized models	1
shared step size	1
unstable training problem	1
unacceptable time consumption	1
merits of the two sides	1
high-performance QNN	1
DTW loss	1
dis- tance measures	1
two signals	1
meaningful discrepancy measurements	1
time axis	1
invariance	1
ranked second and third respectively	1
thesentiment of the tweet	1
top n-influencing words	1
betterthan state-of-the-art embeddings	1
6% relativelyimprovement	1
various shortcut block topologies	1
theself-connected part	1
different mental states	1
alert state	1
muscle artifacts	1
wakeful EEG	1
drowsy state	1
Alpha spindles and Theta burst	1
biologically explainable features	1
average accuracy of 73.22% on 11	1
shared EEG features	1
drivers drowsy states	1
road fatalities	1
English knowledge	1
resources and annotated data	1
improved features	1
classification loss	1
training labels	1
3D-ResNet	1
size, location, shape, and contrast	1
original-sized 256 X 256 MR images	1
theoriginal ones	1
real image distribution	1
limited performance improvement	1
original images;however	1
described problems	1
incorrect parts	1
inaccurate performance	1
awe-inspiring results	1
slightly different data	1
best naturalness and similarity	1
prosody code	1
text and speaker information	1
prosody information	1
decoded text	1
68.72% mAP, 0.2% ASDR	1
RMS values	1
future motionbased	1
multi-modal distribution	1
confidence values	1
distributions of musical attributes	1
high-level conditions	1
valence, phrasing, and time signature	1
pre-defined mood tags	1
perceived emotion	1
positivity or negativity	1
generation output	1
perceived emotional qualities	1
high-level musical characteristics	1
much less parameters	1
final BLEU score	1
36.8 to 44.5	1
ASR objective	1
final objective function	1
End-to-End differentiable path w.r.t	1
noisy ASR hypothesis	1
large performance gap	1
comparable levels of performances	1
score vectors	1
misinformation score	1
credibility scores	1
re-rank	1
relevance, credibility and misinformation scores	1
initial run	1
credibility and misinformation scores	1
13 runs	1
Total Recall Task	1
$11$ runs	1
fixed baseline of 13.6 (host team)	1
required hardware	1
34.6 streaming AP	1
33.2 streaming AP	1
negligible extra inference cost	1
streaming object detection performance	1
balance of accuracy and latency	1
f1-score of 0.91	1
Context	1
negation cue	1
realistic and natural textures	1
consistentlybetter visual quality	1
absolute value	1
discriminatorpredict relative realness	1
Residual-in-Residual	1
adversarial lossand perceptual loss	1
hallucinated details	1
single imagesuper-resolution	1
stroke size	1
proposed stroke perceptual loss	1
arbitrary high-resolution	1
image style	1
style consistency	1
thumbnail's normalization statistics	1
memory problem	1
small stroke size	1
massive memory cost	1
e.g., 10000x10000 pixels)	1
accurate pose	1
action category	1
movement diversity	1
motion prediction accuracy	1
[1].	1
F1 score of 0.58 and 0.57	1
statistical precision and recall values	1
pavement distresses	1
lower cross-lingual loss	1
four downstream tasks	1
isomorphic embedding spaces	1
existing Vecmap and MUSE alignments	1
anchor points	1
ImageNet scale	1
58.2% error)	1
subset of it	1
top-1 error	1
14.8% error)	1
drastically improved state-of-the-art results	1
affine parameters	1
short update times	1
different textualrepresentations: manual and automatic transcriptions	1
informative loss	1
transcriptions	1
notion of informativeness	1
informativeness oftranscriptions	1
satisfactory combinations	1
generationquality and memory ability	1
two quantitative metrics	1
theme concepts	1
scene graph based features	1
Theme Nodes (TTN)	1
memory vectors	1
high-level cross-modality semantics	1
8.4{\%} relative improvement	1
M2 of 63.2	1
F0:5 of 66.61	1
hippocampus volume changes	1
Union (IoU) value	1
Intersection over	1
Dice similarity coefficient (DSC) = 92.3%, sensitivity = 96.5%, positive predicted value (PPV) = 90.4%	1
10 iterations	1
similarity metrics	1
hippocampus changes	1
hidden-sate estimation accuracy	1
large number of data point each time-series data	1
large volume of data	1
sequence of complex input-output relational observations	1
computational power and accuracy	1
convolution layers	1
semantically identical	1
https://github.com/liukun95/Noisy-NER -Confidence-Estimation	1
entity labels	1
labels of low confidence	1
local and global independence assumptions	1
noisy and clean labels	1
different training dynamics	1
calibrated confidence estimation	1
large amount of noise	1
three branches	1
seen categories	1
seen body gesture category	1
new body gesture	1
new emotional body gestures	1
enough samples	1
emotional body gestures	1
reasonable results of F1-Score 0.47 and 0.37	1
models and code	1
navigation tasks	1
scene understanding and navigation policies	1
relatively cheaply (under 1 day	1
relatively early (at 100 million steps	1
90% of peak performance	1
power-law-like distribution	1
3 days of wall-clock time	1
6 months	1
equivalent of 80 years of human experience	1
2.5 Billion steps of experience	1
scaling	1
speedup of 107x	1
near-linear scaling	1
computation is ever stale)	1
terms of TER and BLEU	1
translations of provided MT results	1
Dynamic Weight Average	1
different levels of data	1
pivotal information	1
corresponding objective loss	1
second item	1
semantic difference	1
summary features	1
disproportionate ratio	1
walking activity	1
reference subsequence	1
portion	1
vector component	1
time-series	1
different length	1
burden of computation	1
longer data stream	1
multi-variate	1
TS -dependent	1
components TS -independent	1
components interoperability	1
moderate cost	1
units of meaning	1
AUC by 4.43% on average	1
relatively few past activities	1
relatively few KCs	1
his/her mastery	1
given KC	1
KCs	1
complex representation	1
student's knowledge	1
knowledge concepts (KCs)	1
corresponding hidden state	1
input token embedding	1
similarity of context information	1
document-aware information	1
sentence representation	1
sentence-level representation and document-level representation	1
hierarchical contextualized representation	1
two deficiencies	1
larger scope	1
False Positive Rate	1
UNSW-NB15	1
distinct strengths	1
higher False Positive Rates	1
less accuracy	1
possibility	1
metric/feature or correlation between set of metrics/features	1
high False Positive Rates	1
new variety	1
high applicability	1
2200 samples	1
polarity of each aspect category	1
aspect category detection (ACD) and aspect category polarity	1
user's opinions	1
average sensitivity of 87.00%, specificity of 88.60% and precision of 88.63%	1
forward and the backward directions	1
discriminating temporal features	1
spatial and temporal discriminating features	1
essential seizure patterns	1
considerable variabilities	1
seizure morphologies	1
142 to 113.5	1
perplexity per word (PPW)	1
ternary values, {-1, 0, 1}	1
sloping factor	1
full precision model	1
distributions of weights and activations	1
distribution of tensor values	1
low-bit precision	1
huge accuracy degradation	1
significantly reduced number	1
useful instrument-wise insight	1
competitive classification scores	1
raw waveforms	1
time-frequency representations	1
initial output	1
camera projection matrix	1
initial 2D and 3D object properties	1
power of geometry	1
\emph{https://github.com/THUrssq/Tianchi04}.	1
evasion loss function	1
fragile position	1
bounded \emph{l$_{0}$} norm perturbation	1
satisfactory trade-off	1
adequate global structure	1
high-dimensional problems	1
empirical convergence rate	1
selected dimensions	1
infill-criterion	1
variability of evaluated points	1
evaluated points	1
substantial computational complexity	1
recent variants	1
accuracy and search efficiency	1
corresponding loss functions	1
mixed second derivatives	1
measure factors	1
language specific features	1
mBERT competitive	1
total of 39	1
broader cross-lingual potential	1
second places	1
first place in one track (French-20K-Open)	1
UCCA representation	1
multiple system-outputs	1
Video Super-Resolution and Compressed Video Enhancement Challenges	1
0.82 dB in PSNR	1
similar computational constraint	1
misaligned video frames	1
spatiotemporal information	1
effective length	1
word-level ones	1
subword-level representations	1
10.5% lower MAE	1
5.8% and 14.9% lower Mean Absolute Error (MAE)	1
relevant scale-related information	1
arbitrary perspective	1
non-uniform scale variations	1
crowd density and count estimation	1
definition of what	1
agent performances	1
PPO/RND)	1
Intrinsic Rewards	1
accuracy of 87.93%	1
accuracy of 92%	1
facial and lip images, and facial and lip landmark features	1
four kinds of features	1
WildVVAD)	1
three times	1
44K samples	1
automatic annotations	1
person is speaking or not	1
better accuracy and F1-Score	1
local outliers	1
tail probability	1
synthetic data space	1
comparable F1-scores (85.6% and 82.8%) and accuracies (83.9% and 89.4%)	1
96.8% accuracy	1
620 abnormal images	1
gastrointestinal cancer identification performance	1
98.0%, 100.0%, 96.0% and 98.0%	1
precision, recall, F1-score and accuracy	1
ratio of 1 : 1 : 2	1
histopathological features	1
prefix and suffixes	1
word-tag pair features	1
current, previous and next words	1
word lemma	1
word shape features	1
left or right	1
previous, next tokens and labels, features	1
N-grams of size 6	1
native embeddings	1
two category of word embeddings	1
subtask 2	1
subtask 1)	1
Task 8 subtasks 1 {\&} 2	1
discriminative sparse code functions	1
problem of non-linearity	1
benefits of invariance	1
existing Riemannian representations	1
Fourier temporal pyramid	1
sparsity and vector space representation	1
suitable computational properties	1
inherent non-linearity	1
static skeletal shapes	1
shape space	1
non-linear manifolds	1
temporal evolution	1
(artificial) audio segmentation errors	1
better translation quality (+0.18-2.61 BLEU)	1
Document-level contextual information	1
numerical and analytical results	1
easy tasks optimal solutions	1
substantial gain over NAL	1
much MAML	1
one or few	1
4,730 WSIs, 67 million patches	1
space complexity	1
patient survival	1
salient objects	1
WSIs and genomic features	1
genomic measurements	1
biological priors	1
data heterogeneity gap	1
entire WSIs	1
gigapixel whole slide images (WSIs)	1
Survival outcome prediction	1
brain pathology	1
0.962$\pm$0.012) sampled data	1
0.968$\pm$0.005)	1
acceleration factor of 20	1
highest being 0.990$\pm$0.006 for acceleration factor of 3.5)	1
high SSIM	1
high quality reconstruction	1
various sampling patterns	1
various undersampling patterns	1
better resolution	1
image artefacts	1
loss of resolution	1
undersampling)	1
parts of the data	1
long scan time	1
baseline non-contextual FastText embeddings	1
existing publicly available ELMo embeddings	1
precomputed embeddings	1
estimated outcomes	1
implementation trade-offs	1
achieved performance	1
time-to-market and development costs	1
prolonged efforts	1
increased sense of control and flexibility	1
generative distribution	1
high dimensional data	1
lower dimensional representation	1
effective detector	1
sufficient size	1
initial batch	1
manifold-specific kernel function	1
size of data	1
underlying data distribution	1
core assumption	1
small initial batch	1
F-measure up to 47% over FCN s.	1
four metrics	1
easyversus hard	1
desired threshold	1
image difficultycompares	1
hard images	1
faster single-stagedetector	1
easy images	1
easy versus hardimages	1
test images	1
image difficultypredictor	1
optimaltrade-off between accuracy and speed	1
loweraccuracy rates	1
class probabilities and bounding box coordinates	1
highest accuracy rates	1
distributionally robust FL	1
number of iteration	1
fast convergence rate	1
baseline by approximately 12{\%}.	1
micro-averaged F1 score of 0.7072	1
learned network representations	1
pretrained ELMo word embeddings	1
powerful ability	1
state-of-the-art or comparable results	1
Unicoder-VL	1
image and a text	1
visual and linguistic contents	1
joint representations	1
L1, L2	1
classical losses	1
local perception	1
non-uniform	1
set of blurred and sharp images	1
sharp one	1
effectiveness of CRQDA	1
additional question data	1
revised question representations	1
continuous embedding space	1
accuracy test	1
Naive Bayeson ecological data	1
certain assumptionsabout the data	1
syntactic and semantics features	1
explanatory factors	1
consumers' opinions	1
100k	1
triple fact	1
answer sentences	1
question context	1
direct output result	1
highly context-sensitive	1
careful task-specific choices	1
Morpho-syntactic features	1
decimal numbers	1
Student's performance	1
slope of the learning curve	1
complex taskand	1
2D caricature and 3D caricature shape	1
3D caricature shape space	1
3D exaggerated face shapes and texture	1
2D normal faces	1
face photos	1
artistic style	1
overall disaster magnitude	1
better quantification	1
overall damage	1
economic loss and fatalities)	1
multiple damage dimensions	1
high accuracy (92\%)	1
poor image quality	1
reparation cost	1
significant damage	1
14%	1
n-best	1
word confusions	1
dialogue act	1
best ASR output	1
best output	1
discriminatory losses	1
dialog act	1
three million pixels	1
represented extent	1
Quantization Error	1
experimental time-based imaging data	1
experimentally obtained cell imaging data	1
computer generated images	1
representative experimental data	1
single stages	1
standard bi-lingual text output	1
results of Perplexity and other different metrics like WER	1
high as 0.9599	1
identification capability	1
classification power	1
deep visual, shallow visual, and text features	1
documents' deep visual, shallow visual, and text features	1
\emph{Figure}	1
video segment level	1
abnormality score	1
proposed ranking loss	1
spatial-temporal features	1
false alarm rate	1
temporal-annotations	1
video-level information	1
abnormal and normal videos	1
fixed budget	1
modified objective	1
unlabelled to labelled	1
graph node embeddings	1
labelled ones	1
sufficiently different	1
seed labelled examples	1
edges	1
image's feature	1
scope of improvements	1
BLEU score improvement of as much as ten times over the baseline	1
training (non-static)	1
better gains	1
poor translation quality	1
low syntactic similarities	1
gap between supervised and unsupervised machine translation performance	1
speed comparison	1
number of hyperboxes	1
higher dimensional case	1
$\Theta(n\log n)$	1
previously $O (n^2)$ and $O(n^3)$, for two- and three-objective problems	1
upper bound time complexities	1
exact EHVI values	1
exploration and exploitation	1
maximizing or minimizing an infill criterion	1
computation of cPSE	1
symmetric divergence	1
topological and internal neural processing complexity	1
empirical complexity measure	1
network connectivity	1
concept of {Periodic Spectral Ergodicity} (PSE)	1
4191M GPU memory	1
16057M GPU memory	1
GPU memory occupation	1
small GPU memory occupation	1
deep SR features	1
fast and accurate image super-resolution	1
deep	1
high GPU memory occupation	1
brilliant results	1
memory storage	1
0.3,0.5,0.7}	1
fixed threshold	1
12-45% improvement	1
adaptive threshold	1
incremental database size	1
less similar	1
identity-features	1
threshold or decision boundary	1
entire performance	1
deciding boundary	1
decision threshold	1
lackof time	1
7tasks and 10 demonstrations per task	1
simpler transitionmodel	1
various unexpected behaviors	1
fragile	1
flaws	1
severe stress conditions	1
slight perturbations	1
clues or failures	1
actual behavior	1
overall user experience	1
multiple human evaluations	1
Face-to-Face	1
different constraints	1
substantially fasteralternatives	1
distancesalong each curvilinear feature	1
different optimization criteria	1
corresponding feature	1
response of eachsensor	1
accurate posterior estimation	1
GPC robustness	1
finitely many iterations	1
actual values	1
values $	1
$\epsilon > 0	1
error threshold	1
GPC output	1
functions lower- and upper-bounding	1
minimum and the maximum classification probability	1
test point $x^*$	1
input space $	1
compact subset	1
improved inference time	1
reliable decision support	1
learned graph structure	1
favorable performances	1
intrinsic connections	1
latent graph structure	1
features of each modality	1
patient's condition	1
valid information	1
complex correlation	1
powerful expressive capability	1
BLEU = 36.3	1
0.7 BLEU points	1
6.2 BLEU points	1
BLEU = 37.7	1
deep topology of depth 16	1
fastforward connections	1
10 times of speedup	1
search time to several days	1
high-performance architecture	1
many GPU days	1
data and code	1
meaning representations	1
given training instances	1
logical expressions	1
novel combinations	1
multiple forms	1
aspects of meaning	1
compositional meanings	1
available resources	1
SRL results	1
15$F_1$.	1
deployment costs	1
recent versus distant context	1
13.04{\%} of classification errors	1
one of the two	1
temporal representations	1
recent and distant context	1
wall-clock second difference and turn order offset information	1
hours and days	1
minutes	1
strict grammar or rules	1
persuasive label dependencies	1
two negative results	1
inter- and intra-speaker contextual semantic features	1
intra-speaker relation	1
tactic history	1
strong GNN baselines	1
positional and content information	1
structural and positional information	1
GAT s	1
Positional Embeddings (GAT -POS)	1
positional encoding	1
graph locality	1
similar features and labels--	1
current state of the art performance	1
privacy statements	1
contextual privacy parameters	1
36 real-world privacy policies	1
poor precision and recall	1
privacy parameter extraction problem	1
incomplete and vague statements	1
privacy norms	1
lens of Contextual Integrity	1
privacy policy	1
privacy parameters	1
low model confidence	1
fine-tuned model's performance	1
mislabeled examples	1
learned spurious associations	1
corpus-level understanding	1
practical performance improvements	1
unknown similarities	1
previously unknown bias	1
performance --	1
Fisher --	1
theoretically justified basis of EWC	1
Fisher	1
Fisher Information	1
square root	1
different motivations	1
theoretical quantity	1
strong theoretical and empirical evidence	1
parameter importance	1
large changes	1
important parameters	1
importance of each parameter	1
number of different tasks	1
objectdetection results	1
competitive imageclassification and localization results	1
position, scale, and aspect ratio	1
substantialclassification accuracy improvement	1
non-rigid deformations	1
image scales	1
DCNNexclusively	1
identical complexity	1
deformation-invariant features	1
new mentions	1
4.7 micro-F1 gains	1
20% training data	1
+1.7 micro-F1 gains	1
new medical terminology	1
efficiently learning image representations	1
loss formulation	1
global full softmax objective	1
sampled softmax objective	1
corresponding model parameters	1
set of negative classes	1
demand	1
descriptive power	1
image representations	1
data silos	1
Learning image representations	1
previous SOTA results	1
previous State Of The Art (SOTA)	1
Semantic Textual Similarity (STS) correlations	1
significant task bias	1
pre-training objectives	1
in-domain training data	1
larger amounts	1
500K classification tasks	1
target entity string	1
three metrics	1
background pattern	1
statistical efficiency	1
Local SGD simultaneously	1
theoretical and empirical results	1
asymptotically pivotal statistic	1
rescaled Brownian motion	1
Local SGD	1
averaged iterates	1
data sharing	1
right order	1
global and local temporal alignment	1
Masked Frame Modeling (MFM) objectives	1
global video context	1
10M parameters	1
competitive performance of 2.7%/6.3%	1
1.9%/3.9%	1
WER of 2.1%/4.3%	1
state-of-the-art accuracies	1
local and global dependencies	1
mean F1-score 78.95%	1
1 to 10	1
real-world measurements	1
least as a powerful identification accuracy	1
concurrent loads	1
aggregated consumption	1
specific data	1
outstanding performances	1
traffic flow data	1
spatial connectivity and dis-connectivity	1
DTW distance	1
better temporal similarity	1
prior geographical information	1
spatial and temporal contexts	1
similar patterns	1
Spatio-temporal clustering of traffic flow data	1
extent of improvement	1
associated matching errors	1
DIR performance	1
clinical deformations	1
simulated elastic transformations	1
landmark correspondences	1
number of dimensions	1
aforementioned duality	1
discriminant low dimensional representations	1
dimension of this mapping	1
discriminant aspects	1
weak learners	1
linear classifiers	1
kernel)	1
pre-defined mapping	1
multiclass margin	1
duality	1
estimation error of value function	1
estimation error	1
underestimation bias	1
minimum value	1
much less FLOPs complexity	1
consistent superiority	1
typical detector training schedule	1
generality of our findings	1
longer temporal extent	1
effective clip-level representation	1
short-term view	1
long-term view	1
extended temporal spans	1
action recognition results	1
reduced inductive biases	1
continual learning problems	1
gradient projections	1
suitable destinations	1
specific parameter regularizers	1
little to no loss in performance	1
previous tasks and behaviors	1
course of their lives	1
ImageNet 98.0	1
proposal 97.6 vs. SimCLRv2 97.4	1
performance rates	1
different visualizations	1
annotation labor	1
Vision Transformers (ViT)	1
composed ones	1
higher-order approximation	1
limitation of representational capacity	1
spatial-temporal correlations	1
one-order hop	1
mainstream spectral GCN	1
implicit joint correlations	1
non-Euclidean structure data	1
highest results	1
comparable level	1
baselines models	1
XLM and XLM -RoBERT a --	1
multilingual distilled BERT	1
appropriate RF size within a certain range	1
small or very large RFs	1
time and frequency dimensions	1
RF	1
receptive field (RF)	1
simpler models	1
many of these	1
general interpretability	1
minimally interpretable	1
dense	1
thesecond part	1
thetemporal relation	1
intermediate network features	1
auxiliary distribution	1
predictive label distribution	1
assumed structural domain similarity	1
clustering solutions	1
intrinsic target discrimination	1
assumption of structural domain similarity	1
intrinsic discrimination of target data	1
target ones	1
source features	1
LUS images	1
COVID-19 severity scores	1
approximately 17% more	1
average of 7-12%	1
LUS frames	1
unprecedented condition	1
existing state-of-the-art results	1
utterance-level intent	1
calibration performance	1
calibration	1
confidences	1
overconfident predictions	1
technical assumptions	1
convexified sub-problems	1
DMPC problem	1
resulting complex and non-convex DMPC problems	1
local and shared objectives and constraints	1
agent's sub-problem	1
distributed optimization problems	1
agents' dynamics	1
1.5% score decrease	1
less than 1% accuracy loss	1
battery life over 4x improvement	1
different frequency levels	1
required real-time constraint	1
available frequency levels	1
diverse sparsity	1
battery life	1
dynamic hardware conditions	1
2-3 times faster	1
tighter lower bound (LB Improved)	1
inexpensive lower bound (LB Keogh)	1
triangle inequality	1
POS	1
dynamic optimization problem	1
POS of the next time	1
different moments	1
Pareto Optimal Set (POS )	1
STAPLE AWS translations baseline score of 4.31{\%}.	1
weighted F1 score of 27.56{\%}	1
marginal improvement	1
translation coverage	1
small amount of diversity	1
optimal translation performance	1
higher-quality translations	1
upsurge of research interests	1
minimal performance loss	1
3% improvement	1
ORecognition, Utility and"Counting"	1
performance by more than 5% acrossmultiple question type categories	1
bottom-up and top-down visual features	1
information of question type	1
high-level information summary	1
semanticallydifferent question types	1
multiple spatial scales	1
almost 6 F1 pointsover	1
TAC-KBP score	1
new winning score	1
noise-aware	1
handful of settings	1
parameters ofthese generative models	1
domain heuristics	1
label's path information	1
label dependency prediction	1
hierarchical dependency	1
path dependency information	1
low-level ones	1
knowledge of upper-level labels	1
low Macro-F1	1
sparse lower-level labels	1
text labels	1
additional acoustic and visual modalitiesare	1
-of-the-art sentiment classification and regression results	1
multimodal structure	1
important time steps	1
finer fusion resolution	1
average facial expression intensity	1
bag ofwords representations	1
holistic information	1
proper attentions	1
exploring image feature	1
possible overfitting	1
class prediction confusion	1
pairwise confusion energy	1
significant inter-class similarity	1
two intriguing properties	1
1 AP	1
15.6 AP	1
classification equilibrium	1
instance features	1
frequency and accuracy	1
designed score-guided loss margin	1
mean classification score	1
severely skewed	1
distribution of the training data	1
compositional interactions	1
terms of overall performance	1
time, frequency and time-frequency domains	1
information and patterns	1
high dimensionality problems	1
highly informative data	1
top 20	1
F1-score of 0.91152	1
18th, 8th, and 21st	1
different learning rates	1
unbalanced class distribution	1
14,200 annotated English Tweet comments	1
OffensEval 2020 competition	1
34.43 and 29.01 BLEU score	1
low level to high level	1
layer by layer	1
hidden representations	1
semantic connectivity	1
contextual relation	1
comprehensive empiricalanalysis	1
type of sentiments	1
consumer opinion	1
adversarial and cycle-consistency objectives	1
unseen class labels	1
supervised objective	1
seen class labels	1
associated images	1
seen classes	1
images and class labels	1
cross-modal mapping	1
matching training image	1
unseen classes -- classes	1
PatchNCE loss	1
output image quality	1
patches (negatives)	1
original content	1
input domain to output domain	1
state-of-the-art segmentation performance	1
corrupt ones	1
correct sequences	1
coherence objective	1
sentence-level segmentation objective	1
text coherence	1
apparent link	1
48.8%	1
customized inference costs	1
shallow architectures	1
large architecture related cost	1
architecture related objectives	1
task related learning objectives	1
0.5% higher accuracy	1
10% faster	1
20% faster	1
training-from-scratch accuracy	1
accuracy predictor and on-device measurements	1
block repeats and expansion rates	1
micro-architectural parameters	1
varying macro-architectural parameters	1
three phases	1
many user scenarios	1
diverse architectural search-spaces	1
AU features	1
true feeling	1
extended search space	1
atomic operations	1
input edges	1
activation functions	1
flexible and expressible search space	1
reasonable training speed	1
good improvements	1
given dataset or task	1
new state-of-the-art (SOTA) performance	1
strong competitive performance	1
local context awareness	1
detailed meaning	1
phrase dependencies	1
detailed meaning representation	1
long-range word dependencies	1
many promising results	1
disentangledrepresentation	1
source policy	1
interest data	1
supervised settings	1
character relations	1
sentence constructions	1
formats	1
optimal numeric formats	1
hardware capabilities	1
little tuning	1
generalization gap	1
top-1 eval accuracy of 77.09%	1
4-bit yielding the best Pareto curve	1
4-bit and 8-bit curves	1
bfloat16 compute cost-quality tradeoff curve	1
lower cost	1
inference compute cost-quality tradeoff curves	1
compute cost and memory budgets	1
compute cost	1
language modeling, distillation and cosine-distance losses	1
60% faster	1
97% of its language understanding capabilities	1
constrained computational training or inference budgets	1
https: //github.com/THU-KEG/KECG	1
effectiveness of KECG	1
structural knowledge	1
two KGs	1
projection constraint	1
relational constraints	1
KG-based constraints	1
complementary knowledge graphs (KGs)	1
18 years period of time	1
5 student retention risks	1
students' static demographics	1
students' temporal performance variables	1
temporal advising note embeddings	1
spatiotemporal structured data	1
students' academic information representation	1
type of dropout	1
5 important students' retention risks	1
significant practical privacy gains	1
looser theoretical $\epsilon, \delta$	1
theoretical privacy guarantees	1
faster training times	1
prohibitively slow	1
addresses or phone numbers	1
temporal dependence	1
noisy, normal, and abnormal data	1
Maximum Mean Discrepancy (MMD)	1
spatial dependence	1
normal, abnormal, and noisy data	1
generalized normal patterns	1
multivariate time-series data	1
2-3 times inference real-time factors	1
significant WERR	1
similar model size and latency	1
medium latency	1
24% to 26% relative word error rate reductions (WERRs)	1
medium latency tasks	1
LSTM counterparts	1
changes of architecture	1
intuitive	1
specifics and limitations	1
experiences	1
better encoding ofentity-type and relational information	1
fixed featureextractors	1
35,768 consecutive frames	1
70x faster	1
extreme sunlight-darkness changes	1
recall rates of 100% at 100% precision	1
new state-of-the-art performance standards	1
short TWs	1
false-positive rates	1
source of motion estimation	1
corresponding positional data	1
storage capacity	1
backpropagation through time	1
spacetime scales	1
high compute and storage costs	1
short temporal window (TW) lengths	1
precision-recall performance	1
pairwise similarity results	1
Implicit Relations	1
geometric positions	1
Explicit Relations	1
Two types of visual object relations	1
question-adaptive relation representations	1
multi-type inter-object relations	1
semantically-complicated questions	1
$\sim$2.0 AP	1
VarifocalNet or VFNet	1
Varifocal Loss	1
object presence confidence and localization accuracy	1
combination of classification and predicted localization scores	1
classification score	1
vast number	1
less confident	1
different types of fine-grained semantic divergences	1
types of mismatches	1
noisy parallel training samples	1
EEG distribution	1
30\%	1
micro-sleep detection performance	1
micro-sleep	1
5-class sleep stages	1
Night-sleep data	1
poor data quality	1
1 to 30 secs	1
short sleep	1
HAR data sequences	1
extrinsic evaluations	1
human-understandable representation	1
underlying structures	1
latent HAR patterns	1
obtained Dice Score, Sensitivity and Specificity are 83.1%, 86.7% and 99.3%	1
0.29 second	1
small lesion segmentation	1
focal tversky loss	1
rich contextual relationships	1
channel-wise	1
global public health	1
accuracy of 58%	1
35	1
individual correction tag	1
one error	1
part of the metadata	1
GDPR regulations	1
9 596 sentences	1
Linguistic Acceptability Judgments	1
synthetic and authentic)	1
rich self-supervisory information	1
relative ranking	1
batch	1
relative distance information	1
subjective and objective scores	1
monotonicity correlation	1
non-local representation	1
extracted CNNs features	1
locality bias	1
local structure information	1
local and non-local features	1
subjective evaluations	1
No-Reference Image Quality Assessment (NR-IQA)	1
74.7{\%} and 72.2{\%}	1
inside-to-outside way	1
full advantage of information	1
new representation	1
finer-grained semantic information	1
flat entities	1
mapping performance	1
test and reference signatures	1
sequence of time	1
online signature image data	1
time seriessignature data	1
specific personalized FL objectives	1
best-known communication and computation guarantees	1
communication and local computation	1
practicality and/or optimality	1
strongly convex personalized FL models	1
general personalized objective	1
tailored variant of Local SGD	1
optimization aspects	1
17\%	1
natural disposition	1
different imbalance distributions	1
impact of imbalance	1
performance disparity	1
regional characteristics	1
historical and religious factors	1
different customs	1
culture and geographic locations	1
rank 14/38, 18/47, 24/86, 24/54, and 25/40	1
OffensEval 2	1
suboptimal instance segmentation results	1
5$\times$ the number	1
15$\times$ the number	1
precise per-pixel annotations	1
2,806 high-resolution images	1
large object-scale variations	1
huge number of instances per image	1
mean top~1 error rate to 4%	1
resulting combined objective	1
unlikelihood objective	1
language modeling objective	1
negation incorrectly	1
1.2{\%} relative	1
average slot F1	1
1.7{\%} relative	1
average intent classification accuracy	1
worse average slot F1 (89.87{\%} versus 90.81{\%}	1
better average intent classification accuracy (96.07{\%} versus 95.50{\%}	1
'}s performance	1
development and maintenance cost	1
better than existing best by 1.1	1
better than existing best	1
POS tagging and NER information	1
traditional form	1
lack of patterns	1
word-word dependencies	1
intermediate context	1
multi-head	1
different subspace of the embedded dimension	1
query, key, and value	1
three matrices	1
survival and termination bias	1
single and multiple terminal states	1
multiple terminal states	1
existing reward functions	1
Different types	1
reward bias	1
assumptions	1
thermal energy consumption	1
building thermal behavior	1
critical features	1
specific heat capacity	1
thermal conductivity	1
four parameters	1
key input parameters	1
LDA results	1
best design alternative	1
building thermal loads	1
materials' thermal properties	1
annual thermal energy performance	1
building energy performance	1
Building energy performance	1
recent RegNet	1
7X faster	1
FLOPs and accuracy)	1
2X faster	1
previous compound scaling results	1
network width	1
network depth	1
space-to-batch	1
space-to-depth	1
parallelism, and execution efficiency	1
insufficient operational intensity	1
full advantage	1
sufficient hardware architecture details	1
precision, recall, and F1	1
mention types	1
mention spans	1
fully exploit information	1
NER false negatives	1
NER false positives	1
two separate stages	1
simulated and real world data	1
new geometry	1
time series barycenters	1
differentiable loss	1
invariance class	1
DTW (or its smooth counterpart soft-DTW )	1
feature invariance	1
feature space transformation	1
per-epoch training time by more than 30% over a standard GRU	1
numerical issues	1
modellearn long-term dependencies	1
hyperbolic tangent	1
significantredundancy	1
large time contextsand long-term speech modulations	1
significant noise	1
model's quality and stability	1
optimal R value	1
implicit sentiment	1
rich research results	1
sentimental tendency	1
77{\%} accuracy	1
preprocessing and model estimation decisions	1
every scale	1
box AP	1
all-round improvements	1
higher inference speed	1
comparable mask AP	1
mask prediction branch	1
surface and syntactic properties	1
10\%	1
three novel types of interpretable topological features	1
prominent performance	1
90.84%) FERPlus (89.99%) and AffectNet (66%)	1
State-of-the-art performance	1
reliable labels	1
crowd wisdom	1
around 5K images	1
supervision loss	1
convex combination of supervision loss	1
FER performance	1
memorization ability	1
SBIR problem	1
better distance metric	1
previously unseen classes	1
Zero-Shot	1
1.3%	1
$<$1% average WER degradation	1
$<$0.5% and	1
300 or 2000 hours of SWB data	1
local properties	1
appropriate choice of quantizers and initializations	1
significant Word Error Rate (WER) degradation	1
LSTM portion	1
aggressive low-precision representations of weights and activations	1
gap between empirical performance	1
action-value estimators	1
strict role separation	1
performance bottleneck	1
poor empirical performance	1
strong theoretical guarantee	1
largest class of joint-action value functions	1
large and limited training data	1
small fraction of the training costs	1
3.5 days	1
new single - model state - of - the - art BLEU score of 41.8	1
2 BLEU	1
existing best results	1
28.4 BLEU	1
parallelizable	1
recurrence and convolutions entirely	1
unintended patterns	1
inadequate levels	1
performance saturates	1
unwanted correlations	1
real user queries	1
domain-specific aberrations	1
unintended correlations	1
varying perception of intent	1
+1.28 and +0.89 BLEU points improvements	1
WMT'19 Chinese->English	1
whole performance	1
better	1
more	1
teacher's knowledge	1
different impacts	1
training sample	1
order and the function	1
significant performance differences	1
64 combinations	1
different	1
non-corresponding views	1
corresponding views	1
contrastive learning objectives	1
0.972877 recognition accuracy	1
0.972578 weighted F1 score,0.950828 macro average F1 scores	1
final rankings	1
fourth-place	1
improved generalization performance	1
test set predictions	1
richer learning objective	1
smoother decision boundaries	1
unseen test distribution	1
generalization problems	1
subjective comparisons and objective metrics	1
advantages of RGB and HSV block output images	1
color and saturation	1
underwater image luminance	1
HSV Color Space	1
luminance and saturation	1
image properties	1
powerful representation capabilities	1
existing hand-crafted loss functions	1
parameters of loss function's distribution	1
bunch of existing prevailing loss functions	1
different vision tasks	1
range of parameter counts	1
heuristics of good shapes	1
design variable	1
two critical advantages of shape	1
GLUE benchmarks	1
-off accuracy and model size	1
linear bottleneck matrices	1
hidden dimensions	1
varying shapes	1
varying resource and accuracy constraints	1
fooling ratio	1
largest eigenvalue	1
FIM	1
one term	1
eigenvalues of the FIM	1
eigenvalue of this quadratic form (a.k.a. FIM)	1
quadratic form	1
classification probability densities	1
Euclidean norm	1
benign sample	1
largest eigenvalue of the Fisher information matrix (FIM)	1
limited computing resouces	1
search scope	1
two types of accelerationmethods	1
limited representation ability	1
space-efficient	1
exploration of results	1
variable-length	1
anchor initialization	1
random sample initialization	1
three main differences	1
motif's centers	1
uncertainty quantification	1
small data constraints	1
volume and complexity	1
limited improvements	1
largest uncertainties	1
first principles	1
Earth Sciences	1
contextual signal	1
learnable adversarial noise	1
comparable (sometimes lower) performance	1
Name Regularity Bias	1
latter's first two moments	1
posterior and marginaldistributions	1
Variational Autoencoders(VAE s).In	1
predictable pattern	1
temperature, weather condition	1
seasonal component	1
long term)	1
non-periodic fluctuation behavior	1
cyclic component	1
four components	1
Time Series (TS s)	1
Max-Wregularization	1
unusual generalization gap	1
25.1% top-1 (7.8% top-5) error	1
similar size	1
1.93% (1.98+/-0.07) validation error on CIFAR-10 and 5.5% error (5.8+/-0.3)on the recently released CIFAR-10.1 test set	1
20-30% relative improvement infinal model error	1
50% faster	1
access to manually annotated data	1
appropriate answers	1
named as RefQA)	1
three discontinuous NER datasets	1
three nested NER datasets	1
state-of-the-art (SoTA) or near SoTA performance	1
three types of entity representations	1
tagging schema	1
special design	1
flat NER , nested NER , and discontinuous NER subtasks	1
NER task	1
entity spans	1
par	1
system features	1
fact verification problem	1
inaccurate data	1
arXiv preprint arXiv:2006.03875, 2020	1
arXiv preprint arXiv:2007.15553, 2020	1
AAAI 2020 and IJCAI 2020	1
conservative setting	1
previously learned features	1
deterioration in performance	1
one at a time	1
comparable transformation performance	1
4K images	1
image details	1
reduced resolution	1
content details	1
long inference time	1
dayby day	1
good quality and high accuracy output translations	1
smallest to largest order	1
model's capabilities	1
previous steps	1
custom order	1
predefined order from largest to smallest or smallest to largest	1
order of depth	1
corresponding labels	1
real failure and non-failure samples	1
weighted loss objective	1
first few layers	1
new samples	1
overfitting the training data	1
failure patterns	1
failure samples	1
extremely high cost	1
highly imbalanced training data	1
set of unique challenges	1
failure prediction problems	1
equipment health and performance	1
appreciable memory savings	1
minimal loss of accuracy	1
significantly lower precision	1
maximum information	1
configurations	1
different number of training epochs	1
multiple tasks	1
non-uniform bit distributions	1
significant computation saving	1
low optimally gap	1
final tour	1
node-to-node an optimal tour	1
different node embeddings	1
graph properties	1
TSP instances	1
global graph structure	1
local node neighborhoods	1
proposed measurements	1
better approximation	1
trace coefficient	1
two measurements' bounds	1
policy discrepancy	1
sample trajectories	1
complex sequential decision problems	1
prior knowledge ofsignal duration	1
output stream	1
utterance-level separationerror	1
average precision of 99.57% and country, language and layout classification precision of 99.33%	1
precise	1
profound learning performance	1
8 images	1
training steps	1
little as 10	1
8	1
advanced concepts(such	1
little as 4	1
inordinate amount of data	1
impressive capacity	1
radiocarbon dates	1
benthic $	1
multiple marine records	1
calendar ages (e.g., radiocarbon)	1
continuous ages	1
Continuous Signals (BIGMACS)	1
resolution	1
sequential bins	1
aligned labels	1
Spoken Language Understanding (SLU)on unaligned data	1
sufficient,high-quality training data	1
personal user data	1
100 classes	1
mFID by at least 35%	1
hierarchical features	1
high-resolution bottlenecks	1
shape changes	1
sample efficiency and final rewards	1
PPO baselines	1
good physical interpretation	1
original RL scale	1
over-fit	1
observation-state mapping	1
complex sensory data	1
task-relevant features	1
high sample efficiency	1
Classification quality (areaunder the ROC-curve)	1
spectral distributions	1
graph spectral distributionsare	1
normalized Laplacian spectra	1
fixed corpora and hyper parameters	1
relative merits	1
hypothesis testing and ROC curves	1
shared semantic content	1
heavy data imbalance	1
limited data budget	1
three probabilities	1
prior probability	1
probability of mislabelling a class	1
three terms	1
order of seconds per volume	1
GPU execution time	1
87.48% DICE	1
around 96% volumetric Dice accuracy	1
cutting edge performance	1
VGG weight transfers	1
promising time and accuracy performance	1
around 80-85% Dice coefficient	1
gold-standard	1
strong state-of-the-art accuracy	1
output scores	1
softmax probabilities	1
score bias	1
prediction score bias	1
incrementally arriving training data batches	1
mean temporal location	1
ground truth mean sequences	1
time sequence	1
distinctive durational features	1
durational information	1
accuracy of 90.51%	1
weighted f1-score of 0.77	1
weighted Recall average of 0.74	1
weighted average Precision of 0.88	1
image count	1
noise and picture resolution	1
dermoscopy image	1
High Precision and recall	1
cell type	1
95% of its F1-score	1
51x in terms of latency	1
upto 35x in terms of parameters	1
annotation resources	1
amount of unlabeled data	1
teacher architecture	1
shallow ones	1
huge size	1
1.05% in average	1
2.8% in average on Semantic Textual Similarity (STS) benchmarks	1
various evaluation benchmarks	1
state-of-the-art sentence embeddings	1
PSNR and MS-SSIM distortion metrics	1
popular test sequences	1
common test conditions	1
low-delay causal settings	1
P-frames	1
joint global and local information	1
high transformation capacity	1
large range of magnitudes	1
Novel features	1
compact representation	1
joint results	1
three different lengths	1
69.2%, 70.3%, 98.3% and 76% improvements in terms of the RMSE, MAE, MAPE and SMAPE	1
proposed SSIM	1
real-world time series data	1
past and future information	1
massive number of training data	1
consecutive number of data	1
poor estimates	1
pixelwise segmentations	1
AUROC of 0.89	1
malignancy globally	1
global medically relevant information	1
abstract features	1
non-linear features	1
non-linear edgefeatures	1
non-linear densefeatures and globally normalized CRF objective	1
$3^{d}$ differentclasses	1
$d$-dimensional time series	1
arbitrary type (cylinder, bell, or funnel	1
two more distancefunctions	1
Dog Keeper Distance (DK)	1
Edit Distance withReal Penalty (ERP)	1
two time series	1
real valued vectors	1
linear spaces	1
class separation	1
sparse $\ell^1$ dictionary coding	1
small deformations	1
single dictionary matrix	1
lowest total cost	1
misclassification error and accuracy rates	1
costs of misclassification errors	1
scarcity of labeled fraud data	1
fraud class's incorrect predictions	1
themfacilitates better designs	1
anaverage sensitivity of 87.85% and AUC score of 0.84	1
iEEG data	1
reliable seizure prediction performance	1
Hand-crafted iEEG features	1
thedata size	1
sequence metrics	1
NMT performance gains	1
Minimum Risk Training (MRT)	1
expected document BLEU gradient	1
NMT training objective	1
lines	1
data or model architecture	1
document BLEU	1
desired evaluation metric	1
sentence BLEU	1
sentence-level metrics	1
combination of all three	1
Transformer s.	1
set of pre-training tasks	1
different downstream tasks	1
sparse handcrafted features	1
BM-25 (token matching + TF-IDF weights	1
candidates in time sublinear to the number	1
subset of candidate documents	1
e.g., paragraphs	1
query (e.g., a question	1
loss value of 0.32	1
AUC value of 0.91	1
91.5 percent accuracy	1
learnable features	1
looming threat	1
alter facial features	1
alter facial expressions	1
instance-level topological structure	1
seen and unseen features	1
class-level prototype graph and visual features	1
accuracy and the required training data	1
much higher accuracy	1
long-term dependency characteristics	1
underperformance	1
long-term temporal dependency	1
global spatial characteristics	1
channel	1
local temporal characteristics	1
different spatial frequencies	1
better recall (4.96% on average	1
improvement of 3.63%	1
average F1 score of 72.02%	1
domain-specific linguistic features	1
low coverage	1
overlapping to non-overlapping distributions	1
transform function	1
over-complete distributions	1
generated OCD	1
use of Online Batch Triplet Loss (OBTL) and Center Loss (CL)	1
class scatter	1
separability	1
FRUITS-100ms/500ms/1000ms protocol	1
Even 10% data (WebFace4M)	1
3rd among 430 entries	1
relative 40% failure rate	1
data gap	1
tremendous WebFace260M	1
260M faces	1
identities/42M faces	1
cleaned 2M	1
identities/260M faces (WebFace260M)	1
noisy 4M	1
V&V and safety assurance	1
research directions	1
Several research gaps	1
Verification and Validation (V&V)	1
safety aspect	1
huge amounts of capital	1
state-of-the-art inference speed	1
production time	1
extremely resource intensive	1
tremendous performance	1
highly asymmetric	1
email dataset distribution	1
highly unstable outputs	1
overall global model performance	1
faster convergence speed	1
organizational level performance	1
overall email dataset	1
2 to 5 organizations	1
0.6%	1
BERT accuracy	1
2 to 10	1
1.8% accuracy drop	1
variation in performance	1
organization counts	1
comparable performance statistics	1
balanced and asymmetrical data distribution	1
FL-entangled learning performance	1
commercially sensitive information	1
myriad of privacy, trust, and legal issues	1
decoding speed	1
150 times faster	1
slightly increased computational cost	1
coding performance	1
video compression performance	1
image compression performance	1
channel relationship	1
coding efficiency	1
huge computational cost	1
{\url{https://github.com/IBM/RandomWarpingSeries}}.	1
accuracy and computational time	1
unbounded length	1
RF approximation	1
linear in terms of both the number and the length oftime-series	1
distribution of \emph{Random Warping Series(RWS)}.	1
itsfeature embedding	1
quadratic complexity w.r.t	1
Grammatrix	1
diagonal dominance	1
potential long-term label dependency	1
top-1 position	1
ever-increasing demand	1
missing value	1
[Entity, Slot, ?]	1
theory	1
fast convergence speed	1
$O\left(\frac{1}{N\epsilon^4}\right)$ iteration complexity	1
loss landscape	1
relaxed-smoothness assumption	1
non-Lipschitz continuous gradient	1
nonconvex loss function	1
parallel speedup	1
around 30% AP	1
3D positionsupervision	1
depth input	1
coarse 3D object bounding box	1
2Dleft-right boxes	1
keypoints, viewpoints, and object dimensions	1
sparse and dense, semantic and geometry information	1
real worldpropagation traces	1
traversed links	1
propagation networks (PrNets)	1
probabilistic and the evidential	1
new distance metric	1
special characteristicslike its shortness	1
social messageis	1
20th out of 85	1
language characteristics	1
additional non-linear noise	1
highly dependent	1
Mel Cepstral Coefficients (MCC) mapping	1
fundamental frequency (F0)	1
accuracy, AUC, and Macro F1	1
graph modality	1
graph and non-graph modalities	1
meta-data	1
patients' associations	1
comprehensive insight	1
plausible generation performance	1
caption-action consistencydiscriminator, pose discriminator and pose transition discriminator	1
unique functionality	1
three discriminators	1
captured sequence of poses	1
Action Generation DataSet (AGDS)	1
temporaldomain	1
continuous vectors	1
word indices	1
98.05%	1
2.2 times	1
11.1 audio data per second	1
residual structure	1
depthwise separable convolution	1
efficient performances	1
costs of memory, computation, and latency	1
low False Alarm Rate (FAR)	1
higher reward	1
better sample efficiency	1
long term rewards	1
intrinsic randomness	1
expected return	1
various empirical studies	1
accuracyimprovement over 15.6\%	1
times fewer parameters	1
prediction accuracy and convergence rate	1
betterapproximation	1
rank)	1
theirtraining efficiency	1
large number of model parameters	1
RNNsbecomes computational expensive	1
high dimensional inputs	1
mean Average Precision (mAP)	1
test results	1
category imbalance	1
representative global object features	1
simple structure	1
development concerning resources	1
highest overall speech quality	1
speaker-independent	1
environment dynamics	1
significant performance increase	1
two additional terms	1
environment state	1
model's predicted internal state representation	1
real environment states	1
internal state representations	1
many more tasks	1
future moves	1
realism and diversity	1
human assessments	1
single generated image	1
number of quantitative criteria	1
sense of whatmeaning	1
proper bottlenecks	1
order (and someinherent meaning to some extent)	1
context andmeaning of sentence	1
dense vectors)	1
related or unrelated two sentences	1
tradeoff between model interpretability and detection accuracy	1
increasing detection accuracy	1
high quality of prediction results	1
higher detection accuracy up to 99.87%	1
better explanation	1
SDEL detector outputs	1
pixel-level explanation	1
attention span	1
meaningful word representations	1
3.7\% on average	1
intra-sequence relationships	1
first attention step re-weights visual features	1
contextual dependencies	1
intermediate supervision	1
arbitrary shapes	1
0% and 4%	1
approximately the same level of performance	1
8% and 51% performance	1
memory locality	1
Storing user embeddings locally	1
parameter split	1
federated parameters	1
private user embeddings	1
Private parameters	1
federated and private parameters	1
FURL divides model parameters	1
learned user representations (embeddings)	1
conditions of comparable performance	1
effective adapter module structures	1
computational intensiveness	1
learning inflexibility	1
new component	1
AUC of 98.05% and an accuracy of 95.28%	1
heterogeneous appearance	1
malignant or benign	1
flexibility and generality of MGPSN	1
motion instances	1
effective head features	1
spatial-temporal information on pixel level	1
robust head motion features	1
diverse poses	1
small scales	1
similar head appearance	1
significant classification performance	1
views	1
one of the generators	1
one of its views	1
corresponding observed view	1
missing view	1
one of the views	1
multiview classifier	1
missing languages	1
common discriminator	1
Mask R-CNN [10] detection accuracywith less computation time	1
48.3 AP	1
2 AP	1
better accuracy and latency tradeoff	1
tofuse features	1
combination of top-down and bottom-up connections	1
NER F1	1
{``}missing labels{''}.	1
typed entity mentions	1
unlabeled target videos	1
65% of the labeled training data	1
large margins (e.g. for the F1@25 score, from 59.6% to 69.1% on Breakfast, from 73.4% to 81.5% on 50Salads, and from 83.6% to 89.1% on GTEA	1
GTEA, 50Salads, and Breakfast	1
local and global temporal dynamics	1
spatio-temporal variations	1
single task	1
93.1% of the performance	1
6.4 points	1
Learning sentence embeddings	1
weaker personalization result	1
global model accuracy	1
typical data heterogeneity	1
socially plausible trajectories	1
ETH and UCY)	1
time-step	1
Human trajectory prediction	1
interestingness evaluation	1
discrete measures	1
standard word embeddings	1
state of the art Informativeness measures	1
implicit queries	1
generalization of Informativeness	1
concept of Interestingness	1
CLEF-INEX Tweet Contextualization	1
word n-grams, entities, nuggets, etc.	1
single words	1
bag of terms	1
cosine, ROUGE, Kullback-Leibler, Logarithm Similarity	1
automatic summary	1
n-gram overlapping	1
Standard informativeness measures	1
size and diversity of trainingdata	1
4 of 7	1
thecompetition winners	1
continuousversion of the Pseudo F-measure metric	1
full resolution	1
total of 14	1
source domains	1
test example	1
unique signature	1
pre-defined Domain Related Features (DRFs)	1
unrestricted length	1
unique prompt	1
labeled or unlabeled	1
incredible progress	1
8.7%	1
clear and consistent improvements	1
cross-context patterns	1
limitation of BiLSTM	1
small data lengths	1
surpassed performances	1
higher accuracies	1
small performance improvement	1
minimal accuracy change	1
small data length	1
SVM and FBCCA performances	1
DCNN results	1
window slicing (WS)	1
one electrode (Oz)	1
small data length (0.5 s)	1
82.2% mean test accuracy	1
character-level features and word-level features	1
parallelism and advantageous performance	1
1.33x less time	1
12.3% of the parameters	1
training residual skip connections	1
0.35% as many parameters	1
4.4x less time	1
36% worst subgroup, 25% mean subgroup gap	1
downstream fairness	1
Batch Normalization (BN) statistics	1
first level	1
offer feeds	1
required entities	1
offer	1
offers	1
one of the most accessed advertising data	1
international EEG placement standard	1
79.81%, 96.11%, and 27.07%	1
significantly quicker	1
31.35%	1
significantly higher	1
accuracy of 84.44%, 97.06%, and 9.94% on	1
number a subject	1
best hyperparameters	1
2550 EEG statistical features	1
useful discriminative EEG features	1
additional 2.6 F1 gain	1
event-event relationship	1
21 F1 points	1
less than 200 paragraphs	1
source labels	1
similar oreven better performance	1
new word embeddings	1
practical improvement in performance	1
predicted morphological features	1
manually checked features	1
practical improvement	1
added morphological features	1
quality of features	1
adding morphological features	1
part of speech (POS) tags and universal features	1
named entity recognition (NER ), dependency parsing (DP), and comment filtering (CF)	1
word morphology	1
changes in morphology	1
plenty of information	1
informative features and patterns	1
differing lengths	1
modeling limits	1
within 3 F-1	1
0.75 F-1	1
high performance of around 0.9 F-1	1
binary judgement	1
20,056 pairs	1
corresponding dataset (HLGD)	1
nuanced challenges	1
dataset limitations	1
many standard tasks	1
generated language representations	1
semantic textual similarity	1
attentional focus	1
top 1, 3 and 5 candidate future disorders	1
precision of 0.344, 0.552 and 0.640 (vs LSTM 0.329, 0.538 and 0.633)	1
added granularity	1
modest additional noise	1
text form	1
single-domain predictions and outcomes	1
whole UTAD interpretable	1
intuitive intermediate results	1
high-fidelity yet anomaly-free reconstructions	1
high-fidelity one	1
extra image differences	1
coarse reconstruction	1
anomaly-free data	1
highly unpredictable types	1
anomaly data	1
increase in training and inference time	1
gains in F1 score	1
arXiv:1902.00751	1
total number of model parameters	1
floating point operation efficiency	1
various measures of resource efficiency	1
evaluation criteria	1
varying number	1
parameter efficiency of BERT	1
version 2.0	1
parameter efficiency	1
state encoding baseline	1
sample efficiency and longer-term training	1
9/12 and 10/12 tasks	1
distributions via MSE	1
regularizes Q-value distributions	1
rQdia (pronounced ?	1
great margin	1
pre-trained ViT	1
codes	1
17.9M images	1
600K images are used)	1
97K images	1
model ability	1
2.8M	1
3.5M	1
overall model size	1
demand of computational efficiency	1
various of text appearances	1
node clustering	1
representation's stability	1
oversmoothing problem	1
Bergman divergence	1
inter-node similarity	1
node-to-node geodesic similarity	1
structural and feature information	1
FID scores	1
9 benchmarks	1
compact space	1
recent distribution history	1
quantized values	1
progressively generated distribution	1
fixed target distribution	1
fragile balance	1
mini-batch statistics	1
instability issues	1
maximum margin of 30%	1
optimum number	1
usual visual information (like texture and color)	1
event data	1
relative changes in brightness	1
event camera data	1
motion blur	1
low power consumption	1
high dynamic range	1
relevant codes	1
specific needs	1
10 classes	1
meanings)	1
almost 1,200 cases	1
20,100 samples	1
euphemism, parallelism, personification, oxymoron, paradox, hyperbole, irony and literal	1
concatenatesimage and question features	1
DAQUAR [1]	1
firsthop	1
visual evidence	1
single hop	1
givenphotograph	1
position level	1
top two	1
accuracy 0.5138 and MRR 0.6789	1
CWINDOW word embedding features	1
word usage errors	1
state-of-the-art compression ratio	1
1.05 and 1.62 bits on average	1
significant compression ratio	1
low-bit indexes	1
corresponding low-bit indexes	1
kernel codebook	1
low-bit index	1
weight parameter	1
kernel and weight level	1
quantization unit	1
weight bit-length	1
significant performance loss	1
41.0F1)	1
data collected	1
marginally lower	1
39.9F1 on questions	1
varying model-in-the-loop strengths	1
progressively stronger models	1
total of 36,000 samples	1
three different settings	1
F1-score for both token and entity level	1
auxiliary labels	1
entity level	1
3 vs. 200 epochs	1
fewer training epochs	1
2% difference	1
significant robustness gains	1
conventional ADA	1
discrete text adversarial examples	1
abundant	1
new virtual samples	1
much larger proportion	1
exponentially large attack search space	1
textual adversarial examples	1
ResNet score	1
than90% to 0% on real world data	1
expectedpredictive loss on-line	1
constant space complexity	1
parameter andthe changepoint (CP) posterior	1
exprimental results	1
valuable dependencies	1
strong capacity	1
natural multi-scale features	1
feature inconsistent	1
4:52% and 3:89% respectively	1
robustness and generalization ability	1
small amount of target labelled data	1
quantity of Automatic Speech Recognition annotated data	1
data sparsity challenge	1
limitation of available data	1
high risk	1
state-ofthe-art accuracy	1
74.54 and 75.35 NDCG scores)	1
single-model and ensemble settings	1
top position	1
series of questions	1
free licenses	1
premises and claims	1
typology of argument components	1
https://github.com/razeineldin/DeepSeg/.	1
comparative performance	1
0.81 to 0.84 and 9.8 to 19.7	1
obtained segmentation results	1
dice and Hausdorff distance scores	1
125 cases	1
full resolution probability map	1
encoding and decoding relationship	1
tumor boundaries	1
logical axioms	1
6.9 and 4.4 F1 points	1
mutual restrictions	1
inappropriate relations	1
communicative intent	1
standard NN	1
proof of principle	1
conversion results	1
negligible deterioration in performance	1
ReLU nonlinearity)	1
noisy, incomplete, and misleading input data	1
trained policy	1
generality	1
accurate one	1
Question Answering Systems (QAS)	1
data inefficiency	1
time as data	1
app performance	1
99.30% and 98.40%	1
pinnacle testing accuracy	1
minimal and noisy data	1
two different classification scenarios(Binary/Multiclass)	1
considerable time	1
state of the art accuracy	1
healthcare services	1
Avg F1 score	1
mean F1 score of 0.542 on Test2 and 0.536 on Test1 datasets	1
per country basis	1
Big Data 2020	1
synergistic effecton learning performance	1
task-agnostic parameterizationand	1
theinput data	1
ultrametrically distributed	1
ground state energy	1
theoptimal cost	1
ahierarchical, ultrametric fashion	1
multitude of pure states	1
Parisi's solution	1
abstractions	1
common beliefs	1
new embedding matrix	1
lexical level	1
COVID-19 or non-COVID-19	1
Spatio-temporal features	1
extracted spatial-context features	1
pixel dimension	1
frame-level feature	1
importance of each slice	1
COVID-19 of CT scan	1
original CT scan volume	1
single-slice level	1
COVID-19 symptoms	1
massive damage	1
baseline of just	1
multi-outputs	1
augmented 3DDenseNet	1
3D DenseNet	1
required number of energy or force evaluations	1
optimal locations	1
efficiency improvements	1
Hessian matrix	1
gradient vector	1
GPR surrogate	1
saddle-type transition states	1
true gradients	1
large number of locations	1
energy function	1
extra parameters	1
weights of models	1
path-level	1
channel-level	1
computation saving	1
analysis results	1
learning properties	1
nodes and data points	1
teacher labels	1
source codes	1
single MSE or negative SSIM losses	1
prediction of {residual image}.	1
stage-wise result	1
deraining performance	1
dependencies of deep features	1
input and output, and loss functions	1
complicated and diverse	1
moderate sized problems	1
low-rank+sparse matrix separation	1
existing time complexity bounds	1
corrupted entries	1
small number of its entries	1
frequency-specific information	1
frequency axis	1
learnable feature map biases	1
TF-IDF representation	1
greater number of effective samples	1
Word2vec representation	1
particular classes	1
fixed and optimal temperatures	1
temperature scaling (TS)	1
calibrated ULMFiT (CULMFiT )	1
poorly calibrated	1
primary clinical advice	1
21 subsegmental articulatory features	1
phonological features	1
one-hot encodings	1
growing body of evidence	1
outperformance	1
SVM kernel	1
derivatives	1
Longest Common Subsequence distance measures	1
Dynamic Time Warping	1
two efficient time-series distances measures	1
different lengths	1
multi-dimensional trajectories	1
66.62% top-1 accuracy	1
6.78%	1
81.91% top-1 accuracy	1
spatial, temporal and spatio-temporal perspectives	1
data augmentations	1
sameperformance guarantees	1
times during the day	1
apossibly different, block-specific, distribution	1
sub-optimal for input (video) to output (description) mapping	1
static features	1
video-level features	1
negatively correlates	1
BLEU andthe grammaticality and meaning preservation parameters	1
low or no correlation	1
lexical andstructural aspects	1
informative metric	1
0.7221 F1 score	1
block-wise learning rate	1
layer freezing	1
user questions.~We	1
large source of knowledge	1
text representation	1
following genres	1
51,325 sentences	1
day by day	1
fine-grained masks	1
Instance Segmentation track	1
vulnerabilities	1
even more vulnerable	1
wrong partially	1
another 29.3 to 53.3% of	1
completely wrong	1
20.2 to 45.0% of entities	1
entity context	1
89.2 to 99.4%	1
variation in input data	1
33:3%, 18:6%, and 4% improved accuracy	1
world knowledge and causal reasoning and one requiring domain (healthcare) knowledge	1
electrophysiological features	1
significant correlations	1
19%	1
average of 83%	1
nearly 0	1
coefficients	1
thumb flexion averaged 0.76	1
significant correlation coefficients	1
amplitude of finger flexion force	1
strongly correlated	1
relative FD	1
fractal dimension (FD)	1
19\% (mean	1
mean of 27 +/-	1
maximum 73%)	1
12% (mean	1
mean of 52 +/-	1
EMG artifacts	1
confounding bandwidth overlap	1
compendium of CMC	1
common trends	1
holistic overview	1
scattered knowledge	1
inconsistent view	1
flurry of concurrent publications	1
theprevious high score of 0.608	1
area under the ROCcurve of 0.8562	1
accuracy of 0.6660	1
vastly superior	1
accuracy, the F-Measure, and area under the ReceiverOperating Characteristic (ROC) curve	1
finitedimensional normed vector space	1
IPPO 's strong performance	1
local value function	1
various theoretical shortcomings	1
centralized, joint value function	1
decentralized execution}	1
medical data paucity	1
fixed False Positive rates	1
nodule size	1
size/attenuation conditions	1
real vs synthetic nodules	1
nodule discriminator	1
multiple conditions	1
GAN -based DA performance	1
position/size/attenuation	1
physicians' minimum annotation cost	1
small/fragmented	1
lower vocab-size	1
complete context	1
fewer resources	1
compute and memory intensive	1
English language	1
individual (IND), Group (GRP), or Other (OTH)	1
targeted (TIN) or untargeted (UNT)	1
offensive (OFF) or non-offensive (NOT)	1
visual and text modalities	1
higher layers to lower layers	1
holistic text features	1
+2.09 BLEU points	1
gradient vanishing problem	1
sequential axis	1
stacking layers	1
potential strength	1
NAS pitfalls	1
cell architectures	1
$8$ and $20$	1
change in rankings	1
depth-gap	1
narrow accuracy range	1
contribution of each component	1
average architecture baseline	1
training protocols	1
expertly engineered search spaces	1
$5$ datasets	1
benchmark of $8$	1
speech enhancement quality	1
EEG based speech enhancement results	1
much better robustness performance	1
2.8% mAP loss	1
37.3 times speed up	1
99.5% parameters	1
99.5% FLOPs	1
lower accuracy loss	1
discrete and continuous search space	1
channel pruning ratio	1
residual block	1
pruning choice	1
low accuracy loss	1
sufficient compression ratio	1
computer powers	1
contradictions	1
theoretical and empirical observations	1
source training data	1
PASCAL VOC, 78.7% mIoU on Cityscapes, and 68.5% AP	1
competitive results of 73.1% mAP	1
i.e. 3.75x and 7875x faster	1
nine hours	1
top-1 error rate of 24.88%, i.e. outperforming DARTS and AmoebaNet -B by 1.82% and 1.12% respectively	1
certain computation costs	1
low-fidelity performance estimation	1
slow-learners	1
relatively higher accuracy	1
unique characters	1
high-performance CNNs	1
reasonablydomain-independent representations	1
subsets of the test data	1
74.5% accuracy	1
sentence features	1
better efficiency and effectiveness	1
sparse user-item interaction data	1
smoothing problem	1
non-linear activations	1
training difficulty	1
GCN s.	1
higher-layer collaborative signals	1
user-item interaction behavior	1
convolution aggregation operations	1
synthesis and dehazing performance	1
translating consistency	1
imbalanced and unpaired training samples	1
optimal mapping	1
VAE objectives	1
perception abilities	1
low visibility	1
F-score of 0.526	1
anF-score of 0.569 and BN-EN	1
outperformed Run1	1
n ranged from 2 to 6	1
TF-IDF feature vectors	1
BN-EN	1
sentence level sentiment polarity	1
CONLLU format	1
dependency links and semantic labels	1
types of relations	1
original UCCA files	1
strict accuracy	1
3.5%	1
hyperbolic space	1
mention's encodings	1
hyperbolic geometry	1
FG-NET data	1
hierarchal structure	1
fine-grained entity typing data	1
mentions' context	1
type labels	1
hundreds)	1
wide range of entity types	1
structural constraint	1
three dimensional parametric information	1
high resolution coefficients	1
high frequency components	1
high resolution images	1
missing depth information	1
subtle structural details	1
low resolution face images	1
high resolution face images	1
different iteration	1
detailed features	1
super resolution	1
feature discriminability	1
receptive field block	1
Perceptual Extreme Super-Resolution	1
polyseme representations	1
given polyseme	1
initial classes	1
new classes of images	1
predefined rules	1
correctness of the final prediction	1
multiple single pill images	1
multiple predictions	1
single pill image	1
exact solution	1
generated embedding vectors	1
pill image	1
Proxy Anchor Loss (PAL) function	1
performance efficiency	1
31* and 27* in 65nm technology	1
area and delay	1
significantly reduced computations	1
huge amount of computations and memory requirements	1
significantly speed	1
backbone architecture	1
optimistic estimates	1
count-derived bonuses	1
Q-value estimates	1
provably efficient	1
source of optimism	1
pessimistically initialised Q-values	1
optimistic Q-values	1
pessimistic initialisation	1
lowest possible values	1
positive rewards	1
81.8% top-1 accuracy	1
corresponding centers	1
pushing samples	1
PaCo loss	1
$87.41\%$ top-1 accuracy	1
local discriminating features	1
subtle details	1
$86.36\%$ top-1 classification accuracy	1
extra annotations	1
annotated labels	1
small inter-class	1
useful semantic representations	1
various hand-object pose s	1
data perspective	1
articulated hand-object pose estimation	1
heavy training consumption	1
vast diversity	1
diverse hand poses, object poses, and camera viewpoints	1
articulated 3D hand-object pose	1
77.05%	1
accuracy 86.14%	1
dropout rates	1
varying dropout rates	1
dropout ratesin	1
different layers	1
20th considering recall	1
18th outof 38	1
different feature space	1
English (subtask A	1
qualitatively and quantitatively superior	1
target skin color and lighting conditions	1
barycentric coordinates	1
reenactment, Delaunay Triangulation	1
face views	1
pose and expression variations	1
number of technical contributions	1
less time	1
exact results	1
much larger datasets	1
exact DTW	1
much slower	1
approximate FastDTW	1
well over a thousand citations	1
quickly approximate	1
amortized time	1
quadratic time complexity	1
best measure	1
distance measure	1
automatic scores	1
WAT 2019	1
cross-language and cross-domain capabilities	1
interesting performance	1
superior performance gains	1
almost negligible	1
additional computation and memory overhead	1
careful designs	1
optimal routing path	1
previous inference step	1
corresponding attentions	1
different attention spans	1
global and local dependency modeling	1
micro-views	1
multimodal prediction	1
superior ability	1
optimal variance within a factor of 3	1
immediate sampling variance (exploit)	1
neighbors (exploration)	1
variance information	1
sampling variance	1
neighbors or learned weights	1
intractable computation	1
low as 14% of time consumption	1
perplexity score	1
open knowledge and domain-specific knowledge	1
full information of the training data	1
low-resource scenarios	1
massive computation	1
strong ability	1
influenza poorly(F1=14.80	1
F1=78.91)	1
-related disorders	1
Certain syndrome types	1
F1=39.40)	1
bigramsperforms worst	1
F1=47.38)	1
F1 score above 96.00.The	1
3.6 million	1
outbreak detection speed	1
records	1
emergency department records	1
top score	1
weighted average score of 0.67	1
task deadline	1
subtask B.	1
weighted average score of 0.61	1
rank nine	1
multiple representations	1
low-order to high-order	1
useful representations	1
effective representation	1
clustering results	1
overall MRP evaluation metric	1
final submission	1
edges second	1
small increase in performance	1
BERT memory usage	1
five public German NER tasks	1
training duration	1
larger the number of parameters	1
globally optimal solution	1
types of similarities	1
LQR tasks	1
corresponding MAML objective	1
underlying tasks	1
single model-based micro-expression AU detection results	1
balanced detection loss function	1
micro-expression-level representation	1
Action Units (AUs)	1
subtle changes	1
complex temporal relations	1
multivariate time series	1
blast furnace data	1
relevant patterns	1
higher level of learning capability	1
single asset	1
phenomenon	1
human capabilities	1
https://github.com/fanq15/FewX.	1
significantly better detection results	1
representative query tube features	1
500 classes	1
better subjective and objective performance	1
scale factor as large as 16	1
spatial and temporal redundancies	1
reconstructed features	1
high-resolution video frames	1
Video super-resolution	1
$3.8\times$ less total steps	1
$\gamma$	1
decaying $K$	1
true minimiser	1
quadratic objectives	1
significant savings in terms of energy and time	1
total computation	1
Decaying $K$	1
number of local SGD steps	1
client learning rate, $\gamma$	1
'true' loss	1
parsing accuracy	1
larger treebank	1
i.e.,75.7% top-1 accuracy	1
acompetitive result	1
3rd with score of 0.814	1
4th with score of 0.843	1
macro averaged F1-Score of 0.897 in Arabic	1
moment's enriched snippet features	1
intra-modality relationships	1
video snippets and query tokens	1
semantic alignment	1
videos' and queries' semantic content	1
time interval (or moment)	1
deepened too much	1
MCGL's tolerance	1
traditional classifiers	1
previous understandings	1
diverse interpretations	1
diversity of local interpretations	1
local interpretations	1
piece-wise linear interpretability	1
minimal annotation cost	1
large number of labeled data	1
2x the number	1
25% more depth	1
3x larger	1
image volumes	1
fixed memory budget	1
total number	1
pointwise convolution	1
outputs of that layer	1
input activations	1
activation memory	1
model's depth and width	1
set of tumor classes	1
subsequent step	1
new NE categories	1
4-5%	1
sensitivity of 90.03% and 0.03 FPR/h which	1
correlation between features and labels	1
Effective results	1
sensitivity of 78.11% and 88.21%, and FPR of 0.27/h and 0.14/h	1
true prediction	1
average time of 10 min	1
best ML model	1
level ofperformance superior to that of DQN	1
humanand superhuman levels	1
least one order of magnitude faster	1
optimization speed	1
extremely computationally expensive	1
optimal DA policies	1
better generalisation	1
data variability	1
accuracy of 0.82	1
feature of length	1
corresponding answers (subtask B	1
true factual information	1
factual question (subtask A)	1
high quality posts	1
Vs Ictal, Pre-Ictal Vs Inter-Ictal classification	1
69.1%, 67.6%, 72.3% for Pre-Ictal Vs Ictal, Inter-Ictal	1
76.7% for positive-negative classification	1
65.9%, 69.5% for valence and arousal classification	1
intrinsic variables	1
inter-subject variability	1
good success	1
Subtask 1 (ReCAM-Imperceptibility) and Subtask 2 (ReCAM-Nonspecificity)	1
Ensemble of these	1
abstract word	1
decoder	1
aligned embeddings	1
HR ground truth data distribution	1
resulting latent representations	1
LR brain graph embeddings	1
multimodal brain data distributions (e.g., morphological and structural	1
domain fracture	1
e.g., functional)	1
single LR graph	1
low-resolution (LR) one	1
high-resolution (HR) image	1
45.7% mAP	1
19.0M extra parameters	1
+2.0% mAP	1
2.4M extra parameters	1
+2.5% mAP improvement	1
module input	1
position and semantic information	1
high and low-resolution features	1
detail and position information	1
medical history private	1
desirable privacy utility trade-offs	1
architectures and setups	1
sensitive nature	1
emotional and physical problems	1
orders of magnitude less data	1
highaccuracy NER	1
text contents	1
high IoU thresholds	1
ourstate-of-the-art results	1
theimage holistically	1
variable number	1
initialcategory-level segmentation	1
object class and instance identity label	1
coarse, bounding-box level	1
combination of them scores	1
20\% training data	1
minimal generation length	1
Levenshtein belief spans (Lev)	1
new one	1
old dialogue states	1
over-dependency	1
10% overall	1
+12.0 Mean Average Precision)	1
complex inference facts	1
6 or more facts	1
notion of unification power	1
lexical relevance	1
explanatory patterns	1
NE classes	1
total scenario	1
4 points	1
5 NE classes	1
F1-score by 1 point	1
structured predictions	1
learned internal states	1
high dimensional, sparse vector space	1
recurrence relations	1
skill through time	1
memory states	1
student	1
topics or skills	1
new standards	1
less explored syntax	1
energy consumption 6.9x - 125.8x	1
sustainable runtime	1
4,223 USD to just 18 USD	1
100 million requests	1
12.4x speed-up	1
9.8x up to 233.9x speed-up	1
best settings	1
efficient inference-time performance	1
sequences of morphological category values	1
morphological labels	1
internal structure	1
composite labelsand	1
itsinternal structure	1
monolithic label	1
morphological tag	1
operation selection bias	1
weights and parameters	1
learning rate schemes	1
well-trained supernet weights	1
relative performance improvement of 40 percent and 60 percent respectively (on the key metric of Precision@1)	1
missing entry	1
clarification question	1
information gaps	1
better discriminative feature	1
combining spatial and sequential temporal features	1
range of 19% to 57%	1
97% and 92% accuracy	1
range of 8% to 27%	1
91% R^2 score	1
status classification	1
best learning features	1
sequential patterns	1
patients' data	1
visual representation vectors	1
spatial and temporal aspects	1
perspective historical patients' biological records	1
lung CT-scan images	1
high uncertainties	1
CT-scan images	1
good uncertainty measure	1
softmax output	1
confident enough	1
high F1 test score	1
training time and testing error	1
output layer	1
0.29 to 0.95	1
initial F1 test score	1
certain plant types	1
skewness (99% vs. 1%)	1
593$\times$	1
memory usage by up to 1.9$\times$ and communication cost	1
memory usage and communication cost	1
small subset of variables	1
expensive communication	1
limited memory	1
cost of a tolerable 4-5% drop	1
significant speedup and energy efficiency benefits	1
3.8x and 2x	1
speedup of about 2.5x and 1.7x	1
accuracy, latency and energy consumption	1
``hardware awareness	1
energy term	1
accuracy and target device latency	1
previously reported best results by 7.79%	1
brain activity patterns	1
multiplefilters of exponentially varying lengths	1
1D convolution layer	1
abnormal or normal	1
manual interpretation atime-consuming, resource-hungry	1
rateat which new data	1
volume of the data	1
relativelylow inter-rater agreement (IRA)	1
optimal or close to optimal performance	1
optimal and suboptimal demonstrations	1
demonstration and human evaluative feedback	1
performance of demonstrations	1
expert trajectories	1
sample inefficiency problem	1
image deblurring and super-resolution problems	1
demonstratestate-of-the-art results	1
globally optimal result	1
general inverse problems	1
overallobjective functional	1
$P^3$method	1
chained denoising interpretation	1
inverse problem	1
thisimpressive achievement	1
terms of noise removal performance	1
{``}hard to answer{''} examples	1
{``}easy to answer{''} examples	1
Experimental evaluation	1
``}easy to answer{''}	1
answerable or unanswerable by BERT	1
{``}hard to answer{''}	1
{``}easy to answer{''}	1
Muting pixels	1
Saliency-driven Class-Impressions	1
Misclassification Error Rate	1
interaction between features	1
univariate criterion	1
small set of important features	1
dimension of the data	1
certain evaluation criterion	1
subset of original features	1
Universal Dependencies 2.3	1
precomputing such embeddings	1
appropriate word meaning	1
Federated Dropout	1
model weight updates	1
formation	1
runs and model sizes	1
second best Exact Match	1
relative benefits	1
accuracy by less than 1%	1
result matrices	1
interesting echelon shape	1
different levels of questions	1
$12$ different types of questions	1
directlytranslating the test data	1
collecting data	1
5.3 pt improvement	1
32.7% relative improvement)	1
42.6 HITS@1	1
new state of the art performance	1
performance worse	1
convergence and UA benefits	1
best UA	1
$3\times$ improvement	1
$5\times$	1
target UA	1
number of rounds	1
UA and convergence speed	1
individual User model Accuracy (UA)	1
FL measures global-model accuracy	1
non-Independent and Identically Distributed (non-IID) user data	1
private user data	1
Entity F1 score)	1
Graph Laplacian	1
lot of memory	1
parameters distribution	1
empirical fact	1
logarithmic quantization	1
resource-intensive	1
61.37% mAP	1
end-end differentiable	1
final answer quality	1
required feature representations	1
low-quality or irrelevant answers	1
specific questions	1
Scope Resolution	1
2.84% and 1.38% Character Error Rate (CER) reductions	1
masked phonemes	1
variable-length encoder features	1
negligible loss in accuracy	1
35%-80% reduction	1
roughly 50%-95% reduction	1
FLOPs or memory	1
neuron resource consumption	1
neuron importance	1
importance score	1
high sparsity levels	1
complex nature	1
excessive memory and computational requirements	1
differences in performance	1
Word2Vec, fastText and ELMo	1
word translation probability	1
word meaning similarity	1
kinds of errors	1
Syntactic Tree Kernels	1
set of choices	1
accuracy of 0.80	1
accuracies of 0.70 and 0.73	1
domain and open polaritylexicons	1
polarity values	1
target polarity classification (slot 3)	1
new features	1
i.e., PTB, WikiText-103 and One-billion)	1
ideas of tensor decomposition and parameters sharing	1
RNN's exposure bias	1
output dependencies	1
in-domain and out-of-domain conditions	1
latent codes	1
prohibitively large	1
non-trivial	1
informative latent variables	1
useful statistical dependencies	1
latent random variables	1
p-values	1
disease representations	1
EHR data	1
observed and expected observations	1
age and sex factors	1
human created labels	1
novel patterns	1
false acceptance rate	1
ranks forglobal and local features	1
Bothlocal and global features	1
recognition rateobtained	1
Local features	1
gray level images	1
size of 128 x 128 pixels	1
frontalface image	1
corresponding face image	1
macro F1-score of 0.61	1
macro F1-score of 0.70	1
argument relations	1
i.e., support, attack, rephrase, no relation	1
existing relations	1
premises, claims, etc.)	1
long-term temporal dynamics	1
short-term and long-term relations	1
long-range span	1
temporal dynamics	1
short-term human-context relation	1
reliable relations	1
high threat	1
re-digitized (printed and scanned) images	1
FRS's vulnerability	1
minimal artefacts	1
identity factor	1
high degree of facial resemblance	1
reasonable success rate	1
best reported methods by over 5%	1
sensitivity of 90.77% at 4 false positives per image	1
32,735 lesions	1
weak RECIST labels	1
clinical routine	1
response evaluation criteria	1
anchor configurations	1
particular challenges	1
centroid or bounding-box annotations	1
sizes, locations and appearances	1
lesion types	1
much more interpretabletopics	1
onlyone line of code	1
thecomputational cost	1
much better inference time	1
diverse and contextually relevant responses	1
Response Echo Index	1
two novel automated metrics	1
topical concepts	1
best published CNN result	1
1.4% WER improvement (10.6%relative)	1
word errorrate of 11.8%	1
262 hours of SWB-1 training data	1
absolute 5.77% WERimprovement	1
multi-scale input features	1
small 3x3 kernels	1
to14 weight layers	1
number of architectural advances	1
error rate by 11% and 1%	1
stronger augmentation levels	1
87.71 %	1
92.52 %	1
pedagogical content	1
several failure modes	1
underlying supernets	1
supernet's performance	1
operation	1
magnitude of architecture parameters	1
operation strength	1
values of architecture parameters	1
final architecture	1
largest architecture parameters	1
model weight and architecture parameters	1
search efficiency and simplicity	1
95.7\% F1-score	1
traditional full packet captures	1
cybersecurity scenarios	1
specific circumstances	1
Network traffic Flows (NetFlows)	1
$F_{1}$ score	1
hyperparameter presets	1
GermEval 2018 (fine and coarse)	1
rarity ofrewards	1
low-dimensional state space	1
large action space	1
rare reward signal	1
Negation, All-of-the-above, and None-of-the-above	1
Fairness evaluation	1
WEM stability	1
five parameters	1
given text data	1
dense vector representation	1
multiple runs	1
similar representation	1
positive responses	1
corrupted data	1
tractable prior distributionunder	1
samplesofdata distribution	1
agenerative model	1
DAE	1
test log-likelihood	1
2020-12-06	1
MRR@100 equal to 0.298	1
UD 2.2	1
end-to-end character-level word embeddings	1
agents cooperation policies	1
en-ergy level	1
customer demand	1
complex intelligent behavior	1
interpretable policies	1
higher sample efficiency	1
Cartpole problem	1
RL problems	1
time-variant ones	1
improved version of SPAQL	1
SPAQL with terminal state (SPAQL-TS)	1
mapping from states to actions	1
rank-1 accuracy of $98.27 \%$ with standard deviation of $0.13$ on the Market-1501 and $98.7\%$ with standard deviation of $0.2$	1
re-ID accuracy	1
ensemble of $\sqrt{N}$ classifiers	1
local tokens	1
private test data	1
significant gain of up to 10%	1
strongly text-correlated video features	1
adequate visual representation	1
big potential	1
primary results	1
real-world knowledge	1
dialog belief state	1
F1 score of 52.58 and an accuracy score of 46.60	1
accuracy score of 68.52	1
F1 score of 76.4	1
Different sets of hyperparameters	1
Pretrained weights	1
robustness characteristics	1
considerable portion of the lost accuracy	1
character-level and contextual information	1
detection recall	1
toxicity signal	1
toxicity classifiers	1
short-term temporal dynamics view, spatial dynamics view and long-term temporal dynamics view	1
spatial dynamics	1
spatial data sparsity	1
vehicle scheduling	1
Predictable ride-hailing demand	1
76%-96% compared to 52%-77%	1
features' importance	1
increased stability	1
robustness and consistency	1
superiority of gLIME	1
small partial correlation coefficients	1
specific data points	1
local scale	1
entire dataset	1
global (	1
direct and indirect impact of features	1
conditional relationships	1
models' output	1
simple explanations	1
increase of 13.65%	1
improvement of 14.77%	1
accuracy and running time	1
massive data	1
low-dimensional spacewithin short time	1
high-dimensional features	1
radiologist-driven annotations	1
pathologist-driven annotations	1
reference estimate	1
so-called ground truth	1
inter-expert agreement	1
single expert	1
large margin of 4.7 points	1
generality and practicality of ELCO	1
better model performance	1
fewer examples	1
early stages	1
stages	1
damages	1
interesting MUC7 and CoNNL scores	1
population of over a hundred million people world-wide	1
weighted accuracy of 72.7% and an unweighted accuracy of 73.3%---a 6% improvement	1
different time-frequency resolutions	1
accuracy improvements	1
relative accuracyimprovement of around 40% with only 15 to 20 seconds	1
untranscribed target datato	1
onlyvisual features	1
human perception via Mean Opinion Rank (MOR)	1
less noise	1
better perceptual quality	1
Ground-Truth (GT)	1
high quality face images	1
similar image characteristics	1
JPEG compression artifacts	1
noise distributions	1
realistic blur kernels	1
real LR images	1
natural image characteristics	1
bicubic interpolation	1
High-Resolution (HR) images	1
experimented results	1
training mode	1
face classes	1
given new face image(s)	1
new face image(s)	1
different face classes	1
two modes	1
stir	1
tremendous growth	1
highest performance with 94.03% ACC, 96.09% SEN, 92.01% SPE, 92.19% PRE, 94.10% F1-Score, 88.15% MCC and 88.07% Kappa metric values	1
SVM kernels	1
three different numbers	1
training (%75) and testing (%25)	1
lives of thousands	1
Word2Vec vectors	1
two point scale (positive or negative sentiment	1
RA-UNetachieves good performance	1
attention-aware features	1
high-level ones	1
liver volume of interests (VOI)	1
theirhigh cost	1
heterogeneous and diffusive shapes	1
radar detection performance	1
favorable performance and stability	1
SINR and bandwidth utilization	1
important radar metrics	1
fine range resolution	1
sufficient utilization	1
target detection performance	1
bandwidth and center frequency	1
optimal radar performance	1
global, local and spatial information	1
% higher	1
classification accuracy rate	1
multiple featuresis	1
mutual complementation areadopted	1
Three features	1
low classification accuracy	1
summarized captions	1
standard captions	1
RS image	1
ground-truth captions	1
language domain	1
information deficiency	1
repetitive or semantically similar	1
promising registration speed	1
desirable diffeomorphic properties	1
diffeomorphic maps	1
image registration optimization problem	1
small deformation settings	1
unknown conformations	1
atomic spatial coordinates	1
binding affinity	1
textual molecular representations	1
inhibition constants $K_i$	1
binding affinities	1
molecular binding affinity	1
substantial speedup	1
overfitting bias	1
inferior models	1
slow	1
sheer amount of model parameters	1
impact of each attribute	1
fresh nor current	1
ongoing event mentions	1
corresponding difficultness	1
early training stage	1
feature margin	1
new intbrmation Dora known data	1
infinite nlenlory	1
data types	1
several of the more problematic aspects	1
`` structural relations	1
lexical type of each operator	1
approximate order of preference	1
readings	1
logically redundant readings	1
set of valid scoped readings	1
`` unscoped elements	1
`` scope ambiguities ''	1
arbitrary number of unseen views	1
implicit relationship	1
subsequent modules	1
feature embedding	1
predicted coordinates and confidence	1
video length	1
varying view numbers	1
number of views	1
several variable elements	1
tiny fraction	1
bias terms	1
fixed-point quantization	1
near zero	1
neural network parameters	1
https://github.com/HayeonLee/MetaD2A.	1
past years	1
5.5K times faster	1
average search time of 33 GPU seconds	1
cross-modal latent space	1
time and monetary budget	1
large computational cost	1
every given task	1
61st out of 164	1
Weighted FineGrained f1 score of 0.908648 and 0.533907	1
Coarse-Grained Hostility f1 Score	1
precision and f1 score of 0.96728972 and 0.967324832 respectively	1
high fooling rate	1
popular SSIM index	1
``perceptual quality ball" constraint	1
pixel to pixel distances	1
$l_p$ distances	1
imperceptibility	1
$l_p$ distance	1
mechanics	1
carefully crafted imperceptible perturbations	1
51.1 AP	1
optimal anchors	1
certain level of spatial misalignment	1
spearman of 17.12{\%}	1
accuracy of 76.24{\%}	1
search result	1
large number of search results	1
$>$ 300Hz	1
95.3\% accuracy	1
1 MB	1
lack of robustness	1
person-dependent accuracy	1
eye-gaze estimation	1
signed weights	1
wsGAT layers	1
existence	1
signed weight of links	1
signed and weighted links	1
wide range of domains	1
0.8M and 0.4M	1
0.9M	1
super-light model size	1
short-range local features and long-range contextual features	1
long-range contextual properties	1
short-range local features	1
high level comparison	1
major trends	1
9.2x faster	1
10x faster	1
different search algorithms	1
variety of search algorithms	1
Fully Train	1
platform diversity	1
scalability, integrability	1
four great challenges	1
DTW computations	1
99.99%	1
novel hierarchy of lower bounds representation	1
time-to-compute and tightness-of-lower-bounds	1
best trade-off	1
time series motifs	1
best time series similarity measure	1
57% more parameters	1
31% less model parameters	1
less than 18%	1
4.7% in the zero-shot setting	1
long-distance relations	1
substantially fewer parameters and training steps	1
generated phrase representations	1
corresponding token representations	1
phrase representations	1
phrase level	1
reordering ability	1
phrases)	1
shorter network paths	1
24.6 BLEU score	1
minimized compromise	1
significant speed	1
proposed (dis)similarity measures	1
term of speed-up ratio	1
two new(dis)similarity measures	1
quality ofthe measure	1
quadratic computational cost	1
temporal data	1
'temporal elasticity'	1
proper distance or(dis)similarity measure	1
optimal combinations of corrections	1
previous sentences	1
specific error types	1
channel model	1
Wikipedia edit history	1
low-resource track	1
walking and learning time	1
average improvement of 23 - 57% embedding time	1
embedding cost	1
local proximity	1
any/much information	1
smaller graph	1
huge sizes	1
77.70%	1
temporal axis	1
different temporal band	1
covariance matrices	1
high dimension of feature space	1
intention	1
level of uncertainties	1
acceptable accuracy	1
different vertical loads, velocities	1
dynamic behavior	1
prediction and variable selection accuracy	1
favourable properties	1
empirical properties	1
theproximal operators	1
closed forms	1
amore practical finite dimensional equivalent	1
variational problem	1
reproducing kernelHilbert spaces	1
group lasso and elastic net	1
nonlinear equivalents	1
two new regularizers	1
function spaceto additive models	1
better quality intensity rankings	1
different intensity	1
positive properties	1
submission data	1
final labels	1
language concreteness	1
pre-trained word embeddings (Glove)	1
around 20 times faster	1
massive speedup	1
around 95% candidates	1
longer time sequence	1
hash buckets	1
DTW similarity measure	1
(near perfectly)	1
(probabilistic) indexes	1
longer queries	1
low dimensional time series	1
DTW slow	1
upper hand	1
complexity order	1
gates	1
domain dependant knowledge	1
nearly state-of-the-art performance	1
word level annotations	1
Classification perspective	1
character level annotations	1
sequence to sequence (seq2seq)	1
existing search spaces	1
new search space	1
high-level abstractions	1
numerous low-level implementation details	1
less than one second	1
303 seconds	1
speed of prediction	1
average SSIM of 0.824 compared to 0.783	1
average MSE of 3.768 compared to 4.032	1
average SSIM of 0.636 compared to 0.607	1
average MSE of 27,611 compared to 146,855	1
mean squared error (MSE) and structural similarity index measure (SSIM )	1
two measures of performance	1
resolution levels	1
550 images	1
first 7 and 15 frames	1
70 frames for each sample	1
High-resolution images	1
1200 paired high power and low power images	1
quality of the image	1
one millimeter in thickness	1
parameter and computation overheads	1
new state-of-the-art localization accuracy	1
recognition power	1
integral extent	1
location annotations	1
object location	1
time or computational resource limitations	1
accuracy degradation of less than 0.5%	1
significant saving of power	1
87.36%/0.169, 96.70%/0.102, and 97.61%/0.071	1
sensitivity and FPR (h-1)	1
false positive rate	1
Inference sensitivity	1
inference performance	1
positive average rewards of 100+	1
additional uncertainities	1
200+	1
average rewards of 170+	1
additional uncertainty	1
notion of cumulative long-term reward	1
memory requirements	1
accuracy of 99.71%	1
distinct positions	1
diverse factors	1
publicly available traffic sign datasets	1
8% relative improvement	1
3.47 WER	1
acoustic states	1
one training sample per character	1
final 2.38% Equal Error Rate	1
6	1
64	1
position, posture	1
character of the password	1
high recall and precision values	1
malicious and non-malicious	1
anomalous behavior	1
representative images	1
resource access patterns	1
daily resource usage pattern	1
frequency based attributes	1
MIDI-like output events	1
spectrogram inputs	1
standard decoding methods	1
equivalent performance	1
input/output representations	1
perplexity measure	1
uncertainty of the estimates	1
point - estimates	1
shorter version	1
source - side syntactic information	1
source dependency structure	1
aspects of informativeness and correctness	1
entailment Reward	1
entailment knowledge	1
correct summary	1
cross-lingual improvements onlow-resource data	1
repetition 1	1
summary of higher quality	1
source - side information	1
performance ablations and analysis examples of each contribution	1
salient information	1
https://github.com/ clovaai/FocusSeq2Seq	1
top - 5 accuracy	1
6 % gain	1
state - of - the - art top - 1 accuracy	1
diversity and training efficiency	1
semantically one - to - many relationships	1
reader focused aspects	1
informal and noisy	1
better summary	1
wrong aspect	1
first positive language modeling result	1
perplexity gains	1
encoding information	1
contextual capacity	1
previously generated words	1
size of context	1
propensity	1
negative result	1
latent vector	1
current generated words	1
informative signals	1
high - level extracted features	1
long ( more than 20 words	1
entire text	1
intermediate state - action steps	1
RL reward signal	1
future one	1
current score	1
generative model	1
discrete outputs	1
real - valued data	1
two events	1
temporal relation	1
NLP perspective	1
temporal order	1
temporal and the causal dimension	1
tight connection	1
temporal ones	1
much sparser	1
different model architecture and pre-training tasks	1
speedup of factor 10	1
expression	1
55 % to 79.67 %	1
accuracies ranging from 65	1
45 %	1
smile recognition test accuracy of 99	1
aspect term extraction ( ATE ) and aspect polarity classification ( APC )	1
Chinese language - oriented	1
different experiment settings	1
accuracy , f- score , precision and recall	1
eight hand - crafted features	1
ambiguous definition	1
mood , temperament , personality , disposition , and motivation	1
multitude of factors	1
large number and diverse source of input data	1
complex functions	1
higher - level features	1
discrepancy information	1
intrinsic spatial dependence	1
two spatial orientations	1
asymmetric differences	1
approximately 2 and 1 points performance improvement	1
80 %	1
accuracies of 82.31 % and 79	1
contributing features	1
text , visual and acoustic	1
different input modalities	1
target and left / right contexts	1
two characteristics	1
specific aspect	1
fine - grained opinion polarity	1
larger context	1
9 of 12 experiments	1
data fast	1
heart-rate sensors, and electrical battery data	1
pollution measurements	1
new short-history time series	1
lot of data	1
polarity is positive	1
aspect taste	1
concerned aspect	1
complete and in - depth results	1
emotional orientation	1
conversational videos	1
emotional dynamics	1
several aspects of one or more neighbourhoods	1
target entity	1
single sentiment	1
single entity per document	1
fine - grained information	1
high - level concepts	1
disentangled features	1
sufficient amounts of capacity	1
state of the art by 1.6 % on average	1
target aspect	1
neighboring aspects related information	1
user sentiment	1
business decisions	1
state - of - theart results	1
best published ones	1
compositionality and long - term dependencies	1
convolution filters	1
collocative context	1
targets and contexts	1
aspectspecific features	1
parameterized gates	1
emotion detection performance	1
context and commonsense knowledge	1
external commonsense knowledge	1
contextual utterances	1
annotated entities	1
aspects and context sentences	1
time dependency	1
computations	1
accurate and efficient	1
target - specific representations	1
position - aware representations	1
position embeddings	1
new state of the art accuracy of 97.42 %	1
dense , lowdimensional vector	1
1 st ( tie )	1
alternate bias	1
forward and reverse directions	1
suffix and prefix	1
syntactic properties	1
given target	1
( detected ) context	1
target - sensitive sentiment	1
sentiment context	1
80 % up to 85.4 %	1
single sentence positive / negative classification	1
fine grained sentiment labels	1
powerful models	1
user questions	1
precise contributions	1
computational improvements	1
MAML 's performance	1
simplification of MAML	1
dominant factor	1
high quality features	1
meta initialization	1
MAML 's popularity	1
misleading ones	1
decreasing weights	1
conventional training objective	1
correct / incorrect prediction	1
maximum attention weight	1
useful attention supervision information	1
context word	1
accuracy improvement of 3?4 % over the state of the art	1
inter-speaker dependencies	1
past utterances	1
audio , visual and textual features	1
utterance - level emotions	1
inter-speaker dependency relations	1
comparable or superior	1
mor -	1
semantically ambiguous	1
performance competitive with or better	1
3.8 in informativeness	1
kinds of linguistic features	1
around 30 %	1
desired compression length	1
PoS or NE tags , or dependencies	1
token deletion decisions	1
sequence of zeros and ones	1
state - of - the - art results by 2 % - 3 %	1
better over all classification performance	1
state - of - the - art results , 87.4 F1 and 87.0 F1	1
spanlevel features	1
higher scoring labeled spans	1
possible argument spans	1
50 K tokens per second	1
1.8 and 1.0 F1 score	1
previous state - of - the - art results	1
F1 = 82.7	1
F1 = 83.4	1
surprisingly obvious errors	1
long - distance dependencies	1
10 % relative error reduction	1
83.4 F1 on CoNLL 2012	1
number of recent best practices	1
3.5 F1	1
2.5 F1 absolute higher	1
increased accuracy	1
explicit linguistic features	1
precision, recall and F1 score metrics	1
textual and image features	1
grammatical and linguistic errors	1
rich , shared input features	1
contextualized span representations	1
independent decisions	1
predicates , arguments spans	1
high performing	1
low - level information	1
rough sketch of its meaning	1
input utterance	1
structured meaning representations	1
stylometric and personality features	1
person to person	1
sarcastic nature	1
background and commonsense knowledge	1
contextual presumptions	1
user , topic , and conversation context	1
self - annotated	1
balanced and unbalanced label regimes	1
many times more instances	1
previous dataset	1
10 times	1
1.3 million	1
hoc features	1
wrong label problem	1
alignment results	1
P-prefix	1
Q-prefix	1
1 Unique IDs	1
average error reduction of 24 %	1
context representations	1
target relation	1
sentential context	1
22.2 % to 26.7 %	1
F 1 score	1
much better relation extraction performance	1
TAC KBP relations	1
frustratingly slowly	1
Organized relational knowledge	1
task 's training data	1
task agnostic relation representations	1
text representations ( specifically , BERT )	1
arbitrary relations	1
's effectiveness	1
limited side information	1
entity type and relation alias information	1
additional side information	1
founded and co-founded	1
relevant side information	1
significantimprovement in both speed and accuracy	1
computationalefficiency and accuracy	1
theoretical basis	1
Globally Optimal Reparameterization	1
-LRB- some branches of -RRB- lexical semantics	1
fixed levels	1
applicability conditions	1
prev best was 60.49	1
cascading errors	1
entity mention spans	1
1.076 F1-score	1
94.848 F1- score	1
second place F1-score	1
96.499 F1score	1
quantitative metrics ( BLEU , METEOR , ROUGE , and CIDEr	1
places , captions , and tags	1
answer position	1
rigid heuristic rules	1
certain sub- spans	1
aggregated evidence	1
combination of evidence	1
existing baselines by up to 2.6 %	1
hierarchical levels	1
passage and query	1
two distinct characteristics	1
state - of - the - art / highly competitive results	1
long and short term information	1
multi-granular sequence information	1
different levels of granularity	1
couple attentions temporally	1
correct semantic relations	1
multiple entities	1
less than 10 % of the training data	1
discretized prosodic prominence	1
number of different models	1
prosodic labels	1
iterates	1
uniform boundedness assumption	1
strong convexity	1
strongly convex regularizers	1
fast convergence rate $O(1/T)$	1
general convex setting	1
high-probability convergence rate $O(1/\sqrt{T})$	1
favorable $O(d)$ space and per-iteration time complexities	1
general penalty terms	1
large scale streaming data	1
AUC maximization	1
pairwise nonlinearity	1
widely used performance metric	1
contribution of each element	1
new performance record	1
20 % - 60 % relative )	1
pertinence scores	1
text content	1
best level	1
attended visual features	1
target text	1
contextualized word and sentence embeddings	1
MRR@ 10	1
27 % ( relative )	1
top entry	1
small noise levels	1
POS tagging loss function	1
languages and data sizes	1
word , character , and unicode byte embeddings	1
data set size	1
target languages	1
input representations	1
potential long - term label dependency	1
91.21 % F1	1
97.55 % accuracy	1
taskspecific knowledge	1
cleaner word representations	1
improved tagging performance	1
27 languages	1
input perturbations	1
well - formed	1
Quantitative evaluation	1
token level F 1 score	1
considerable performance	1
reading tests	1
incorrect answer extraction	1
insufficient lexical understanding	1
inefficiency	1
best reported result	1
accuracy of 85.5 %	1
cross -domain data	1
top	1
fixedlength vector	1
fairly sufficient simulate data	1
60.8% of its entire population	1
specific training schemes	1
weather forecast information	1
Muslim worships schedule	1
adding features	1
students grade information	1
schedule info	1
curriculum information	1
actual information	1
baseline by a large margin	1
answer content	1
answer boundary	1
content representations	1
single passage	1
context hops	1
extracted commonsense information	1
disjoint pieces of information	1
results to 75.9 %	1
71.3 %	1
positions of answers	1
given passage	1
one correct answer	1
maximizing marginal likelihood	1
absolute gains of 2 - 10 %	1
update	1
likely solution	1
one correct option	1
possible solutions ( e.g. different mentions or equations )	1
many different equations	1
minimum amount of order	1
word - order information	1
almost an order of magnitude fewer parameters	1
beginning and ending points	1
matched vectors	1
matching vector	1
encoded question	1
relevancy weight	1
word - embedding vector	1
answer beginning and ending points	1
syntactic parsing information	1
additional improvement	1
accuracy of 88.6 %	1
hidden variable	1
possible alternatives	1
correct ending	1
expectation of what	1
plot consistency	1
emotional trajectory	1
three distinct semantic aspects	1
social norms	1
optimization policies w.r.t	1
skip connection	1
computationally efficient ones	1
extra computation cost	1
substantial memory consumption and computation cost	1
3.1 % and F1 by 3.0 %	1
exact match accuracy	1
CFC	1
3 % accuracy	1
new stateof - the - art result of 70.6 % on	1
different parts	1
close together	1
answer and evidence	1
new state - of - the - art scores	1
best single model and ensemble model results	1
lightweight parameterization	1
base word representations	1
scalar features	1
alignment vectors	1
surprising finding	1
three settings	1
addressing and output stages	1
much more information	1
certain types of answers	1
labels information	1
new objective function	1
representations of them	1
deep connections	1
important discourse markers	1
interaction architectures	1
two given sentences	1
sparse dependencies	1
soft attention	1
mutual benefit	1
soft and hard attention	1
combinatorial nature	1
soft probabilities	1
omitted information	1
applicable skills	1
reader performance	1
20 % F1 )	1
considerable gap in performance	1
around 100,000 gap - filling queries	1
ability of GORU	1
redundant / irrelevant information	1
remembering ability	1
challenge metrics	1
referring challenge system score	1
third in Subtask B and second in Subtask C	1
final ranking	1
binary classification problems	1
high precision regimes	1
$6.4$ times faster	1
$\geq 81.3\%$	1
GENet s	1
responding time	1
high recognition accuracy	1
query - answer pairs	1
limits of existing methods	1
contradiction or the neutral relationship label	1
important mismatches	1
optimal hyper - parameters	1
previous highest scores of 83.4 % and 87.5 %	1
MAP scores of 92 % and 94.3 % ,	1
long - range dependencies	1
subset ( 20 % - 80 % )	1
significantly more robust	1
extracted general knowledge	1
hunger	1
https://github.com / facebookresearch/LASER	1
parallel corpus mining ( BUCC dataset	1
English annotated data	1
joint multilingual sentence representations	1
best reported performance	1
binary paraphrase labels	1
deep version	1
computationalcomplexity	1
resulting lower bound an optimal variational distribution	1
therecurrent structure	1
open - ended lingual descriptions	1
increasingly intertwined	1
ordered representations	1
partial order structure	1
20 / 20 tasks	1
smaller elements	1
complex questions	1
low - dimensional embeddings	1
Universal Turing Machine	1
variable contexts	1
computer behaviors	1
listwise to pointwise	1
neutral ( neither entailment nor contradiction	1
false )	1
premise is true	1
true )	1
greater than 20 % error reduction	1
richer semantic information	1
denser interaction tensor	1
interaction tensor ( attention weight )	1
interaction space	1
hierarchically extracting semantic features	1
high - level understanding	1
natural language premise	1
two orders of magnitude larger	1
570 K pairs	1
underlying narrative	1
essential integrative aspect	1
global term frequency )	1
local context similarity	1
superficial information	1
RC ability	1
full document	1
accuracy comparable to or better	1
inference times ( up to 13 times )	1
training ( up to 15 times )	1
minimal context	1
drug name recognition (Drug NER ) and clinical entityrecognition (Clinical NER )	1
disease namerecognition (Disease NER )	1
sameset of features	1
contextualas well as morphological features	1
Fully Attention	1
faster computations	1
1.1 BLEU increase	1
gains of up to 6	1
new stateof - the - art results	1
bidirectional encoder )	1
generalizing BERT	1
fine - grained entity information	1
15 out of the 20	1
coreference relations	1
explicit memory	1
directed acyclic subgraphs	1
resulting graph	1
arbitrarily distant elements	1
explicit signal	1
state - of the - art accuracy	1
better similarity measurement	1
fine - grained word - level information	1
Textual similarity measurement	1
56.7 F1	1
score of 71.3 F1	1
globally correct output	1
sharednormalization training objective	1
well calibrated confidence scores	1
answer in the target style	1
styles	1
NLG capability	1
answer style	1
various answer styles	1
answer span	1
two key characteristics	1
multiple training objectives	1
diverse training objectives	1
general purpose features	1
distributed vector representations	1
interdependences	1
little or no information	1
vanishing and exploding gradients problem	1
unitary matrix	1
rotational operation	1
Rotational Unit of Memory ( RUM )	1
associative memory	1
unitary evolution matrices	1
speed - up gain	1
equivalent accuracy	1
4x to 9 x faster	1
3x to 13x faster	1
sequential nature	1
READING COMPRE - HENSION	1
LOCAL CONVOLUTION	1
MinDCF of $0.1942	1
EER of $3.798\%$	1
EER of $3.808\%$ and a MinDCF of $0.1958$	1
Three key points	1
first and second tracks	1
new state - of the - art	1
contextual semantics	1
explicit contextual semantics	1
plain context - sensitive features	1
contextualized features	1
important linguistic properties	1
8 out of 10	1
8 out of 9	1
7 out of 10	1
additional source of question type information	1
question vector	1
answer type	1
meaningful facts	1
question and answer type	1
passagequestion relation	1
ST0 data	1
global dependency	1
word distance	1
forward and backward directional information	1
matching results	1
timesteps	1
matching direction	1
two directions P	1
single direction	1
ever - increasing size	1
original and the co-attentive feature information	1
hidden features	1
concatenated information of attentive features	1
logical and semantic relationship	1
human - level scores	1
near - human - level performance	1
6 %	1
1.5 % ?	1
highly competitive performance	1
Search QA	1
long and short - term context	1
long and short - term dependencies	1
gating vectors	1
new state - of - theart encoding result	1
strong improvements	1
entailment , contradiction , or neural	1
two vectors	1
different matching signals	1
BM25 scores	1
secondary extracted features	1
multiple primary word embedding	1
text automatically	1
ease	1
plain text data	1
fixed - length vectors	1
canonical and inflected word forms	1
general way regularities	1
idiosyncratic peculiarities	1
syntactic restrictions	1
certain types of variation	1
frequency distribution	1
certain domain	1
WORDNET word senses	1
domains -RRB-	1
certain category	1
tree structures	1
text and sentence level	1
system architecture	1
implications of this view	1
user-requirements orientated outlook	1
implications	1
total of four	1
degree of disagreement	1
measure of the quality	1
average number	1
different complexities ~ vere	1
generation rules	1
several distinct stages	1
bulk	1
`` konpyuutaa ''	1
`` computer ''	1
names and technical terms	1
aboutness	1
known distributional properties	1
log-likelihood ratio	1
-LRB- word probability	1
difference in performance	1
different n	1
n-gram models	1
particular variational distributions	1
derivations	1
probable derivation	1
computationally intractable	1
decoding -RRB-	1
best string -LRB- e.g.	1
total probability	1
many distinct derivations -LRB-	1
output string	1
spurious ambiguity	1
F-score of 0.9355	1
N-best candidate word segmentations	1
use of global features	1
F-scores of 80.2 % and 70.4 %	1
gold standard parses	1
sentence transformation rules	1
60 % F-measure error reduction -LRB- from 14.4 % to 5.8 %	1
sentence lengths	1
transfer lexicons	1
reliable cues	1
corresponding translation duals	1
98.2 % to 85.6 %	1
F-measure	1
different styles	1
cognate frequency	1
alignment-type distribution -LRB-	1
length distribution	1
alignment features	1
sentence length	1
satisfying performance	1
short supply	1
F-measures of 96.6 % and 94.1 %	1
4 -RRB- external macro context feature	1
3 -RRB- internal gazetteer feature	1
2 -RRB- internal semantic feature	1
1 -RRB- simple deterministic internal feature	1
named entity -LRB- NE -RRB- recognition	1
higher-level constituent labels	1
20 %	1
higher nodes	1
overall performance by nearly 5 %	1
performance loss of more than 9 %	1
overall argument F1 of 0.76	1
nominals	1
nominal SRL	1
time expressions	1
consistent animation	1
coarse-grained allwords task	1
81.6 % , 57.6 % , 88.7 %	1
global context information	1
topic feature	1
unique conditions	1
automatic speech recognition	1
alternative modes	1
training and operational demands	1
two dimensions	1
bodies of rules	1
probabilistic regular languages	1
data sparseness problem	1
bit-string representation	1
ranging in size from 5 million to 50 million words	1
bottom-up	1
70,000 words	1
posteriori probability	1
data sparseness prohlem	1
tire problems	1
likely tag	1
decoding problem	1
77 % recall with 81 % precision	1
subjective nouns , discourse features	1
subjective nouns	1
extraction patterns	1
objective sentences	1
collected data	1
dialogue data	1
noun concepts	1
English and 98.10 %	1
overall accuracy of 98.44 %	1
character position information	1
ngram statistics	1
phonetic rules	1
personal or location name	1
simple similarity	1
number of examples	1
syntactic similarity	1
`` deeper '' correspondences	1
structural similarity	1
variety of morphological and contextual features	1
PoS tags	1
discussion of datasets and evaluations metrics	1
lack of data available	1
various aspects of simplification (lexical, semantic and syntactic)	1
comprehensive overview	1
real application data	1
inference quality	1
selectional preferences	1
previous notions	1
Contextual preferences	1
Contextual Preferences	1
contextual considerations	1
8.7 % improvement	1
rich semantic constraints	1
case frames	1
valency information	1
case relations	1
additional semantic relations	1
less manpower	1
one of the remaining bottlenecks	1
number of training sense examples	1
little manual effort	1
sense examples	1
sense inventories	1
common training and testing resources	1
improved evaluation criteria	1
several observations	1
error by up to 24 %	1
cross-lingual morpheme patterns	1
morpheme segmentations	1
major discoveries	1
deep connection	1
numerical entities	1
given how-question type	1
quantifiable how questions	1
given string	1
73.6 F-measure -LRB- 76.1 precision and 71.4 recall -RRB-	1
qualification	1
String similarity	1
set of string similarity metrics	1
doubled FP probability	1
FP from word positions	1
entropies and word rankings	1
Local perplexities	1
LM histories	1
high and low FP likelihood	1
-LRB- 2	1
LM history	1
35 different categories	1
96\% accuracy	1
good semantic parsing quality	1
Better syntactic parsing quality	1
modest improvements	1
syntactic parsing quality	1
Hyper-parameters	1
training and prediction times	1
first order features	1
substantial efficiency advantage	1
strong preference	1
4.3 times faster	1
mean time	1
average entity creation time	1
average 3.5-fold speed improvement	1
objectives -RRB-	1
military units and control measures	1
coverage , ambiguity and grammar size	1
global measure	1
selectional restrictions	1
intuitive hypothesis	1
best trade-off between disambiguation rate and precision	1
CER performance	1
character error rate -LRB- CER -RRB-	1
various angles	1
linguistically syntactic knowledge	1
variety of clustering evaluation metrics	1
number of hidden states	1
infinite	1
additional layers of annotation	1
least 80 %	1
labeling cost	1
less labeling cost	1
informativeness , representativeness and diversity	1
little as two rounds	1
100\%	1
convergence of the detection rate	1
SIGMA %	1
previously unseen types	1
attacks faster	1
basic word-association statistics	1
alignment accuracy	1
450 words	1
vocabulary covered	1
2000	1
syntactic features -LRB- O-roles , case , etc	1
compact data structures	1
table of lexical co-occurrence -RRB-	1
configurations and lexical information	1
efficient ones	1
Thecontextsarethelexically-anchoredsemantic dependency relations	1
events and non-events	1
text patterns	1
highest descriptive variance	1
fast ... slow	1
description -LRB-	1
parameter spaces	1
` semantic basis functions	1
perceptual grounding	1
semantically attached ' terms -LRB- terms	1
perceptual meaning	1
language features	1
high amount	1
general features	1
semantic or ontological patterns	1
accuracy rate of 64 %	1
syntactic role	1
subject-verb , verb-direct object	1
three sets of patterns	1
correct sense of each word	1
syntactic components	1
ontology elements	1
right semantic categories	1
part-of-speech ambiguity	1
many different meanings	1
specific real-time constraints	1
microplanning constraints	1
TAG formalism	1
latest developments	1
core aspects	1
transform basis	1
pairwise orthogonality constraints	1
SR mapping function	1
spatial domain	1
corresponding high resolution (HR) version	1
thelow resolution (LR) image	1
compelling state-of-the-art resultsfor single image Super-Resolution (SR)	1
system-oriented	1
original grammar	1
zero morphemes	1
F-measure of 66.5 %	1
transitive closure	1
automatically clause boundaries	1
flexibly calculate thresholds	1
threshold calculation	1
low value	1
conceptual closeness	1
calculation of thresholds	1
previously accredited evidence	1
five new algorithmic derivations	1
semantic accuracy	1
probable semantic interpretation	1
syntactic annotations	1
terms of WER by 10 %	1
precision\/recall -RRB- and the language model performance -LRB- PPL and WER	1
parsing performance	1
reported baseline results	1
LP\/LR , PPL and\/or WER	1
N-best	1
, perplexity -LRB- PPL -RRB- and worderror-rate -LRB- WER	1
parsing accuracy -LRB-	1
richer syntactic dependencies	1
basic unit	1
serious performance degradation	1
derivation and -LRB- single-word -RRB- composition	1
estimated scores	1
output and reference sentences	1
estimated semantic similarity	1
convenient properties	1
rich syntactic pattern features	1
competitive precision scores on the test data	1
parsing speed of about 300,000 words per hour and state-of-the-art performance	1
ishighlyrobustandhybridonanumberof levels	1
speed and low complexity	1
robust and quite fast	1
enriched lexical representations	1
prosodic morphology	1
many subjective patterns	1
subjective sentences	1
learned patterns	1
linguistically rich extraction patterns	1
chemical names	1
readily available data	1
1 -RRB-	1
labeling function	1
weights of edges	1
labeled and unlabeled examples	1
simple Web counts	1
correct transliteration hypothesis	1
mined information	1
transliteration hypotheses	1
relevant Web pages	1
almost infinite size	1
information extraction rules	1
corresponding texts	1
development texts	1
95.67% accuracy on UD v1.3	1
95.71% accuracy	1
English Universal Dependencies POS tagging	1
semantic tags	1
90.31 % , , and 89.62 %	1
certain principles	1
value of M	1
-LRB- - M , + N -RRB-	1
certain number	1
ambiguous word	1
contextual words	1
Mutual Information	1
status of discourse information	1
different syntactic forms	1
rational relation	1
good effect	1
representative feature	1
among-cluster separation	1
within-cluster compactness	1
trade-off measure	1
ambiguous name	1
pointwise mutual information	1
essa5 responses	1
, \/ o - 94 %	1
human rater scores ranges from 87 ?	1
predictive features	1
69 % agreement	1
82 %	1
ArgContent scores	1
average agreement	1
individual arguments	1
` Content and ArgContent	1
argument partitioning	1
importance ofdiscourse marking	1
essay scores	1
e-rater	1
long distance word dependency	1
15 % error rate reduction	1
cluster PHTM	1
headword of each phrase	1
3.8 % total error rate	1
real misspellings	1
confidence classifiers	1
manually annotated training data	1
positive or negative context	1
special knowledge	1
positive and negative view	1
functionality and interface	1
PGF grammar	1
open source	1
target format	1
finer-grained representation	1
factored representation	1
genre	1
different statistics	1
negative sentimental information	1
key information	1
word and the phrase level	1
unseen word forms	1
principledbased description	1
formalism	1
-LRB- to -RRB- English to -LRB-	1
theoretical complexity results	1
parsing complexity	1
given -LRB- statistical -RRB- word alignment	1
implicit grammatical information	1
Indirect evaluation	1
6 million -LRB-	1
surrounding dependency relations	1
coordinate structures	1
ambiguities	1
string information and morphological information	1
word n-gram information	1
natural text sentences	1
construction part	1
`` headwords ''	1
`` keywords ''	1
F1 figure	1
promising initial results	1
0.7-1.0% models	1
2.8%	1
around 66% of the data	1
parameter and data efficient	1
half of the weights	1
efficient parameter sharing	1
parameter inefficient	1
one of these optimisations	1
combinatorial explosion	1
high paraphrastic power	1
manually set weightings	1
simple additive scores	1
different types of information	1
Corpus sentences	1
corresponding sense	1
emotion modeling capabilities	1
4th place	1
best entry	1
adaptation parameters	1
importance of features	1
stream combination weights	1
`` Articulatory Features ''	1
stream weights	1
subjectivity	1
relative comparison	1
absolute score	1
92 %	1
useful level	1
sense distinctions	1
English word senses	1
significant improvement in performance	1
estimation bias	1
data sparseness	1
character tags	1
word building rules	1
word and character features	1
medical terms	1
original image format	1
preprocessed images	1
kidney and tumor pixel classifications	1
Model output images	1
2), and only tumor (1)	1
corpus type	1
varying error rates	1
Several numerical parameters	1
individual linguistic styles	1
complexity problem	1
optimizing policy	1
reasonable number	1
complexity problems	1
denotation	1
Different forms	1
-LRB- generalized -RRB- relations	1
relations between states	1
domain of events	1
events , intervals and states	1
particular result	1
semantic behavior	1
nominalized expressions	1
conditionally-structured	1
Word + Features	1
conditional probability of Tag	1
neighboring words	1
binary ags	1
observed child	1
negative training data	1
virtual evidence	1
initial lexical probabilities	1
typical heuristics	1
theory of heuristics or preferences	1
idiosyncracics	1
one of the bottlenecks	1
automatically detected dependency structures	1
automatically detected sentence boundaries	1
75.2 % to 77.2 %	1
F-measure of 84.9	1
new names	1
name elements	1
overallbetter recognition rate	1
ahigher priority	1
bounded gradient	1
adifferentiable function	1
shortcut connectionbetween	1
multiple ways	1
term	1
multiple descriptions	1
single text	1
paragraph-style descriptions	1
12.2 % relative increase in BLEU score	1
22 % in recall and 15 % in precision	1
new examples	1
redundant and misleading training examples	1
heavily underrepresented	1
application speci c data	1
design and development time	1
consistent design	1
UE know-how	1
time , costs	1
extensive and error prone	1
-LRB- call-types	1
useful operational service performances	1
maximum accuracy of more than 80 %	1
420,000	1
given word class	1
basis of relative probabilities	1
new words	1
fewer words	1
one single sentence	1
partial results	1
results of German	1
results and experiences	1
20 out of 39	1
best rank	1
rank of 28 out of 43	1
English-20 out of 85	1
Danish-26 out of 39, Arabic-39 out of 53	1
Greek-19 out of 37, Turkish-22 out of 46	1
final submissions	1
frameworks	1
two particular types	1
semirings and directed hypergraphs	1
reordering constraints	1
IBM constraints	1
different reordering constraints	1
search problem	1
Task 1 and 29.27	1
30.58 F-score	1
many other linguistic features	1
LSA the richness	1
TREC data and the HandQA data	1
previous interaction context	1
users ' information needs	1
1 score of 0.37	1
F ? = 1 score of 0.501	1
lexical heads	1
noisy English translations	1
similar syntactic behavior	1
semantic elements of meaning	1
lexical semantic verb classes	1
discourse pragmatics	1
non-isomorphic correspondences	1
isomorphic correspondences	1
ad hoc measures	1
similar sounding property	1
3000	1
11 % Word Error Rate	1
linguistic peculiarities	1
orthography	1
norm	1
major deviations	1
14percentage points better	1
75.70% and 58.55% phoneme accuracy	1
SNR of0dB.	1
additive white noise	1
acoustic and visual features	1
lip-reading features	1
memory andcomputation requirements	1
distribution of features in the corpus data	1
linguistic diagnostics	1
domain independent bottom-up sentence scoring features and domain-aware top-down features	1
shallow semantic features	1
noun phrase syntax	1
models and features	1
non-projective edge attributes	1
reranker features	1
subject	1
favorability	1
significant loss of accuracy	1
verb semantic classes	1
number of suggested research directions	1
number of shortcomings	1
underlying regularities	1
discourse-oriented concise responses	1
extensional response	1
lengthy list	1
innovative evaluation metrics	1
complex search space decisions	1
high dimensional parameter space	1
piecewise linear function	1
non-probabilistic evaluation metrics	1
reasonable predictions	1
high-quality embeddings	1
~99% training samples	1
redundant training samples	1
sampling efficiency	1
expressive graph embeddings	1
60 seconds	1
minimal set of featuresleading	1
word-frequency features	1
word types	1
nearly 60 % coverage	1
word translation relationships	1
9 and 13 % in absolute terms of cluster purity	1
considerable gains in performance	1
dependency based word spaces	1
69.5 % precision	1
precision of 60.0 %	1
quite dialectally diversified	1
extensive systematic redundancy	1
appropriate correction	1
number of linguistic constraints	1
collating information	1
two qualitatively different modes	1
word chain	1
number of properties	1
almost unaffected accuracy	1
computational footprint	1
resulting computational burden	1
feature spaces	1
implicit representation	1
additional external data	1
highest lowercased NIST score of 6.963 and the second best lowercased Bleu score of 24.91 %	1
99 % confidence level	1
offline on test data	1
metric called `` distortion perplexity	1
possible phrase reordering	1
lower bound for stopping conditions	1
upper bound and min-error	1
max-confidence	1
stopping conditions	1
max-confidence and min-error	1
withinclass imbalance problem	1
90.3 % partial-match figure	1
5 % improvement	1
95.9 % F-measure	1
fully correct semantic analyses	1
86 % F-measure	1
learned costs	1
flexible word order	1
non-standard CCG combinators	1
underlying semantics	1
lambda-calculus representations	1
alignment error rates of 5.29 and 25.8	1
large number of highly predictive features	1
arbitrary and overlapping features	1
TREC2003 Novelty track data	1
MPQA data	1
various interactions	1
mutual impacts	1
semantic deficits	1
$\Sigma$-net	1
robust and high SSIM scores	1
quantitative metrics	1
k-space data	1
variable splitting	1
gradient descent	1
proximal mappings	1
data consistency	1
content and GAN losses	1
explicit sensitivity maps	1
implicit coil weighting	1
ensembled $\Sigma$-net	1
aceptable derivation	1
strong asumption of locality	1
abstract case frames	1
semantic generalizations	1
meaning representation	1
semantically acceptable phrases	1
estimate of the pronunciation	1
combination of carefully crafted phonetic features	1
temporal distribution	1
utility of many features	1
highly complex , non-local features	1
coreference aspect	1
storage structure	1
existing ones	1
new LKBs	1
horizontally -LRB- new information -RRB- and vertically -LRB-	1
LKB	1
dynamic knowledge level	1
static storage level	1
Two levels	1
baseline majority class	1
9.25 to 14.62 %	1
entailment accuracy	1
accuracy of 60.50 and 65.87 % and average precision of 58.97 and 60.96 %	1
two final decision rules	1
candidate features	1
syntax and semantics	1
strongly domainspecific	1
microaveraged F1 value of 86.6	1
different input lengths	1
diverse temporal scales	1
different temporal scales	1
smoothing and parsing results	1
labeled bracket F-score of 76.2	1
overall parsing accuracy	1
small increase	1
reading time advantage	1
within coordinate structures	1
user-defined performance thresholds	1
people 's opinion	1
economic stakes	1
positive and negative words	1
Pearson correlation coefficient of 0.867	1
Semantic similarity	1
decision trees	1
Several thousand sentences	1
acoustic realization	1
pronunciations	1
total improvement	1
best parsing result	1
parsing results	1
NIST evaluation metric	1
maximization of translation accuracy	1
3.6 % absolute increase	1
global consistency	1
transitivity -LRB- A	1
two types of implicit global constraints	1
local decisions	1
globally inconsistent labels	1
longrange cohesion dependencies	1
normalized cut criterion	1
10k arguments	1
choice of languages	1
stance of arguments	1
lowest weight	1
manually generated training data	1
50 -- 65 % reduction	1
verb , slot , and noun class information	1
future assignments	1
initial unambiguous role assignments	1
acquisition performance	1
extra temporal and domain knowledge	1
psycholinguistic findings	1
new words automatically	1
empirical pattern	1
testable prediction	1
local vs. global sequence information	1
patterns of difficulty	1
internal computational constraints	1
task constraints	1
normal conditions and conditions	1
relative difficulty	1
unwanted strings	1
query vector	1
much as 76 %	1
negated terms	1
negated term or terms	1
query vectors	1
vector models	1
reprocessing results	1
negated query term	1
answer\/question terms	1
one-onone games	1
relative preferences	1
relative preference	1
scored hypotheses	1
good tree identification results	1
low redundancy	1
poor WER	1
F scores by over five points	1
high as 50 %	1
WER 's	1
short snippet	1
much redundancy	1
relatively low	1
singlebest output of ASR	1
level of competence	1
successful conclusion	1
one subdialogue	1
overall task	1
High recognition accuracy	1
ridge patterns	1
ridge reconstruction loss	1
SRGAN quality discriminator	1
distinctive feature representation	1
low-resolution ones	1
pore information	1
fingerprint image	1
fine features	1
correct and incorrect sentences	1
syntactic error patterns	1
baseline -LRB- 62.66 % -RRB-	1
44.73 % improvement	1
accuracy of 90.69 %	1
annotation guidelines	1
derived features	1
basic features	1
Information Structure -LRB-	1
semantic and word order information	1
-RRB- stylistic differences	1
training classifiers	1
30 categories	1
ontology defining constraints	1
many different categories and relations	1
` playsForTeam -LRB- athlete , team -RRB- '	1
unsupervised type	1
degree of membership	1
cluster prototypes	1
two million	1
unigram and the bigram statistics	1
substantial 4 % DCG5 gain	1
semantic text matching features	1
text words	1
syntactico-semantic patterns	1
syntacticosemantic patterns	1
variety of annotations	1
clause boundaries	1
clause	1
clause level and the sentence level	1
high parsing performance	1
greater sentence length	1
exact counterpart	1
https://github.com/dmlc/dgl/tree/master/python/dgl/	1
3 billion	1
training epoch	1
13 seconds	1
high parallel efficiency and memory scalability	1
design choices	1
communication overheads	1
multiple balancing constraints	1
overheads	1
computational decomposition	1
machines	1
associated data (initial features and embeddings)	1
several billions	1
linguistically motivated lexical features	1
F-score of 0.938	1
inherent linguistic challenges	1
alternation behavior	1
set of basic classes	1
complementation patterns	1
verbs ' syntactic realization	1
nonstandard derivations	1
expected recall	1
lexical relations	1
linguistic and factual knowledge	1
finite binary relations	1
binary relationships	1
levels of search error	1
factor of ten	1
model order -LRB- cluster number -RRB-	1
cluster structure	1
cluster validation criterion	1
constrained syntactic realization	1
widespread ambiguity	1
dialog act sequence	1
lexical , prosodic , syntactic , and semantic nature	1
linguistic realization	1
actual situation	1
initial assumptions	1
textual data -RRB-	1
new discoveries	1
higher ranking correlation score	1
conventional RS/MB search spaces	1
irregular connections	1
BLEU score by 1.76 %	1
50 %	1
translation model size	1
linguistic flexibility	1
possible combinations	1
system of features	1
possible positions	1
false lexical ambiguities	1
semi-free word order	1
high coverage and rich structure	1
cross-validation tests	1
74 % F-score	1
Approximately 3400 terms	1
extensive terminologies	1
degree of coverage	1
around 100 %	1
high degree	1
orthographic proximity	1
mental associations	1
confusion errors	1
F1-score of 88.54 %	1
one or more elements	1
set of comparative keywords	1
12.17%/11.23%	1
Rank-1/mAP by 6.70%/6.13% on SYSU-MM01	1
two benchmarks	1
great boost	1
labor intensive	1
large modality discrepancy	1
cross-modality pedestrian images	1
syntactic functions	1
unprecedented 92 %	1
attachment accuracy	1
14 %	1
number of all parsing errors	1
actual benefit	1
attachment predictions	1
many different contexts	1
two alternatives	1
various sense granularities	1
4.0 %	1
13.6 % on	1
absolute F-score improvement of 4.1 % on	1
human sense merging judgments	1
corpus-based evidence	1
WordNet structure	1
wide variety of features	1
word sense distinctions	1
different sense granularities	1
potential combinatorial explosions	1
collective and distributive readings	1
plural descriptions	1
shared context	1
higher data diversity	1
high quality query content	1
25 %	1
36 % improvement	1
narrative order	1
event relatedness	1
narrative relations	1
deep semantic knowledge	1
correct phonological representations	1
small risk	1
co-occurrence information	1
correct sequence	1
relationships between terms	1
F1 scores	1
good prediction results	1
F1 scores of 51.0% and 51.4%	1
different base models and configurations	1
human safety	1
potentially new forms of evidence	1
correct description	1
stringent definition	1
query word or phrase	1
2 -RRB- cluster-based word similarity classes	1
1 -RRB- WordNet hypernym relations	1
word relatedness	1
several hardness results	1
nonlocal information	1
others	1
dependency decision	1
novel polynomial time solutions	1
standard automatic metrics	1
learning curves	1
reliable metrics	1
well correlated	1
good automatic evaluation metrics	1
99.4 % 2-way recognition accuracy	1
False Accept Rate of 8.1 % at a False Reject Rate equal to zero	1
best parameter settings	1
average profiles	1
text profile	1
large numbers of counts of linguistic features	1
sense concreteness	1
semantic specificity	1
three lexical use factors	1
general usage properties	1
individual words	1
others ' errors	1
semantic contributions	1
conclusive advantages	1
domainspecific representation	1
better precision and recall	1
generic representation	1
indexing recommendations	1
robust and fast	1
slight decrease in performance	1
parsing complexity as low as possible	1
engineering knowledge	1
\url{https://github.com/juditacs/subword-choice}.	1
first subword'	1
terms of precision and recall	1
results of evaluation	1
segment 's function	1
segmental discourse structure	1
durations	1
time course	1
Event duration information	1
implicit typical durations	1
User affect parameters	1
generic and tutoring-speci c parameters	1
useful predictors	1
Alhough generic parameters	1
1 -RRB- system-generic , and 2 -RRB-	1
2 parameter types	1
translational capabilities	1
` grammatical metaphor '	1
theoretically specifiable limits	1
Japanese and English terms	1
translation candidates	1
significant difference	1
accurate 78 % of the time	1
accurate 71 % of the time	1
clear decision	1
enough evidence	1
confidence limits	1
little effort	1
-LRB- overall success	1
average score of more than 99 % correctly transcribed words	1
one or more transcriptions	1
single transcription	1
natural language intraword features	1
serious problems	1
-LRB- i.e.	1
decoder part	1
identity component	1
expression representation	1
expression information	1
incorrect models	1
prosodic regularities	1
prosodic features	1
tonal make-up	1
nuclear pitch accents	1
embedded city names	1
consistent pattern	1
spontaneous answers	1
Half of the utterances	1
matched read and spontaneous versions	1
prosodic characteristics	1
sub-language patterns	1
noun phrase , subject-verb and verb-object patterns	1
positive and negative evidence	1
as-is	1
shallow patterns	1
finite automata	1
basic syntactic relationships	1
shallow linguistic patterns	1
translation patterns	1
corresponding results	1
bilingual information	1
previously proposed categorical representations	1
non-categorical or graded	1
BLEU , NIST , WER and PER -RRB-	1
tractable first stage	1
potentially expensive second stage	1
basis of information	1
utility of the knowledge	1
high-density features	1
better and worse	1
consistency in performance	1
distributional similarity	1
low-frequency words	1
opinions , evaluations , and speculations	1
three time periods	1
past , present , and future events	1
noisy transcriptions	1
topic-spotting performance	1
conversation topics	1
person 's context	1
MUC and MET evaluation results -RRB-	1
best hand-coded pattern performance -LRB-	1
humantagged keys	1
RoboTag performance	1
good precision levels	1
natural stopping criteria	1
gradually degrading precision	1
continuous stream of patterns	1
new state ofthe art results	1
baseline of about 0.72 to 0.81	1
F-measure of performance	1
argument structure mappings	1
vast amounts of lexical data	1
appropriate vector representations	1
intervening space	1
word and noun phrase boundaries	1
morpheme boundaries	1
long-distance morphological dependencies	1
tile candidate terms	1
`` good '' ones	1
-LRB- lifl ` e. rent statistical scores	1
drastic deterioration in performance	1
many useful patterns	1
small loss	1
relevance ranking by 14 %	1
25-35 %	1
top-1 transcripts	1
corresponding lineartext indexes	1
five times larger	1
phrase-matching constraints	1
strictness	1
similar time boundaries	1
posterior-probability representation	1
limited code changes	1
surface patterns	1
many relevant `` nuggets '' of information	1
probable correction	1
modified edit distance	1
error words	1
additional ambiguities	1
explicit word boundary	1
chemical NER performance	1
contextualized ELMo word representations	1
structural and linguistic complexity	1
individual analysis	1
monolingual Chinese knowledge	1
spoken modality	1
lexical entities	1
bidirectional MEMMs	1
comparably good performance	1
corresponding decomposition structure	1
highest probability sequence	1
possible decomposition structures	1
inaccurate -RRB- information	1
partial -LRB-	1
word and sentence grammar	1
grammatical definitions	1
LFG requirements of completeness and coherence	1
unordered nature of information	1
87 % to 94 % across the 15	1
score predictions	1
Exact or adjacent agreement	1
set of predictive features	1
test question	1
weighted set of predictive features	1
essay responses	1
statistical redundancy	1
criterion of future usefulness	1
abundant supply	1
tree descriptions	1
system of polarized features	1
linear logic	1
~ specified trees	1
three intuitive simplicity criteria	1
conciseness and intelligibility	1
legibility	1
$400\times$ fewer parameters	1
largenetwork	1
bigger and more complex	1
word alignments	1
37 % and 35 %	1
average tonal and toneless STW improvements	1
-LRB- STW -RRB- accuracies of 99 % and 92 %	1
-RRB- and toneless	1
four tones	1
: -LRB- 1	1
association degree	1
perfect text transcriptions	1
level approaching the accuracy	1
correct order	1
F1 and the average number of correct title words	1
automatically recognized speech	1
21190 news stories	1
second-order co-occurrence relations	1
synonym most typical , or expected	1
cluster stopping rules	1
highest F-scores -LRB- 82.89 -RRB-	1
finergrained sense distinctions	1
sense inventory	1
exact number of senses an ambiguity	1
accumulated slack	1
coarseto-fine case	1
search errors	1
moderate levels	1
tradeoffs and relative strengths	1
particular context	1
definition statements	1
near-synonyms	1
agenda	1
mutually agreed-upon information	1
product	1
single turn , -LRB-	1
WH-traces	1
three different metrics	1
algorithm 's performance	1
production rules	1
limited number of patterns	1
pertinent tree structures	1
feature similarities	1
Krein Space	1
neighbor-based kernel matrix	1
normalized adjacency matrix	1
node feature similarities	1
node's feature vector	1
significant performance advantage	1
sentential level	1
strengths of each	1
node structures	1
another specified path	1
logically inferable	1
possible semantic relations links	1
source language semantic relations	1
bilingual lexical semantic relation	1
translation equivalence relation	1
top ontology or word translations	1
lexical semantic relations	1
one sense	1
corresponding feature vector	1
certain sense	1
words and syntactic relations	1
multi-level score functions	1
agenda graph	1
dialog state	1
dialog examples	1
accuracy figures	1
simple bracketing	1
little or no computational overhead	1
aforementioned features	1
respective user utterances	1
word graphs	1
system question types	1
Dice 's Coef cient	1
Longest Common Subsequence Ratio	1
traditional orthographic measures	1
double the precision	1
exceptional performance	1
physicians ' questions	1
abstracts	1
higher ranking positions	1
clinically relevant aspects	1
0.2577 and 0.2882 RMSE value	1
68.50% and 71.53% accuracy	1
15 MFLOPs	1
3.1M training parameters	1
Various metrics	1
subtle facial expressions	1
less numbers of training parameters and floating point operations per second (FLOPs)	1
function wtih bounded derivative	1
observed feature vectors	1
spectral dynamics	1
acceptability scores	1
derived grammaticality index	1
acceptability judgements	1
grammaticality indices	1
grammaticality index	1
automatic evaluation scores	1
large data scenarios	1
little computation	1
local syntactic structure	1
phrase	1
features of the context	1
four second best and one the fifth	1
out-of-vocabulary -LRB- OOV -RRB- word recall	1
possible errors	1
full set of constraints	1
prohibitive complexity	1
language constraints	1
arguably semantic nature	1
-LRB- 18	1
-RRB- -RRB- and ` Nearest Mutual Information ' -LRB-	1
-LRB- 27	1
properties ` Distributed frequency of object ' -LRB-	1
range of classifiers	1
existing statistical features	1
ezperimental results	1
perimental results	1
new text	1
placement of boundaries	1
considerable ambiguity	1
highest precision and the highest recall	1
Entity Loss	1
full span	1
multi-scale contexts	1
equivalent version	1
one -LRB- or more -RRB-	1
many errors	1
word-processing mishaps	1
69-79 %	1
fast approximation	1
information radius	1
similar meaning	1
closely related	1
deeper structural properties	1
surface cues	1
various surface cues	1
larger and more heterogeneous	1
recall rates	1
significantly better precision rates by about 8 percent over the best-reported systems	1
MUC6 and	1
Precision \/ Recall \/ F-measures of 84.7 % \/ 65.8 % \/ 73.9 and 82.8 % \/ 55.7 % \/ 66.5	1
coreference relationship	1
various kinds of special knowledge	1
various kinds of general knowledge	1
practical morphological and orthographic issues	1
type of inflection	1
4 % for comparison and 16 %	1
modality , context , and lexical features	1
length of verb phrases	1
Levin verb classes	1
polarity tags	1
several linguistically informed features	1
`` because ''	1
`` but ''	1
sense of implicit discourse relations	1
author 's general feeling	1
linguistically uninformed word co-occurrence features	1
particle up	1
compositionality	1
magnitude lesser	1
terms of clustering accuracy	1
45% more accurate	1
accuracy and computational complexity	1
Pivotal Sampling	1
involved sampling	1
i.e. SC with VQ, HC with Pivotal Sampling, and HC with VQ	1
terms of Silhouette Values	1
substantially more accuracy	1
2400	1
phenotypic data	1
probability based	1
accuracy challenge	1
high computational complexity issues	1
phenotypic characteristics	1
beliefs , desires , and intentions	1
belief -LRB- or desire , or intention -RRB-	1
certain belief -LRB- or desire , or intention -RRB-	1
crucial difference	1
communicative intentions	1
speaker 's communicative intentions	1
computational and linguistic implications	1
exponential in grammar size	1
worst-case runtime	1
Shieber 's purported runtime bound	1
ID and LP constraints	1
linear order	1
immediate dominance	1
surface complexity	1
underlying meaning	1
hierarchical representations	1
formal meaning representations	1
suchcomplexityaskernelfunctionsgenerate features automatically	1
modeling and implementation point of view	1
slow search	1
wide range of problems	1
much smaller con dence interval	1
large con dence intervals	1
MDP statespace	1
-LRB- 1 -RRB- better	1
con dence intervals	1
reliable policy	1
enough collected data	1
dialog control policies	1
human-annotated word level alignments	1
two languages	1
little training data	1
taxonomic names	1
accuracy of 61.00 % and 62.62 %	1
lexical similarity metric	1
univariate Gaussian density	1
two sets of results	1
new metrics	1
average increase of about 6% F1	1
16 of which	1
M-BERT (E-BERT )	1
manual labeling	1
data labeling	1
compatible and partially uncorrelated information	1
phonemebased , grapheme-based or hybrid features	1
natural division of transliteration features	1
optimal combinations	1
94 % accuracy	1
corresponding SQL queries	1
parser errors	1
particular parameter settings	1
text units	1
Phrasal Verb identification problem	1
95.8 % -97.5 %	1
precision\/recall combined performance	1
borderline	1
key functional characteristic	1
one such relation	1
adequate domain knowledge	1
83.2 %	1
F-score of 48.4 %	1
syntactic and domain-dependent semantic information	1
subcellular localization relations	1
kernel grammar	1
run-time stage	1
priori all the surface forms	1
full coverage	1
order of years of highly-skilled labor	1
abstract thematic representation	1
abstract information	1
protocol formulations	1
planning and formatting routines	1
protocol	1
individual turns	1
simplified paraphrases	1
dialogue acts	1
thematic information	1
dialogue structure	1
manually-labeled dialogue acts	1
tutorial dialogue modes	1
uncased BERT embeddings	1
varying domain and casing quality	1
output distributions	1
truecaser	1
pretraining objective	1
drastically lower performance	1
robust processing capabilities	1
total parsing time	1
number of chart edges	1
local semantic ambiguity	1
local syntactic ambiguity	1
Limited leftcontext constraints	1
local ambiguity	1
Weather Forecast and Monthly Economic Report	1
lack of agreement	1
set of carefully devised error detection rules	1
Incremental Vector Space KL-Divergence Agglomerative Vector Space	1
coreference chains	1
grammatically correct	1
98 %	1
users ' specifications	1
linguistic sophistication	1
different forms of cooperativity	1
different linguistic marks	1
73.1% semantic dependencies F1	1
80.5% macro-average F1 , 87.6% syntactic dependencies LAS	1
71.0% semantic dependencies F1	1
86.9% syntactic dependencies LAS	1
79.1% macro-average F1 performance	1
likely derivation	1
directionality	1
ontological commitments	1
naming conventions	1
specific structuring choices	1
'new' relations	1
recall and precision metrics	1
congruence	1
original MeSH relations	1
lexically-induced relations	1
morphological variants	1
hierarchical (or other types of) relations	1
classical TD control methodsSarsa ($\lambda$), Q($\lambda$)	1
eligibility traces	1
parsing strategies	1
worked examples	1
limited domain semantics	1
structure and surface representation	1
conceptual and practical problems	1
model 's strengths and weaknesses	1
POS correspondence , and bilingual dictionary coverage	1
IBM Model 3 alignment probabilities	1
possible additional variables	1
target language sentence	1
source langauge sentence	1
linguistic generality	1
dependency treelet translation pairs	1
source dependency parse	1
dialogue state	1
negative feedback	1
overall pattern	1
nonverbal behaviors	1
common ground	1
problems of vagueness and ambiguity	1
new similarity measures	1
impact of precision and recall	1
1.7 and 0.7 p.p	1
best-reported mention detection F1	1
improvements of up to 5.3 and 6.2 p.p	1
mention recall	1
gains of up to 1.8 percentage points	1
ELMO embeddings	1
full range	1
CER	1
either of the criteria	1
combined criterion	1
two criteria	1
high-performance of rank	1
character error rate (CER)	1
three pruning criteria	1
probability, rank , and entropy	1
(LM) size	1
bound on synthetic data	1
first a posteriori bound	1
existing bounds	1
critical points	1
triangularizer	1
optimization specific properties	1
observable matrices	1
M. The bound	1
exact joint triangularizer	1
approximate joint triangularizer	1
first-order upper bound	1
noise perturbed versions	1
set M'	1
jointly diagonalizable and real	1
approximate joint matrix triangularization	1
joint eigenstructure	1
Joint matrix triangularization	1
thorough numerical results	1
optimum	1
data dependent local smoothness	1
Stochastic Variance Reduced Gradient (SVRG) and Stochastic Dual Coordinate Ascent (SDCA)	1
multiple citations	1
author names	1
object characteristics	1
efficient proposals	1
probabilistic citation grammar	1
author and title corruption	1
publication	1
identifiers	1
unique identifiers	1
limits of traditional MT architectural designs	1
baseline on all three aspects	1
Intra-sentential quality	1
semantic similarity measures	1
multiple aspects of coherence	1
Criterion 's capability	1
open-domain question answering capability	1
utility of this constraint	1
non-overlapping intervals	1
cohesion constraint	1
error reduction of 4.4% on the best previous single automatically learned tagging result	1
97.24% accuracy	1
unknown word features	1
miscommunication --- reference problems	1
miscommunications	1
misunderstandings miscommunication	1
reference failures	1
difficulties and mistakes	1
beliefs , contexts , perceptions , backgrounds , or goals	1
$\textbf{1.98$\times$}$ faster in terms of search time	1
higher/comparable performance	1
up-to $\textbf{50\%}$	1
similar low-level representations	1
use	1
lot of memory footprint	1
less search time	1
significant efficiency gains	1
parsing data	1
baseline model's score of 88.2%	1
F-measure error	1
13% relative decrease	1
89.75% F-measure	1
additional 500,000 features	1
arbitrary set of features	1
parses	1
associated probabilities	1
set of candidate parses	1
proposed word segments	1
submitted segmentation results	1
speech recognition accuracies	1
grammatically complicated positions	1
output sentences	1
industry standards	1
theoretical generalization result	1
hard budget constraints	1
cost zero solution	1
regressed-to values	1
inversely proportional	1
data insights	1
aggregate queries	1
sampling probabilities	1
single common hypothesis	1
unique hypothesis	1
spatial similarity	1
non-uniformity	1
three geometric constraints	1
feature detection errors	1
noise and reverberation robustness	1
higher-order cepstral coefficients	1
far more robust	1
DOCC features	1
test/train mismatch	1
standard MFCC features	1
matched and mismatched conditions	1
multiple evaluation metrics	1
consistent pattern of findings	1
noise robustness, damped oscillator cepstral coefficients (DOCCs)	1
2) features	1
speech cues	1
relatively quiet conditions	1
word significance (weights)	1
viewpoint of IR	1
weighted word error rate (WWER)	1
(ASR) performance	1
word significance oriented	1
slightly superior	1
least 96% correct	1
equivalence in meaning	1
least 99% correct sentences	1
grammaticality	1
objective machine translation evaluation measures	1
10.08%	1
improvement of dependency accuracy	1
Phase II	1
Phase I	1
left-side dependents and right-side nominal dependents	1
right-side dependencies	1
left	1
flat NER state-of-the-art results	1
recently published contextual embeddings	1
nested NER state	1
word whose label	1
hard attention	1
one label	1
Automatic evaluation metrics	1
97,5%	1
precision rate	1
pronoun	1
expletive occurrences	1
anaphoric occurrences of il	1
anaphoric or [IMP]	1
tag [ANA]	1
every occurrence	1
tightly controlled measure	1
commercial applications	1
derived strings	1
labeled pointers	1
semantic relations ( synonymy , antonymy , hyponymy , meronymy , causal and troponymic entailment	1
amount of human effort	1
pixel-level labels	1
additional boost in accuracy	1
significantly more supervision	1
simple task	1
correct temporal order	1
raw spatiotemporal signals	1
fine surface detail	1
inherent global ambiguity	1
coarse scene geometry	1
original texture	1
initial, low-frequency shading estimate	1
intrinsic appearance parameters	1
pixel-resolution surface textures	1
unknown illumination conditions	1
intrinsic texture properties (albedo, shading, normal)	1
global parse tree	1
argumental relations	1
unambiguous structures	1
domain distributions	1
transferable representation	1
fluorescence's wavelength-shifting property	1
object's shape	1
strong similarity	1
longer wavelengths	1
certain wavelength	1
important characteristics	1
deliberate as well as spontaneous facial affect data	1
multiple emotions	1
ordinal manifold	1
H-CORF parameters	1
multidimensional continuous facial affect data	1
intrinsic topology	1
binary classifiers	1
nonlinear quality functions	1
search	1
classifier functions	1
fewer evaluations	1
balanced workloads	1
expensive synchronization overhead	1
dynamic textures	1
optimal manifold	1
Spatial, temporal and periodic information	1
distribution of the input data	1
output values	1
remaining degrees of freedom	1
low dimensional representation	1
known distribution	1
neighborhood graph structure	1
changing configurations	1
added cost	1
cost of slightly decreased pixel accuracy	1
improved flexibility	1
substantially reduced computational complexity	1
knowledge of intrinsic parameters	1
intrinsic parameters	1
high resolution imagery	1
panoramic area	1
domain specific problems	1
enhanced discrimination ability	1
small-sample-size	1
learned intensity distributions	1
intensity correspondences	1
slice locations	1
various image modalities	1
previously learned intensity relations	1
joint intensity distributions	1
kernel density estimate	1
joint intensity distribution	1
statistically learned prior knowledge	1
missing image structure	1
registration results	1
purely low-level criterion	1
good registration results	1
criterion of maximum mutual information	1
powerful registration criteria	1
homographies	1
spatial overlap	1
amount of blurring	1
global alignment and super-resolution	1
Preliminary modeling and recognition results	1
arbitrary viewpoint	1
multiple images	1
normalized representation	1
Multi-view constraints	1
CIDEr evaluation measure	1
13.3% improvement	1
graph-level semantics	1
rational quartic curve	1
alternative configuration	1
critical configuration	1
twisted cubic	1
straight line	1
image coordinates	1
projective transform	1
points in the images	1
3D geometrical configuration	1
46.0% to 60.62%	1
separation margin	1
real tasks	1
possible variations	1
approximation error	1
actual tape-recorded descriptions	1
logical well-formedness conditions	1
CCR formalism	1
restrictive statements	1
Boolean conditions	1
Category Cooccurrence Restrictions (CCRs)	1
outstanding problems	1
levels of textual representation	1
translation equivalence	1
isomorphic derivations	1
SL and TL expressions	1
Isomorphic Grammars	1
resampling pairwise constraints	1
original instances	1
sampled pairwise constraints	1
pair of instances	1
instances or features	1
various extensions	1
soundness and completeness results	1
propositional atoms	1
classical propositional logic	1
syntax	1
simple logical properties	1
17.85\% and 7.90\% increases in performance	1
raw data leakage	1
privacy of the training data	1
near embedding spaces	1
privacy-preserving	1
\emph{Federated Knowledge Graphs Embedding} (FKGE)	1
privacy of exchanged data	1
low quality	1
high-qualityquestions/answers	1
bothquantifying numerical quality scores	1
quality of questions and answers	1
positively correlated	1
massive volume	1
WER to 14.54%	1
14.24%	1
state-of-the-art Word Error Rate (WER)	1
back-off states	1
big gap	1
30,871 video-level labels	1
5.24 millionhours)	1
70M	1
soundtracks	1
context-free locality	1
universal constraints	1
time complexity cubic in the length of the input	1
regular to context-free structures	1
better generalization capabilities	1
weightsdefine mini-batch learning rates	1
model overfitting	1
generalization and test error	1
lineage	1
similar model size	1
inferred result	1
additional learning parameters and hyper-parameters	1
step size becomes large	1
bits	1
low-bit expressions	1
drop in accuracy	1
many parameters and activation data	1
theprediction performance	1
significant superiority	1
extensive experimentalevaluations	1
real-world house transaction datacollected	1
different regularization terms	1
ways	1
sufficient training samples	1
theentire data	1
facility profile	1
census data	1
suburb profilebased	1
education profile (e.g., school zones and ranking)	1
transportation profile (e.g., distance to nearest trainstation)	1
fine-grained location profile	1
spatio-temporal patterns	1
stability features	1
novel image representation	1
temporal stability	1
new spatio-temporal features	1
less than 40 min	1
17B facts	1
(minimal) TGs	1
real-world KBs	1
benefits of TGs	1
notion of Trigger Graphs (TGs)	1
materialize Knowledge Bases (KBs)	1
real 256 channeldata	1
neighbors	1
most	1
observed EEG	1
problem of ill-posedness	1
inversion problem	1
givenmeasurement at given time	1
corresponding data point	1
self-adaptive detection threshold	1
calculated AARE value and its corresponding forecast AARE value	1
short-term historical AARE values	1
every upcoming data point	1
AARE value	1
series of average absolute relative error (AARE) values on the fly	1
target time series	1
anomalies in real time	1
anomalous events	1
human gait	1
system resource consumption	1
transportation passenger volume	1
recurrent or repetitive patterns	1
Real-world time series data	1
return-maximizing and risk-minimizing behaviors	1
expected return and conditional value at risk	1
user specific risk tolerance	1
overly aggressive and unsafe policies	1
completely ignoring risk	1
mean or MAP reward function	1
adversarial reward function	1
corresponding optimal policy	1
parameterized reward function	1
demonstrations	1
state distribution	1
promising shrunk search spaces	1
stable and accurate	1
comprehensive evidences	1
major functions	1
fresh data	1
one function	1
fast algorithms	1
several to (at most)	1
1,000 entity types	1
unique features	1
5758 to 576,and 88.8% reduction	1
90% reduction	1
number of required labeled samples	1
reached or slightly outperformed	1
carefully tuned hyperparameters	1
expensive and time consuming	1
large number of labeled training samples	1
security vulnerability reports	1
software names and versions and vulnerability types	1
structured forms	1
unstructured texts	1
reports	1
CVE reports	1
Public security vulnerability reports	1
L2G	1
well between unseen classes	1
classification error	1
random classes	1
different classification tasks	1
combinatorial number	1
improved sentence representations and question answering abilities	1
different training examples	1
much stronger dependencies	1
two order of magnitudefaster	1
FVbuilt	1
CNN results	1
binary featuresallowed	1
emerging Convolutional Neural Network (CNN) features	1
aggregated binaryfeatures	1
Fisher Kernels	1
binary local features	1
recently proposedbinary local features	1
visual descriptors	1
different OEM monitor data	1
(1) type; (2) frequency; (3) length	1
commonlydefined data	1
Signal Quality Indicators (SQI)	1
one specific type of CCU	1
six themes	1
processing time	1
predicate	1
part-of-speech tags	1
domain-specific training data	1
structured representation	1
14% of its test theorems	1
partial proof trees	1
eschewing hand-constructed features	1
higher order logic	1
constant lower bounds	1
asymptotic competitive ratio	1
optimal paths	1
counter-intuitive result	1
flowtime and makespan	1
asymptotically bounded from both below and above	1
time in sequence	1
commonly-used objective functions	1
quality of paths	1
time)	1
different categories	1
online MAPF	1
existing complexity results of (offline) MAPF	1
given goal locations	1
average speed up of 44 times	1
customer complaints data	1
fast results	1
high-dimensional text data	1
useful business insights	1
inherent grouping	1
lower profitability	1
wealth of customer feedback data	1
average latency of only 0.12 s.	1
classification accuracy of 80%	1
First Person View	1
average observer	1
quality scorepredictions of DeepBIQ	1
human subjective scores of almost 0.91 and0.98	1
LinearCorrelation Coefficient (LCC)	1
scorespredicted	1
generic image description	1
different design choices	1
relatifs suppl{\'e}mentaires	1
5,1{\%}	1
7,6{\%}	1
niveau du phone (PER)	1
des mod{\`e}les	1
quantit{\'e} limit{\'e}e	1
des donn{\'e}es bruit{\'e}es	1
des disfluences	1
une lecture	1
5-7 ans	1
\`a}	1
les performances	1
absolute performance gain of 15\% on average	1
less language priors	1
language modality	1
limited patterns	1
language prior problem	1
language shortcut	1
proof of convergence	1
least model size	1
geometric structure	1
much lowerreconstruction error	1
sparse acquisition data	1
eigenspace	1
potential representative 2D images	1
prior data	1
limited measurements	1
achievestate-of-the-art camera relocalization results	1
navigational structure overthe solution space	1
local optima	1
latent target variables	1
non-convex function	1
selection of synthetic data	1
authentic data	1
smallermodels significantly improves	1
previous timesteps	1
LSTM's internal states	1
strong competency	1
complex ones	1
order of training instances	1
much-needed trust	1
TOD challenge	1
72651 box-levelannotations	1
1610 images	1
TOD Challenge	1
performancessteadily	1
semantic descriptors	1
L2 normalization constraint	1
visual features andsemantic descriptors	1
classsemantic descriptors	1
class semanticdescriptors	1
class semantic descriptors	1
visualfeatures	1
false positive rates	1
fairly-calibrated probabilities	1
state-of-the-art)	1
different false positive rates (FSN)	1
accuracy (AGENDA, FTC)	1
ethnicity	1
false positive (incorrect face match	1
swarm size	1
90% faster	1
run time	1
particles finalposition	1
curvature	1
two consecutive dominant points	1
thecurvature connected	1
lot faster	1
static background	1
various domain gap scenarios	1
prior best work on mAP	1
2.2% - 9.5% better	1
noisy pseudo labeling	1
domain content distribution gap	1
domain style gap	1
expensive label cost	1
newly-designed importance filtered soft labels	1
category-irrelevant MMD loss	1
target novel classes	1
prominent probabilities	1
ambiguous label	1
threshold value	1
confident label	1
maximum probability	1
confident and ambiguous ones	1
negative transfer desirably	1
shared and private classes	1
category-relevant form	1
many small noisy probabilities	1
hard labels	1
hard or soft labels	1
dominant position	1
cleaner word representations.5	1
improvedtagging performance	1
over-fitting	1
27 languages),we	1
unambiguous examples	1
sentence contexts	1
raw text examples	1
inflection tables	1
little or no labeled corpus data	1
benefits of context	1
far fewer distinct types	1
distinct words (types)	1
dictionary form	1
inflected forms	1
sparse data problem	1
nearly the full complexity	1
433k examples	1
RNN predictions	1
prediction scores	1
sensitiveness	1
Oresponse (2)	1
(1)LISA:	1
theirhidden behavior	1
exceeded state-of-the-art	1
mentioned constraints	1
final range of heuristic network output	1
final condition	1
initial and final states	1
independence measurements	1
well-founded theoretical guarantees	1
heuristic representations	1
larger domain discrepancy	1
domain-specific properties	1
domain-specific characteristics	1
traditional measures	1
identity issues	1
one frame	1
another object of a different identity	1
state-of-the-art robust accuracy	1
local robust features and global features	1
input and the feature representation	1
noisy mutual information	1
threats	1
111	1
implicit structure	1
direct data	1
current best results	1
one of the smallest variant (depth and number of parameter wise	1
considerably less volume of data	1
overall solution	1
UAS of 87.23{\%}	1
equivalent contributions	1
similar parsing accuracy	1
dependency annotations	1
Chinese dependency parsing accuracy	1
likely contribution	1
concrete reduced Level-of-Effort (LOE) numbers	1
rationale and benefits	1
best previous result	1
best zero-cost proxy	1
final validation accuracy	1
Spearman's rank correlation coefficient	1
3 orders of magnitude less computation	1
model's score	1
single minibatch of training data	1
recent pruning literature	1
final trained accuracy	1
rankings	1
conventional reduced-training proxies	1
computational power and time	1
compute-intensive	1
90{\%}	1
discontinuous order	1
\url{https://github.com/zhzhang2018/DecentralizedFL}}.	1
variance between model weights	1
non-optimal	1
partial sharing	1
model aggregation frequency	1
comprehensive node representations	1
complex structural and semantic information	1
versatile node embeddings	1
specific semantic	1
standard FedAvg baseline	1
aggregation operator parameters	1
multi-criteria contribution	1
local client's contribution	1
i.e., local dataset size	1
single criteria	1
data security	1
users' personal privacy	1
2.44% above thebaseline accuracy	1
validation accuracy of 55.23%	1
suitable verb	1
new compositions	1
video frames and transcripts)	1
raw multimedia data	1
previously seen compositions	1
explicit language knowledge	1
robust setof features	1
of0.142 FP/h	1
sensitivity of 87.8% and a low false prediction rate	1
approximately tenminutes	1
204 recordingsdemonstrate	1
measuringKullback-Leibler divergence	1
ten-minuteseizure prediction horizon	1
Computational solutions	1
priori assumption	1
optimal seizure prediction horizon	1
interictal,preictal, and ictal	1
period	1
quantitative signatures	1
two competing objectives	1
early as possible	1
prediction horizon	1
tolearn features	1
scalp electroencephalogram (EEG ) data	1
additional boundary information	1
interpretation	1
pixel-level binary annotation data	1
Mean-Squared Errors <0.0005)	1
prostate tumor annotations	1
95% pixel-by-pixel overlap	1
SSIM 0.9, CC 0.963 and PSNR	1
native nonstained form	1
22.821 dB	1
Noise Ratio (PSNR)	1
Structural Similarity Index (SSIM ) 0.902, Pearsons Correlation Coefficient (CC) 0.962 and Peak Signal	1
Histopathological diagnoses	1
realistic deformations	1
registration accuracy	1
better registration performance	1
increased errors	1
global constraint	1
globally smooth and continuous	1
explanation of type embeddings	1
type clustering	1
latent type embedding	1
type information	1
1-N, N-1 and N-N relations	1
symmetry, inversion and composition	1
diverse type representations	1
explicit types	1
additional type information	1
continuous vector spaces	1
label-preserving	1
insufficienttraining data problem	1
target-object-dominated	1
implicit assumption	1
strict labelrequirement	1
recorded iterations	1
several linguistic observations	1
region of the SBM parameters	1
analytically and numerically	1
optimal sampling strategy	1
SBM parameters	1
fraction of the sampling budget	1
recovery rate upper bounds	1
SBM	1
sampling budget	1
cluster recovery rate	1
information-theoretical upper bounds	1
cluster estimates	1
Query Archive (LPAQA)	1
resulting LM Prompt	1
tighter lower bound on what	1
accuracy from 31.1% to 39.6%	1
better prompts	1
lower bound estimate	1
given prompt	1
inappropriate prompt	1
another prompt	1
intriguing results	1
average identification rate of 95.14%	1
recognition	1
text line-level	1
best in PLTE	1
performanceand	1
BERT representations	1
PLTEperforms up to 11.4 times faster	1
rich long-term dependencies	1
DAG structure	1
word boundary information	1
extensive numerical experiments	1
pseudo-label features	1
given label information	1
optimal graph	1
intrinsic complexity	1
realistic SLP	1
multi-channel sign	1
new benchmarks	1
state-of-the art SLP back-translation performance	1
facial features and mouthing patterns	1
non-manual features	1
realistic and articulate output	1
mean	1
under-articulated output	1
full sign morphology	1
direction and formation)	1
influence of factors	1
simple statistical correlations	1
small but semantically significant alterations	1
number of strengths and weaknesses	1
variety ofconditions	1
semantically-valid alterations	1
singleevaluation metric	1
form of accuracy scores	1
impressive testset performance	1
less stressful experience	1
higher cognitive load	1
complete picture	1
qualitative and quantitative evidence	1
continuous, objective information	1
final option	1
question-option tuple	1
90% detection rate	1
limited network attack data	1
minority problem	1
every single task	1
network attack traf	1
suf network traf data	1
imbalanced traf data	1
sentimentsof	1
Movie rating	1
subjective opinion	1
underlying viewpoint	1
memory limitation	1
new knowledge over time	1
low degradation	1
new and the generated samples	1
increment	1
imbalance samples	1
Learning new knowledge	1
expense of performance and accuracy	1
new concepts perfectly	1
theoretically predicted behaviour	1
expectation under reasonable conditions	1
eigenvalues and eigenvector	1
reasonable settings	1
Censored Block Model	1
normalized standard and signless Laplacians of positive and negative edges	1
matrix power mean	1
Signed Power Mean Laplacians	1
positive (attractive) and negative (repulsive) relations	1
low and high resolutions	1
speaker information	1
utterance-level representation	1
detailed acoustic information	1
shallow and deep features	1
different resolution spectrograms	1
invariant property	1
deep feature	1
parallelizing data	1
rotation-equivariance	1
data manifold	1
small fraction of the computational time	1
total variation	1
reported metrics	1
shorter training times	1
undersampling artefacts	1
sufficient data similarity	1
operational- and environmental conditions	1
machine type	1
industrial machine data	1
strong data similarity	1
industrial context	1
many otheroffline regression problems	1
driver drowsiness estimation	1
better regression performance	1
reliability, representativeness	1
small number ofthem to label	1
pool of unlabeled EEG epochs	1
model updates	1
poor generalizability	1
negative log likelihood (NLL)	1
distinct micro and macro architecture parameters	1
body structure	1
task-specific	1
architectures and weights	1
query-document pairs	1
semantic connections	1
individual query result view	1
inner workings and fine-grained results	1
retrieval results	1
ranking results	1
incomplete information	1
<https://github.com/ntunlp/pronoun-finetuning>.	1
corresponding improvements	1
32.10 to 33.13	1
31.81 to 32 BLEU	1
0.5 BLEU improvement	1
combination of targeted fine-tuning objectives	1
lower level of imbalance ratio	1
Negative Binomial distribution	1
Location-Scale distribution	1
twenty real-world datasets	1
learning techniques	1
four performance measures	1
specific tumor	1
empirical advantages	1
robust acquisition maximisers	1
queried configurations	1
Pareto front solutions	1
empirical efficacy	1
values of lea\rned parameters	1
53.62% competition baseline	1
accuracy of 64.68%	1
top-downfeatures	1
global emotion	1
variable lightingconditions	1
everyday life pictures	1
Code and videos	1
high intrinsic dimensionality	1
state representation	1
simple low-dimensional dynamics	1
direct state observability	1
complex dynamics	1
high dimensional state representation	1
number oftraining images	1
expression, pose, and facial details	1
single type, format and composition of image	1
different facial expression	1
variant illumination	1
private security	1
user personal Gmail emails datasets	1
particular department	1
query, concern	1
email-id	1
accuracy drop of only 3% compared	1
17.7x size reduction	1
2-bit precision	1
compression bottlenecks	1
weight values	1
8-bit precision	1
extreme compression levels	1
optimized low-bit-precision targets	1
8.9% (from 78.4% to 87.3% detection accuracy	1
accuracy improvements up to 5.5% (from 72.9% to 78.4%)	1
neutral, onset-transition, apex, offset-transition, and neutral	1
evoked emotions	1
real face images	1
various face expressions	1
item 3.2	1
advantage and robustness	1
gain of the overall performance	1
optimal transport	1
limited annotations	1
reference translations	1
Higher BLEU scores (close to 0.5)	1
en/pt, es/en, and en/es	1
en/fr, de/en, en/de, pt/en,	1
zh/en, en/zh, fr/en	1
total of 10	1
total of six	1
substantial memory savings	1
memory utilization	1
compact topology	1
excessive accuracy loss	1
unquestionable savings	1
Single Path	1
single large model	1
known intermediate inference goals	1
joint formulation	1
efficient scaling behavior	1
Symmetric Multiway Cut objective	1
accuracy and flexibility	1
one order of magnitude fewer simulations	1
vastly more computationally efficient	1
functional estimate	1
arbitrary proposals	1
intractable likelihoods	1
full engagement state	1
perfect knowledge	1
range observability	1
wide range of challenging target maneuvers	1
time varying center of mass	1
angle and rotational velocity measurements	1
Gaussian noise	1
scale factor errors	1
parasitic attitude loop	1
thruster control lag	1
seeker angle measurement lag	1
parasitic effects	1
thruster on-off commands	1
rate gyro measurements	1
strapdown seeker angles	1
better and more stable performance	1
Manifold Quantization (ManiQuant)	1
metric tensor	1
quantization function	1
approximated gradient	1
$\boldsymbol{W}$	1
gradients $\nabla_{\boldsymbol{W}}$ w.r.t	1
infinite or zero gradients	1
quantized weights	1
full-precision weights	1
second best results	1
PRID450S and GRID)	1
rank-1matching rates	1
similar coding vectors	1
representativeness andsimilarity nonlinearly	1
strong nonlineartransition	1
different camera conditions	1
small-sample-size problem	1
different illumination conditions	1
global identity	1
certain amount of repetition	1
sizeable TM	1
consistent and substantial improvements	1
fuzzy TM matches	1
Neural Machine Translation (NMT) performance	1
time-variant	1
themodel parameters	1
longer duration of time	1
non-stationary characteristics	1
minute of computation	1
one second of computation	1
good solutions instantaneously	1
dataset metadata embeddings	1
datasets and of algorithms	1
vector embeddings	1
language embeddings	1
practical performance	1
e.g., XGB)	1
kinds of privacy regulations	1
mean Jaccard index	1
11.25%, 4.87%, and 0.76%	1
Dice loss	1
skewed class distributions	1
background pixels	1
Dice loss formulation	1
new state-of-the-art harmonic mean results	1
discriminative attributes	1
pretrained visual features	1
global versus local text features	1
text and image features	1
different levels of sense granularity	1
ambiguous query terms	1
image and text	1
deep image features	1
color information	1
color compatibility	1
ground-truth labels and pseudo labels	1
outfit compatibility	1
Color compatibility	1
95% rank-1accuracy	1
anunprecedented performance of 85% rank-1 accuracy	1
unseen identities	1
unseen images	1
91%accuracy for verifying	1
orthogonality constraints	1
similar representationsacross	1
extreme distortions	1
significant variationsin	1
temporal classification results	1
symbols and spatial relations	1
Connectionist Temporal Classification loss	1
temporal classification	1
multiple paths of symbols and spatial relations	1
effectiveness and competitiveness	1
consensus information of multi-view data	1
trace-norm	1
low-rank constraint	1
orthonormality constraint	1
clustering properties	1
underlying information	1
10% more accurate	1
67% more fair	1
fairness and quality	1
better balance	1
optimal trade-offs between fairness and quality	1
data permutations	1
better closed caption transcriptions	1
biases in data	1
world	1
Big data)	1
ubiquitous	1
digital mapsand remotely-sensed imagery spatio-temporal data	1
health status	1
population leveldiffers	1
temporal or spatial patterns	1
various characteristics	1
biological, social, geographic, economic, andmedical factors	1
county-level outcomes	1
higher correlation	1
higher year-to-year stability	1
fewer extreme outliers	1
county-level predictions	1
Big Five county-level personality traits	1
target side word frequencies	1
varying word distributions	1
different word distributions	1
labeled Twitter/county data	1
privacy and ethical regulations	1
personality distributions	1
general predictions	1
Facebook language	1
one datum	1
space and per-iteration costs	1
strongly convex functions	1
convergence rate of O(log t/t)	1
cheap per-iteration costs	1
sample output (summarization)	1
Qualitative assessments	1
state-of-the-art or comparable performance	1
future generation	1
overall fluency	1
incentive cost	1
system latency, energy consumption	1
block generation rate	1
training latency	1
system lifetime	1
energy and CPU constraints	1
variance and overestimation	1
overestimation phenomena	1
variance of the target values	1
predefined action space	1
historical states	1
initial sampling	1
frame/clip	1
frame-level saliency	1
great research interest	1
``1''	1
digits ``0''	1
boundary conditions	1
better binary classifiers	1
Boundary conditions	1
initial value problem	1
similar architecture	1
trainable weights	1
several different scenarios	1
physical meaning	1
Fairness, Accountability, Confidentiality, Transparency	1
impressive visual results	1
given trimap	1
cross-patch contextual dependency	1
consistency issues	1
contextual dependency	1
real-world input images	1
hardware limitations	1
relations and equivalences	1
analytic forms	1
effective kernels	1
DGP composition	1
non-local and non-stationary correlation	1
expressivity parameter of DGP	1
variational approximation	1
specified activation functions	1
DGP distributions	1
heavy-tailed nature	1
exact moments	1
composition functions	1
non-Gaussian distribution	1
Expressive power	1
quantified uncertainty	1
robust and near to supervised learning performance	1
negative ones	1
dynamic and static visual cues	1
interesting use-cases	1
11 million texts	1
six languages	1
limited scale	1
relative quality	1
openness	1
additional contextualfeatures	1
fine grained level	1
combined segmentation and POS tagfor	1
model preferences	1
respective preferences	1
preference differences	1
textual clues	1
different preferences	1
fake news posts	1
shared patterns	1
ranking twelfth and fourth	1
F0.5 = 58.62 and 59.50	1
Unrestricted Track	1
Restricted Track	1
predicted distributions	1
CovarianceNet correctly	1
proposed metric	1
uni-modal distribution	1
bi-variate Gaussian distribution	1
Gaussian latent variables	1
predicted distribution	1
human motion	1
correct characterization	1
3.8$\mu$W	1
spike patterns	1
single-timeframes	1
even lower power consumption	1
low-powerchips	1
fixed word embeddings	1
significant progress over time	1
amount of annotated data	1
various proportions	1
examples of activity	1
proof of robustness	1
greater accuracy	1
normal cyber behaviors	1
KG dependent	1
searched SFs	1
expressive ability	1
AutoSF efficient	1
distinct KGs	1
complex patterns	1
different kinds of relations	1
plausibility of triplets in knowledge graph (KG)	1
occasional disagreement	1
salient differences	1
Pearson's r = 0.94 and 0.95	1
human judgment and automatic evaluation (BLEU)	1
+22.33 BLEU	1
best improvement	1
noisy comments	1
Fairness Transparently	1
per-category basis	1
cost efficiency	1
principled documentation	1
brand image	1
customer loyalty	1
business product integrity	1
aspects of transparency and accountability	1
visualisation aspects	1
object-attribute form	1
humanthinking and analysing data	1
basic units	1
Formal Concept Analysis (FCA)	1
lower memory budget	1
additional supervision or memory budget	1
pseudo CIL tasks	1
good ones	1
good or bad placebos	1
placebos and the old data	1
class overlap	1
Google Images	1
free image stream	1
placebo data	1
old class knowledge	1
new class data	1
subsequent phases	1
sub-category feature	1
ranking result	1
set of relevant answers	1
treebank encodings	1
cross-genre and cross-time settings	1
classical subtask	1
additional supervised data	1
DWT coefficientsbelonging	1
128 x 128 pixels	1
grayscale and its dimensions	1
FrontalFace	1
properties of L*a*b* color space	1
credible accuracy rate	1
data processing capability	1
extremelylow variance	1
recall by more than 10%	1
combination of levels	1
graph-level and the vector-level	1
vector forms	1
graph's nodes and edges	1
general information	1
retrieval challenge	1
scene graph levels	1
inter-relationship information	1
splits	1
caption diversity	1
audio content	1
eight to 20 words length	1
24 905 captions	1
15 to 30 seconds duration	1
general audio content description	1
complete model parameters	1
latent dependencies	1
one client	1
sequentially partitioned data	1
direct access	1
pair Choquet/Sugeno integrals and overlap functions	1
90,76%	1
88.80% of accuracy	1
extensions and overlap functions	1
Choquet and Sugeno integrals	1
classical aggregations	1
wide range of aggregation functions	1
six	1
time-invariant	1
non-invasive nature	1
significantly lower bias	1
nominal and adversarial)	1
separatesub-policies	1
learned bias	1
decision space	1
off-lineoptimization	1
sub optimally	1
DRL policy	1
fewer calls	1
fewer number	1
good choices of penalty parameters	1
solver data	1
similar combinatorial optimisation problems	1
repeated solutions	1
multiple expensive calls	1
chosen values	1
objective and penalty terms	1
recollecting data	1
easy state abstraction	1
fixed dataset	1
theoriginal MDP	1
valid hierarchical decomposition	1
transferable subtaskpolicies	1
temporal abstraction	1
data preparations	1
various training settings	1
best ensemble results	1
state-of-the-art single model performance	1
adverse impacts	1
new loss	1
overall loss	1
weighting factor	1
extra input	1
TTS performance	1
unrelated polyphonic character	1
nice tradeoff	1
weak operators	1
variable resource constraint	1
$10^{160}$ candidates	1
manually designed constraints	1
search flexibility	1
accurate and 2x faster	1
``back-off"	1
RePAQ's strength	1
1K questions per second)	1
size (under 500MB)	1
RePAQ by over 15%	1
comparable baselines by 5%	1
available QA-pairs	1
substantially less knowledge	1
high degree of control	1
terms of speed and memory	1
interrelated information	1
top $k$	1
terms of the license	1
unannotated sensor data	1
392,556 sequential frames	1
3D bounding box annotations	1
12,497 frames	1
semantic segmentation image and point cloud labels	1
41,277 frames	1
mutually registered	1
time synchronized	1
recorded data	1
full 360 degree coverage	1
instance segmentation	1
3D bounding boxes	1
Audi Autonomous Driving Dataset (A2D2)	1
high quality annotated data	1
F1-score of 0.51	1
Vector Quantization (VQ)	1
relative meritsof	1
kernel version	1
kernel Hilbert spaces	1
standard inner products	1
global minimum	1
sum of quadratic functions	1
1D class sub-spaces	1
class subspace	1
thefeatures of each class	1
cardinality of thefeatures	1
1D subspace	1
classes (or categories	1
spacedefined	1
EEG responses	1
features importance	1
16 % chance level	1
highest scores (mean CA = 53 $\pm$ 12 %	1
training configurations	1
Classification Accuracy (CA)	1
statistically significant (p < 0.05) differences	1
ERPs amplitude	1
cerebral data	1
still-high 97.3\%	1
system's accuracy	1
3Dobjects accurately	1
time gap	1
subtle traces	1
uneven 3Dshapes	1
unique textual features	1
physical characteristics	1
clear and strong security guarantees	1
pixel ratio	1
lineheight, matra line	1
skewedthe image	1
skew angle	1
values the sub imageswere	1
line height	1
theirheight-width ratio	1
every sub image	1
tothese areas	1
horizontal and vertical area ofevery pixel	1
theedges of the input image	1
category properly	1
garbage textsas output	1
graphic APIs	1
semantic relevant visual information	1
extremely imbalanced	1
different settings of the parameters	1
extremely varied	1
appearances	1
performance differences	1
absolute BLEU points	1
src {--}{\textgreater	1
previously unlabeled data	1
2% absolute	1
certain amount of data	1
initial training iteration	1
threshold of confidence scoresis	1
economic reasons	1
high performance automated decision supportsystems	1
largeamounts of annotated data	1
large quantities of annotated training data	1
state-distribution shift	1
informative demonstrations	1
state familiarity	1
set of demonstrations	1
coherence	1
detailed content	1
translated image	1
global image	1
object instances	1
unpaired training images	1
adaptation accuracy	1
thelearning speed	1
2%-20.2%	1
Pearson correlation	1
17.7%	1
adapted logistic functions	1
nearly 8.9%	1
raw IQAs	1
23.2%	1
discrimination resolution of MOS	1
low to mid quality range	1
9.4%	1
Logistic Function	1
mapped IQAs	1
2%	1
widely used IQAs	1
discrimination resolution	1
MOS subjective scores	1
23% resolution	1
precisions	1
Image Quality Assessment (IQA) meters	1
accuracy/precision	1
high quality range	1
measured quality	1
subjective tests results	1
input forest	1
training bitext	1
syntactically highly divergent	1
unseen noise	1
system's robustness or accuracy	1
F1 score of 74.51{\%}	1
Angry, Happy, Sad and Others	1
one of four emotion classes	1
`}	1
information called rewards	1
information about data	1
i.e. schema)	1
latent structure	1
scalability issue	1
practical tasks	1
Bi-FLEET	1
element and clause types	1
invariant knowledge	1
element types	1
semantic complexity	1
implicit entity preference	1
fake samples	1
evaluation capacity	1
learned useful information	1
original performance	1
different intrinsic characteristics	1
online items	1
rich user-item interaction data	1
missing fact information	1
standard episodic memory	1
current progress	1
overall memory constraints	1
appropriate compression	1
given stage	1
compression ability	1
later decoder states	1
earlier encoder states	1
sample once	1
greater generalization properties	1
KG-specific tasks	1
significant improvements of up to 8.8% in NDCG@10	1
average improvement of 16% in accuracy	1
22% MRR improvement	1
link prediction objective	1
greater difficulty	1
varying difficultywhere	1
good policies	1
par performances	1
image translation multimodality	1
synthetic images realism	1
typical traits	1
limited effectiveness	1
1.8ms/sample processing time	1
10-second windows	1
72.2% accuracy	1
highest correlated	1
time window lengths	1
boredom, calmness, horror and joy	1
'Goat Simulator'	1
'Slender The Arrival'	1
'Unravel'	1
Train Sim World'	1
emotion patterns	1
subject-specific calibration data	1
FOWT dynamics	1
probabilisticdetection threshold	1
observer prediction error	1
theMahalanobis Distance	1
rigid rotorand platform dynamics	1
limitedaccessibility	1
operation and maintenance costs	1
in-degree of thenecessary features	1
much better sample complexity	1
severalhundred-fold faster	1
significantlyimproved anomaly detection performance	1
data sample	1
theseadversarially learned features	1
reconstruction errors	1
adversarially learned features	1
complex high-dimensional distributions	1
faster and more stable	1
training times	1
denser reward signal	1
parameter sharing	1
difficult problems	1
60.2% and 72.1% top-1 accuracy with 1% and 10% labeled samples	1
contrastive similarity	1
prediction distribution	1
pairwise similarities	1
massive unlabeled data	1
word error rates (WERs)	1
usability	1
four medium-sized (longer than 22 hours each)	1
better life	1
GS camera model	1
high-quality Global Shutter (GS) images	1
constant velocity assumption	1
two consecutive frames	1
model generalizability and accuracy	1
topological and deep features	1
vast array	1
unique information	1
quantitative measure	1
wide overview	1
erroneous words	1
two times	1
large number of instances	1
EL difficulty	1
variety of features	1
special characteristics	1
-specific features	1
particular entity mention	1
theusefulness of automated disambiguation results	1
recent improvements	1
inadmissible estimates	1
Explicit Estimation Search (EES)	1
given factor of optimal	1
costs of its solutions	1
small runtimes	1
around 7 annotators	1
9,476 sentences	1
complexity value (complex vs. non-complex	1
dimensions of knowledge	1
77%)	1
34% higher accuracy	1
original database schema	1
entities and values	1
equal length	1
MTSC archive problems	1
26 of the 30	1
multivariate dimensions	1
univariate classifiers	1
single label	1
single series	1
ordered, real valued, attributes	1
Discrete Denoising Flows (DDFs)	1
categorical random variables	1
common proxemics and social rules	1
proposed pedestrian detection	1
toeach constraint	1
mixtureof asymmetric Gaussian functions	1
human awareness	1
once	1
relation labels	1
table representation	1
possible improvement directions	1
respective impact	1
remaining key challenges	1
large gap	1
``}There is an attack{''}	1
{``}A city was attacked{''}	1
set of Textual Entailment (TE) and/or Question Answering (QA) queries	1
expensive annotation	1
standarddirected information measures	1
best indiscriminating	1
different audio qualities	1
connectivity results	1
thedifferent causal measures	1
analytical relationship	1
directed information	1
standard directedinformation measures	1
cortical functional connectivity	1
five metrics	1
865 lines	1
shared attention	1
gloss-source language tags	1
BLEU score of 25.94	1
70,918 glosses	1
four-fold	1
accurate templates	1
sparse codes	1
two orders of magnitude faster	1
similar level of accuracy	1
continuous-time shifts	1
interpolated variants	1
discrete-time shifts	1
estimates of the times	1
Convolutional Dictionary Update (CDU)	1
source--	1
target word{'}s in-context complexity	1
out-of-context information	1
linguistic and psycholinguistic variables	1
single words lexical complexity	1
conditional entropy	1
statistical relationships	1
clustering assignments	1
data clustering information	1
dissimilar representations	1
Clustering InfoNCE	1
hashtags	1
punctuations and formatting	1
baseline by 1.3 % minDCF and 2.2 % ERR	1
0.3098 minDCF and 5.076 % ERR	1
original negative Euclidean distance	1
testing utterance pairs	1
t-SNE normalized distance	1
30 hiddenlayers	1
8million observations	1
thescalability and performance	1
accurate quantification of uncertainty	1
limited scalability	1
sound quantification of uncertainty	1
self-supervised and supervised counterparts	1
maximal information	1
massive fMRI big data	1
Experimental data	1
processing powerof	1
complexhierarchical structure	1
alarge amount of tfMRI data	1
corresponding spatial maps	1
truth of underlying neural activities	1
intrinsic complex structure	1
sheer size	1
input blurry one	1
wide range of frequencies	1
results comparable orbetter	1
one to two orders of magnitude faster	1
therun-time	1
low complexity	1
higher resolution version of it	1
low and high resolution images	1
corresponding pairs	1
higher image quality	1
significantlymore pixels	1
larger size	1
wrong wh-word	1
fluency and uniqueness	1
semantic adequacy	1
syntactic correctness	1
dependency parse information	1
relative pronouns	1
shared semantics	1
similaritybetween images	1
two types of DANs	1
essential information	1
high-dimensional regime	1
large-scale gene expression data	1
causal effects	1
input mentions	1
temporal contexts	1
temporal signatures	1
long time periods	1
NED quality	1
specific time interval	1
within 0.2 and 1.9 GPU-day	1
2.25\% and 24.7\%	1
values of the architecture parameters	1
norm balance	1
imbalanced norms	1
almost thousands of times in GPU-day	1
network representation	1
special syntax rules	1
non-projective sentences	1
projective tree	1
subtree	1
TSP	1
edge costs	1
average only 21% of the least-squares classifier computational costs	1
severely limited	1
Hyperdimensional Computing	1
simple vector and distance calculations	1
simple design	1
certain resource constraints and efficiency requirements	1
comparable PSNR and SSIM	1
best PI and LPIPS performance	1
previous image-space loss functions	1
additional structure priors	1
perceptual-pleasant details	1
undesired structural distortions	1
hard restrictions	1
non-convex regularization terms	1
certain output	1
two large groups	1
task-specific metrics	1
diagnostic value	1
recovered undersampled images	1
extreme undersampling factors	1
x16 acceleration factor	1
SSIM of 0.956	1
MSE of 0.00114, a PSNR of 29.6 dB	1
final image quality	1
recovery models	1
undersampling and the downscaling factors	1
sampling patterns	1
underresolved images	1
published papers	1
MRI acceleration factors (a.k.a.	1
individual objectives	1
correct mentions	1
layer-wise quantization of parameters	1
77.5% lower cost	1
averages of 53% lower	1
accuracy losses of less than 1%	1
accuracy losses of up to 50%	1
optimal bitwidths and fractional offsets	1
low bitwidth fixed-point representations	1
32-bit floating-point precision parameters	1
loss in inference accuracy	1
weights, biases and activations of each layer	1
cost of a loss	1
memory and computational complexity	1
high memory consumption	1
Code and the collected test data	1
occlusion and variant pose	1
high attention weights	1
varied number of region features	1
variant poses	1
real-world occlusions	1
three-fold contributions	1
real-world pose and occlusion robust FER problem	1
occlusion-robust and pose-invariant issues	1
facial appearance	1
Occlusion and pose variations	1
respective data size	1
choice of domains	1
many limitations	1
form of who, what, when, where and why	1
targeted information	1
required information	1
original text	1
large amount of potentially useful information	1
explicit form	1
state and control variables	1
aggressive takeout orders	1
passive limit orders	1
different trading sessions	1
lit vs. dark liquidity	1
inherent complexities	1
child orders	1
given time horizon	1
smaller child orders	1
big parent order	1
big security positions	1
thesegmentation results	1
Liver Tumor Segmentation (LiTS)	1
inter-slice features	1
theintra-slice representations	1
intra-slice features	1
2D DenseUNet	1
highcomputational cost and GPU memory consumption	1
spatialinformation along the third dimension	1
optimistic variants	1
known optimum solutions	1
optimistic and pessimistic	1
benchmark problems	1
bilevel problems	1
non-convex and strongly NP-Hard	1
one of the constraints	1
effectiveness and universality	1
identified poisoned data	1
BIC cost	1
poisoned components	1
different classifier structures	1
classifier's accuracy	1
Internet networking condition	1
considerable computation overhead	1
major bottleneck	1
following bottlenecks	1
efficiency problems	1
cost of extra computation and communication consumption	1
data privacy protection	1
increasing concerns	1
resulting fairness metrics and accuracy	1
client level	1
various insights	1
fPAD model	1
\textit{data centers}	1
rich fPAD information	1
legal and privacy issues	1
real face images and spoof images	1
different input distributions	1
model and the predicted difficulty scores	1
difficulty estimates	1
improvedalignment of source and target distributions	1
generality and scalability	1
embeddings closer	1
simple adversarial objective	1
informative representations	1
ballpark	1
efficient word representations	1
boost in recognition performance	1
related joint loss	1
inter-class dependencies	1
global sense of class dependencies	1
huge amounts of data	1
e.g., graph2seq, graph2tree, and graph2graph)	1
multi-types	1
multi-chart representation	1
subjective attributes	1
conditional setting	1
variance and look-ahead-bias trade-off	1
layers of information	1
larger variance	1
look-ahead-bias	1
future performance	1
missing returns	1
full panel data	1
Missing time-series data	1
dynamic trajectories	1
static artefacts	1
different navigational modes	1
motionpatterns	1
predictedtrajectory	1
inefficient features	1
traffic patterns	1
knowledge learned previously	1
new traffic patterns	1
long-term period	1
new patterns	1
expansion and evolving patterns	1
massive amount of traffic flow data	1
available results	1
short concrete answers	1
source of general knowledge	1
higher importance	1
general and commonsense knowledge	1
visual observations	1
target relations	1
source relations	1
relation-invariant features	1
different relations	1
different but related low resource relations	1
high resource relations	1
knowledge/features	1
limited training instances	1
new facts	1
many known samples	1
labeled sentences	1
satisfactory number	1
versatile vectors	1
sufficient training triples	1
syntactical analysis and semantic measurements	1
comment	1
usefulness	1
Task 3	1
pronounced {`}Morse{'}	1
25% better	1
cluster quality	1
Soybeangenome data	1
crucial similaritymatrix	1
complexity ofSC is cubic in-terms of the input size	1
one or more of the following four	1
continuation	1
4 points in BLUE-4 and 5 points	1
13.25 BLUE-4 and 36.28 ROUGE scores	1
additional target annotation	1
additional labeling	1
gloss level	1
much larger search space	1
high complexity	1
entity-level $F_1$ scores	1
improvement of about 7 percentage points	1
unified annotation	1
labelling functions	1
varying accuracies and confusions	1
broad spectrum of labelling functions	1
Named Entity Recognition (NER ) performance	1
intuitive understanding	1
target datasets	1
disentangled domain-irrelevant and domain-specific features	1
labeled target data	1
$(	1
$(1)$ HMTGIN	1
two million nodes	1
corresponding predictions	1
tasks' relationships	1
respective losses	1
useful learning signals	1
corresponding empirical results	1
less than 100 lines	1
clear interpretations	1
sequential task specifications	1
interesting causal dependencies	1
non-Markovian rewards	1
explicitly design reward functions	1
effective robot control policies	1
annotation training data	1
sentence-level score predictions	1
content scores	1
labeled annotation data	1
annotation spans	1
essay level	1
formative feedback	1
human scoring	1
holistic scores	1
set of characteristics	1
tradeoff between accuracy	1
simplicity and good results	1
fast computational speed	1
high reconstruction accuracies	1
different sampling ratios	1
optimized parameters	1
shrinkage functions	1
image transforms	1
computational speed	1
under-sampled data	1
distant target domains	1
base category data	1
sparsely labeled novel category data	1
less than 24 hours	1
new language capability	1
69% and 80%	1
64% and 78%	1
overall test accuracy ranging between 61% and 69% for the hotels domain	1
new languages	1
training data automatically	1
types of sleep events	1
interpretable input representation	1
mean F1-score of at least 80.9% and 82.6%	1
visual criteria	1
fixed time window	1
complex spectrogram	1
one of two input representations	1
Recurrent Event Detector (RED)	1
significant inter-expert variability	1
several short events	1
strongly labeled data	1
extensive noise	1
large amount of weakly labeled data	1
small amount of strongly labeled data	1
almosttight lower bounds	1
distribution of graphs	1
$k>2$	1
$o(n)$ edges	1
outlier errors	1
Feige---Kilian or monotone errors	1
modeling errors	1
prior distribution of noise	1
+.64 F1 score	1
semantic indicators	1
lexicographic features	1
lot of time	1
trained taggers	1
17 percentage points	1
temporal localization capabilities	1
time coordinate maps	1
7 times fewer parameters	1
91.6% of accuracy	1
acoustic content	1
acoustic inputs	1
selected spans	1
automatically annotated data	1
sufficient cleanly annotated data	1
6,890 relations	1
1000x faster	1
0.15 GPU hours	1
state-of-the-art performance and efficiency tradeoff	1
specific augmentation policy	1
expected training loss	1
proper augmentation policy	1
better trade-off	1
searched structures	1
4-6 times fewer computation resources	1
better reconstruction results	1
sub-sampled k-space data	1
state-of-the-art Fr\'echet Inception Distance (FID) performance	1
high-quality image outputs	1
Langevin dynamics	1
target domain images	1
denoising score matching objective	1
lessons	1
sub-architectures	1
smaller size	1
potential redundancy	1
key property	1
enormous computational cost	1
massive computations	1
burden	1
moregeneralized knowledge	1
original model	1
thesheer amount of model parameters	1
maximum disparity	1
learning invariant features	1
cluster segmentations	1
semantic, spatial and motion information	1
batch input	1
17.0% with	1
79.4%	1
either handcrafted statistical or temporal features	1
interval embeddings	1
time adjacent intervals	1
pairs of embeddings	1
human behaviour	1
underlying behaviour	1
trends and properties	1
5.8%-10.9% on Hits@1	1
relation specific embeddings	1
two key criteria	1
phenomena	1
two counter-intuitive phenomena	1
architectures	1
multi-source KGs	1
even more alignment paths	1
ends	1
full alignment	1
entire label	1
entire sequence	1
possible alignment paths	1
pairs of audio (input sequence) and text (output label),without temporal alignment information	1
non-linear abilities	1
exorbitant size of data	1
various possible relationships	1
rotation matrix	1
comparable vector space representations	1
bilingual word vectors	1
super-resolution images	1
low-resolution conditions	1
position and the content	1
character-level details	1
arbitrary orientations	1
text-level layouts and character-level details	1
text-specific properties	1
scene text images	1
text shapes	1
realistic features	1
Image super-resolution	1
various quality metrics	1
real-time electricity consumption data	1
aberrant consumption patterns	1
balanced data	1
consumers' electricity consumption patterns	1
complex architectures	1
large training times	1
consecutive missing values	1
safety, reliability	1
Non Technical Loses (NTLs)	1
electricity consumption data	1
state-of-the-art FSOD performance	1
distractor utilization loss	1
incurred false positives	1
incomplete annotations	1
commonly-overlooked but destructive issue	1
low-data constraint	1
intrinsic architecture limitation	1
classification incapability (false positives)	1
failure modes	1
closer relation	1
surface keypoints	1
spacecraft's geometric features	1
3D bounding box corners	1
texture-randomized spacecraft images	1
pre-defined order	1
known correspondences	1
corresponding 3D model coordinates	1
2D locations	1
25% of FLOPs	1
90.3% F1-score	1
temporal and frequency dimensions	1
square convolutional kernels	1
heavy computational burden	1
surgical outcomes	1
clinical context	1
210 (70%)	1
comprehensive clinical outcomes	1
segmentation masks	1
wide array of morphometric features	1
manually quantifying imaging predictors	1
clinical outcomes	1
kidney tumor morphology	1
morphometry	1
on-device capabilities	1
average deterministic accuracy increase of at least ~11.01%	1
model scores	1
overlapping information gain	1
restricted motor abilities	1
color cues	1
best overall accuracy of 80.6\%	1
model's efficiency	1
signal band power	1
correlation features	1
spectral power features	1
important cognitive feature	1
effectiveness and the flexibility	1
regularization terms	1
auxiliary loss function	1
new unseen examples	1
stellar performance	1
solved one	1
short and noisy textual data	1
LOD features	1
ranked 2nd and 3rd	1
F-scores of 46.16 and 60.24	1
rich contextual features	1
interpretable phenotypes	1
similar or better performancethan	1
interpretable phenotype features	1
meaningful data-drivenrepresentations and patterns	1
stylistic	1
L1 differences	1
semantic similarities	1
embedding representations	1
relatively poor performance	1
word and document embeddings	1
bi and trigram features	1
word uni	1
macro F1 of 0.8264	1
synthesized output	1
provided metadata	1
augmented sample space	1
distinguishable features	1
masking possibility	1
wide variety of samples	1
potential EEG signals	1
augmented samples	1
distribution of real samples	1
generated EEG signals	1
high-quality and high-diversity	1
reduced over-fitting	1
increased accuracy, stability	1
choice pairs	1
natural language relations	1
answer choice	1
salient instance centroids	1
Centroid Detection Branch	1
class discrepancy information	1
Boundary Detection Branch	1
class consistency information	1
class and subitizing labels	1
salient instances	1
high semantic affinities	1
instance-aware saliency information	1
15%-58% on Hit@1	1
connected relations' meta semantics	1
node's incoming and outgoing neighbors	1
cross-lingual entity embeddings	1
n-to-n	1
relation nor complex relations	1
meta semantics	1
entity or triple instances	1
node differentiations	1
cross-lingual knowledge	1
visual discourse cues	1
corresponding discourse cues	1
discourse cues	1
learningdiscourse cues	1
subset of video frames	1
semi-supervised (20%)	1
state-of-the-art question generation performances	1
ground truth answer	1
model's proposed answer	1
pretested answer	1
corresponding answer	1
expensive data annotation costs	1
87.31%	1
categorization	1
limitation of FCN	1
widely used baseline features	1
Multiscale Fractal Dimension	1
emotion-related features	1
complex and noisy structure	1
similar generalization performance	1
test phase	1
sum-decomposable structure	1
refined pseudo-labels	1
diverse information	1
Disjoint Residual Labels	1
different stochastic (i) input augmentation and (ii) feedback	1
inferred target pseudo-labels	1
structured noise	1
significant amount	1
privacy reasons	1
improvement of 29 BLEU	1
strong boost of performance	1
paragraph level parallelism	1
word level parallelism	1
geographical and cultural distributions	1
morphologies	1
historical origins	1
machine translation systems performance	1
multilingualism (and associated similarities	1
large number (more than 2,000)	1
around 30%	1
slang word senses	1
dynamism	1
i.e., GTA5/SYNTHIA to Cityscapes/BDDS/Mapillary	1
various SRSS settings	1
regularization of Consistency	1
texture difference	1
diverse unreal texture styles	1
target real-world data	1
corresponding label	1
large image limit	1
fixed FLOP-count	1
generalization curves	1
> 10x reduced FLOP-count	1
fixed ratio of FLOPs to parameters of standard convolutions	1
parameter count	1
many FLOPs	1
demoisaicing, denoising and super-resolution	1
0.105 seconds	1
averageinference time	1
mean F1 score of 0.528 at an IoU of50%	1
fastmanner	1
Road Damage Detection and Classification Challenge	1
statistically significant improvement in BLEU scores	1
better alignment	1
remaining iterations	1
pre-decided number	1
shuffling noise'	1
decreased BLEU	1
\textit{scrambled}	1
interesting kind of error	1
strong transition paths	1
domain-slot	1
slot-slot	1
domain-domain	1
graph node and edge embeddings	1
domains, slots and values	1
wrong inference	1
type and language coverage	1
English SLU training data	1
abundant training data	1
publicly available evaluation data	1
44.53 to 46.94 in ROUGE-L.	1
21.24 to 22.33	1
17.55 to 18.53 in BLEU-4	1
46.58 to 47.69	1
increased recall	1
grammar and vocabulary	1
type of interrogative word	1
four lines	1
single command	1
average gain of 7.26 pp	1
61.7% on TriviaQA	1
45.5% Exact Match accuracy	1
user data	1
imbalanced data distribution problems	1
model stability	1
autonomous driving policy	1
centralized large-scale data	1
testing EEG data	1
mind state	1
drowsiness estimation problem	1
terminologies	1
drowsiness and driving performance	1
one manifestation	1
intra-domain discrepancy	1
strongly augmented unlabeled target images	1
original (input image)	1
source and unlabeled target distribution	1
labeled and unlabeled target distributions	1
unlabeled target distribution	1
labeled source distribution	1
weightsfor each component	1
state-of-the-art resultsin	1
APEand QE	1
outputspace	1
different input representations	1
machine translation hypothesis	1
representation ofthe original source	1
input factors	1
Word-level features	1
>70 times faster and more accurate	1
generator's ranking	1
correction term	1
generative objective	1
source sequence length	1
proposed ConResNet	1
inter-slice context information	1
context residual mapping	1
fast therapeutic schedules	1
3.0 %	1
4.1 +/-	1
2.5 %	1
mean absolute difference between estimated and reference EF of 3.5 +/-	1
S{\o}rensen-Dice score 0.91 +/- 0.072 and 0.93 +/-	1
1MSA and 2MSA settings	1
left ventricular segmentation quality and ejection fraction (EF) estimation	1
model outputs	1
timepoints	1
cardiac function	1
lower image resolution	1
good substitutes	1
best sense	1
likelihoods	1
sense labeled data	1
word sense disambiguation -LRB- WSD -RRB- difficult	1
Data sparsity	1
twelve evaluation metrics	1
current frame deep	1
object affinities	1
two frames	1
several levels of abstraction	1
compact; yet comprehensive features	1
affinities	1
object appearances	1
spatial proximity	1
appearance, motion	1
hand crafted constraints	1
tracks	1
models generalization capabilities	1
lexical and stylistic variations	1
inter-document variability	1
71out of 85	1
improvement in accuracy	1
measureinter-datasets similarities	1
model's predictions	1
7140 different deep neuralnetworks	1
learned features(the network's weights	1
sentiment label information	1
subject-oriented document representations	1
sentiment contexts	1
explicit subject patterns	1
key sentiment	1
major points	1
vague semantic links	1
D-MILN	1
document-level sentiment	1
aspect-level sentiments	1
document-level signals	1
aspect-level classifier	1
aspect-level and document-level sentiment	1
time-consuming and laborious	1
many more entities	1
high quality KB	1
best characterization	1
sparse KBs	1
event representations	1
regular time intervals	1
temporal and semantic similarity	1
low-dimensional embedding	1
current data graph structure	1
current data representation	1
semantic and temporal similarity of the data	1
graph and its graph embedding	1
semantic and temporal similarity	1
whole	1
10 labeled examples	1
mean absolute error, mean squared error, Pearson correlation, and Spearman correlation	1
different linguistic features	1
wide range of linguistic features (e.g. psycholinguistic features	1
five point Likert scale	1
excellent sample complexity	1
approximately 1.1 million	1
bespoke properties	1
significant and consistent improvements	1
wrong labelling problem	1
low manual annotation cost	1
scientific relation	1
weakly superviseddatasets	1
paucity of training data	1
range of noisy scenarios	1
spectrogram images	1
audio domain	1
imagined-speech EEG recognition performance	1
analysis phase	1
analysis phase and a support phase	1
parallel information	1
+3.9 BLEU points	1
improvements of up to +11.8 BLEU points	1
limited amount of ST data	1
text-audio difference	1
wrong language	1
end-to-end ST data	1
much as a nat per datapoint	1
posterior approximations	1
kernel basis functions	1
predictive uncertainty	1
many of the attractive features	1
Deep Gaussian Processes (DGPs)	1
user queries and clinical notes	1
clinical notes	1
annotated clinical notes	1
9.18, and 11.76 BLEU point improvements	1
Multilingual Speech Translation Corpus (MuST-C)	1
speech, text representations	1
text translations (e.g., English-German MT	1
vast amounts	1
large amounts of parallel data	1
smaller model size	1
acoustic information	1
ASR output	1
textual, but also acoustic information	1
advanced KD variants	1
10x less parameters	1
3x less memory	1
20x more sample efficient	1
optimal student architecture distribution and KD parameters	1
given teacher	1
negligible differences in performance	1
considerable human expertise	1
substantial performance gap	1
device hardware limitations	1
tentative comparison	1
third and fifth place	1
MRC subtasks 2 and 3	1
knowledge graph embeddings	1
triples	1
completion	1
different aspects of entities	1
Knowledge graphs (KGs)	1
greatly reduced	1
strong dependence	1
out-of-vocabulary problem	1
natural language question	1
fair comparison	1
2.17 points	1
robustness of visual representation	1
language semantic	1
visual task	1
cost of bounding box annotations	1
pixel and text level	1
region-based image features	1
image and sentence pairs	1
image pixels and language semantics	1
accurate and thorough connection	1
visual and language embedding	1
2% of its cloud compute cost	1
wordpiece vectors	1
resulting word vectors	1
hardware, runtime and CO_2 emissions	1
language-specific test data	1
multilingual NLU model performance	1
language separately	1
new language models	1
linear investment of effort	1
rank-1 recognition rate	1
mapping function	1
individual's appearance	1
individuality of each person	1
instance pairs	1
fixed distance metric	1
discriminative matching metrics	1
robust feature representation	1
disjoint camera views	1
several times faster	1
weakly supervised baselines	1
sub-quadratic performance	1
points on the Pareto frontier curve	1
given preference over accuracy and fairness measures	1
convex and non-convex objectives	1
provable guarantees	1
PEF notion	1
well-defined notion of fairness	1
definition-agnostic	1
proposed PEF notion	1
optimal trade-off between overall loss and other fairness criteria	1
suitable fairness notion	1
basis of gender, race, ethnicity, religion	1
rapidly expanding publications	1
query term	1
superconductivity terms	1
term similarity	1
human annotator agreement rates	1
terms of micro-F1	1
around 77{\%}	1
8\% higher	1
96\% classification accuracy	1
COVID-19 lung CT	1
Distant Domain Transfer Learning (DDTL)	1
number of privacy policies	1
novelty	1
manual and automatic variations	1
out-of-domain	1
one of three possible sources	1
first hit	1
surprisingly competitive	1
manually created variations	1
original questions	1
statistical parity	1
group fairness	1
equal proportions	1
treatment parity	1
following desirable properties	1
desiderata capturing well-motivated fairness criteria	1
unjust outcomes	1
positive-class membership (such as criminal/fraud)	1
race/ethnicity/sex/age)	1
4.4%	1
non-overlapping or totally nested	1
0.018 points behind the winning submission	1
Pearson correlation of 0.7704	1
LightGBM	1
related task	1
standard morphosyntactic and frequency-based features	1
complexity score	1
high performance and fine-grained extraction results	1
one evidences	1
close to SOTA performance	1
BLEU score of 23.35	1
WER of 11.61	1
thestate-of-the-art metric depths	1
poseand trained end-to-end	1
depth predictionsystem	1
camera pose	1
3Dstructure	1
real-time requirements	1
sequenceof images	1
Recovering structure and motion parameters	1
0.06/h, 0.16/h, 0.22/h on	1
sensitivity of 81.4%, 81.2%, 82.3% and false prediction rate(FPR)	1
lower frequencies	1
highfrequencies features	1
whole frequency range	1
frequency and time domains	1
50% overlapping	1
high sensitivity and lowfalse prediction rate	1
Subtask B.	1
true, false or not a proper answer	1
desired accuracy-runtime trade-off	1
hyperparameter values	1
different NAS formulation choices	1
5,000x faster	1
24 TPU-hours)	1
overall cost of only 8 epochs	1
accuracy-runtime trade-off	1
~80ms)	1
similar latency settings	1
ImageNet accuracy (75.62%)	1
state-of-the-art top-1	1
search overhead	1
shared convolutional kernel parameters	1
architectural decisions	1
one single-path over-parameterized ConvNet	1
mobile latency constraints	1
state-of-the-art image classification results	1
less than 3 hours	1
NAS search cost	1
significant search time (at least 200 GPU-hours	1
combinatorially large design space	1
NAS problem	1
days down to only few hours	1
legitimate use	1
small as twice the input dimension	1
number of queries	1
corresponding probability outputs	1
basis	1
arbitrary embedding vectors	1
orders of magnitude fewer	1
high-fidelity copies	1
algebraic properties	1
respective NLMs	1
full sense inventory	1
part-of-speech and lemma features	1
sense distributions	1
full-coverage	1
unprecedented gains	1
traditional word embeddings	1
one of our embeddings	1
two versions (domain-specific and generalized	1
Stacked Embeddings	1
Word Embeddings, Flair Embeddings	1
vector and tensor embedding representations	1
farther away	1
pure models	1
accuracyof 76.26%	1
one of the fourtraining&testing tasks	1
visual or semantic feature correlation	1
spatial and semantic neighborhoods' features	1
object-level and triplet-level	1
triplet-level dependencies	1
structural triplet	1
low dimensionality	1
semantic hierarchies	1
relational context	1
hierarchical relation patterns	1
rich semantic hierarchical relations	1
hierarchical nature	1
inversion, and composition typed relations	1
symmetry/asymmetry	1
rich relationships	1
T1/T2/T3 types of query	1
phoneme posteriors and Bottle-Neck features (BN)	1
Acoustic Keyword Spotting (AKWS)	1
required run	1
dimensions of analysis	1
remaining majority	1
over-represented	1
large number of test facts	1
various design choices	1
fast growing literature	1
KG incompleteness	1
82.12% and 89.02% of success in the Recall and F1-score measurements	1
CPDs	1
CPD variant	1
CPD problem	1
Recall and F1-Score measurements	1
speaker identities	1
similar noisy data	1
researchsupplement NER results	1
large scale results	1
70-75 % (Kettunen andP\"a\"akk\"onen, 2016	1
estimated word level correctness	1
lots of OCRerrors	1
material	1
years1771-1910	1
1,960,921 pages	1
genre and domain dependent	1
NER system's performance	1
frequent informational elements	1
namesand name	1
KGAT's effectiveness	1
meaningful clues	1
70.38% FEVER score	1
edge kernels	1
node kernels	1
subtle clues	1
three times faster	1
steadily slightly better and more robust results	1
unit norm and orthogonality constraints	1
smooth and convex function	1
GSMV formulation	1
Group Sparse Maximum Variance (GSMV) formulation	1
group-$\ell_{1}$ norm	1
principal components situation	1
loadings	1
group sparse formulation	1
quantitative and qualitativecomparison	1
accurate and robust ego-motion estimates	1
theinstantaneous angular and linear velocities	1
geometric characteristics	1
camera motionchanges abruptly	1
RS distortion	1
motion prediction	1
ego-motion estimates	1
illumination condition	1
undesirable artifactswhen	1
low-costimaging capability	1
0.9855 f1-score	1
great incline	1
system results	1
individual UniMorph tags	1
verse level	1
highly multilingual nature	1
secondary tasks	1
visually appealing images	1
realistic VIS images	1
aligned paired data	1
shape guidance	1
visible (VIS) images	1
facial shapes	1
independent factors	1
spectrum	1
different face modalities	1
cross-sensor gap	1
decomposed variance	1
high inter-example correlations	1
lower-than-expected correlations	1
training curve	1
unstable final performance	1
potential solutions	1
reliability of the conclusions	1
highly unstable	1
high-level overview	1
96.91{\%} on classical, 90.87{\%} on cross-genre and 87.35{\%} on cross-time	1
closed modality	1
additional annotated data	1
90.64{\%} and 87.00{\%}	1
better data	1
several embeddings	1
either few or inaccurate data	1
Speech Recognition, Emotion Recognition tasks	1
Speaker Diarisation	1
labels and their values	1
user roles	1
temporal segmentation	1
sequence of inputs	1
word indexes	1
negative, neutral and positive polarity	1
https://sweichwald.de/coroICA /	1
documentation	1
performance and robustness	1
unmixing matrix	1
different stationary noise	1
grouped data	1
rendered dependent)	1
linearly mixed multivariate observations	1
theoretical implications	1
ensemble knowledge	1
User heterogeneity	1
PSNR optimized DVC	1
OpenDVC (PSNR)	1
open source codes	1
comparable PSNR performance	1
better MS-SSIM performance	1
ER signals	1
novel loss term	1
Entity Resolution (ER) features	1
domain, intent and slots	1
recent trends	1
relationsautomatically	1
personand organization	1
well-defined relations	1
sentenceare	1
lot of importantinformation	1
information automatically	1
quickly and efficiently	1
small perturbation	1
strong potential	1
highly robust	1
lowest value of 5.5	1
classification standard deviation	1
less than 0.025 seconds	1
average accuracy of 88.4% and 88.6%	1
least by 3%	1
raw EEG signals	1
end	1
performance within 1{--}5 F1 points	1
typed	1
named entity boundaries	1
identifiers or co-referenced	1
entire sentence	1
text in real time	1
prior art	1
computationally lightweight	1
hardware agnostic	1
heterogeneous data and resource distribution	1
client/device data	1
bilingual dictionary or parallel data	1
NER knowledge	1
manually crafted features	1
\url{https://github.com/thangvubk/Cascade-RPN	1
3.1 and 3.5 points	1
AR 13.4 points higher	1
sampled features	1
\textit{adaptive convolution}	1
anchor-based metrics	1
anchor-free metric	1
\textit{single anchor}	1
predefined scales and aspect ratios	1
\textit{aligns}	1
region-proposal quality and detection performance	1
novel information (unseen concepts	1
core components	1
strong ground	1
ourmethod time efficient	1
number of communities	1
recall metrics	1
data augmentation	1
77.54% unweighted accuracy (UA)	1
79.34% weighted accuracy (WA)	1
varied granularities	1
fixed attention granularity	1
diverse forms of energy patterns	1
similar typology	1
lemma and morpho-syntactic description	1
multi-kernel Maximum Mean Discrepancy	1
sub-optimal domain adaptation performance	1
participants{'} approaches and results	1
78.3{\%}	1
RQE task	1
74.9{\%}	1
accuracy of 98{\%}	1
best performances	1
trained parameters	1
optimal auxiliary branch	1
better losses	1
phonemes estimation	1
multilingual data	1
singing voice trails	1
https://github.com/iitmnlp/BERT -Analysis-RCQA	1
numerical quantities	1
much/how many)	1
defined roles	1
Integrated Gradients	1
layer's role or functionality	1
predefined roles	1
near human-level performance	1
Levels of Autonomy (LoA)	1
LSAOM capabilities	1
expressed or implied sentiment	1
class invariant features	1
generalization power	1
observed classes	1
training and test examples	1
novel sampling strategies	1
semantically embedding space	1
linear projection	1
greater or equal performance	1
clustering quality	1
strong mathematical guarantees	1
jointly trainable data distributions	1
geometric properties	1
local clients' data distributions	1
suboptimal results	1
privacy constraints	1
1.44%	1
2.37% and 1.49%	1
80.73% and 40.52%	1
mAP	1
consistency regularization term	1
unlabeled images	1
data and model diversity	1
student model weights	1
temporal model weights	1
stochastic perturbations	1
temporal predictions	1
class imbalance issue	1
upper-bound	1
first experimental results	1
gold standard annotations	1
real-world referents	1
61.7{\%}	1
45.5{\%} Exact Match accuracy	1
close false positives	1
high confidence MRC model predictions	1
+1.6 BLEU	1
average improvement	1
+2.3 BLEU	1
average improvement of +1.1 BLEU	1
8 different translation directions	1
source language transcriptions	1
oncollaborative preferences	1
training window	1
purchase probabilities	1
dense vectorizations	1
customer trajectories	1
purchase data	1
binary purchase data	1
new product descriptions	1
explicitcustomer feedback data	1
https:	1
1-shot and 5-shots settings	1
stand-by semantic knowledge	1
handful of annotations	1
geometric error	1
document's boundaries	1
axis aligned	1
text lines	1
geometric distortions	1
large local variance	1
F1 points on average	1
F1 score points	1
improvements of up to 11	1
generated training data	1
specific relation types	1
E&M domain and 77.97 (2.64 absolute improvement)	1
74.24 (2.23 absolute improvement)	1
GYAFC benchmark's BLEU	1
66.77 and 65.22	1
CoNLL-2014 benchmark's $F_{0.5}$ score and JFLEG Test GLEU score to 62.61 and 63.54	1
GEC	1
model's trust	1
different phases	1
gold training data	1
strong annotation signals	1
previously-addressed memory information	1
sequence of queries	1
evaluative metric	1
univariate time series	1
security concern	1
biophysical trait retrieval	1
slightly better	1
?5%)	1
low levels	1
>20%)	1
poorly (<50%)	1
ANN (<5%)	1
MTN (<3%)	1
<0.05%)	1
added noise	1
water, and dry matter contents	1
Leaf Area Index	1
visible ranges	1
band 2	1
Carotenoid concentrations	1
S2 data	1
increasing noise levels	1
Mean Absolute Percentage Error (MAPE)	1
surrogate data	1
biophysical variables	1
additional inference cost	1
input data instances	1
various views	1
useful representational knowledge	1
actual scale	1
displayspromising results	1
known environment conditions	1
object's pose	1
themotion trajectory	1
conventional trackable feature	1
standard computer vision problems	1
audio or textual data	1
18.87%	1
unimodal scenarios	1
21.08% in terms of accuracy	1
fair comparisons	1
given audio and textual information	1
textual input	1
answers (choices or text spans	1
textual inputs (paragraphs and questions)	1
source of pretraining	1
semi-synthetic	1
thirty minutes	1
NER accuracies	1
less sparse	1
resulting sentence patterns	1
-level patterns	1
virtually no training time	1
constant number	1
strong anomaly detection performance	1
deep pre-trained features	1
Unweighted Average Recall (UAR) performance metric	1
arelative improvement of 11.13% compared	1
various functionals	1
degrees of abnormalities	1
top 10 and 100 ranking documents level	1
2 % -5 % improvement in precision	1
average 10 % -11 % improvement	1
initial ranking documents	1
extracted Global Key Terms	1
Global Key Terms	1
retrieved documents	1
part-of-speech information	1
different problems	1
number of possible alternative analyses	1
certain simplifications	1
